{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/img/20161110143539889.png","path":"img/20161110143539889.png","modified":0,"renderable":0},{"_id":"source/img/20161110144142460.png","path":"img/20161110144142460.png","modified":0,"renderable":0},{"_id":"source/img/20161110143829127.png","path":"img/20161110143829127.png","modified":0,"renderable":0},{"_id":"source/img/20161110144711307.png","path":"img/20161110144711307.png","modified":0,"renderable":0},{"_id":"source/img/20161110145017808.png","path":"img/20161110145017808.png","modified":0,"renderable":0},{"_id":"source/img/20161110153244326.png","path":"img/20161110153244326.png","modified":0,"renderable":0},{"_id":"source/img/20161110145224254.png","path":"img/20161110145224254.png","modified":0,"renderable":0},{"_id":"source/img/gitshiyong.png","path":"img/gitshiyong.png","modified":0,"renderable":0},{"_id":"source/img/20161110145428374.png","path":"img/20161110145428374.png","modified":0,"renderable":0},{"_id":"source/img/jvm.jpg","path":"img/jvm.jpg","modified":0,"renderable":0},{"_id":"source/img/nginx1.png","path":"img/nginx1.png","modified":0,"renderable":0},{"_id":"source/img/nginx11.png","path":"img/nginx11.png","modified":0,"renderable":0},{"_id":"source/img/nginx10.png","path":"img/nginx10.png","modified":0,"renderable":0},{"_id":"source/img/nginx3.png","path":"img/nginx3.png","modified":0,"renderable":0},{"_id":"source/img/nginx2.png","path":"img/nginx2.png","modified":0,"renderable":0},{"_id":"source/img/nginx5.png","path":"img/nginx5.png","modified":0,"renderable":0},{"_id":"source/img/nginx4.png","path":"img/nginx4.png","modified":0,"renderable":0},{"_id":"source/img/nginx6.png","path":"img/nginx6.png","modified":0,"renderable":0},{"_id":"source/img/nginx7.png","path":"img/nginx7.png","modified":0,"renderable":0},{"_id":"source/img/nginx9.png","path":"img/nginx9.png","modified":0,"renderable":0},{"_id":"source/img/nginx8.png","path":"img/nginx8.png","modified":0,"renderable":0},{"_id":"source/img/servlet1.jpeg","path":"img/servlet1.jpeg","modified":0,"renderable":0},{"_id":"themes/yilia/source/main.0cf68a.css","path":"main.0cf68a.css","modified":0,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.js","path":"main.0cf68a.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/mobile.992cbe.js","path":"mobile.992cbe.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/slider.e37972.js","path":"slider.e37972.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":0,"renderable":1}],"Cache":[{"_id":"source/img/20161110144142460.png","hash":"e95dca24d5dbcb877518ba4e7d0fc3dd2dad74ca","modified":1747369525444},{"_id":"source/img/20161110143539889.png","hash":"91fe5b9016805eca6ee524ba68d8617b9495728f","modified":1747369525441},{"_id":"source/img/20161110144711307.png","hash":"0e876ec23b9dc4d21d45d60927621282e19c6fcf","modified":1747369525445},{"_id":"source/img/20161110145428374.png","hash":"84099be25908360557822a8ccbed8924588cb57c","modified":1747369525447},{"_id":"source/img/20161110145017808.png","hash":"6df00eca9ebd6e8459ddcfbb98923dd29f95379e","modified":1747369525445},{"_id":"source/img/20161110153244326.png","hash":"b87241b14475757d0e1ba7d0400499d231751a17","modified":1747369525448},{"_id":"source/img/20161110145224254.png","hash":"5081354be921699bce95c99a67e526955eff875f","modified":1747369525446},{"_id":"source/img/nginx1.png","hash":"1dcdfbbc2b7489fd0eb25a9dc1262a16b000ad83","modified":1747369525452},{"_id":"source/img/gitshiyong.png","hash":"baa6ce16eadbf228f4b25a9dd822001f1bd8cfab","modified":1747369525449},{"_id":"source/img/nginx10.png","hash":"18e959cd21d3b75cc7758ce628c987ab67ef2ab1","modified":1747369525453},{"_id":"source/img/nginx11.png","hash":"c97f64439e4193836a8e4d57611cf7d1bde00d54","modified":1747369525454},{"_id":"source/img/nginx3.png","hash":"4167005b0e09241962e3a5c4256b685b7aab2686","modified":1747369525456},{"_id":"source/img/nginx2.png","hash":"7a54119d4f24a8f84a6fe9d6a78a1888dae0a255","modified":1747369525455},{"_id":"source/img/nginx4.png","hash":"8808b97a14d57ff008dae4d47e2e86c559c235b4","modified":1747369525457},{"_id":"source/img/nginx5.png","hash":"acc189845e7227507af8c738ed88893025280651","modified":1747369525458},{"_id":"source/img/nginx6.png","hash":"8e1f52c520edf31ab3c6098153f4ad697a0aa41d","modified":1747369525459},{"_id":"source/img/nginx7.png","hash":"404e619d6c1594dd9192c9523766dddc94c3e0fd","modified":1747369525460},{"_id":"source/img/nginx8.png","hash":"38ee759e2e0e8255402b2ed6ad9c5c8fa1cd2f75","modified":1747369525461},{"_id":"source/img/nginx9.png","hash":"04c90cc93f3ee6ff775473592f68f1d300c4864f","modified":1747369525462},{"_id":"source/img/servlet1.jpeg","hash":"de35e3600e7b4fe43afcbc1f78bc02927d0d0630","modified":1747369525463},{"_id":"source/_posts/Nginx可以做什么？看完这篇你就懂了.md","hash":"0c7b6490bcfdf0acc45155fb59c32f548ce73915","modified":1747369525416},{"_id":"source/_posts/markdown语法.md","hash":"dccb5c8a2462777615c8bd44569d8e6b7dd83c90","modified":1747385368110},{"_id":"source/_posts/github+hexo博客搭建.md","hash":"60e7cc502f9d2573bf878696a20a48529c979cea","modified":1747369525419},{"_id":"source/_posts/发布的git代码.md","hash":"5512ddc8b20b4dde94fe0aceade180c94fccb38e","modified":1747383251151},{"_id":"source/_posts/使用git上传到coding.md","hash":"ad0913ce3f6861a08d4efdc2e93fd8202721f8cd","modified":1747369525432},{"_id":"source/_posts/android/Android6.0没有权限读取外部存储的问题.md","hash":"37fe4afa54d374dda827bf795de4cdac6ce6fbeb","modified":1747730994716},{"_id":"source/_posts/android/Android基础 -- Activity之间传递数据（bitmap和map对象）.md","hash":"46d178972e3fbd1b239020ccd2d6a7338c3a33aa","modified":1747369525412},{"_id":"source/_posts/android/ZipUtil.md","hash":"9b11ef381a0b239e58a2615e51b38901060d45b3","modified":1747369525417},{"_id":"source/_posts/android/安卓listview嵌套gridview.md","hash":"01954bde989bf27aa8c01c4671dbc5d646aade69","modified":1747369525434},{"_id":"source/_posts/android/安卓抽象布局.md","hash":"680916f057f268f665ad27e1d2acee80c4648481","modified":1747369525436},{"_id":"source/_posts/android/安卓面试经验.md","hash":"fd981e9c137ee47e069fb4bd7acdb1ab42127829","modified":1747369525437},{"_id":"source/_posts/android/安卓四种启动模式.md","hash":"8b3ecdde07a5e4658461f55ec1cc4d4df7cd00a3","modified":1747369525435},{"_id":"source/_posts/h5/video标签.md","hash":"d64c039284aa2fe22a830f82e40aaa31285bbd40","modified":1747369525431},{"_id":"source/_posts/h5/传参数乱码.md","hash":"aa934b211d8be2a1268dd1d2820b986c68ebfada","modified":1747369525431},{"_id":"source/_posts/java/JAVA并发.md","hash":"1b6aa5fbdc37c7664606ec8c56048c7840e78968","modified":1747369525413},{"_id":"source/_posts/android/观察者模式.md","hash":"b5e812cdda2b834111d603ddf140e21c747ceec7","modified":1747369525439},{"_id":"source/_posts/java/MQ机制.md","hash":"269562bdc678fc5407244922248894ddceda8769","modified":1747369525415},{"_id":"source/_posts/java/JVM.md","hash":"71067b80f331c01f249cbcfafbe38f2a6ac9e76c","modified":1747369525414},{"_id":"source/_posts/java/Netty.md","hash":"84c67da5bd6221f5fed72c5ae16a02c7fca36d1c","modified":1747369525415},{"_id":"source/_posts/java/arthas使用.md","hash":"000c5c16bbd215d32f9843e2d477fca22e9bb05d","modified":1747385242387},{"_id":"source/_posts/java/dubbo.md","hash":"8e6ecbf3d7d6abc666152ace523567c2338564f5","modified":1747385237360},{"_id":"source/_posts/java/java.md","hash":"f21c51c7322cbeac71724984ad78b523a1921425","modified":1747369525421},{"_id":"source/_posts/java/hashmap原理.md","hash":"44e2e515ded2ea8dbb37b4477a0743b79b39f1da","modified":1747369525419},{"_id":"source/_posts/java/java切面.md","hash":"282347f2ba89c12d386bd0b52512b91963e905da","modified":1747369525422},{"_id":"source/_posts/java/mybatis源码解析.md","hash":"6584d8b4d10d0419c9849bae4f01726f627aea7f","modified":1747369525423},{"_id":"source/_posts/java/java面试总结.md","hash":"f034c34746450b727242f7bbb73f20e5e1dbf488","modified":1747369525438},{"_id":"source/_posts/java/mysql对比小工具.md","hash":"3617797ac42a671df2b04b5b1c3535c0261661ef","modified":1747369525424},{"_id":"source/_posts/java/redis机制.md","hash":"1c66b66a961693903eb9440509c66355d66a3953","modified":1747383244832},{"_id":"source/_posts/java/mysql机制.md","hash":"fbd08cd6f844926149531fce70c532c53136c0a7","modified":1747369525425},{"_id":"source/_posts/java/servlet.md","hash":"40c315d192998872c38dee561041a8ca604c9b3e","modified":1747369525428},{"_id":"source/_posts/java/springcloud.md","hash":"3a793cdedbdff7759bc217c4b55e8f9ae462367d","modified":1747369525429},{"_id":"source/_posts/java/线程池.md","hash":"02fa72ce3e88784feb02ee663d952270d7da508b","modified":1747369525439},{"_id":"source/_posts/java/锁.md","hash":"e46f4db6fc8bcca168414995d883bc4eedce2ac1","modified":1747379659615},{"_id":"source/img/20161110143829127.png","hash":"5d03e334881a1b59805f42b287adfca9f7850daf","modified":1747369525443},{"_id":"source/img/jvm.jpg","hash":"cb08e36ace8dab89628c8ea0148a80758be9fe88","modified":1747369525451},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1747378762684},{"_id":"themes/yilia/.editorconfig","hash":"daaa8757fac18f8735fadd0a37a42c06f421ca14","modified":1747378762658},{"_id":"themes/yilia/.eslintrc.js","hash":"303d25adf02ad65720e537a16a4a137d14bb755f","modified":1747378762659},{"_id":"themes/yilia/.babelrc","hash":"db600d40e93e6d8023737a65d58d3be7370e5e30","modified":1747378762657},{"_id":"themes/yilia/.eslintignore","hash":"ed9d8911ca08c3dd5072c48dd0be4d06f8897730","modified":1747378762659},{"_id":"themes/yilia/.gitattributes","hash":"758cfbecfa7919e99abddf3297f37cde7e3d8d4e","modified":1747378762660},{"_id":"themes/yilia/.gitignore","hash":"d5fc575329853ff620b50fc62ad4b18fa09a308a","modified":1747378762661},{"_id":"themes/yilia/README.md","hash":"1bf755806af9d8874bd22e1abbdaaa24328ef4dc","modified":1747378762661},{"_id":"themes/yilia/package.json","hash":"ee6aa61f1cb89fd549e3e087c0232207a9c9ee30","modified":1747378762691},{"_id":"themes/yilia/_config.yml","hash":"67dbb34e7839a5822f13b23459d5e93dfb9ea50f","modified":1747386020927},{"_id":"themes/yilia/languages/fr.yml","hash":"b4be1c1592a72012e48df2b3ec41cc9685573e50","modified":1747378762663},{"_id":"themes/yilia/webpack.config.js","hash":"da7657347109ddb4ab8602b219778117254677fe","modified":1747378762746},{"_id":"themes/yilia/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1747378762664},{"_id":"themes/yilia/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1747378762663},{"_id":"themes/yilia/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1747378762665},{"_id":"themes/yilia/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1747378762665},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1747378762667},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1747378762666},{"_id":"themes/yilia/source/slider.e37972.js","hash":"ce5eac88301fe4f2fce0fb6203adfd58eb8313ac","modified":1747378762745},{"_id":"themes/yilia/source/main.0cf68a.css","hash":"ddf6e2c6b953c2c59a3c271e6070010a4cc81cf9","modified":1747378762741},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1747378762686},{"_id":"themes/yilia/layout/layout.ejs","hash":"b471ab706d48e0be3f783eab1c94bf5878ef5a94","modified":1747378762688},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1747378762690},{"_id":"themes/yilia/layout/index.ejs","hash":"ec498c6c0606acde997ce195dad97b267418d980","modified":1747378762687},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1747378762687},{"_id":"themes/yilia/source-src/css.ejs","hash":"cf7eab48d626433120d1ef9697f719a359817018","modified":1747378762692},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1747378762690},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1747378762689},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1747378762733},{"_id":"themes/yilia/source-src/script.ejs","hash":"28abac2426761d7e715b38aadd86ce6549c8ae77","modified":1747378762732},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1747378762736},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1747378762734},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1747378762735},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1747378762737},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1747378762739},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1747378762738},{"_id":"themes/yilia/source/img/avatar.jpg","hash":"2a0a1bb0818c0b48314ee76ea82666e6c4bb25e0","modified":1747385668074},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1747378762739},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a4eacc2bc1278095a0ef99f904b0634c78f980eb","modified":1747378762669},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"edc0154b30a4127acda10297bec6aacf754b4ac4","modified":1747378762668},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1747378762740},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"8dea8f5f93a60185439b330b0f1d1649a6ab4bd0","modified":1747378762669},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"c70f367f54064a441e574c913f5e0ea121d0f899","modified":1747378762667},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"155327c23607f69989b58845f24d842a54e504b8","modified":1747378762671},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"751e5deab5365348be5243688b419c82d337ab9a","modified":1747378762670},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"871f81cacd5d41cb2eb001cd56254217a857dc2f","modified":1747378762672},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1747378762673},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"236f8a377b2e4e35754319c3029bcd4a4115431d","modified":1747378762671},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"b69855e07b65117769adc515cb64b803932068c9","modified":1747378762674},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"12ca7d8dba56bc767b9309dda9526dcbaffc1614","modified":1747378762673},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"fb1b8457b9eb15b55da1bf7b133e12c375dd26f8","modified":1747378762674},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"ccec1fc70f021cb50ac85b524e7949878ab93a18","modified":1747378762676},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"11550a418921d330e6553be0569a94ab5a217967","modified":1747378762675},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"0ffcb251b79e8a920c9b4cb6bb7a96a808816165","modified":1747378762685},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"cc1c39903aed0a0601d104238d2bbd13ad2a36f3","modified":1747378762685},{"_id":"themes/yilia/source-src/js/anm.js","hash":"d18f6276a352b871390a4112d479b9e58b8cdbbe","modified":1747378762724},{"_id":"themes/yilia/source-src/js/aside.js","hash":"5e4c3c3d61f1e1ce2f09688d3aff25fadc851fff","modified":1747378762725},{"_id":"themes/yilia/source-src/js/browser.js","hash":"4dc04845cf27f350922b63f1813a9c82e6e33b05","modified":1747378762725},{"_id":"themes/yilia/source-src/js/fix.js","hash":"67b8819abb886c9d066fb3b0624ca15e06f63fe0","modified":1747378762726},{"_id":"themes/yilia/source-src/js/Q.js","hash":"e56d9710afa79b31ca6b9fbd845f6d1895f5214b","modified":1747378762723},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"461c08ffcbc724d74ec7e0ff38e171eefe0f89fd","modified":1747378762728},{"_id":"themes/yilia/source-src/js/slider.js","hash":"0beaa112657ad57c723d9e773d5b79de60c1dd74","modified":1747378762730},{"_id":"themes/yilia/source-src/js/main.js","hash":"fe98bf90ce61658fe16ae057f8b6a512a845af3b","modified":1747378762727},{"_id":"themes/yilia/source-src/js/report.js","hash":"57680f9a23bd0a1eaafd64ae08cc33e20627ab15","modified":1747378762728},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"29ba600e98ed55f7af4ade8038272c84cba21188","modified":1747378762693},{"_id":"themes/yilia/source-src/js/share.js","hash":"d4ccff8266c37363b3904226f5d035b7db882c61","modified":1747378762729},{"_id":"themes/yilia/source-src/js/util.js","hash":"3bcdeb95072b85600874424e6929e3e22cfddaa0","modified":1747378762731},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"c699cf3c89409ec8f044258e0715a470861b5d5d","modified":1747378762731},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"ce227b6f5a9af194fd5d455200630f32c05e151f","modified":1747378762693},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"8f82fe898ba1c1bd00c24a7d8270feddc7eba3bc","modified":1747378762696},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"d6a7dd88404b383b5b94e4c7ec675a410c41f3cc","modified":1747378762694},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"1577a2336b3ad122f49f60dff2bc1a97d4e7b18b","modified":1747378762695},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"f7388f5c11370ef462f7cb913d8f72edf24ecaf9","modified":1747378762695},{"_id":"themes/yilia/source-src/css/article.scss","hash":"55d082fec4c6bb341725567acaa29ce37d50320a","modified":1747378762697},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"07244c188f58ecfb90bb7c047b8cde977f1dc4b4","modified":1747378762697},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"b85f344f2c66d43d7094746e0a9ccb21d0534201","modified":1747378762698},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7ca837a4cc34db1c35f01baec85eb10ccc64ea86","modified":1747378762707},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"96d7eb1d42c06fdcccb8ef969f6ecd30c3194903","modified":1747378762703},{"_id":"themes/yilia/source-src/css/left.scss","hash":"80dac621e43581a254d0152d5df901e4d0b01c09","modified":1747378762713},{"_id":"themes/yilia/source-src/css/global.scss","hash":"b4cb4f45a55d4250cd9056f76dab2a3c0dabcec4","modified":1747378762708},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"f53ea8270752b5919ec5d79224d22af91f2eda12","modified":1747378762709},{"_id":"themes/yilia/source-src/css/main.scss","hash":"9eba1fcf4805256697528fcf3b767cf6dd8d0591","modified":1747378762713},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"40e5aa5056dc0b3b9f51c5b387370b612e265d4e","modified":1747378762710},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"d995dcd483a250fe61b426158afb61bf8923a927","modified":1747378762715},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"19f10fd2f0c3377aa4b165b3c2291ecf86dd9351","modified":1747378762714},{"_id":"themes/yilia/source-src/css/page.scss","hash":"244c4d75c375978ff9edb74acc68825e63c6b235","modified":1747378762716},{"_id":"themes/yilia/source-src/css/share.scss","hash":"9d6f6884f40c191882e56a1e1e1192400944a515","modified":1747378762718},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"2495f7e4e3b055735c531f944b5f40a118a351ec","modified":1747378762718},{"_id":"themes/yilia/source-src/css/social.scss","hash":"a10a038a1dac8953cb4ffc7e04272eff9fac54e4","modified":1747378762719},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"a557a9ed244c82b8b71e9da9de3339d92783499f","modified":1747378762717},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"399744e98e7c67939ed9b23c2670d8baad044eda","modified":1747378762720},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"2924fb6f77c4a9973cd928c2c7db0acb848ed483","modified":1747378762721},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"b81cedbe31accca82e597801186911a7b5e6841c","modified":1747378762722},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"915c93edd67c5326695cc7dc84b14c5f154dbcc8","modified":1747378762721},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"aae96de18d48cd3b9b7bf6fed0100e15b53cca97","modified":1747378762678},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"e777cbf959b11c4dfda649c562799899b90ab4a3","modified":1747378762677},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"b6a97043f9ec37e571aacacfedcda1d4d75e3c7c","modified":1747378762680},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"345b262e3c3b75c0cd9a93d9ecabcf06e33e54ff","modified":1747378762680},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"086c8a88fd3bcae7ec13258df58e25d6354af2fa","modified":1747378762677},{"_id":"themes/yilia/layout/_partial/post/gitment.ejs","hash":"25655016773aa5d0774c56115ae1736a9fc9ea1f","modified":1747378762679},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1747378762682},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"f6b4c4eaafb5ac386273354b5f64a26139b7a3b0","modified":1747378762678},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"fb022502c741b4a26bad6b2ad37245c10ede3f1a","modified":1747378762682},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2c4e4ca36c9bb4318506c38aca7127f1f44d827f","modified":1747378762681},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1747378762711},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1747378762710},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1747378762712},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1747378762704},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1747378762706},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1747378762707},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1747378762705},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"91db061c9c17628291a005e5bd4936cf9d35a6c4","modified":1747378762700},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"262ffcd88775080b7f511db37f58d2bcb1b2bfc7","modified":1747378762700},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"1834c3ed8560716e63bb3a50be94cac87fbbeaf3","modified":1747378762699},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"6e75bdaa46de83094ba0873099c6e7d656a22453","modified":1747378762702},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"398a49913b4a47d928103562b1ce94520be4026a","modified":1747378762701},{"_id":"themes/yilia/source/main.0cf68a.js","hash":"283ae27ea37ac3e0e45b2e05c2482a4c594b9c25","modified":1747378762742},{"_id":"themes/yilia/source/mobile.992cbe.js","hash":"1801ef448909ea23c0a48e9d63b80d0cfd5534ce","modified":1747378762744},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"e98ec0b3b56f14d1d79af99ceb42727719a584f3","modified":1747378762684},{"_id":"public/2025/05/16/java/arthas使用/index.html","hash":"f465298322a13ac655beb8a29ac9ed880fa76a14","modified":1747731356767},{"_id":"public/2025/05/16/markdown语法/index.html","hash":"2ec88bfadd353f9cef84dcf99b7c206ba188fb50","modified":1747731356767},{"_id":"public/2021/01/20/java/JAVA并发/index.html","hash":"3ef890e198f3d85f5d75a1ad101f59b89b5f8473","modified":1747731356767},{"_id":"public/2021/01/13/java/springcloud/index.html","hash":"1aa977e1239c0cbc30c277051b02285db76a743f","modified":1747731356767},{"_id":"public/2021/01/12/java/Netty/index.html","hash":"739e082aecec88ef95c5bb1898ba34cda2cdafaa","modified":1747731356767},{"_id":"public/2021/01/09/java/mybatis源码解析/index.html","hash":"c7455e155b57015538869f32d6f9ada515b089ef","modified":1747731356767},{"_id":"public/2021/01/07/java/java面试总结/index.html","hash":"361c414f7eb9847c43e0a232e9a863d74e53f63b","modified":1747731356767},{"_id":"public/2020/11/26/java/java切面/index.html","hash":"1ddd7e9b5906b149fb8018e08234722f132da9f6","modified":1747731356767},{"_id":"public/2020/11/26/java/线程池/index.html","hash":"59c2489851ab98e308142e1e0beb6d428c000610","modified":1747731356767},{"_id":"public/2020/04/22/java/锁/index.html","hash":"1b5d2569bde5f7223e190f83f054a2ac258722d5","modified":1747731356767},{"_id":"public/2020/04/01/java/JVM/index.html","hash":"70202322c9286c71be0247741e96e7c0660a0b55","modified":1747731356767},{"_id":"public/2020/04/01/java/dubbo/index.html","hash":"7220341400dbd69127e1be4999b610801d680b7c","modified":1747731356767},{"_id":"public/2020/04/01/java/java/index.html","hash":"27fb7fe9795e86e15518d72d136e7f446e8f7ab3","modified":1747731356767},{"_id":"public/2020/03/27/java/hashmap原理/index.html","hash":"6eec769bfa8be52da547f9a46adc5c5784ea2122","modified":1747731356767},{"_id":"public/2020/03/27/java/mysql对比小工具/index.html","hash":"e96474eac9c9372fefa16b2df43b83a034203d65","modified":1747731356767},{"_id":"public/2020/03/27/java/servlet/index.html","hash":"4b5cea9e782094b30e4726a9b2b056812372b354","modified":1747731356767},{"_id":"public/2020/03/21/java/mysql机制/index.html","hash":"00844e1231540a10d7e76e4f3bb5287fab371b39","modified":1747731356767},{"_id":"public/2020/03/17/Nginx可以做什么？看完这篇你就懂了/index.html","hash":"385b65613407a33da914d1c7ff0b6b95320e9c35","modified":1747731356767},{"_id":"public/2020/03/17/java/MQ机制/index.html","hash":"81d6a50bda0d975c8a0e18cc8aa156aa3e182dd0","modified":1747731356767},{"_id":"public/2020/03/17/java/redis机制/index.html","hash":"fe04e8537296f3c8bbddcc89f7c8efc1f81911c4","modified":1747731356767},{"_id":"public/2020/03/10/github+hexo博客搭建/index.html","hash":"529fe2d86c4822b64ad66b5719d9c9c71aafcd52","modified":1747731356767},{"_id":"public/2019/03/17/使用git上传到coding/index.html","hash":"94c47a939a73b4031be3f9ae5997c3cf6a59faff","modified":1747731356767},{"_id":"public/2017/07/13/发布的git代码/index.html","hash":"fdd92c16abc1dd7b441f98a527a62d980abaa2b7","modified":1747731356767},{"_id":"public/2017/07/13/android/安卓listview嵌套gridview/index.html","hash":"1711d4bb73bfba10f03d8036e7569dece2b26596","modified":1747731356767},{"_id":"public/2017/03/02/android/安卓抽象布局/index.html","hash":"f5c13959ac1773f8493d8cbff10057691f74d2a9","modified":1747731356767},{"_id":"public/2017/01/16/android/安卓四种启动模式/index.html","hash":"6f5b15245a0ebf583e3aabbac3c00638bbd03b63","modified":1747731356767},{"_id":"public/2017/01/16/android/观察者模式/index.html","hash":"9b5b67960150b89fc9f1d9b115318beedaefab9f","modified":1747731356767},{"_id":"public/2016/12/23/android/Android基础 -- Activity之间传递数据（bitmap和map对象）/index.html","hash":"3e413cff343f6e69db0f459052ce2b1c3f512a29","modified":1747731356767},{"_id":"public/2016/12/23/android/安卓面试经验/index.html","hash":"fdb03f6295ce5e4e2cd8e2bfb8700e3d5e5938d1","modified":1747731356767},{"_id":"public/2016/12/23/android/Android6.0没有权限读取外部存储的问题/index.html","hash":"658e9b712702bd08ec111efc1b101afd65128e4b","modified":1747731356767},{"_id":"public/2016/12/23/android/ZipUtil/index.html","hash":"b207f1806e4c42b799b43c749a97d2348d8cfa00","modified":1747731356767},{"_id":"public/2016/12/23/h5/video标签/index.html","hash":"60b8df3bc77bd18ef0e13e9ba824d4d3759ed2f2","modified":1747731356767},{"_id":"public/2016/12/23/h5/传参数乱码/index.html","hash":"86352e637d41aac1e13c604ec41d385d3dbe376c","modified":1747731356767},{"_id":"public/archives/index.html","hash":"d7872533219c23066dea1b9bc213e26bfbf9de45","modified":1747731356767},{"_id":"public/archives/page/2/index.html","hash":"8b155411f8e794f8924cf49c915d95501ab830d3","modified":1747731356767},{"_id":"public/archives/page/3/index.html","hash":"e0c330a2f9b2a3d4e41542a9a1a15a5d15f33abb","modified":1747731356767},{"_id":"public/archives/page/4/index.html","hash":"f4f8c8cfc17eb0a79c03338d3806490512dbeb1b","modified":1747731356767},{"_id":"public/archives/2016/index.html","hash":"343c34d72e262cab8a04a2b6300434dc42ae9bdc","modified":1747731356767},{"_id":"public/archives/2016/12/index.html","hash":"24cfa2e820e96fa8a0e0901caf021f2aa1bbee7a","modified":1747731356767},{"_id":"public/archives/2017/index.html","hash":"b5058415d1fa8d6f25c1b44dcfbeee3ac9ef4815","modified":1747731356767},{"_id":"public/archives/2017/01/index.html","hash":"646fbf25d498c9ddc72390ce54ee90b2026446d0","modified":1747731356767},{"_id":"public/archives/2017/03/index.html","hash":"aa25dfdc997e3510504c0ef0cada4a726af96471","modified":1747731356767},{"_id":"public/archives/2017/07/index.html","hash":"4152bda63c6b64a394b5e70a9954a821a2ba3927","modified":1747731356767},{"_id":"public/archives/2019/index.html","hash":"6d035c10a37bbad7c1b82f8366ce39f34768ef12","modified":1747731356767},{"_id":"public/archives/2019/03/index.html","hash":"1ece8ddbd374df359351f1e4f0d5f51d35c8dfb8","modified":1747731356767},{"_id":"public/archives/2020/index.html","hash":"b796ae4b39197ecce825f64302906da3104749b7","modified":1747731356767},{"_id":"public/archives/2020/page/2/index.html","hash":"48a3fdb6c7c251f8375963536722242f280b9e2a","modified":1747731356767},{"_id":"public/archives/2020/03/index.html","hash":"7d4161e4df217f18772c50a131927979945be1e8","modified":1747731356767},{"_id":"public/archives/2020/04/index.html","hash":"86aebefb632b3fe6378eb01b3decc0bf50560a09","modified":1747731356767},{"_id":"public/archives/2020/11/index.html","hash":"f76746cb36a132ec36c1900d64ca8ba66916083d","modified":1747731356767},{"_id":"public/archives/2021/index.html","hash":"2d7bbad4c1f9944f640b190cc5d71a2cfd50730d","modified":1747731356767},{"_id":"public/archives/2021/01/index.html","hash":"37c75fae8cc07015eba13a9641e562e373f0280b","modified":1747731356767},{"_id":"public/archives/2025/index.html","hash":"6872f31d4338abd1b7a35ac9a3321bca7f04ae79","modified":1747731356767},{"_id":"public/archives/2025/05/index.html","hash":"2e1c827ad5d06e6787a37a343a7f0ce0061eadc8","modified":1747731356767},{"_id":"public/index.html","hash":"2e00d963831abb0648e7895cdc311a9db574f918","modified":1747731356767},{"_id":"public/page/2/index.html","hash":"727216a324b5e0fb9099f0615c7561cf185c878b","modified":1747731356767},{"_id":"public/page/4/index.html","hash":"1562f40bf872c071136f52e45cdee5a009be1e66","modified":1747731356767},{"_id":"public/page/3/index.html","hash":"0376e2e5c7bcac8e384edce7efc01627b06ee573","modified":1747731356767},{"_id":"public/categories/安卓/index.html","hash":"b16c72a35bfe6e2c98e98423821b7d7b0522d358","modified":1747731356767},{"_id":"public/categories/日志/index.html","hash":"799d0d896a9202991290efbf05816568a884cefd","modified":1747731356767},{"_id":"public/tags/其他/index.html","hash":"f844f8421ac1d09666b8e4aa1f26cf14cc6170e6","modified":1747731356767},{"_id":"public/tags/nginx/index.html","hash":"1bf2191aebde9a161b07095967e427792c511b2f","modified":1747731356767},{"_id":"public/tags/Android/index.html","hash":"060cfe4a62124fd32620ff56ce3026d677f31453","modified":1747731356767},{"_id":"public/tags/安卓/index.html","hash":"6e8d4566ba467cd1aa67ac2be6610bb138bb35c8","modified":1747731356767},{"_id":"public/tags/H5/index.html","hash":"3dfd31ae878fc46c6e2eaff7a49633eb730b8ec7","modified":1747731356767},{"_id":"public/tags/java/index.html","hash":"b6acc023d54aa777a2dc5bdc3cec20f90b92e253","modified":1747731356767},{"_id":"public/tags/JAVA/index.html","hash":"da91fd04ea63f1d1ce2e201f08bebd931ca6f741","modified":1747731356767},{"_id":"public/tags/JAVA/page/2/index.html","hash":"81b989b58867406677b648875f406ea9a8010742","modified":1747731356767},{"_id":"public/tags/MQ/index.html","hash":"a7065b8fea0e37598d3a08429afd583d3a12be24","modified":1747731356767},{"_id":"public/tags/arthas/index.html","hash":"9b628c9a61c3f943829c45aabd95a16c4134f49a","modified":1747731356767},{"_id":"public/tags/hashmap/index.html","hash":"761752cf40315bd4541dead71e1e55f65a6ba142","modified":1747731356767},{"_id":"public/tags/mysql/index.html","hash":"9db6df466fd5ce2b805187f8ad6ebbfb3ee55e90","modified":1747731356767},{"_id":"public/tags/mybatis/index.html","hash":"e3d2780c9f71966d77a06d970399bf016b870f82","modified":1747731356767},{"_id":"public/tags/servlet/index.html","hash":"8ab796a76bfaebb65de9e46d97d12d41edeaccfc","modified":1747731356767},{"_id":"public/tags/redis/index.html","hash":"2ced216efefd76b63ab2445ef60994fe67e5aa60","modified":1747731356767},{"_id":"public/tags/锁/index.html","hash":"d5bc1b4c232f3a833a36a886b92988a09e32fd4f","modified":1747731356767},{"_id":"public/img/20161110144142460.png","hash":"e95dca24d5dbcb877518ba4e7d0fc3dd2dad74ca","modified":1747731356767},{"_id":"public/img/20161110143539889.png","hash":"91fe5b9016805eca6ee524ba68d8617b9495728f","modified":1747731356767},{"_id":"public/img/20161110144711307.png","hash":"0e876ec23b9dc4d21d45d60927621282e19c6fcf","modified":1747731356767},{"_id":"public/img/20161110153244326.png","hash":"b87241b14475757d0e1ba7d0400499d231751a17","modified":1747731356767},{"_id":"public/img/20161110145017808.png","hash":"6df00eca9ebd6e8459ddcfbb98923dd29f95379e","modified":1747731356767},{"_id":"public/img/20161110145224254.png","hash":"5081354be921699bce95c99a67e526955eff875f","modified":1747731356767},{"_id":"public/img/gitshiyong.png","hash":"baa6ce16eadbf228f4b25a9dd822001f1bd8cfab","modified":1747731356767},{"_id":"public/img/20161110145428374.png","hash":"84099be25908360557822a8ccbed8924588cb57c","modified":1747731356767},{"_id":"public/img/nginx10.png","hash":"18e959cd21d3b75cc7758ce628c987ab67ef2ab1","modified":1747731356767},{"_id":"public/img/nginx1.png","hash":"1dcdfbbc2b7489fd0eb25a9dc1262a16b000ad83","modified":1747731356767},{"_id":"public/img/nginx11.png","hash":"c97f64439e4193836a8e4d57611cf7d1bde00d54","modified":1747731356767},{"_id":"public/img/nginx5.png","hash":"acc189845e7227507af8c738ed88893025280651","modified":1747731356767},{"_id":"public/img/nginx3.png","hash":"4167005b0e09241962e3a5c4256b685b7aab2686","modified":1747731356767},{"_id":"public/img/nginx2.png","hash":"7a54119d4f24a8f84a6fe9d6a78a1888dae0a255","modified":1747731356767},{"_id":"public/img/nginx6.png","hash":"8e1f52c520edf31ab3c6098153f4ad697a0aa41d","modified":1747731356767},{"_id":"public/img/nginx9.png","hash":"04c90cc93f3ee6ff775473592f68f1d300c4864f","modified":1747731356767},{"_id":"public/img/nginx8.png","hash":"38ee759e2e0e8255402b2ed6ad9c5c8fa1cd2f75","modified":1747731356767},{"_id":"public/img/nginx7.png","hash":"404e619d6c1594dd9192c9523766dddc94c3e0fd","modified":1747731356767},{"_id":"public/img/nginx4.png","hash":"8808b97a14d57ff008dae4d47e2e86c559c235b4","modified":1747731356767},{"_id":"public/img/servlet1.jpeg","hash":"de35e3600e7b4fe43afcbc1f78bc02927d0d0630","modified":1747731356767},{"_id":"public/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1747731356767},{"_id":"public/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1747731356767},{"_id":"public/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1747731356767},{"_id":"public/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1747731356767},{"_id":"public/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1747731356767},{"_id":"public/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1747731356767},{"_id":"public/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1747731356767},{"_id":"public/img/avatar.jpg","hash":"2a0a1bb0818c0b48314ee76ea82666e6c4bb25e0","modified":1747731356767},{"_id":"public/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1747731356767},{"_id":"public/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1747731356767},{"_id":"public/main.0cf68a.css","hash":"ddf6e2c6b953c2c59a3c271e6070010a4cc81cf9","modified":1747731356767},{"_id":"public/img/20161110143829127.png","hash":"5d03e334881a1b59805f42b287adfca9f7850daf","modified":1747731356767},{"_id":"public/slider.e37972.js","hash":"6dec4e220c89049037eebc44404abd8455d22ad7","modified":1747731356767},{"_id":"public/main.0cf68a.js","hash":"993fadeb5f6d296e9d997a49ee20dc97333ceab7","modified":1747731356767},{"_id":"public/mobile.992cbe.js","hash":"01b35e71e37aa2849664eb5daf26daede2278398","modified":1747731356767},{"_id":"public/img/jvm.jpg","hash":"cb08e36ace8dab89628c8ea0148a80758be9fe88","modified":1747731356767}],"Category":[{"name":"安卓","_id":"cmawa4jrj000eskqrepc09exr"},{"name":"日志","_id":"cmawa4jrq000oskqr84oi8e19"}],"Data":[],"Page":[],"Post":[{"date":"2020-03-10T03:35:00.000Z","title":"github + hexo 博客搭建","_content":"\n摘要:github + hexo 博客搭建 \n<!--more-->\n看小茗同学的博客就可以了\nhttps://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\n\ngitee+ hexo博客搭建\nhttps://segmentfault.com/a/1190000016083265","source":"_posts/github+hexo博客搭建.md","raw":"---\ndate: 2020-03-10 11:35\ntitle: github + hexo 博客搭建\ntags:\n  - 其他\n---\n\n摘要:github + hexo 博客搭建 \n<!--more-->\n看小茗同学的博客就可以了\nhttps://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\n\ngitee+ hexo博客搭建\nhttps://segmentfault.com/a/1190000016083265","slug":"github+hexo博客搭建","published":1,"updated":"2025-05-16T04:25:25.419Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jqx0000skqrgxq7gp4h","content":"<p>摘要:github + hexo 博客搭建 </p>\n<span id=\"more\"></span>\n<p>看小茗同学的博客就可以了<br><a href=\"https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\">https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a></p>\n<p>gitee+ hexo博客搭建<br><a href=\"https://segmentfault.com/a/1190000016083265\">https://segmentfault.com/a/1190000016083265</a></p>\n","site":{"data":{}},"excerpt":"<p>摘要:github + hexo 博客搭建 </p>","more":"<p>看小茗同学的博客就可以了<br><a href=\"https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\">https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a></p>\n<p>gitee+ hexo博客搭建<br><a href=\"https://segmentfault.com/a/1190000016083265\">https://segmentfault.com/a/1190000016083265</a></p>"},{"date":"2019-03-16T16:00:00.000Z","title":"使用 Git上传代码到coding.net代码仓库详解","_content":"\n摘要:使用 Git上传代码到coding.net代码仓库详解\n<!--more-->\n\n1.创建本地代码库\n\n在本地创建一个文件夹，作为你上传代码的本地仓库，接下来就要把这个仓库与coding服务器端进行配置\n\n在这个文件夹内点击右键，选择Git Bash Here，首先要初始化本地仓库，输入”git init”命令\n\n![avatar](/img/20161110143539889.png)\n\n接下来进行远程代码库克隆（前提：自行在coding中建立一个项目，空项目即可），输入”git clone https：//xxxxxx”命令，命令中的url获取方式如图： \n![avatar](/img/20161110143829127.png)\n\n左下角HHTPS处即为要输入的url\n\n将这个url粘贴到命令中，进行远程仓库的克隆，克隆时会出现输入账号密码的环节（coding注册时的账号和密码） \n![avatar](/img/20161110144142460.png)\n\n输入账号密码之后便可以完成克隆。\n\n2.代码推送\n\n克隆之后在原来的文件夹中会多出一个文件夹（即从代码库中下载的文件夹），例如 \n![avatar](/img/20161110144711307.png)\n\n这时候，本地仓库的配置就完成了，将要上传的代码文件放入这个文件夹中，接下来要查看一下本地仓库的状态，一检查配置是否成功，进而进行代码的推送，输入命令”git status”\n\n例如放入了一个“stringKMP.c”文件之后输入命令”git status”\n\n![avatar](/img/20161110145017808.png)\n\n\n\n输入git status命令后，会发现以红色字体打印出来的“stringKMP.c”，说明该文件存在于本地仓库，但并未推送到云端， 接下来，输入”git add 文件名”命令，可以再输入命令”git status”进行状态检查，如下\n![avatar](/img/20161110145224254.png)\n\n\n会发现出现了“new file”。\n\n接下来， 输入”git commit -m “代码备注随便写” “命令提交\n\n然后输入”git push origin master”命令推送到云端，origin是服务器，master是分枝。\n![avatar](/img/20161110145428374.png)\n\n\n一切结束后，输入”git status”查看本地代码状态，会用绿字显示，表示上传成功，进入coding.Net的项目主页，你会发现自己在本地推送的代码已经出现在项目中。\n![avatar](/img/20161110153244326.png)\n\n以上就是使用Git上传代码到coding的流程，希望对大家有所帮助。\n\n再补充一个可以上传git到github的图片\n![avatar](/img/gitshiyong.png)\n","source":"_posts/使用git上传到coding.md","raw":"---\ndate: 2019-03-17\ntitle: 使用 Git上传代码到coding.net代码仓库详解\ntags:\n  - 其他\n---\n\n摘要:使用 Git上传代码到coding.net代码仓库详解\n<!--more-->\n\n1.创建本地代码库\n\n在本地创建一个文件夹，作为你上传代码的本地仓库，接下来就要把这个仓库与coding服务器端进行配置\n\n在这个文件夹内点击右键，选择Git Bash Here，首先要初始化本地仓库，输入”git init”命令\n\n![avatar](/img/20161110143539889.png)\n\n接下来进行远程代码库克隆（前提：自行在coding中建立一个项目，空项目即可），输入”git clone https：//xxxxxx”命令，命令中的url获取方式如图： \n![avatar](/img/20161110143829127.png)\n\n左下角HHTPS处即为要输入的url\n\n将这个url粘贴到命令中，进行远程仓库的克隆，克隆时会出现输入账号密码的环节（coding注册时的账号和密码） \n![avatar](/img/20161110144142460.png)\n\n输入账号密码之后便可以完成克隆。\n\n2.代码推送\n\n克隆之后在原来的文件夹中会多出一个文件夹（即从代码库中下载的文件夹），例如 \n![avatar](/img/20161110144711307.png)\n\n这时候，本地仓库的配置就完成了，将要上传的代码文件放入这个文件夹中，接下来要查看一下本地仓库的状态，一检查配置是否成功，进而进行代码的推送，输入命令”git status”\n\n例如放入了一个“stringKMP.c”文件之后输入命令”git status”\n\n![avatar](/img/20161110145017808.png)\n\n\n\n输入git status命令后，会发现以红色字体打印出来的“stringKMP.c”，说明该文件存在于本地仓库，但并未推送到云端， 接下来，输入”git add 文件名”命令，可以再输入命令”git status”进行状态检查，如下\n![avatar](/img/20161110145224254.png)\n\n\n会发现出现了“new file”。\n\n接下来， 输入”git commit -m “代码备注随便写” “命令提交\n\n然后输入”git push origin master”命令推送到云端，origin是服务器，master是分枝。\n![avatar](/img/20161110145428374.png)\n\n\n一切结束后，输入”git status”查看本地代码状态，会用绿字显示，表示上传成功，进入coding.Net的项目主页，你会发现自己在本地推送的代码已经出现在项目中。\n![avatar](/img/20161110153244326.png)\n\n以上就是使用Git上传代码到coding的流程，希望对大家有所帮助。\n\n再补充一个可以上传git到github的图片\n![avatar](/img/gitshiyong.png)\n","slug":"使用git上传到coding","published":1,"updated":"2025-05-16T04:25:25.432Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jr50001skqrgo3324ih","content":"<p>摘要:使用 Git上传代码到coding.net代码仓库详解</p>\n<span id=\"more\"></span>\n\n<p>1.创建本地代码库</p>\n<p>在本地创建一个文件夹，作为你上传代码的本地仓库，接下来就要把这个仓库与coding服务器端进行配置</p>\n<p>在这个文件夹内点击右键，选择Git Bash Here，首先要初始化本地仓库，输入”git init”命令</p>\n<p><img src=\"/img/20161110143539889.png\" alt=\"avatar\"></p>\n<p>接下来进行远程代码库克隆（前提：自行在coding中建立一个项目，空项目即可），输入”git clone https：//xxxxxx”命令，命令中的url获取方式如图：<br><img src=\"/img/20161110143829127.png\" alt=\"avatar\"></p>\n<p>左下角HHTPS处即为要输入的url</p>\n<p>将这个url粘贴到命令中，进行远程仓库的克隆，克隆时会出现输入账号密码的环节（coding注册时的账号和密码）<br><img src=\"/img/20161110144142460.png\" alt=\"avatar\"></p>\n<p>输入账号密码之后便可以完成克隆。</p>\n<p>2.代码推送</p>\n<p>克隆之后在原来的文件夹中会多出一个文件夹（即从代码库中下载的文件夹），例如<br><img src=\"/img/20161110144711307.png\" alt=\"avatar\"></p>\n<p>这时候，本地仓库的配置就完成了，将要上传的代码文件放入这个文件夹中，接下来要查看一下本地仓库的状态，一检查配置是否成功，进而进行代码的推送，输入命令”git status”</p>\n<p>例如放入了一个“stringKMP.c”文件之后输入命令”git status”</p>\n<p><img src=\"/img/20161110145017808.png\" alt=\"avatar\"></p>\n<p>输入git status命令后，会发现以红色字体打印出来的“stringKMP.c”，说明该文件存在于本地仓库，但并未推送到云端， 接下来，输入”git add 文件名”命令，可以再输入命令”git status”进行状态检查，如下<br><img src=\"/img/20161110145224254.png\" alt=\"avatar\"></p>\n<p>会发现出现了“new file”。</p>\n<p>接下来， 输入”git commit -m “代码备注随便写” “命令提交</p>\n<p>然后输入”git push origin master”命令推送到云端，origin是服务器，master是分枝。<br><img src=\"/img/20161110145428374.png\" alt=\"avatar\"></p>\n<p>一切结束后，输入”git status”查看本地代码状态，会用绿字显示，表示上传成功，进入coding.Net的项目主页，你会发现自己在本地推送的代码已经出现在项目中。<br><img src=\"/img/20161110153244326.png\" alt=\"avatar\"></p>\n<p>以上就是使用Git上传代码到coding的流程，希望对大家有所帮助。</p>\n<p>再补充一个可以上传git到github的图片<br><img src=\"/img/gitshiyong.png\" alt=\"avatar\"></p>\n","site":{"data":{}},"excerpt":"<p>摘要:使用 Git上传代码到coding.net代码仓库详解</p>","more":"<p>1.创建本地代码库</p>\n<p>在本地创建一个文件夹，作为你上传代码的本地仓库，接下来就要把这个仓库与coding服务器端进行配置</p>\n<p>在这个文件夹内点击右键，选择Git Bash Here，首先要初始化本地仓库，输入”git init”命令</p>\n<p><img src=\"/img/20161110143539889.png\" alt=\"avatar\"></p>\n<p>接下来进行远程代码库克隆（前提：自行在coding中建立一个项目，空项目即可），输入”git clone https：//xxxxxx”命令，命令中的url获取方式如图：<br><img src=\"/img/20161110143829127.png\" alt=\"avatar\"></p>\n<p>左下角HHTPS处即为要输入的url</p>\n<p>将这个url粘贴到命令中，进行远程仓库的克隆，克隆时会出现输入账号密码的环节（coding注册时的账号和密码）<br><img src=\"/img/20161110144142460.png\" alt=\"avatar\"></p>\n<p>输入账号密码之后便可以完成克隆。</p>\n<p>2.代码推送</p>\n<p>克隆之后在原来的文件夹中会多出一个文件夹（即从代码库中下载的文件夹），例如<br><img src=\"/img/20161110144711307.png\" alt=\"avatar\"></p>\n<p>这时候，本地仓库的配置就完成了，将要上传的代码文件放入这个文件夹中，接下来要查看一下本地仓库的状态，一检查配置是否成功，进而进行代码的推送，输入命令”git status”</p>\n<p>例如放入了一个“stringKMP.c”文件之后输入命令”git status”</p>\n<p><img src=\"/img/20161110145017808.png\" alt=\"avatar\"></p>\n<p>输入git status命令后，会发现以红色字体打印出来的“stringKMP.c”，说明该文件存在于本地仓库，但并未推送到云端， 接下来，输入”git add 文件名”命令，可以再输入命令”git status”进行状态检查，如下<br><img src=\"/img/20161110145224254.png\" alt=\"avatar\"></p>\n<p>会发现出现了“new file”。</p>\n<p>接下来， 输入”git commit -m “代码备注随便写” “命令提交</p>\n<p>然后输入”git push origin master”命令推送到云端，origin是服务器，master是分枝。<br><img src=\"/img/20161110145428374.png\" alt=\"avatar\"></p>\n<p>一切结束后，输入”git status”查看本地代码状态，会用绿字显示，表示上传成功，进入coding.Net的项目主页，你会发现自己在本地推送的代码已经出现在项目中。<br><img src=\"/img/20161110153244326.png\" alt=\"avatar\"></p>\n<p>以上就是使用Git上传代码到coding的流程，希望对大家有所帮助。</p>\n<p>再补充一个可以上传git到github的图片<br><img src=\"/img/gitshiyong.png\" alt=\"avatar\"></p>"},{"date":"2020-03-16T16:00:00.000Z","title":"Nginx可以做什么","_content":"\n摘要:Nginx可以做什么？看完这篇你就懂了\n<!--more-->\n\n本文只针对Nginx在不加载第三方模块的情况能处理哪些事情，由于第三方模块太多所以也介绍不完，当然本文本身也可能介绍的不完整，毕竟只是我个人使用过和了解到过得，欢迎留言交流。\n\nNginx能做什么\n\n——反向代理\n\n——负载均衡\n\n——HTTP服务器（动静分离）\n\n——正向代理\n\n以上就是我了解到的Nginx在不依赖第三方模块能处理的事情，下面详细说明每种功能怎么做。\n\n# 反向代理\n\n反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。\n\n下面贴上一段简单的实现反向代理的代码\n\n![avatar](/img/nginx1.png)\n\n保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问localhost:8080了\n\n# 负载均衡\n\n负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。\n\n1、RR（默认）\n\n每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。\n\n简单配置\n\n![avatar](/img/nginx2.png)\n\n负载均衡的核心代码为\n\n![avatar](/img/nginx3.png)\n\n这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的,也就是说访问不到，但是我们访问http://localhost 的时候,也不会有问题，会默认跳转到http://localhost:8080 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。\n\n2、权重\n\n指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。\n\n例如\n\n![avatar](/img/nginx4.png)\n\n那么10次一般只会有1次会访问到8081，而有9次会访问到8080\n\n3、ip_hash\n\n上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。\n\n![avatar](/img/nginx5.png)\n\n4、fair（第三方）\n\n按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n\n![avatar](/img/nginx6.png)\n\n\n5、url_hash（第三方）\n\n按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法\n![avatar](/img/nginx7.png)\n\n以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍\n\n# HTTP服务器\n\nNginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器\n![avatar](/img/nginx8.png)\n\n这样如果访问http://localhost 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。\n回去一查，发现我公司的不是配置root  而是配置alias  那这区别是什么呢？ \n\n![avatar](/img/nginx11.png)\n\n网上一搜还真有 \nalias与root的用法区别\n最基本的区别：alias指定的目录是准确的，root是指定目录的上级目录，并且该上级目录要含有location指定名称的同名目录。另外，根据前文所述，使用alias标签的目录块中不能使用rewrite的break\n\n(1) . alias虚拟目录配置中，location匹配的path目录如果后面不带\"/\"，那么访问的url地址中这个path目录后面加不加\"/\"不影响访问，访问时它会自动加上\"/\"；\n    但是如果location匹配的path目录后面加上\"/\"，那么访问的url地址中这个path目录必须要加上\"/\"，访问时它不会自动加上\"/\"。如果不加上\"/\"，访问就会失败！\n(2) . root目录配置中，location匹配的path目录后面带不带\"/\"，都不会影响访问。\n\n所以，一般情况下，在nginx配置中的良好习惯是：\n1）在location /中配置root目录；\n2）在location /path中配置alias虚拟目录。\n\n# 动静分离\n\n动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路\n\n再补充一个可以上传git到github的图片\n![avatar](/img/nginx9.png)\n\n这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活\n\n# 正向代理\n\n正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。\n\n ![avatar](/img/nginx10.png)\nresolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。\n\n出处 https://www.cnblogs.com/mq0036/p/9794540.html","source":"_posts/Nginx可以做什么？看完这篇你就懂了.md","raw":"---\ndate: 2020-03-17\ntitle: Nginx可以做什么\ntags:\n  - nginx\n---\n\n摘要:Nginx可以做什么？看完这篇你就懂了\n<!--more-->\n\n本文只针对Nginx在不加载第三方模块的情况能处理哪些事情，由于第三方模块太多所以也介绍不完，当然本文本身也可能介绍的不完整，毕竟只是我个人使用过和了解到过得，欢迎留言交流。\n\nNginx能做什么\n\n——反向代理\n\n——负载均衡\n\n——HTTP服务器（动静分离）\n\n——正向代理\n\n以上就是我了解到的Nginx在不依赖第三方模块能处理的事情，下面详细说明每种功能怎么做。\n\n# 反向代理\n\n反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。\n\n下面贴上一段简单的实现反向代理的代码\n\n![avatar](/img/nginx1.png)\n\n保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问localhost:8080了\n\n# 负载均衡\n\n负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。\n\n1、RR（默认）\n\n每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。\n\n简单配置\n\n![avatar](/img/nginx2.png)\n\n负载均衡的核心代码为\n\n![avatar](/img/nginx3.png)\n\n这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的,也就是说访问不到，但是我们访问http://localhost 的时候,也不会有问题，会默认跳转到http://localhost:8080 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。\n\n2、权重\n\n指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。\n\n例如\n\n![avatar](/img/nginx4.png)\n\n那么10次一般只会有1次会访问到8081，而有9次会访问到8080\n\n3、ip_hash\n\n上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。\n\n![avatar](/img/nginx5.png)\n\n4、fair（第三方）\n\n按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n\n![avatar](/img/nginx6.png)\n\n\n5、url_hash（第三方）\n\n按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法\n![avatar](/img/nginx7.png)\n\n以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍\n\n# HTTP服务器\n\nNginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器\n![avatar](/img/nginx8.png)\n\n这样如果访问http://localhost 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。\n回去一查，发现我公司的不是配置root  而是配置alias  那这区别是什么呢？ \n\n![avatar](/img/nginx11.png)\n\n网上一搜还真有 \nalias与root的用法区别\n最基本的区别：alias指定的目录是准确的，root是指定目录的上级目录，并且该上级目录要含有location指定名称的同名目录。另外，根据前文所述，使用alias标签的目录块中不能使用rewrite的break\n\n(1) . alias虚拟目录配置中，location匹配的path目录如果后面不带\"/\"，那么访问的url地址中这个path目录后面加不加\"/\"不影响访问，访问时它会自动加上\"/\"；\n    但是如果location匹配的path目录后面加上\"/\"，那么访问的url地址中这个path目录必须要加上\"/\"，访问时它不会自动加上\"/\"。如果不加上\"/\"，访问就会失败！\n(2) . root目录配置中，location匹配的path目录后面带不带\"/\"，都不会影响访问。\n\n所以，一般情况下，在nginx配置中的良好习惯是：\n1）在location /中配置root目录；\n2）在location /path中配置alias虚拟目录。\n\n# 动静分离\n\n动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路\n\n再补充一个可以上传git到github的图片\n![avatar](/img/nginx9.png)\n\n这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活\n\n# 正向代理\n\n正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。\n\n ![avatar](/img/nginx10.png)\nresolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。\n\n出处 https://www.cnblogs.com/mq0036/p/9794540.html","slug":"Nginx可以做什么？看完这篇你就懂了","published":1,"updated":"2025-05-16T04:25:25.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jr90003skqrgv0z3rbf","content":"<p>摘要:Nginx可以做什么？看完这篇你就懂了</p>\n<span id=\"more\"></span>\n\n<p>本文只针对Nginx在不加载第三方模块的情况能处理哪些事情，由于第三方模块太多所以也介绍不完，当然本文本身也可能介绍的不完整，毕竟只是我个人使用过和了解到过得，欢迎留言交流。</p>\n<p>Nginx能做什么</p>\n<p>——反向代理</p>\n<p>——负载均衡</p>\n<p>——HTTP服务器（动静分离）</p>\n<p>——正向代理</p>\n<p>以上就是我了解到的Nginx在不依赖第三方模块能处理的事情，下面详细说明每种功能怎么做。</p>\n<h1 id=\"反向代理\"><a href=\"#反向代理\" class=\"headerlink\" title=\"反向代理\"></a>反向代理</h1><p>反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。</p>\n<p>下面贴上一段简单的实现反向代理的代码</p>\n<p><img src=\"/img/nginx1.png\" alt=\"avatar\"></p>\n<p>保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问localhost:8080了</p>\n<h1 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h1><p>负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。</p>\n<p>1、RR（默认）</p>\n<p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p>\n<p>简单配置</p>\n<p><img src=\"/img/nginx2.png\" alt=\"avatar\"></p>\n<p>负载均衡的核心代码为</p>\n<p><img src=\"/img/nginx3.png\" alt=\"avatar\"></p>\n<p>这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的,也就是说访问不到，但是我们访问<a href=\"http://localhost/\">http://localhost</a> 的时候,也不会有问题，会默认跳转到<a href=\"http://localhost:8080/\">http://localhost:8080</a> 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。</p>\n<p>2、权重</p>\n<p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</p>\n<p>例如</p>\n<p><img src=\"/img/nginx4.png\" alt=\"avatar\"></p>\n<p>那么10次一般只会有1次会访问到8081，而有9次会访问到8080</p>\n<p>3、ip_hash</p>\n<p>上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p>\n<p><img src=\"/img/nginx5.png\" alt=\"avatar\"></p>\n<p>4、fair（第三方）</p>\n<p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p>\n<p><img src=\"/img/nginx6.png\" alt=\"avatar\"></p>\n<p>5、url_hash（第三方）</p>\n<p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法<br><img src=\"/img/nginx7.png\" alt=\"avatar\"></p>\n<p>以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍</p>\n<h1 id=\"HTTP服务器\"><a href=\"#HTTP服务器\" class=\"headerlink\" title=\"HTTP服务器\"></a>HTTP服务器</h1><p>Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器<br><img src=\"/img/nginx8.png\" alt=\"avatar\"></p>\n<p>这样如果访问<a href=\"http://localhost/\">http://localhost</a> 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。<br>回去一查，发现我公司的不是配置root  而是配置alias  那这区别是什么呢？ </p>\n<p><img src=\"/img/nginx11.png\" alt=\"avatar\"></p>\n<p>网上一搜还真有<br>alias与root的用法区别<br>最基本的区别：alias指定的目录是准确的，root是指定目录的上级目录，并且该上级目录要含有location指定名称的同名目录。另外，根据前文所述，使用alias标签的目录块中不能使用rewrite的break</p>\n<p>(1) . alias虚拟目录配置中，location匹配的path目录如果后面不带”/“，那么访问的url地址中这个path目录后面加不加”/“不影响访问，访问时它会自动加上”/“；<br>    但是如果location匹配的path目录后面加上”/“，那么访问的url地址中这个path目录必须要加上”/“，访问时它不会自动加上”/“。如果不加上”/“，访问就会失败！<br>(2) . root目录配置中，location匹配的path目录后面带不带”/“，都不会影响访问。</p>\n<p>所以，一般情况下，在nginx配置中的良好习惯是：<br>1）在location /中配置root目录；<br>2）在location /path中配置alias虚拟目录。</p>\n<h1 id=\"动静分离\"><a href=\"#动静分离\" class=\"headerlink\" title=\"动静分离\"></a>动静分离</h1><p>动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路</p>\n<p>再补充一个可以上传git到github的图片<br><img src=\"/img/nginx9.png\" alt=\"avatar\"></p>\n<p>这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活</p>\n<h1 id=\"正向代理\"><a href=\"#正向代理\" class=\"headerlink\" title=\"正向代理\"></a>正向代理</h1><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。</p>\n<p> <img src=\"/img/nginx10.png\" alt=\"avatar\"><br>resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。</p>\n<p>出处 <a href=\"https://www.cnblogs.com/mq0036/p/9794540.html\">https://www.cnblogs.com/mq0036/p/9794540.html</a></p>\n","site":{"data":{}},"excerpt":"<p>摘要:Nginx可以做什么？看完这篇你就懂了</p>","more":"<p>本文只针对Nginx在不加载第三方模块的情况能处理哪些事情，由于第三方模块太多所以也介绍不完，当然本文本身也可能介绍的不完整，毕竟只是我个人使用过和了解到过得，欢迎留言交流。</p>\n<p>Nginx能做什么</p>\n<p>——反向代理</p>\n<p>——负载均衡</p>\n<p>——HTTP服务器（动静分离）</p>\n<p>——正向代理</p>\n<p>以上就是我了解到的Nginx在不依赖第三方模块能处理的事情，下面详细说明每种功能怎么做。</p>\n<h1 id=\"反向代理\"><a href=\"#反向代理\" class=\"headerlink\" title=\"反向代理\"></a>反向代理</h1><p>反向代理应该是Nginx做的最多的一件事了，什么是反向代理呢，以下是百度百科的说法：反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。</p>\n<p>下面贴上一段简单的实现反向代理的代码</p>\n<p><img src=\"/img/nginx1.png\" alt=\"avatar\"></p>\n<p>保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问localhost:8080了</p>\n<h1 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h1><p>负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。</p>\n<p>1、RR（默认）</p>\n<p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p>\n<p>简单配置</p>\n<p><img src=\"/img/nginx2.png\" alt=\"avatar\"></p>\n<p>负载均衡的核心代码为</p>\n<p><img src=\"/img/nginx3.png\" alt=\"avatar\"></p>\n<p>这里我配置了2台服务器，当然实际上是一台，只是端口不一样而已，而8081的服务器是不存在的,也就是说访问不到，但是我们访问<a href=\"http://localhost/\">http://localhost</a> 的时候,也不会有问题，会默认跳转到<a href=\"http://localhost:8080/\">http://localhost:8080</a> 具体是因为Nginx会自动判断服务器的状态，如果服务器处于不能访问（服务器挂了），就不会跳转到这台服务器，所以也避免了一台服务器挂了影响使用的情况，由于Nginx默认是RR策略，所以我们不需要其他更多的设置。</p>\n<p>2、权重</p>\n<p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</p>\n<p>例如</p>\n<p><img src=\"/img/nginx4.png\" alt=\"avatar\"></p>\n<p>那么10次一般只会有1次会访问到8081，而有9次会访问到8080</p>\n<p>3、ip_hash</p>\n<p>上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p>\n<p><img src=\"/img/nginx5.png\" alt=\"avatar\"></p>\n<p>4、fair（第三方）</p>\n<p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p>\n<p><img src=\"/img/nginx6.png\" alt=\"avatar\"></p>\n<p>5、url_hash（第三方）</p>\n<p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法<br><img src=\"/img/nginx7.png\" alt=\"avatar\"></p>\n<p>以上5种负载均衡各自适用不同情况下使用，所以可以根据实际情况选择使用哪种策略模式,不过fair和url_hash需要安装第三方模块才能使用，由于本文主要介绍Nginx能做的事情，所以Nginx安装第三方模块不会再本文介绍</p>\n<h1 id=\"HTTP服务器\"><a href=\"#HTTP服务器\" class=\"headerlink\" title=\"HTTP服务器\"></a>HTTP服务器</h1><p>Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器<br><img src=\"/img/nginx8.png\" alt=\"avatar\"></p>\n<p>这样如果访问<a href=\"http://localhost/\">http://localhost</a> 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。<br>回去一查，发现我公司的不是配置root  而是配置alias  那这区别是什么呢？ </p>\n<p><img src=\"/img/nginx11.png\" alt=\"avatar\"></p>\n<p>网上一搜还真有<br>alias与root的用法区别<br>最基本的区别：alias指定的目录是准确的，root是指定目录的上级目录，并且该上级目录要含有location指定名称的同名目录。另外，根据前文所述，使用alias标签的目录块中不能使用rewrite的break</p>\n<p>(1) . alias虚拟目录配置中，location匹配的path目录如果后面不带”/“，那么访问的url地址中这个path目录后面加不加”/“不影响访问，访问时它会自动加上”/“；<br>    但是如果location匹配的path目录后面加上”/“，那么访问的url地址中这个path目录必须要加上”/“，访问时它不会自动加上”/“。如果不加上”/“，访问就会失败！<br>(2) . root目录配置中，location匹配的path目录后面带不带”/“，都不会影响访问。</p>\n<p>所以，一般情况下，在nginx配置中的良好习惯是：<br>1）在location /中配置root目录；<br>2）在location /path中配置alias虚拟目录。</p>\n<h1 id=\"动静分离\"><a href=\"#动静分离\" class=\"headerlink\" title=\"动静分离\"></a>动静分离</h1><p>动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路</p>\n<p>再补充一个可以上传git到github的图片<br><img src=\"/img/nginx9.png\" alt=\"avatar\"></p>\n<p>这样我们就可以吧HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了，只要搞清楚了最基本的流程，很多配置就很简单了，另外localtion后面其实是一个正则表达式，所以非常灵活</p>\n<h1 id=\"正向代理\"><a href=\"#正向代理\" class=\"headerlink\" title=\"正向代理\"></a>正向代理</h1><p>正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。当你需要把你的服务器作为代理服务器的时候，可以用Nginx来实现正向代理，但是目前Nginx有一个问题，那么就是不支持HTTPS，虽然我百度到过配置HTTPS的正向代理，但是到最后发现还是代理不了，当然可能是我配置的不对，所以也希望有知道正确方法的同志们留言说明一下。</p>\n<p> <img src=\"/img/nginx10.png\" alt=\"avatar\"><br>resolver是配置正向代理的DNS服务器，listen 是正向代理的端口，配置好了就可以在ie上面或者其他代理插件上面使用服务器ip+端口号进行代理了。</p>\n<p>出处 <a href=\"https://www.cnblogs.com/mq0036/p/9794540.html\">https://www.cnblogs.com/mq0036/p/9794540.html</a></p>"},{"title":"markdown语法","_content":"\n摘要:markdown语法\n<!--more-->\n```\n正文:我的第一篇\n1. 斜体和粗体\n\t1. *斜体*或_斜体_\n\t2. **粗体**\n\t3. ***加粗斜体***\n\t4. ~~删除线~~\n2. 分级标题\n\t1. # 一级标题  最大\n\t2. ## 二级标题\n\t3. ### 三级标题\n\t4. #### 四级标题\n\t5. ##### 五级标题\n\t6. ###### 六级标题\n3. < 与 &  \n\t1.<会不显示，要写&lt  \n\t2.&要写&amp  \n4. 如果你确实想要依赖 Markdown 来插入 <br /> 标签的话，在插入处先按入两个以上的空格然后回车。\n5. 今天又学到一招 Markdown 插入图片的话 ! [ avatar ]( / img/ 20161110153244326.png) 在source文件夹下面加多一个img文件夹\n\t 然后用 hexo g  //提交\n\t hexo d //上传\n```\n\t *干的漂亮*\n\n","source":"_posts/markdown语法.md","raw":"---\ntitle: markdown语法\ntags:\n  - 其他\n---\n\n摘要:markdown语法\n<!--more-->\n```\n正文:我的第一篇\n1. 斜体和粗体\n\t1. *斜体*或_斜体_\n\t2. **粗体**\n\t3. ***加粗斜体***\n\t4. ~~删除线~~\n2. 分级标题\n\t1. # 一级标题  最大\n\t2. ## 二级标题\n\t3. ### 三级标题\n\t4. #### 四级标题\n\t5. ##### 五级标题\n\t6. ###### 六级标题\n3. < 与 &  \n\t1.<会不显示，要写&lt  \n\t2.&要写&amp  \n4. 如果你确实想要依赖 Markdown 来插入 <br /> 标签的话，在插入处先按入两个以上的空格然后回车。\n5. 今天又学到一招 Markdown 插入图片的话 ! [ avatar ]( / img/ 20161110153244326.png) 在source文件夹下面加多一个img文件夹\n\t 然后用 hexo g  //提交\n\t hexo d //上传\n```\n\t *干的漂亮*\n\n","slug":"markdown语法","published":1,"date":"2025-05-16T04:25:25.422Z","updated":"2025-05-16T08:49:28.110Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jra0004skqr533590lx","content":"<p>摘要:markdown语法</p>\n<span id=\"more\"></span>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">正文:我的第一篇</span><br><span class=\"line\">1. 斜体和粗体</span><br><span class=\"line\">\t1. *斜体*或_斜体_</span><br><span class=\"line\">\t2. **粗体**</span><br><span class=\"line\">\t3. ***加粗斜体***</span><br><span class=\"line\">\t4. ~~删除线~~</span><br><span class=\"line\">2. 分级标题</span><br><span class=\"line\">\t1. # 一级标题  最大</span><br><span class=\"line\">\t2. ## 二级标题</span><br><span class=\"line\">\t3. ### 三级标题</span><br><span class=\"line\">\t4. #### 四级标题</span><br><span class=\"line\">\t5. ##### 五级标题</span><br><span class=\"line\">\t6. ###### 六级标题</span><br><span class=\"line\">3. &lt; 与 &amp;  </span><br><span class=\"line\">\t1.&lt;会不显示，要写&amp;lt  </span><br><span class=\"line\">\t2.&amp;要写&amp;amp  </span><br><span class=\"line\">4. 如果你确实想要依赖 Markdown 来插入 &lt;br &#x2F;&gt; 标签的话，在插入处先按入两个以上的空格然后回车。</span><br><span class=\"line\">5. 今天又学到一招 Markdown 插入图片的话 ! [ avatar ]( &#x2F; img&#x2F; 20161110153244326.png) 在source文件夹下面加多一个img文件夹</span><br><span class=\"line\">\t 然后用 hexo g  &#x2F;&#x2F;提交</span><br><span class=\"line\">\t hexo d &#x2F;&#x2F;上传</span><br></pre></td></tr></table></figure>\n<pre><code> *干的漂亮*\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>摘要:markdown语法</p>","more":"<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">正文:我的第一篇</span><br><span class=\"line\">1. 斜体和粗体</span><br><span class=\"line\">\t1. *斜体*或_斜体_</span><br><span class=\"line\">\t2. **粗体**</span><br><span class=\"line\">\t3. ***加粗斜体***</span><br><span class=\"line\">\t4. ~~删除线~~</span><br><span class=\"line\">2. 分级标题</span><br><span class=\"line\">\t1. # 一级标题  最大</span><br><span class=\"line\">\t2. ## 二级标题</span><br><span class=\"line\">\t3. ### 三级标题</span><br><span class=\"line\">\t4. #### 四级标题</span><br><span class=\"line\">\t5. ##### 五级标题</span><br><span class=\"line\">\t6. ###### 六级标题</span><br><span class=\"line\">3. &lt; 与 &amp;  </span><br><span class=\"line\">\t1.&lt;会不显示，要写&amp;lt  </span><br><span class=\"line\">\t2.&amp;要写&amp;amp  </span><br><span class=\"line\">4. 如果你确实想要依赖 Markdown 来插入 &lt;br &#x2F;&gt; 标签的话，在插入处先按入两个以上的空格然后回车。</span><br><span class=\"line\">5. 今天又学到一招 Markdown 插入图片的话 ! [ avatar ]( &#x2F; img&#x2F; 20161110153244326.png) 在source文件夹下面加多一个img文件夹</span><br><span class=\"line\">\t 然后用 hexo g  &#x2F;&#x2F;提交</span><br><span class=\"line\">\t hexo d &#x2F;&#x2F;上传</span><br></pre></td></tr></table></figure>\n<pre><code> *干的漂亮*\n</code></pre>"},{"date":"2016-12-23T03:35:00.000Z","status":"public","title":"Android 权限管理","_content":"\n摘要:Android6.0没有权限读取外部存储的问题\n<!--more-->\n最近在做一个电子商城APP，本人负责Android客户端，在项目尾期遇到一个问题，经测试发现，Android6.0以上的手机都没有权限直接读取外部存储，即使在AndroidManifest.xml加上\n<uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\" />\n<uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\n\n也没有任何效果，最后查询国外论坛发现6.0以后很多权限都需要主动请求后才能使用，以下为解决方案：\n\t\tpublic class AuthorityUtil {\n\t    public static int ExternalRW_PERMISSIONS_CODE = 124;\n\t    //读取手机存储的权限\n\t    public static boolean isGrantExternalRW(Activity activity) {\n\t        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {\n\t            if (PackageManager.PERMISSION_GRANTED == ContextCompat.checkSelfPermission(activity, android.Manifest.permission.WRITE_EXTERNAL_STORAGE)) {\n\t                return true;\n\t            } else {\n\t                Toast.makeText(activity, \"请到手机设置允许读取手机存储权限，不然会更新失败哦~\", Toast.LENGTH_LONG).show();\n\t                String[] mPermissionList = new String[]{\n\t                        Manifest.permission.READ_EXTERNAL_STORAGE,\n\t                        Manifest.permission.WRITE_EXTERNAL_STORAGE};\n\t                ActivityCompat.requestPermissions(activity, mPermissionList, ExternalRW_PERMISSIONS_CODE);\n\t                return false;\n\t            }\n\t        }\n\t        return true;\n\t    }\n\t\t}\n调用\n\t\tif(AuthorityUtil.isGrantExternalRW(MainActivity.this)) {\n\t\t}\n回调\n\t\t@Override\n    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {\n        super.onRequestPermissionsResult(requestCode, permissions, grantResults);\n\n        if (requestCode == AuthorityUtil.ExternalRW_PERMISSIONS_CODE) {\n            for (int i = 0; i < permissions.length; i++) {\n                String permission = permissions[i];\n                int grantResult = grantResults[i];\n                if (permission.equals(Manifest.permission.READ_EXTERNAL_STORAGE)) {\n                    if (grantResult == PackageManager.PERMISSION_GRANTED) {\n                        //授权成功后的逻辑\n                        if (!BaseTools.isServiceWork(getApplicationContext(), \"com.sun0769.wirelessdongguan.service.UpdataService\")) {\n                            Log.e(\"info\", \"启动服务！！\");\n                            Intent intent = new Intent(MainActivity.this, UpdataService.class);\n                            startService(intent);\n                        } else {\n                            Log.e(\"info\", \"服务已经启动了！！\");\n                        }\n                    }\n                }\n            }\n        }\n    }","source":"_posts/android/Android6.0没有权限读取外部存储的问题.md","raw":"---\ndate: 2016-12-23 11:35\nstatus: public\ntitle: Android 权限管理\ntags:\n  - Android\n---\n\n摘要:Android6.0没有权限读取外部存储的问题\n<!--more-->\n最近在做一个电子商城APP，本人负责Android客户端，在项目尾期遇到一个问题，经测试发现，Android6.0以上的手机都没有权限直接读取外部存储，即使在AndroidManifest.xml加上\n<uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\" />\n<uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\n\n也没有任何效果，最后查询国外论坛发现6.0以后很多权限都需要主动请求后才能使用，以下为解决方案：\n\t\tpublic class AuthorityUtil {\n\t    public static int ExternalRW_PERMISSIONS_CODE = 124;\n\t    //读取手机存储的权限\n\t    public static boolean isGrantExternalRW(Activity activity) {\n\t        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {\n\t            if (PackageManager.PERMISSION_GRANTED == ContextCompat.checkSelfPermission(activity, android.Manifest.permission.WRITE_EXTERNAL_STORAGE)) {\n\t                return true;\n\t            } else {\n\t                Toast.makeText(activity, \"请到手机设置允许读取手机存储权限，不然会更新失败哦~\", Toast.LENGTH_LONG).show();\n\t                String[] mPermissionList = new String[]{\n\t                        Manifest.permission.READ_EXTERNAL_STORAGE,\n\t                        Manifest.permission.WRITE_EXTERNAL_STORAGE};\n\t                ActivityCompat.requestPermissions(activity, mPermissionList, ExternalRW_PERMISSIONS_CODE);\n\t                return false;\n\t            }\n\t        }\n\t        return true;\n\t    }\n\t\t}\n调用\n\t\tif(AuthorityUtil.isGrantExternalRW(MainActivity.this)) {\n\t\t}\n回调\n\t\t@Override\n    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {\n        super.onRequestPermissionsResult(requestCode, permissions, grantResults);\n\n        if (requestCode == AuthorityUtil.ExternalRW_PERMISSIONS_CODE) {\n            for (int i = 0; i < permissions.length; i++) {\n                String permission = permissions[i];\n                int grantResult = grantResults[i];\n                if (permission.equals(Manifest.permission.READ_EXTERNAL_STORAGE)) {\n                    if (grantResult == PackageManager.PERMISSION_GRANTED) {\n                        //授权成功后的逻辑\n                        if (!BaseTools.isServiceWork(getApplicationContext(), \"com.sun0769.wirelessdongguan.service.UpdataService\")) {\n                            Log.e(\"info\", \"启动服务！！\");\n                            Intent intent = new Intent(MainActivity.this, UpdataService.class);\n                            startService(intent);\n                        } else {\n                            Log.e(\"info\", \"服务已经启动了！！\");\n                        }\n                    }\n                }\n            }\n        }\n    }","slug":"android/Android6.0没有权限读取外部存储的问题","published":1,"updated":"2025-05-20T08:49:54.716Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrb0005skqr758k0nmj","content":"<p>摘要:Android6.0没有权限读取外部存储的问题</p>\n<span id=\"more\"></span>\n<p>最近在做一个电子商城APP，本人负责Android客户端，在项目尾期遇到一个问题，经测试发现，Android6.0以上的手机都没有权限直接读取外部存储，即使在AndroidManifest.xml加上<br><uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\" /><br><uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" /></p>\n<p>也没有任何效果，最后查询国外论坛发现6.0以后很多权限都需要主动请求后才能使用，以下为解决方案：<br>        public class AuthorityUtil {<br>        public static int ExternalRW_PERMISSIONS_CODE = 124;<br>        //读取手机存储的权限<br>        public static boolean isGrantExternalRW(Activity activity) {<br>            if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) {<br>                if (PackageManager.PERMISSION_GRANTED == ContextCompat.checkSelfPermission(activity, android.Manifest.permission.WRITE_EXTERNAL_STORAGE)) {<br>                    return true;<br>                } else {<br>                    Toast.makeText(activity, “请到手机设置允许读取手机存储权限，不然会更新失败哦~”, Toast.LENGTH_LONG).show();<br>                    String[] mPermissionList = new String[]{<br>                            Manifest.permission.READ_EXTERNAL_STORAGE,<br>                            Manifest.permission.WRITE_EXTERNAL_STORAGE};<br>                    ActivityCompat.requestPermissions(activity, mPermissionList, ExternalRW_PERMISSIONS_CODE);<br>                    return false;<br>                }<br>            }<br>            return true;<br>        }<br>        }<br>调用<br>        if(AuthorityUtil.isGrantExternalRW(MainActivity.this)) {<br>        }<br>回调<br>        @Override<br>    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {<br>        super.onRequestPermissionsResult(requestCode, permissions, grantResults);</p>\n<pre><code>    if (requestCode == AuthorityUtil.ExternalRW_PERMISSIONS_CODE) &#123;\n        for (int i = 0; i &lt; permissions.length; i++) &#123;\n            String permission = permissions[i];\n            int grantResult = grantResults[i];\n            if (permission.equals(Manifest.permission.READ_EXTERNAL_STORAGE)) &#123;\n                if (grantResult == PackageManager.PERMISSION_GRANTED) &#123;\n                    //授权成功后的逻辑\n                    if (!BaseTools.isServiceWork(getApplicationContext(), &quot;com.sun0769.wirelessdongguan.service.UpdataService&quot;)) &#123;\n                        Log.e(&quot;info&quot;, &quot;启动服务！！&quot;);\n                        Intent intent = new Intent(MainActivity.this, UpdataService.class);\n                        startService(intent);\n                    &#125; else &#123;\n                        Log.e(&quot;info&quot;, &quot;服务已经启动了！！&quot;);\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>摘要:Android6.0没有权限读取外部存储的问题</p>","more":"<p>最近在做一个电子商城APP，本人负责Android客户端，在项目尾期遇到一个问题，经测试发现，Android6.0以上的手机都没有权限直接读取外部存储，即使在AndroidManifest.xml加上<br><uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\" /><br><uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" /></p>\n<p>也没有任何效果，最后查询国外论坛发现6.0以后很多权限都需要主动请求后才能使用，以下为解决方案：<br>        public class AuthorityUtil {<br>        public static int ExternalRW_PERMISSIONS_CODE = 124;<br>        //读取手机存储的权限<br>        public static boolean isGrantExternalRW(Activity activity) {<br>            if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.M) {<br>                if (PackageManager.PERMISSION_GRANTED == ContextCompat.checkSelfPermission(activity, android.Manifest.permission.WRITE_EXTERNAL_STORAGE)) {<br>                    return true;<br>                } else {<br>                    Toast.makeText(activity, “请到手机设置允许读取手机存储权限，不然会更新失败哦~”, Toast.LENGTH_LONG).show();<br>                    String[] mPermissionList = new String[]{<br>                            Manifest.permission.READ_EXTERNAL_STORAGE,<br>                            Manifest.permission.WRITE_EXTERNAL_STORAGE};<br>                    ActivityCompat.requestPermissions(activity, mPermissionList, ExternalRW_PERMISSIONS_CODE);<br>                    return false;<br>                }<br>            }<br>            return true;<br>        }<br>        }<br>调用<br>        if(AuthorityUtil.isGrantExternalRW(MainActivity.this)) {<br>        }<br>回调<br>        @Override<br>    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {<br>        super.onRequestPermissionsResult(requestCode, permissions, grantResults);</p>\n<pre><code>    if (requestCode == AuthorityUtil.ExternalRW_PERMISSIONS_CODE) &#123;\n        for (int i = 0; i &lt; permissions.length; i++) &#123;\n            String permission = permissions[i];\n            int grantResult = grantResults[i];\n            if (permission.equals(Manifest.permission.READ_EXTERNAL_STORAGE)) &#123;\n                if (grantResult == PackageManager.PERMISSION_GRANTED) &#123;\n                    //授权成功后的逻辑\n                    if (!BaseTools.isServiceWork(getApplicationContext(), &quot;com.sun0769.wirelessdongguan.service.UpdataService&quot;)) &#123;\n                        Log.e(&quot;info&quot;, &quot;启动服务！！&quot;);\n                        Intent intent = new Intent(MainActivity.this, UpdataService.class);\n                        startService(intent);\n                    &#125; else &#123;\n                        Log.e(&quot;info&quot;, &quot;服务已经启动了！！&quot;);\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n</code></pre>"},{"date":"2017-07-13T03:35:00.000Z","status":"public","title":"使用git发布文件的时候需要注意的东西","_content":"git上传自己的博客也好 上传文件也好首先你需要有一个git\n<!--more-->\n使用hexo+github搭建免费个人博客详细教程 http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\n首先要下载node.js 然后下载hexo 对着c：目录下下载   $ npm install -g hexo-cli\n开启gitbush 找到对应的文件目录\nhexo g # 生成\nhexo s # 启动服务 一开始会弹出您的github登录 然后输入账号密码 \n","source":"_posts/发布的git代码.md","raw":"---\ndate:  2017-7-13 11:35\nstatus: public\ntitle: 使用git发布文件的时候需要注意的东西\ntags:\n  - 安卓\n---\ngit上传自己的博客也好 上传文件也好首先你需要有一个git\n<!--more-->\n使用hexo+github搭建免费个人博客详细教程 http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\n首先要下载node.js 然后下载hexo 对着c：目录下下载   $ npm install -g hexo-cli\n开启gitbush 找到对应的文件目录\nhexo g # 生成\nhexo s # 启动服务 一开始会弹出您的github登录 然后输入账号密码 \n","slug":"发布的git代码","published":1,"updated":"2025-05-16T08:14:11.151Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jre0008skqr6nm6b0jr","content":"<p>git上传自己的博客也好 上传文件也好首先你需要有一个git</p>\n<span id=\"more\"></span>\n<p>使用hexo+github搭建免费个人博客详细教程 <a href=\"http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\">http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a><br>首先要下载node.js 然后下载hexo 对着c：目录下下载   $ npm install -g hexo-cli<br>开启gitbush 找到对应的文件目录<br>hexo g # 生成<br>hexo s # 启动服务 一开始会弹出您的github登录 然后输入账号密码 </p>\n","site":{"data":{}},"excerpt":"<p>git上传自己的博客也好 上传文件也好首先你需要有一个git</p>","more":"<p>使用hexo+github搭建免费个人博客详细教程 <a href=\"http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html\">http://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a><br>首先要下载node.js 然后下载hexo 对着c：目录下下载   $ npm install -g hexo-cli<br>开启gitbush 找到对应的文件目录<br>hexo g # 生成<br>hexo s # 启动服务 一开始会弹出您的github登录 然后输入账号密码 </p>"},{"title":"安卓传递数据","date":"2016-12-23T14:37:23.000Z","_content":"\n摘要:安卓传递数据\n<!--more-->\n正文:面试的时候遇到这个，记下来以后可以用，之前没有用过\n\n第一个：传递bitmap\n\n  这个问题非常奇葩（可能我Android水平还不够），居然不会报错，我是直接用bundle或Intent的extral域直接存放bitmap，结果运行时各种宕机，各种界面乱窜（我非常的纳闷）。。。搜索之后看大家都说不能直接传递大于40k的图片，然后在德问论坛上找到了解法。就是把bitmap存储为byte数组，然后再通过Intent传递。\n\n的 \n\n 代码如下所示：\n\nBitmap bmp=((BitmapDrawable)order_con_pic.getDrawable()).getBitmap();  \nIntent intent=new Intent(OrderConfirm.this,ShowWebImageActivity.class);  \nByteArrayOutputStream baos=new ByteArrayOutputStream();  \nbmp.compress(Bitmap.CompressFormat.PNG, 100, baos);  \nbyte [] bitmapByte =baos.toByteArray();  \nintent.putExtra(\"bitmap\", bitmapByte);  \nstartActivity(intent);  \n\n其中 第一行代码就是如何从一个imageview中获得其图片，这个问题也倒腾了下，貌似用setDrawingCacheEnabled也行，因为开始用的这个方法，但是直接在activity之间传递bitmap，所以导致运行时错误，后来改正之后没有再尝试。\n先new一个ByteArrayOutputStream流，然后使用Bitmap中的compress方法，把数据压缩到一个byte中，传输就可以了。\n\n在另一个activity中取出来的方法是：\n\nimageView = (ZoomableImageView) findViewById(R.id.show_webimage_imageview);  \n        Intent intent=getIntent();  \n        if(intent !=null)  \n        {  \n            byte [] bis=intent.getByteArrayExtra(\"bitmap\");  \n            Bitmap bitmap=BitmapFactory.decodeByteArray(bis, 0, bis.length);  \n            imageView.setImageBitmap(bitmap);  \n        }  \n取出来字节数组之后，用BitmapFactory中的decodeByteArray方法组合成一个bitmap就可以了。\n再加上一个存储的代码：\n\npublic void saveMyBitmap(String bitName,Bitmap mBitmap) throws IOException {  \n        File f = new File(\"/sdcard/Note/\" + bitName);  \n        if(!f.exists())  \n            f.mkdirs();//如果没有这个文件夹的话，会报file not found错误  \n        f=new File(\"/sdcard/Note/\"+bitName+\".png\");  \n        f.createNewFile();  \n        try {  \n            FileOutputStream out = new FileOutputStream(f);  \n             mBitmap.compress(Bitmap.CompressFormat.PNG, 100, out);  \n             out.flush();  \n             out.close();  \n        } catch (FileNotFoundException e) {  \n                Log.i(TAG,e.toString());  \n        }  \n         \n    }  \n\n\n2.传递map对象：\n\n封装到bundle中：\n\nMap<String,Object> data=orderlist.get(arg2-1);  \n            SerializableMap tmpmap=new SerializableMap();  \n            tmpmap.setMap(data);  \n            bundle.putSerializable(\"orderinfo\", tmpmap);  \n            intent.putExtras(bundle);  \n\n这个SeralizableMap是自己封装的一个实现了Serializable接口的类：\npublic class SerializableMap implements Serializable {  \n    private Map<String,Object> map;  \n    public Map<String,Object> getMap()  \n    {  \n        return map;  \n    }  \n    public void setMap(Map<String,Object> map)  \n    {  \n        this.map=map;  \n    }  \n}  \n这样才能把map对象扔到bundle中去，\n取出来的方法是：\n\nBundle bundle = getIntent().getExtras();  \n        SerializableMap serializableMap = (SerializableMap) bundle  \n                .get(\"orderinfo\");  ","source":"_posts/android/Android基础 -- Activity之间传递数据（bitmap和map对象）.md","raw":"---\ntitle: 安卓传递数据\ndate: 2016-012-23 22:37:23\ncategories:\n  - 安卓\ntags:\n  - 其他\n---\n\n摘要:安卓传递数据\n<!--more-->\n正文:面试的时候遇到这个，记下来以后可以用，之前没有用过\n\n第一个：传递bitmap\n\n  这个问题非常奇葩（可能我Android水平还不够），居然不会报错，我是直接用bundle或Intent的extral域直接存放bitmap，结果运行时各种宕机，各种界面乱窜（我非常的纳闷）。。。搜索之后看大家都说不能直接传递大于40k的图片，然后在德问论坛上找到了解法。就是把bitmap存储为byte数组，然后再通过Intent传递。\n\n的 \n\n 代码如下所示：\n\nBitmap bmp=((BitmapDrawable)order_con_pic.getDrawable()).getBitmap();  \nIntent intent=new Intent(OrderConfirm.this,ShowWebImageActivity.class);  \nByteArrayOutputStream baos=new ByteArrayOutputStream();  \nbmp.compress(Bitmap.CompressFormat.PNG, 100, baos);  \nbyte [] bitmapByte =baos.toByteArray();  \nintent.putExtra(\"bitmap\", bitmapByte);  \nstartActivity(intent);  \n\n其中 第一行代码就是如何从一个imageview中获得其图片，这个问题也倒腾了下，貌似用setDrawingCacheEnabled也行，因为开始用的这个方法，但是直接在activity之间传递bitmap，所以导致运行时错误，后来改正之后没有再尝试。\n先new一个ByteArrayOutputStream流，然后使用Bitmap中的compress方法，把数据压缩到一个byte中，传输就可以了。\n\n在另一个activity中取出来的方法是：\n\nimageView = (ZoomableImageView) findViewById(R.id.show_webimage_imageview);  \n        Intent intent=getIntent();  \n        if(intent !=null)  \n        {  \n            byte [] bis=intent.getByteArrayExtra(\"bitmap\");  \n            Bitmap bitmap=BitmapFactory.decodeByteArray(bis, 0, bis.length);  \n            imageView.setImageBitmap(bitmap);  \n        }  \n取出来字节数组之后，用BitmapFactory中的decodeByteArray方法组合成一个bitmap就可以了。\n再加上一个存储的代码：\n\npublic void saveMyBitmap(String bitName,Bitmap mBitmap) throws IOException {  \n        File f = new File(\"/sdcard/Note/\" + bitName);  \n        if(!f.exists())  \n            f.mkdirs();//如果没有这个文件夹的话，会报file not found错误  \n        f=new File(\"/sdcard/Note/\"+bitName+\".png\");  \n        f.createNewFile();  \n        try {  \n            FileOutputStream out = new FileOutputStream(f);  \n             mBitmap.compress(Bitmap.CompressFormat.PNG, 100, out);  \n             out.flush();  \n             out.close();  \n        } catch (FileNotFoundException e) {  \n                Log.i(TAG,e.toString());  \n        }  \n         \n    }  \n\n\n2.传递map对象：\n\n封装到bundle中：\n\nMap<String,Object> data=orderlist.get(arg2-1);  \n            SerializableMap tmpmap=new SerializableMap();  \n            tmpmap.setMap(data);  \n            bundle.putSerializable(\"orderinfo\", tmpmap);  \n            intent.putExtras(bundle);  \n\n这个SeralizableMap是自己封装的一个实现了Serializable接口的类：\npublic class SerializableMap implements Serializable {  \n    private Map<String,Object> map;  \n    public Map<String,Object> getMap()  \n    {  \n        return map;  \n    }  \n    public void setMap(Map<String,Object> map)  \n    {  \n        this.map=map;  \n    }  \n}  \n这样才能把map对象扔到bundle中去，\n取出来的方法是：\n\nBundle bundle = getIntent().getExtras();  \n        SerializableMap serializableMap = (SerializableMap) bundle  \n                .get(\"orderinfo\");  ","slug":"android/Android基础 -- Activity之间传递数据（bitmap和map对象）","published":1,"updated":"2025-05-16T04:25:25.412Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrg000askqrg734gvem","content":"<p>摘要:安卓传递数据</p>\n<span id=\"more\"></span>\n<p>正文:面试的时候遇到这个，记下来以后可以用，之前没有用过</p>\n<p>第一个：传递bitmap</p>\n<p>  这个问题非常奇葩（可能我Android水平还不够），居然不会报错，我是直接用bundle或Intent的extral域直接存放bitmap，结果运行时各种宕机，各种界面乱窜（我非常的纳闷）。。。搜索之后看大家都说不能直接传递大于40k的图片，然后在德问论坛上找到了解法。就是把bitmap存储为byte数组，然后再通过Intent传递。</p>\n<p>的 </p>\n<p> 代码如下所示：</p>\n<p>Bitmap bmp=((BitmapDrawable)order_con_pic.getDrawable()).getBitmap();<br>Intent intent=new Intent(OrderConfirm.this,ShowWebImageActivity.class);<br>ByteArrayOutputStream baos=new ByteArrayOutputStream();<br>bmp.compress(Bitmap.CompressFormat.PNG, 100, baos);<br>byte [] bitmapByte =baos.toByteArray();<br>intent.putExtra(“bitmap”, bitmapByte);<br>startActivity(intent);  </p>\n<p>其中 第一行代码就是如何从一个imageview中获得其图片，这个问题也倒腾了下，貌似用setDrawingCacheEnabled也行，因为开始用的这个方法，但是直接在activity之间传递bitmap，所以导致运行时错误，后来改正之后没有再尝试。<br>先new一个ByteArrayOutputStream流，然后使用Bitmap中的compress方法，把数据压缩到一个byte中，传输就可以了。</p>\n<p>在另一个activity中取出来的方法是：</p>\n<p>imageView = (ZoomableImageView) findViewById(R.id.show_webimage_imageview);<br>        Intent intent=getIntent();<br>        if(intent !=null)<br>        {<br>            byte [] bis=intent.getByteArrayExtra(“bitmap”);<br>            Bitmap bitmap=BitmapFactory.decodeByteArray(bis, 0, bis.length);<br>            imageView.setImageBitmap(bitmap);<br>        }<br>取出来字节数组之后，用BitmapFactory中的decodeByteArray方法组合成一个bitmap就可以了。<br>再加上一个存储的代码：</p>\n<p>public void saveMyBitmap(String bitName,Bitmap mBitmap) throws IOException {<br>        File f = new File(“/sdcard/Note/“ + bitName);<br>        if(!f.exists())<br>            f.mkdirs();//如果没有这个文件夹的话，会报file not found错误<br>        f=new File(“/sdcard/Note/“+bitName+”.png”);<br>        f.createNewFile();<br>        try {<br>            FileOutputStream out = new FileOutputStream(f);<br>             mBitmap.compress(Bitmap.CompressFormat.PNG, 100, out);<br>             out.flush();<br>             out.close();<br>        } catch (FileNotFoundException e) {<br>                Log.i(TAG,e.toString());<br>        }  </p>\n<pre><code>&#125;  \n</code></pre>\n<p>2.传递map对象：</p>\n<p>封装到bundle中：</p>\n<p>Map&lt;String,Object&gt; data=orderlist.get(arg2-1);<br>            SerializableMap tmpmap=new SerializableMap();<br>            tmpmap.setMap(data);<br>            bundle.putSerializable(“orderinfo”, tmpmap);<br>            intent.putExtras(bundle);  </p>\n<p>这个SeralizableMap是自己封装的一个实现了Serializable接口的类：<br>public class SerializableMap implements Serializable {<br>    private Map&lt;String,Object&gt; map;<br>    public Map&lt;String,Object&gt; getMap()<br>    {<br>        return map;<br>    }<br>    public void setMap(Map&lt;String,Object&gt; map)<br>    {<br>        this.map=map;<br>    }<br>}<br>这样才能把map对象扔到bundle中去，<br>取出来的方法是：</p>\n<p>Bundle bundle = getIntent().getExtras();<br>        SerializableMap serializableMap = (SerializableMap) bundle<br>                .get(“orderinfo”);  </p>\n","site":{"data":{}},"excerpt":"<p>摘要:安卓传递数据</p>","more":"<p>正文:面试的时候遇到这个，记下来以后可以用，之前没有用过</p>\n<p>第一个：传递bitmap</p>\n<p>  这个问题非常奇葩（可能我Android水平还不够），居然不会报错，我是直接用bundle或Intent的extral域直接存放bitmap，结果运行时各种宕机，各种界面乱窜（我非常的纳闷）。。。搜索之后看大家都说不能直接传递大于40k的图片，然后在德问论坛上找到了解法。就是把bitmap存储为byte数组，然后再通过Intent传递。</p>\n<p>的 </p>\n<p> 代码如下所示：</p>\n<p>Bitmap bmp=((BitmapDrawable)order_con_pic.getDrawable()).getBitmap();<br>Intent intent=new Intent(OrderConfirm.this,ShowWebImageActivity.class);<br>ByteArrayOutputStream baos=new ByteArrayOutputStream();<br>bmp.compress(Bitmap.CompressFormat.PNG, 100, baos);<br>byte [] bitmapByte =baos.toByteArray();<br>intent.putExtra(“bitmap”, bitmapByte);<br>startActivity(intent);  </p>\n<p>其中 第一行代码就是如何从一个imageview中获得其图片，这个问题也倒腾了下，貌似用setDrawingCacheEnabled也行，因为开始用的这个方法，但是直接在activity之间传递bitmap，所以导致运行时错误，后来改正之后没有再尝试。<br>先new一个ByteArrayOutputStream流，然后使用Bitmap中的compress方法，把数据压缩到一个byte中，传输就可以了。</p>\n<p>在另一个activity中取出来的方法是：</p>\n<p>imageView = (ZoomableImageView) findViewById(R.id.show_webimage_imageview);<br>        Intent intent=getIntent();<br>        if(intent !=null)<br>        {<br>            byte [] bis=intent.getByteArrayExtra(“bitmap”);<br>            Bitmap bitmap=BitmapFactory.decodeByteArray(bis, 0, bis.length);<br>            imageView.setImageBitmap(bitmap);<br>        }<br>取出来字节数组之后，用BitmapFactory中的decodeByteArray方法组合成一个bitmap就可以了。<br>再加上一个存储的代码：</p>\n<p>public void saveMyBitmap(String bitName,Bitmap mBitmap) throws IOException {<br>        File f = new File(“/sdcard/Note/“ + bitName);<br>        if(!f.exists())<br>            f.mkdirs();//如果没有这个文件夹的话，会报file not found错误<br>        f=new File(“/sdcard/Note/“+bitName+”.png”);<br>        f.createNewFile();<br>        try {<br>            FileOutputStream out = new FileOutputStream(f);<br>             mBitmap.compress(Bitmap.CompressFormat.PNG, 100, out);<br>             out.flush();<br>             out.close();<br>        } catch (FileNotFoundException e) {<br>                Log.i(TAG,e.toString());<br>        }  </p>\n<pre><code>&#125;  \n</code></pre>\n<p>2.传递map对象：</p>\n<p>封装到bundle中：</p>\n<p>Map&lt;String,Object&gt; data=orderlist.get(arg2-1);<br>            SerializableMap tmpmap=new SerializableMap();<br>            tmpmap.setMap(data);<br>            bundle.putSerializable(“orderinfo”, tmpmap);<br>            intent.putExtras(bundle);  </p>\n<p>这个SeralizableMap是自己封装的一个实现了Serializable接口的类：<br>public class SerializableMap implements Serializable {<br>    private Map&lt;String,Object&gt; map;<br>    public Map&lt;String,Object&gt; getMap()<br>    {<br>        return map;<br>    }<br>    public void setMap(Map&lt;String,Object&gt; map)<br>    {<br>        this.map=map;<br>    }<br>}<br>这样才能把map对象扔到bundle中去，<br>取出来的方法是：</p>\n<p>Bundle bundle = getIntent().getExtras();<br>        SerializableMap serializableMap = (SerializableMap) bundle<br>                .get(“orderinfo”);  </p>"},{"date":"2016-12-23T03:35:00.000Z","status":"public","title":"压缩图片单例Util","_content":"\n摘要:压缩图片的工具类，内存经常由于图片占用空间大而内存溢出，有了这个压缩最起码会好好多。\n<!--more-->\npublic class ZipUtil {\nprivate static ZipUtil instance;\nprivate ZipUtil() {\n}\npublic static synchronized ZipUtil getInstance() {\nif (instance == null) {\n    instance = new ZipUtil();\n}\n    return instance;\n}\nprivate File compressImage(Bitmap image) {  \n        ByteArrayOutputStream baos = new ByteArrayOutputStream();  \n        image.compress(Bitmap.CompressFormat.JPEG, 100, baos);//质量压缩方法，这里100表示          不压缩，把压缩后的数据存放到baos中  \n        int options = 100;  \n        while ( baos.toByteArray().length / 1024>200) {  //循环判断如果压缩后图片是否大于200kb,大于继续压缩         \n            baos.reset();//重置baos即清空baos  \n            image.compress(Bitmap.CompressFormat.JPEG, options, baos);//这里压缩options%，把压缩后的数据存放到baos中  \n            options -= 10;//每次都减少10  \n        }\n//        ByteArrayInputStream isBm = new ByteArrayInputStream(baos.toByteArray());//把压缩后的数据baos存放到ByteArrayInputStream中  \n//        Bitmap bitmap = BitmapFactory.decodeStream(isBm, null, null);//把ByteArrayInputStream数据生成图片  \n        new DateFormat();  \n        String name = DateFormat.format(\"yyyyMMdd_hhmmss\",Calendar.getInstance(Locale.CHINA)) + \".JPEG\";   \n        File f = new File( \"/sdcard/Image/\"+name);\n        try {  \n            FileOutputStream fos = new FileOutputStream(f);  \n            fos.write(baos.toByteArray());  \n            fos.flush();  \n            fos.close();  \n        } catch (Exception e) {  \n            e.printStackTrace();  \n        }  \n        return f;  \n    }  \npublic File getimage(String srcPath) {  \n        BitmapFactory.Options newOpts = new BitmapFactory.Options();  \n        //开始读入图片，此时把options.inJustDecodeBounds 设回true了  \n        newOpts.inJustDecodeBounds = true;  \n        Bitmap bitmap = BitmapFactory.decodeFile(srcPath,newOpts);//此时返回bm为空  \n        newOpts.inJustDecodeBounds = false;  \n        int w = newOpts.outWidth;  \n        int h = newOpts.outHeight;  \n        //现在主流手机比较多是800*480分辨率，所以高和宽我们设置为  \n        float hh = 800f;//这里设置高度为800f  \n        float ww = 480f;//这里设置宽度为480f  \n        //缩放比。由于是固定比例缩放，只用高或者宽其中一个数据进行计算即可  \n        int be = 1;//be=1表示不缩放  \n        if (w > h && w > ww) {//如果宽度大的话根据宽度固定大小缩放  \n            be = (int) (newOpts.outWidth / ww);  \n        } else if (w < h && h > hh) {//如果高度高的话根据宽度固定大小缩放  \n            be = (int) (newOpts.outHeight / hh);  \n        }  \n        if (be <= 0)  \n            be = 1;  \n        newOpts.inSampleSize = be;//设置缩放比例  \n        //重新读入图片，注意此时已经把options.inJustDecodeBounds 设回false了  \n        bitmap = BitmapFactory.decodeFile(srcPath, newOpts);  \n        return compressImage(bitmap);//压缩好比例大小后再进行质量压缩  \n    }  \n}","source":"_posts/android/ZipUtil.md","raw":"---\ndate: 2016-12-23 11:35\nstatus: public\ntitle: 压缩图片单例Util\ntags:\n  - 安卓\n---\n\n摘要:压缩图片的工具类，内存经常由于图片占用空间大而内存溢出，有了这个压缩最起码会好好多。\n<!--more-->\npublic class ZipUtil {\nprivate static ZipUtil instance;\nprivate ZipUtil() {\n}\npublic static synchronized ZipUtil getInstance() {\nif (instance == null) {\n    instance = new ZipUtil();\n}\n    return instance;\n}\nprivate File compressImage(Bitmap image) {  \n        ByteArrayOutputStream baos = new ByteArrayOutputStream();  \n        image.compress(Bitmap.CompressFormat.JPEG, 100, baos);//质量压缩方法，这里100表示          不压缩，把压缩后的数据存放到baos中  \n        int options = 100;  \n        while ( baos.toByteArray().length / 1024>200) {  //循环判断如果压缩后图片是否大于200kb,大于继续压缩         \n            baos.reset();//重置baos即清空baos  \n            image.compress(Bitmap.CompressFormat.JPEG, options, baos);//这里压缩options%，把压缩后的数据存放到baos中  \n            options -= 10;//每次都减少10  \n        }\n//        ByteArrayInputStream isBm = new ByteArrayInputStream(baos.toByteArray());//把压缩后的数据baos存放到ByteArrayInputStream中  \n//        Bitmap bitmap = BitmapFactory.decodeStream(isBm, null, null);//把ByteArrayInputStream数据生成图片  \n        new DateFormat();  \n        String name = DateFormat.format(\"yyyyMMdd_hhmmss\",Calendar.getInstance(Locale.CHINA)) + \".JPEG\";   \n        File f = new File( \"/sdcard/Image/\"+name);\n        try {  \n            FileOutputStream fos = new FileOutputStream(f);  \n            fos.write(baos.toByteArray());  \n            fos.flush();  \n            fos.close();  \n        } catch (Exception e) {  \n            e.printStackTrace();  \n        }  \n        return f;  \n    }  \npublic File getimage(String srcPath) {  \n        BitmapFactory.Options newOpts = new BitmapFactory.Options();  \n        //开始读入图片，此时把options.inJustDecodeBounds 设回true了  \n        newOpts.inJustDecodeBounds = true;  \n        Bitmap bitmap = BitmapFactory.decodeFile(srcPath,newOpts);//此时返回bm为空  \n        newOpts.inJustDecodeBounds = false;  \n        int w = newOpts.outWidth;  \n        int h = newOpts.outHeight;  \n        //现在主流手机比较多是800*480分辨率，所以高和宽我们设置为  \n        float hh = 800f;//这里设置高度为800f  \n        float ww = 480f;//这里设置宽度为480f  \n        //缩放比。由于是固定比例缩放，只用高或者宽其中一个数据进行计算即可  \n        int be = 1;//be=1表示不缩放  \n        if (w > h && w > ww) {//如果宽度大的话根据宽度固定大小缩放  \n            be = (int) (newOpts.outWidth / ww);  \n        } else if (w < h && h > hh) {//如果高度高的话根据宽度固定大小缩放  \n            be = (int) (newOpts.outHeight / hh);  \n        }  \n        if (be <= 0)  \n            be = 1;  \n        newOpts.inSampleSize = be;//设置缩放比例  \n        //重新读入图片，注意此时已经把options.inJustDecodeBounds 设回false了  \n        bitmap = BitmapFactory.decodeFile(srcPath, newOpts);  \n        return compressImage(bitmap);//压缩好比例大小后再进行质量压缩  \n    }  \n}","slug":"android/ZipUtil","published":1,"updated":"2025-05-16T04:25:25.417Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jri000dskqrcwpf6w7s","content":"<p>摘要:压缩图片的工具类，内存经常由于图片占用空间大而内存溢出，有了这个压缩最起码会好好多。</p>\n<span id=\"more\"></span>\n<p>public class ZipUtil {<br>private static ZipUtil instance;<br>private ZipUtil() {<br>}<br>public static synchronized ZipUtil getInstance() {<br>if (instance == null) {<br>    instance = new ZipUtil();<br>}<br>    return instance;<br>}<br>private File compressImage(Bitmap image) {<br>        ByteArrayOutputStream baos = new ByteArrayOutputStream();<br>        image.compress(Bitmap.CompressFormat.JPEG, 100, baos);//质量压缩方法，这里100表示          不压缩，把压缩后的数据存放到baos中<br>        int options = 100;<br>        while ( baos.toByteArray().length / 1024&gt;200) {  //循环判断如果压缩后图片是否大于200kb,大于继续压缩<br>            baos.reset();//重置baos即清空baos<br>            image.compress(Bitmap.CompressFormat.JPEG, options, baos);//这里压缩options%，把压缩后的数据存放到baos中<br>            options -= 10;//每次都减少10<br>        }<br>//        ByteArrayInputStream isBm = new ByteArrayInputStream(baos.toByteArray());//把压缩后的数据baos存放到ByteArrayInputStream中<br>//        Bitmap bitmap = BitmapFactory.decodeStream(isBm, null, null);//把ByteArrayInputStream数据生成图片<br>        new DateFormat();<br>        String name = DateFormat.format(“yyyyMMdd_hhmmss”,Calendar.getInstance(Locale.CHINA)) + “.JPEG”;<br>        File f = new File( “/sdcard/Image/“+name);<br>        try {<br>            FileOutputStream fos = new FileOutputStream(f);<br>            fos.write(baos.toByteArray());<br>            fos.flush();<br>            fos.close();<br>        } catch (Exception e) {<br>            e.printStackTrace();<br>        }<br>        return f;<br>    }<br>public File getimage(String srcPath) {<br>        BitmapFactory.Options newOpts = new BitmapFactory.Options();<br>        //开始读入图片，此时把options.inJustDecodeBounds 设回true了<br>        newOpts.inJustDecodeBounds = true;<br>        Bitmap bitmap = BitmapFactory.decodeFile(srcPath,newOpts);//此时返回bm为空<br>        newOpts.inJustDecodeBounds = false;<br>        int w = newOpts.outWidth;<br>        int h = newOpts.outHeight;<br>        //现在主流手机比较多是800*480分辨率，所以高和宽我们设置为<br>        float hh = 800f;//这里设置高度为800f<br>        float ww = 480f;//这里设置宽度为480f<br>        //缩放比。由于是固定比例缩放，只用高或者宽其中一个数据进行计算即可<br>        int be = 1;//be=1表示不缩放<br>        if (w &gt; h &amp;&amp; w &gt; ww) {//如果宽度大的话根据宽度固定大小缩放<br>            be = (int) (newOpts.outWidth / ww);<br>        } else if (w &lt; h &amp;&amp; h &gt; hh) {//如果高度高的话根据宽度固定大小缩放<br>            be = (int) (newOpts.outHeight / hh);<br>        }<br>        if (be &lt;= 0)<br>            be = 1;<br>        newOpts.inSampleSize = be;//设置缩放比例<br>        //重新读入图片，注意此时已经把options.inJustDecodeBounds 设回false了<br>        bitmap = BitmapFactory.decodeFile(srcPath, newOpts);<br>        return compressImage(bitmap);//压缩好比例大小后再进行质量压缩<br>    }<br>}</p>\n","site":{"data":{}},"excerpt":"<p>摘要:压缩图片的工具类，内存经常由于图片占用空间大而内存溢出，有了这个压缩最起码会好好多。</p>","more":"<p>public class ZipUtil {<br>private static ZipUtil instance;<br>private ZipUtil() {<br>}<br>public static synchronized ZipUtil getInstance() {<br>if (instance == null) {<br>    instance = new ZipUtil();<br>}<br>    return instance;<br>}<br>private File compressImage(Bitmap image) {<br>        ByteArrayOutputStream baos = new ByteArrayOutputStream();<br>        image.compress(Bitmap.CompressFormat.JPEG, 100, baos);//质量压缩方法，这里100表示          不压缩，把压缩后的数据存放到baos中<br>        int options = 100;<br>        while ( baos.toByteArray().length / 1024&gt;200) {  //循环判断如果压缩后图片是否大于200kb,大于继续压缩<br>            baos.reset();//重置baos即清空baos<br>            image.compress(Bitmap.CompressFormat.JPEG, options, baos);//这里压缩options%，把压缩后的数据存放到baos中<br>            options -= 10;//每次都减少10<br>        }<br>//        ByteArrayInputStream isBm = new ByteArrayInputStream(baos.toByteArray());//把压缩后的数据baos存放到ByteArrayInputStream中<br>//        Bitmap bitmap = BitmapFactory.decodeStream(isBm, null, null);//把ByteArrayInputStream数据生成图片<br>        new DateFormat();<br>        String name = DateFormat.format(“yyyyMMdd_hhmmss”,Calendar.getInstance(Locale.CHINA)) + “.JPEG”;<br>        File f = new File( “/sdcard/Image/“+name);<br>        try {<br>            FileOutputStream fos = new FileOutputStream(f);<br>            fos.write(baos.toByteArray());<br>            fos.flush();<br>            fos.close();<br>        } catch (Exception e) {<br>            e.printStackTrace();<br>        }<br>        return f;<br>    }<br>public File getimage(String srcPath) {<br>        BitmapFactory.Options newOpts = new BitmapFactory.Options();<br>        //开始读入图片，此时把options.inJustDecodeBounds 设回true了<br>        newOpts.inJustDecodeBounds = true;<br>        Bitmap bitmap = BitmapFactory.decodeFile(srcPath,newOpts);//此时返回bm为空<br>        newOpts.inJustDecodeBounds = false;<br>        int w = newOpts.outWidth;<br>        int h = newOpts.outHeight;<br>        //现在主流手机比较多是800*480分辨率，所以高和宽我们设置为<br>        float hh = 800f;//这里设置高度为800f<br>        float ww = 480f;//这里设置宽度为480f<br>        //缩放比。由于是固定比例缩放，只用高或者宽其中一个数据进行计算即可<br>        int be = 1;//be=1表示不缩放<br>        if (w &gt; h &amp;&amp; w &gt; ww) {//如果宽度大的话根据宽度固定大小缩放<br>            be = (int) (newOpts.outWidth / ww);<br>        } else if (w &lt; h &amp;&amp; h &gt; hh) {//如果高度高的话根据宽度固定大小缩放<br>            be = (int) (newOpts.outHeight / hh);<br>        }<br>        if (be &lt;= 0)<br>            be = 1;<br>        newOpts.inSampleSize = be;//设置缩放比例<br>        //重新读入图片，注意此时已经把options.inJustDecodeBounds 设回false了<br>        bitmap = BitmapFactory.decodeFile(srcPath, newOpts);<br>        return compressImage(bitmap);//压缩好比例大小后再进行质量压缩<br>    }<br>}</p>"},{"date":"2017-07-13T03:35:00.000Z","status":"public","title":"安卓嵌套listview gridview","_content":"\n摘要:经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用\n<!--more-->\n\n经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用\n但是实际试过之后就会发现这样做有一个问题，无论ListView的高度怎么设置，\n都会只显示一行的高度，那是由于ListView的父容器测量模式为UNSPECIFIED的时候，gridviewView的高度默认为一个item的高度，这样我们就重写ListView的onMeasure方法，来自定义高度：\n\n\tpublic class FixedGridView extends GridView {\n\tpublic boolean onMeasure = false;//用于判断的布尔值，只有完成计算，即onLayout后才为false,在onMeasure时为true\n\tpublic FixedGridView(Context context)\n\t{\n\t\tsuper(context);\n\t}\n\n\tpublic FixedGridView(Context context, AttributeSet attrs)\n\t{\n\t\tsuper(context, attrs);\n\t}\n\t\n\tpublic FixedGridView(Context context, AttributeSet attrs, int defStyle)\n\t{\n\t\tsuper(context, attrs, defStyle);\n\t}\n\t//无论ListView的高度怎么设置，都会只显示一行的高度，那是由于ListView对于父容器测量模式为UNSPECIFIED时\n\t// ListView的父容器测量模式为UNSPECIFIED的时候，ListView的高度默认为一个item的高度\n\t//在measure里面重新计算一下高度 动态设置一下高度就可以了\n\t@Override       \n    public void onMeasure(int widthMeasureSpec, int heightMeasureSpec)\n\t{       \n\t\tonMeasure = true;\n        int expandSpec = MeasureSpec.makeMeasureSpec(Integer.MAX_VALUE >> 2, MeasureSpec.AT_MOST);       \n        super.onMeasure(widthMeasureSpec, expandSpec + 4);       \n    }  \n\t@Override\n\tprotected void onLayout(boolean changed, int l, int t, int r, int b) {\n\t\tonMeasure = false;\n\t\tsuper.onLayout(changed, l, t, r, b);\n\t}\n\t好了 大功告成，这样子嵌套在listview就不会说只是显示一个item的高度啦 ","source":"_posts/android/安卓listview嵌套gridview.md","raw":"---\ndate: 2017-7-13 11:35\nstatus: public\ntitle: 安卓嵌套listview gridview\ntags:\n  - 安卓\n---\n\n摘要:经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用\n<!--more-->\n\n经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用\n但是实际试过之后就会发现这样做有一个问题，无论ListView的高度怎么设置，\n都会只显示一行的高度，那是由于ListView的父容器测量模式为UNSPECIFIED的时候，gridviewView的高度默认为一个item的高度，这样我们就重写ListView的onMeasure方法，来自定义高度：\n\n\tpublic class FixedGridView extends GridView {\n\tpublic boolean onMeasure = false;//用于判断的布尔值，只有完成计算，即onLayout后才为false,在onMeasure时为true\n\tpublic FixedGridView(Context context)\n\t{\n\t\tsuper(context);\n\t}\n\n\tpublic FixedGridView(Context context, AttributeSet attrs)\n\t{\n\t\tsuper(context, attrs);\n\t}\n\t\n\tpublic FixedGridView(Context context, AttributeSet attrs, int defStyle)\n\t{\n\t\tsuper(context, attrs, defStyle);\n\t}\n\t//无论ListView的高度怎么设置，都会只显示一行的高度，那是由于ListView对于父容器测量模式为UNSPECIFIED时\n\t// ListView的父容器测量模式为UNSPECIFIED的时候，ListView的高度默认为一个item的高度\n\t//在measure里面重新计算一下高度 动态设置一下高度就可以了\n\t@Override       \n    public void onMeasure(int widthMeasureSpec, int heightMeasureSpec)\n\t{       \n\t\tonMeasure = true;\n        int expandSpec = MeasureSpec.makeMeasureSpec(Integer.MAX_VALUE >> 2, MeasureSpec.AT_MOST);       \n        super.onMeasure(widthMeasureSpec, expandSpec + 4);       \n    }  \n\t@Override\n\tprotected void onLayout(boolean changed, int l, int t, int r, int b) {\n\t\tonMeasure = false;\n\t\tsuper.onLayout(changed, l, t, r, b);\n\t}\n\t好了 大功告成，这样子嵌套在listview就不会说只是显示一个item的高度啦 ","slug":"android/安卓listview嵌套gridview","published":1,"updated":"2025-05-16T04:25:25.434Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrj000gskqr4bwu4rd9","content":"<p>摘要:经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用</p>\n<span id=\"more\"></span>\n\n<p>经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用<br>但是实际试过之后就会发现这样做有一个问题，无论ListView的高度怎么设置，<br>都会只显示一行的高度，那是由于ListView的父容器测量模式为UNSPECIFIED的时候，gridviewView的高度默认为一个item的高度，这样我们就重写ListView的onMeasure方法，来自定义高度：</p>\n<pre><code>public class FixedGridView extends GridView &#123;\npublic boolean onMeasure = false;//用于判断的布尔值，只有完成计算，即onLayout后才为false,在onMeasure时为true\npublic FixedGridView(Context context)\n&#123;\n    super(context);\n&#125;\n\npublic FixedGridView(Context context, AttributeSet attrs)\n&#123;\n    super(context, attrs);\n&#125;\n\npublic FixedGridView(Context context, AttributeSet attrs, int defStyle)\n&#123;\n    super(context, attrs, defStyle);\n&#125;\n//无论ListView的高度怎么设置，都会只显示一行的高度，那是由于ListView对于父容器测量模式为UNSPECIFIED时\n// ListView的父容器测量模式为UNSPECIFIED的时候，ListView的高度默认为一个item的高度\n//在measure里面重新计算一下高度 动态设置一下高度就可以了\n@Override       \npublic void onMeasure(int widthMeasureSpec, int heightMeasureSpec)\n&#123;       \n    onMeasure = true;\n    int expandSpec = MeasureSpec.makeMeasureSpec(Integer.MAX_VALUE &gt;&gt; 2, MeasureSpec.AT_MOST);       \n    super.onMeasure(widthMeasureSpec, expandSpec + 4);       \n&#125;  \n@Override\nprotected void onLayout(boolean changed, int l, int t, int r, int b) &#123;\n    onMeasure = false;\n    super.onLayout(changed, l, t, r, b);\n&#125;\n好了 大功告成，这样子嵌套在listview就不会说只是显示一个item的高度啦 \n</code></pre>\n","site":{"data":{}},"excerpt":"<p>摘要:经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用</p>","more":"<p>经常在做安卓的时候会有这样的需求，listview嵌套gridview来使用<br>但是实际试过之后就会发现这样做有一个问题，无论ListView的高度怎么设置，<br>都会只显示一行的高度，那是由于ListView的父容器测量模式为UNSPECIFIED的时候，gridviewView的高度默认为一个item的高度，这样我们就重写ListView的onMeasure方法，来自定义高度：</p>\n<pre><code>public class FixedGridView extends GridView &#123;\npublic boolean onMeasure = false;//用于判断的布尔值，只有完成计算，即onLayout后才为false,在onMeasure时为true\npublic FixedGridView(Context context)\n&#123;\n    super(context);\n&#125;\n\npublic FixedGridView(Context context, AttributeSet attrs)\n&#123;\n    super(context, attrs);\n&#125;\n\npublic FixedGridView(Context context, AttributeSet attrs, int defStyle)\n&#123;\n    super(context, attrs, defStyle);\n&#125;\n//无论ListView的高度怎么设置，都会只显示一行的高度，那是由于ListView对于父容器测量模式为UNSPECIFIED时\n// ListView的父容器测量模式为UNSPECIFIED的时候，ListView的高度默认为一个item的高度\n//在measure里面重新计算一下高度 动态设置一下高度就可以了\n@Override       \npublic void onMeasure(int widthMeasureSpec, int heightMeasureSpec)\n&#123;       \n    onMeasure = true;\n    int expandSpec = MeasureSpec.makeMeasureSpec(Integer.MAX_VALUE &gt;&gt; 2, MeasureSpec.AT_MOST);       \n    super.onMeasure(widthMeasureSpec, expandSpec + 4);       \n&#125;  \n@Override\nprotected void onLayout(boolean changed, int l, int t, int r, int b) &#123;\n    onMeasure = false;\n    super.onLayout(changed, l, t, r, b);\n&#125;\n好了 大功告成，这样子嵌套在listview就不会说只是显示一个item的高度啦 \n</code></pre>"},{"date":"2017-03-02T03:35:00.000Z","status":"public","title":"安卓抽象布局--include、merge 、ViewStub","_content":"\n摘要:经常在做安卓的时候会用到这些东西，这些东西使得你加载的速度快了不止一倍\n<!--more-->\n在布局优化中，Android官方提到了这三种布局 include、merge、ViewStub，并介绍了这三种布局各有的优势，下面也是简单说一下他们的优势，以及怎么使用，记下来权当做笔记。\n\n1、布局重用include 使用如下：    \n\t  LinearLayout \n\t\t\t\txmlns:android=\"http://schemas.android.com/apk/res/android\"  \n\t\t    android:orientation=\"vertical\"   \n\t\t    android:layout_width=\"match_parent\"  \n\t\t    android:layout_height=\"match_parent\"  \n\t\t    android:background=\"@color/app_bg\"  \n\t\t    android:gravity=\"center_horizontal\">  \n\t\t  \n\t\t    <include layout=\"@layout/titlebar\"/>  \n\t\t  \n\t\t    <TextView android:layout_width=”match_parent”  \n\t\t              android:layout_height=\"wrap_content\"  \n\t\t              android:text=\"@string/hello\"  \n\t\t              android:padding=\"10dp\" />  \n\t\tLinearLayout \n好处：我们写一个通用布局的时候可以用include重用，不至于写多遍，\n比如布局一个APP的顶部布局、侧边栏布局、底部Tab栏布局、ListView和GridView每一项的布局将这些同一个APP中有多个界面用到的布局抽取出来再通过include标签引用，既可以降低layout的复杂度，又可以做到布局重用\n\n2、减少视图层级merge使用如下：  \n\t\tmerge \n\t\txmlns:android=\"http://schemas.android.com/apk/res/android\">  \n\t\t  \n\t\t    <Button  \n\t\t        android:layout_width=\"fill_parent\"   \n\t\t        android:layout_height=\"wrap_content\"  \n\t\t        android:text=\"@string/add\"/>  \n\t\t  \n\t\t    <Button  \n\t\t        android:layout_width=\"fill_parent\"   \n\t\t        android:layout_height=\"wrap_content\"  \n\t\t        android:text=\"@string/delete\"/>  \n\t\t  \n\t\tmerge   \n好处：可以删减多余的层级，优化UI，从而减少视图在绘制过程消耗的时间，达到提高UI性能的效果。\n\n3、需要时使用ViewStub 使用如下：  \n\t\tViewStub  \n\t\t    android:id=\"@+id/stub_import\"  \n\t\t    android:inflatedId=\"@+id/panel_import\"  \n\t\t    android:layout=\"@layout/progress_overlay\"  \n\t\t    android:layout_width=\"fill_parent\"  \n\t\t    android:layout_height=\"wrap_content\"  \n\t\t    android:layout_gravity=\"bottom\"   />  \n好处：最大的优点是当你需要时才会加载，他并不会影响UI初始化时的性能，各种不常用的布局想进度条、显示错误消息等可以使用<ViewStub />标签，以减少内存使用量，加快渲染速度。<ViewStub />是一个不可见的，大小为0的View。\n\n","source":"_posts/android/安卓抽象布局.md","raw":"---\ndate: 2017-3-2 11:35\nstatus: public\ntitle: 安卓抽象布局--include、merge 、ViewStub\ntags:\n  - 安卓\n---\n\n摘要:经常在做安卓的时候会用到这些东西，这些东西使得你加载的速度快了不止一倍\n<!--more-->\n在布局优化中，Android官方提到了这三种布局 include、merge、ViewStub，并介绍了这三种布局各有的优势，下面也是简单说一下他们的优势，以及怎么使用，记下来权当做笔记。\n\n1、布局重用include 使用如下：    \n\t  LinearLayout \n\t\t\t\txmlns:android=\"http://schemas.android.com/apk/res/android\"  \n\t\t    android:orientation=\"vertical\"   \n\t\t    android:layout_width=\"match_parent\"  \n\t\t    android:layout_height=\"match_parent\"  \n\t\t    android:background=\"@color/app_bg\"  \n\t\t    android:gravity=\"center_horizontal\">  \n\t\t  \n\t\t    <include layout=\"@layout/titlebar\"/>  \n\t\t  \n\t\t    <TextView android:layout_width=”match_parent”  \n\t\t              android:layout_height=\"wrap_content\"  \n\t\t              android:text=\"@string/hello\"  \n\t\t              android:padding=\"10dp\" />  \n\t\tLinearLayout \n好处：我们写一个通用布局的时候可以用include重用，不至于写多遍，\n比如布局一个APP的顶部布局、侧边栏布局、底部Tab栏布局、ListView和GridView每一项的布局将这些同一个APP中有多个界面用到的布局抽取出来再通过include标签引用，既可以降低layout的复杂度，又可以做到布局重用\n\n2、减少视图层级merge使用如下：  \n\t\tmerge \n\t\txmlns:android=\"http://schemas.android.com/apk/res/android\">  \n\t\t  \n\t\t    <Button  \n\t\t        android:layout_width=\"fill_parent\"   \n\t\t        android:layout_height=\"wrap_content\"  \n\t\t        android:text=\"@string/add\"/>  \n\t\t  \n\t\t    <Button  \n\t\t        android:layout_width=\"fill_parent\"   \n\t\t        android:layout_height=\"wrap_content\"  \n\t\t        android:text=\"@string/delete\"/>  \n\t\t  \n\t\tmerge   \n好处：可以删减多余的层级，优化UI，从而减少视图在绘制过程消耗的时间，达到提高UI性能的效果。\n\n3、需要时使用ViewStub 使用如下：  \n\t\tViewStub  \n\t\t    android:id=\"@+id/stub_import\"  \n\t\t    android:inflatedId=\"@+id/panel_import\"  \n\t\t    android:layout=\"@layout/progress_overlay\"  \n\t\t    android:layout_width=\"fill_parent\"  \n\t\t    android:layout_height=\"wrap_content\"  \n\t\t    android:layout_gravity=\"bottom\"   />  \n好处：最大的优点是当你需要时才会加载，他并不会影响UI初始化时的性能，各种不常用的布局想进度条、显示错误消息等可以使用<ViewStub />标签，以减少内存使用量，加快渲染速度。<ViewStub />是一个不可见的，大小为0的View。\n\n","slug":"android/安卓抽象布局","published":1,"updated":"2025-05-16T04:25:25.436Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrm000iskqr74u3eux0","content":"<p>摘要:经常在做安卓的时候会用到这些东西，这些东西使得你加载的速度快了不止一倍</p>\n<span id=\"more\"></span>\n<p>在布局优化中，Android官方提到了这三种布局 include、merge、ViewStub，并介绍了这三种布局各有的优势，下面也是简单说一下他们的优势，以及怎么使用，记下来权当做笔记。</p>\n<p>1、布局重用include 使用如下：<br>      LinearLayout<br>                xmlns:android=”<a href=\"http://schemas.android.com/apk/res/android&quot;\">http://schemas.android.com/apk/res/android&quot;</a><br>            android:orientation=”vertical”<br>            android:layout_width=”match_parent”<br>            android:layout_height=”match_parent”<br>            android:background=”@color/app_bg”<br>            android:gravity=”center_horizontal”&gt;  </p>\n<pre><code>        &lt;include layout=&quot;@layout/titlebar&quot;/&gt;  \n      \n        &lt;TextView android:layout_width=”match_parent”  \n                  android:layout_height=&quot;wrap_content&quot;  \n                  android:text=&quot;@string/hello&quot;  \n                  android:padding=&quot;10dp&quot; /&gt;  \n    LinearLayout \n</code></pre>\n<p>好处：我们写一个通用布局的时候可以用include重用，不至于写多遍，<br>比如布局一个APP的顶部布局、侧边栏布局、底部Tab栏布局、ListView和GridView每一项的布局将这些同一个APP中有多个界面用到的布局抽取出来再通过include标签引用，既可以降低layout的复杂度，又可以做到布局重用</p>\n<p>2、减少视图层级merge使用如下：<br>        merge<br>        xmlns:android=”<a href=\"http://schemas.android.com/apk/res/android&quot;&gt;\">http://schemas.android.com/apk/res/android&quot;&gt;</a>  </p>\n<pre><code>        &lt;Button  \n            android:layout_width=&quot;fill_parent&quot;   \n            android:layout_height=&quot;wrap_content&quot;  \n            android:text=&quot;@string/add&quot;/&gt;  \n      \n        &lt;Button  \n            android:layout_width=&quot;fill_parent&quot;   \n            android:layout_height=&quot;wrap_content&quot;  \n            android:text=&quot;@string/delete&quot;/&gt;  \n      \n    merge   \n</code></pre>\n<p>好处：可以删减多余的层级，优化UI，从而减少视图在绘制过程消耗的时间，达到提高UI性能的效果。</p>\n<p>3、需要时使用ViewStub 使用如下：<br>        ViewStub<br>            android:id=”@+id/stub_import”<br>            android:inflatedId=”@+id/panel_import”<br>            android:layout=”@layout/progress_overlay”<br>            android:layout_width=”fill_parent”<br>            android:layout_height=”wrap_content”<br>            android:layout_gravity=”bottom”   /&gt;<br>好处：最大的优点是当你需要时才会加载，他并不会影响UI初始化时的性能，各种不常用的布局想进度条、显示错误消息等可以使用<ViewStub />标签，以减少内存使用量，加快渲染速度。<ViewStub />是一个不可见的，大小为0的View。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:经常在做安卓的时候会用到这些东西，这些东西使得你加载的速度快了不止一倍</p>","more":"<p>在布局优化中，Android官方提到了这三种布局 include、merge、ViewStub，并介绍了这三种布局各有的优势，下面也是简单说一下他们的优势，以及怎么使用，记下来权当做笔记。</p>\n<p>1、布局重用include 使用如下：<br>      LinearLayout<br>                xmlns:android=”<a href=\"http://schemas.android.com/apk/res/android&quot;\">http://schemas.android.com/apk/res/android&quot;</a><br>            android:orientation=”vertical”<br>            android:layout_width=”match_parent”<br>            android:layout_height=”match_parent”<br>            android:background=”@color/app_bg”<br>            android:gravity=”center_horizontal”&gt;  </p>\n<pre><code>        &lt;include layout=&quot;@layout/titlebar&quot;/&gt;  \n      \n        &lt;TextView android:layout_width=”match_parent”  \n                  android:layout_height=&quot;wrap_content&quot;  \n                  android:text=&quot;@string/hello&quot;  \n                  android:padding=&quot;10dp&quot; /&gt;  \n    LinearLayout \n</code></pre>\n<p>好处：我们写一个通用布局的时候可以用include重用，不至于写多遍，<br>比如布局一个APP的顶部布局、侧边栏布局、底部Tab栏布局、ListView和GridView每一项的布局将这些同一个APP中有多个界面用到的布局抽取出来再通过include标签引用，既可以降低layout的复杂度，又可以做到布局重用</p>\n<p>2、减少视图层级merge使用如下：<br>        merge<br>        xmlns:android=”<a href=\"http://schemas.android.com/apk/res/android&quot;&gt;\">http://schemas.android.com/apk/res/android&quot;&gt;</a>  </p>\n<pre><code>        &lt;Button  \n            android:layout_width=&quot;fill_parent&quot;   \n            android:layout_height=&quot;wrap_content&quot;  \n            android:text=&quot;@string/add&quot;/&gt;  \n      \n        &lt;Button  \n            android:layout_width=&quot;fill_parent&quot;   \n            android:layout_height=&quot;wrap_content&quot;  \n            android:text=&quot;@string/delete&quot;/&gt;  \n      \n    merge   \n</code></pre>\n<p>好处：可以删减多余的层级，优化UI，从而减少视图在绘制过程消耗的时间，达到提高UI性能的效果。</p>\n<p>3、需要时使用ViewStub 使用如下：<br>        ViewStub<br>            android:id=”@+id/stub_import”<br>            android:inflatedId=”@+id/panel_import”<br>            android:layout=”@layout/progress_overlay”<br>            android:layout_width=”fill_parent”<br>            android:layout_height=”wrap_content”<br>            android:layout_gravity=”bottom”   /&gt;<br>好处：最大的优点是当你需要时才会加载，他并不会影响UI初始化时的性能，各种不常用的布局想进度条、显示错误消息等可以使用<ViewStub />标签，以减少内存使用量，加快渲染速度。<ViewStub />是一个不可见的，大小为0的View。</p>"},{"title":"面试经验","date":"2016-12-23T14:37:23.000Z","_content":"\n摘要:安卓面试经验\n<!--more-->\n正文:我的第一篇\n公司面临重组，项目重新搭建，薪资不到位，公司倒闭，都会使大家重新选择新的公司，楼主也准备重新寻找目标，希望自己能尽快找到新东家。\n在这里写下安卓常见的面试题目：\n\n1，Linklist与Arraylist区别  hashmap 与hashset区别 arraylist与vector的区别\n今天上午去笔试看到这题，自己也是蒙了戈壁啊，虽然楼主arraylist用的很多，但是却完全没有注意到这两个问题啊，在这里赶紧\n代码一下，LinkList是一个链表的集合，Arraylist是一个数组的集合\nhashmap存储的是键值对，实现了map接口，用put存储数据\nHashSet存储的是对象，实现了set接口，用add添加数据\narraylist与vector都是底层基于数组实现的，vector中的元素超过它的初始大小生成多出一倍的数据，而arraylist则生成50%的空间，vector线程安全，arraylist线程非安全\n2，windowmanager的知识\n3，自定义view的知识\n4，安卓view viewgroup事件分发\n这个问题在面试的时候好常问到，但是基本上都回答不出来，这个问题要深究一下\nview的分发机制\nsetOnClickListener与setOnTouchListener 按钮按下的时候会先执行ontouch 之后才 onclick 当ontouch返回为true时候会屏蔽掉onclick\n只要你触摸到了任何一个控件，就一定会调用该控件的dispatchTouchEvent方法，属于view的dispatchtouchevent方法\nhttp://blog.csdn.net/guolin_blog/article/details/9097463/\n\nviewgroup的分发机制\nViewGroup就是一组View的集合，它包含很多的子View和子VewGroup，是android中所有布局的父类或间接父类像LinearLayout、RelativeLayout等都是继承自ViewGroup的。\n只不过比起View，它多了可以包含子View和定义布局参数的功能。\nAndroid中touch事件的传递，绝对是先传递到ViewGroup，再传递到View的\nonInterceptTouchEvent\n当你点击了某个控件，首先会去调用该控件所在布局的dispatchTouchEvent方法，\n然后在布局的dispatchTouchEvent方法中找到被点击的相应控件，再去调用该控件的dispatchTouchEvent方法。\n如果我们点击了MyLayout中的按钮，会先去调用MyLayout的dispatchTouchEvent方法，\n可是你会发现MyLayout中并没有这个方法。那就再到它的父类LinearLayout中找一找，发现也没有这个方法。\n那只好继续再找LinearLayout的父类ViewGroup，你终于在ViewGroup中看到了这个方法，\n按钮的dispatchTouchEvent方法就是在这里调用的\nhttp://blog.csdn.net/guolin_blog/article/details/9153747\n\n5，链表与数组的区别增删查改\n链表的组成是地址指向  链表删除增加会好用一点\n数组的组成是一块地址分配给它 数组查找会好一点  数组删除下标下移就行了\n\n6，安卓有序广播，无序广播\n大家都知道广播的注册方式有两种，动态注册和静态注册，静态注册就是文件清单注册，就是退出应用都是可以收到广播的，例如别人打电话来的广播，这个时候我要关闭音乐后台播放\n动态注册跟随activity的生命周期，只要activity关闭 则广播也就自动关闭。今天问到一个有序广播无序广播，我也是蒙了戈壁啊，然后回来查了一下\n有序广播是通过Context.sendOrderedBroadcast来发送，可以通过在intent-filter中设置android:priority属性来设置receiver的优先级。优先级相同的receiver其执行顺序不确定。\n有序广播，即从优先级别最高的广播接收器开始接收，接收完了如果没有丢弃，就下传给下一个次高优先级别的广播接收器进行处理，依次类推，直到最后。\n这里接收短信的广播是有序广播，因此可以设置你自己的广播接收器的级别高于系统原来的级别，就可以拦截短信，并且不存收件箱，也不会有来信提示音。\n<receiver android:name=\".SmsReceiver\" >\n   <intent-filter android:priority=\"100\">\n    <action android:name=\"android.provider.Telephony.SMS_RECEIVED\" />                    \n   </intent-filter>\n</receiver>\n\n7，您的代码的一个性能优化你做了什么处理\nListView列表滑动过程中卡顿，不流畅；应用程序自定义的某特定界面执行速度慢；\n响应某一用户事件时长时间无响应（ANR）；操作数据库时，执行大量数据的增删改查操作，执行速度慢；\n文件读写频繁，缓存文件过大导致卡顿；应用长时间运行后，随机出现卡顿现象。\n\nlistview的滑动不流畅，这个我们第一个可以重用convertview，第二个我们要尽量减少item的层级布局，可以用merge\n尽量复用控件，第三个getView方法中不能做复杂的逻辑计算，特别是数据库操作，否则会严重影响滑动时的性能，第四个考虑分页加载\n\n调用bitmap的时候可以适当使用软应用，不至于在图片对象没有使用的时候还没有得到内存的释放\n\n\n8，广播BroadCast动态注册时，记得要在调用者生命周期结束时unregisterReceiver,防止内存泄漏。这句话很重要，在onresume里面注册广播 在onpause里面注销广播 \n\n9，抽象类和接口经常都会笔试有遇到\n其实说实话 抽象类我用都没有用过，但是接口是经常用的，所以说之前我回答的时候都是基本上靠背书上的知识\n因为我觉得父类和接口以及够用了，所以我对抽象类的认识就停留在概念上，下面来说一下区别：\n类都是单继承 接口可以实现多个 两个都不能被实例化 都要子类去实现 这个没得说\n接下来说方法，抽象类中的方法可以是抽象的 也可以是非抽象的，也可以实现，有抽象方法的肯定是抽象类，抽象类不一定有抽象方法\n接口中的方法都是抽象的，不能实现的，必须要子类去实现。\n接下来说变量，接口中的变量都是常量，都是public static final的常量，而抽象类中的都是变量\n这句话我觉得还是说的蛮准确的：\n当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。\n\n10，string stringbuffer stringbuilder 也是经常考的面试知识\nstring是一个不能修改的变量，当string变量被赋值一个新值的时候就是新建了一个string变量\nstringbuffer则是不会新建一个变量，只是修改原来的变量，所以说修改的时候stringbuffer的速度是大于string的\nstringbuffer是线程安全，而stringbuilder是线程非安全，所谓线程安全和线程非安全就是指访问一个线程中的一个变量的时候\n如果有锁定机制，不让另外的线程去访问这个变量就是线程安全，要不然就是线程非安全\n\n11，activity生命周期是一个老生常谈的一个问题，但是有时候考官还是会出比较奇葩的问题\nonstart 与 onresume的区别  一个是执行先后的问题，另外一个是onstart是指用户可以看到 onresume是用户可以看到而且可以进行交互\n例如有一个dialog在activity上面的时候 onstart是在执行的，但是onresume已经变成了onpause\n\n12，面试官很喜欢问的一个问题是你做安卓遇到的问题以及你解决的方法\n问这个问题主要是面试官想要了解你的解决问题的方式 \n这里可以回答一个listview嵌套gridview 只能显示一个item 可以复写gridview onMeasure方法显示多行数据\n设置viewpager高度 为屏幕的1/4 利用LinearLayout.LayoutParams动态设置高度  listview中间加多一个viewpager 奇葩要求 显示不出来！！ 只好动态设置高度\n适配问题 使用不同布局layout 图片使用多套 使用动态设置高度\n\n13，安卓四大组件会安卓的人来说，基本上都不用说的了，这里说一下知识盲点\nservice启动的时候有两种一个是startservice，一个是onbindservice，这两种的区别是onbindservice是需要跟调用者绑定的\n而startservice是不需要跟调用者绑定的，就是说onbindservice一旦调用者退出了，则service也关闭了。\nservice不管调用多少次onstartservice onbindservice，oncreateservice只会调用一次，就是只会生成一次service，但是会调用onstart方法多次\n\n14，handler的消息传递机制那是经常问到的东西，其实楼主对这东西了解不深，我只知道我用过这东西来做消息通知，就是异步线程子线程通知UI线程的UI更新\n具体里面怎么实现的呢，我还真是一头雾水，所以每次问到的时候都是模棱两可，所以现在普及一下自己的认识，希望下次面试能说出点所以然来\nMessage：消息，其中包含了消息ID，消息处理对象以及处理的数据等，由MessageQueue统一列队，终由Handler处理。 \nHandler：处理者，负责Message的发送及处理。使用Handler时，需要实现handleMessage(Message msg)方法来对特定的Message进行处理，例如更新UI等。 \nMessageQueue：消息队列，用来存放Handler发送过来的消息，并按照FIFO规则执行。当然，存放Message并非实际意义的保存，而是将Message以链表的方式串联起来的，等待Looper的抽取。 \nLooper：消息泵，不断地从MessageQueue中抽取Message执行。因此，一个MessageQueue需要一个Looper。 \nThread：线程，负责调度整个消息循环，即消息循环的执行场所。\n\n15，说到了handler那就顺便说说消息传递有哪几种吧\nasynctask handler eventbus 广播   view.post（）\n\n16，内存溢出与内存泄露的区别，以及怎么就会产生这些问题，需要怎么优化？\n内存溢出是指我申请了内存，但是不够存放，例如我用int型去存储long型的数值，就会内存溢出\n内存泄露是指我对某一内存空间的使用，使用完成后没有释放。\n内存优化：Android中容易内存溢出的部分，就是图片bitmap的加载，我们可以使用图片的压缩加上使用LruCache缓存的目的来控制图片所能够使用的内存。\n还有对于比较耗资源的对象及时的关闭，例如Database Conn , 各种传感器 ， Service 等等。\n\n17，Androidstudio怎么检查内存使用？\n有一个monitor的工具，打开就可以看到点击车的图标可以GC释放内存，然后看它的曲线与JavaHeap\n\n18，安卓多渠道打包\nAndroid studio中\n（一）在AndroidManifest.xml里设置动态渠道变量\n<meta-data\n    android:name=\"UMENG_CHANNEL\"\n    android:value=\"${UMENG_CHANNEL_VALUE}\" />\n    \n（二）在build.gradle设置productFlavors\n（三）执行打包操作\nhttp://blog.csdn.net/mynameishuangshuai/article/details/51783303\n\n19，view与surfaceview的区别\nSurfaceView和View最本质的区别在于，surfaceView是在一个新起的单独线程中可以重新绘制画面而View必须在UI的主线程中更新画面，渲染速度surfaceview比view快\n\n20，屏幕旋转调用的生命周期\n不设置activity的android:onconfigchang=oriention横屏一次，竖屏两次，设置Android：configchange=oriention横屏一次，竖屏一次，设置Android：\nconfigchange:oriention|keyboardhidden不执行生命周期\n\n21安卓系统架构\n底层是linux层次\n之后是c++运行层\n之后是framework框架层\n最后是application应用层\n","source":"_posts/android/安卓面试经验.md","raw":"---\ntitle: 面试经验\ndate: 2016-012-23 22:37:23\ncategories:\n  - 日志\ntags:\n  - 其他\n---\n\n摘要:安卓面试经验\n<!--more-->\n正文:我的第一篇\n公司面临重组，项目重新搭建，薪资不到位，公司倒闭，都会使大家重新选择新的公司，楼主也准备重新寻找目标，希望自己能尽快找到新东家。\n在这里写下安卓常见的面试题目：\n\n1，Linklist与Arraylist区别  hashmap 与hashset区别 arraylist与vector的区别\n今天上午去笔试看到这题，自己也是蒙了戈壁啊，虽然楼主arraylist用的很多，但是却完全没有注意到这两个问题啊，在这里赶紧\n代码一下，LinkList是一个链表的集合，Arraylist是一个数组的集合\nhashmap存储的是键值对，实现了map接口，用put存储数据\nHashSet存储的是对象，实现了set接口，用add添加数据\narraylist与vector都是底层基于数组实现的，vector中的元素超过它的初始大小生成多出一倍的数据，而arraylist则生成50%的空间，vector线程安全，arraylist线程非安全\n2，windowmanager的知识\n3，自定义view的知识\n4，安卓view viewgroup事件分发\n这个问题在面试的时候好常问到，但是基本上都回答不出来，这个问题要深究一下\nview的分发机制\nsetOnClickListener与setOnTouchListener 按钮按下的时候会先执行ontouch 之后才 onclick 当ontouch返回为true时候会屏蔽掉onclick\n只要你触摸到了任何一个控件，就一定会调用该控件的dispatchTouchEvent方法，属于view的dispatchtouchevent方法\nhttp://blog.csdn.net/guolin_blog/article/details/9097463/\n\nviewgroup的分发机制\nViewGroup就是一组View的集合，它包含很多的子View和子VewGroup，是android中所有布局的父类或间接父类像LinearLayout、RelativeLayout等都是继承自ViewGroup的。\n只不过比起View，它多了可以包含子View和定义布局参数的功能。\nAndroid中touch事件的传递，绝对是先传递到ViewGroup，再传递到View的\nonInterceptTouchEvent\n当你点击了某个控件，首先会去调用该控件所在布局的dispatchTouchEvent方法，\n然后在布局的dispatchTouchEvent方法中找到被点击的相应控件，再去调用该控件的dispatchTouchEvent方法。\n如果我们点击了MyLayout中的按钮，会先去调用MyLayout的dispatchTouchEvent方法，\n可是你会发现MyLayout中并没有这个方法。那就再到它的父类LinearLayout中找一找，发现也没有这个方法。\n那只好继续再找LinearLayout的父类ViewGroup，你终于在ViewGroup中看到了这个方法，\n按钮的dispatchTouchEvent方法就是在这里调用的\nhttp://blog.csdn.net/guolin_blog/article/details/9153747\n\n5，链表与数组的区别增删查改\n链表的组成是地址指向  链表删除增加会好用一点\n数组的组成是一块地址分配给它 数组查找会好一点  数组删除下标下移就行了\n\n6，安卓有序广播，无序广播\n大家都知道广播的注册方式有两种，动态注册和静态注册，静态注册就是文件清单注册，就是退出应用都是可以收到广播的，例如别人打电话来的广播，这个时候我要关闭音乐后台播放\n动态注册跟随activity的生命周期，只要activity关闭 则广播也就自动关闭。今天问到一个有序广播无序广播，我也是蒙了戈壁啊，然后回来查了一下\n有序广播是通过Context.sendOrderedBroadcast来发送，可以通过在intent-filter中设置android:priority属性来设置receiver的优先级。优先级相同的receiver其执行顺序不确定。\n有序广播，即从优先级别最高的广播接收器开始接收，接收完了如果没有丢弃，就下传给下一个次高优先级别的广播接收器进行处理，依次类推，直到最后。\n这里接收短信的广播是有序广播，因此可以设置你自己的广播接收器的级别高于系统原来的级别，就可以拦截短信，并且不存收件箱，也不会有来信提示音。\n<receiver android:name=\".SmsReceiver\" >\n   <intent-filter android:priority=\"100\">\n    <action android:name=\"android.provider.Telephony.SMS_RECEIVED\" />                    \n   </intent-filter>\n</receiver>\n\n7，您的代码的一个性能优化你做了什么处理\nListView列表滑动过程中卡顿，不流畅；应用程序自定义的某特定界面执行速度慢；\n响应某一用户事件时长时间无响应（ANR）；操作数据库时，执行大量数据的增删改查操作，执行速度慢；\n文件读写频繁，缓存文件过大导致卡顿；应用长时间运行后，随机出现卡顿现象。\n\nlistview的滑动不流畅，这个我们第一个可以重用convertview，第二个我们要尽量减少item的层级布局，可以用merge\n尽量复用控件，第三个getView方法中不能做复杂的逻辑计算，特别是数据库操作，否则会严重影响滑动时的性能，第四个考虑分页加载\n\n调用bitmap的时候可以适当使用软应用，不至于在图片对象没有使用的时候还没有得到内存的释放\n\n\n8，广播BroadCast动态注册时，记得要在调用者生命周期结束时unregisterReceiver,防止内存泄漏。这句话很重要，在onresume里面注册广播 在onpause里面注销广播 \n\n9，抽象类和接口经常都会笔试有遇到\n其实说实话 抽象类我用都没有用过，但是接口是经常用的，所以说之前我回答的时候都是基本上靠背书上的知识\n因为我觉得父类和接口以及够用了，所以我对抽象类的认识就停留在概念上，下面来说一下区别：\n类都是单继承 接口可以实现多个 两个都不能被实例化 都要子类去实现 这个没得说\n接下来说方法，抽象类中的方法可以是抽象的 也可以是非抽象的，也可以实现，有抽象方法的肯定是抽象类，抽象类不一定有抽象方法\n接口中的方法都是抽象的，不能实现的，必须要子类去实现。\n接下来说变量，接口中的变量都是常量，都是public static final的常量，而抽象类中的都是变量\n这句话我觉得还是说的蛮准确的：\n当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。\n\n10，string stringbuffer stringbuilder 也是经常考的面试知识\nstring是一个不能修改的变量，当string变量被赋值一个新值的时候就是新建了一个string变量\nstringbuffer则是不会新建一个变量，只是修改原来的变量，所以说修改的时候stringbuffer的速度是大于string的\nstringbuffer是线程安全，而stringbuilder是线程非安全，所谓线程安全和线程非安全就是指访问一个线程中的一个变量的时候\n如果有锁定机制，不让另外的线程去访问这个变量就是线程安全，要不然就是线程非安全\n\n11，activity生命周期是一个老生常谈的一个问题，但是有时候考官还是会出比较奇葩的问题\nonstart 与 onresume的区别  一个是执行先后的问题，另外一个是onstart是指用户可以看到 onresume是用户可以看到而且可以进行交互\n例如有一个dialog在activity上面的时候 onstart是在执行的，但是onresume已经变成了onpause\n\n12，面试官很喜欢问的一个问题是你做安卓遇到的问题以及你解决的方法\n问这个问题主要是面试官想要了解你的解决问题的方式 \n这里可以回答一个listview嵌套gridview 只能显示一个item 可以复写gridview onMeasure方法显示多行数据\n设置viewpager高度 为屏幕的1/4 利用LinearLayout.LayoutParams动态设置高度  listview中间加多一个viewpager 奇葩要求 显示不出来！！ 只好动态设置高度\n适配问题 使用不同布局layout 图片使用多套 使用动态设置高度\n\n13，安卓四大组件会安卓的人来说，基本上都不用说的了，这里说一下知识盲点\nservice启动的时候有两种一个是startservice，一个是onbindservice，这两种的区别是onbindservice是需要跟调用者绑定的\n而startservice是不需要跟调用者绑定的，就是说onbindservice一旦调用者退出了，则service也关闭了。\nservice不管调用多少次onstartservice onbindservice，oncreateservice只会调用一次，就是只会生成一次service，但是会调用onstart方法多次\n\n14，handler的消息传递机制那是经常问到的东西，其实楼主对这东西了解不深，我只知道我用过这东西来做消息通知，就是异步线程子线程通知UI线程的UI更新\n具体里面怎么实现的呢，我还真是一头雾水，所以每次问到的时候都是模棱两可，所以现在普及一下自己的认识，希望下次面试能说出点所以然来\nMessage：消息，其中包含了消息ID，消息处理对象以及处理的数据等，由MessageQueue统一列队，终由Handler处理。 \nHandler：处理者，负责Message的发送及处理。使用Handler时，需要实现handleMessage(Message msg)方法来对特定的Message进行处理，例如更新UI等。 \nMessageQueue：消息队列，用来存放Handler发送过来的消息，并按照FIFO规则执行。当然，存放Message并非实际意义的保存，而是将Message以链表的方式串联起来的，等待Looper的抽取。 \nLooper：消息泵，不断地从MessageQueue中抽取Message执行。因此，一个MessageQueue需要一个Looper。 \nThread：线程，负责调度整个消息循环，即消息循环的执行场所。\n\n15，说到了handler那就顺便说说消息传递有哪几种吧\nasynctask handler eventbus 广播   view.post（）\n\n16，内存溢出与内存泄露的区别，以及怎么就会产生这些问题，需要怎么优化？\n内存溢出是指我申请了内存，但是不够存放，例如我用int型去存储long型的数值，就会内存溢出\n内存泄露是指我对某一内存空间的使用，使用完成后没有释放。\n内存优化：Android中容易内存溢出的部分，就是图片bitmap的加载，我们可以使用图片的压缩加上使用LruCache缓存的目的来控制图片所能够使用的内存。\n还有对于比较耗资源的对象及时的关闭，例如Database Conn , 各种传感器 ， Service 等等。\n\n17，Androidstudio怎么检查内存使用？\n有一个monitor的工具，打开就可以看到点击车的图标可以GC释放内存，然后看它的曲线与JavaHeap\n\n18，安卓多渠道打包\nAndroid studio中\n（一）在AndroidManifest.xml里设置动态渠道变量\n<meta-data\n    android:name=\"UMENG_CHANNEL\"\n    android:value=\"${UMENG_CHANNEL_VALUE}\" />\n    \n（二）在build.gradle设置productFlavors\n（三）执行打包操作\nhttp://blog.csdn.net/mynameishuangshuai/article/details/51783303\n\n19，view与surfaceview的区别\nSurfaceView和View最本质的区别在于，surfaceView是在一个新起的单独线程中可以重新绘制画面而View必须在UI的主线程中更新画面，渲染速度surfaceview比view快\n\n20，屏幕旋转调用的生命周期\n不设置activity的android:onconfigchang=oriention横屏一次，竖屏两次，设置Android：configchange=oriention横屏一次，竖屏一次，设置Android：\nconfigchange:oriention|keyboardhidden不执行生命周期\n\n21安卓系统架构\n底层是linux层次\n之后是c++运行层\n之后是framework框架层\n最后是application应用层\n","slug":"android/安卓面试经验","published":1,"updated":"2025-05-16T04:25:25.437Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrn000kskqr7xr3fxv0","content":"<p>摘要:安卓面试经验</p>\n<span id=\"more\"></span>\n<p>正文:我的第一篇<br>公司面临重组，项目重新搭建，薪资不到位，公司倒闭，都会使大家重新选择新的公司，楼主也准备重新寻找目标，希望自己能尽快找到新东家。<br>在这里写下安卓常见的面试题目：</p>\n<p>1，Linklist与Arraylist区别  hashmap 与hashset区别 arraylist与vector的区别<br>今天上午去笔试看到这题，自己也是蒙了戈壁啊，虽然楼主arraylist用的很多，但是却完全没有注意到这两个问题啊，在这里赶紧<br>代码一下，LinkList是一个链表的集合，Arraylist是一个数组的集合<br>hashmap存储的是键值对，实现了map接口，用put存储数据<br>HashSet存储的是对象，实现了set接口，用add添加数据<br>arraylist与vector都是底层基于数组实现的，vector中的元素超过它的初始大小生成多出一倍的数据，而arraylist则生成50%的空间，vector线程安全，arraylist线程非安全<br>2，windowmanager的知识<br>3，自定义view的知识<br>4，安卓view viewgroup事件分发<br>这个问题在面试的时候好常问到，但是基本上都回答不出来，这个问题要深究一下<br>view的分发机制<br>setOnClickListener与setOnTouchListener 按钮按下的时候会先执行ontouch 之后才 onclick 当ontouch返回为true时候会屏蔽掉onclick<br>只要你触摸到了任何一个控件，就一定会调用该控件的dispatchTouchEvent方法，属于view的dispatchtouchevent方法<br><a href=\"http://blog.csdn.net/guolin_blog/article/details/9097463/\">http://blog.csdn.net/guolin_blog/article/details/9097463/</a></p>\n<p>viewgroup的分发机制<br>ViewGroup就是一组View的集合，它包含很多的子View和子VewGroup，是android中所有布局的父类或间接父类像LinearLayout、RelativeLayout等都是继承自ViewGroup的。<br>只不过比起View，它多了可以包含子View和定义布局参数的功能。<br>Android中touch事件的传递，绝对是先传递到ViewGroup，再传递到View的<br>onInterceptTouchEvent<br>当你点击了某个控件，首先会去调用该控件所在布局的dispatchTouchEvent方法，<br>然后在布局的dispatchTouchEvent方法中找到被点击的相应控件，再去调用该控件的dispatchTouchEvent方法。<br>如果我们点击了MyLayout中的按钮，会先去调用MyLayout的dispatchTouchEvent方法，<br>可是你会发现MyLayout中并没有这个方法。那就再到它的父类LinearLayout中找一找，发现也没有这个方法。<br>那只好继续再找LinearLayout的父类ViewGroup，你终于在ViewGroup中看到了这个方法，<br>按钮的dispatchTouchEvent方法就是在这里调用的<br><a href=\"http://blog.csdn.net/guolin_blog/article/details/9153747\">http://blog.csdn.net/guolin_blog/article/details/9153747</a></p>\n<p>5，链表与数组的区别增删查改<br>链表的组成是地址指向  链表删除增加会好用一点<br>数组的组成是一块地址分配给它 数组查找会好一点  数组删除下标下移就行了</p>\n<p>6，安卓有序广播，无序广播<br>大家都知道广播的注册方式有两种，动态注册和静态注册，静态注册就是文件清单注册，就是退出应用都是可以收到广播的，例如别人打电话来的广播，这个时候我要关闭音乐后台播放<br>动态注册跟随activity的生命周期，只要activity关闭 则广播也就自动关闭。今天问到一个有序广播无序广播，我也是蒙了戈壁啊，然后回来查了一下<br>有序广播是通过Context.sendOrderedBroadcast来发送，可以通过在intent-filter中设置android:priority属性来设置receiver的优先级。优先级相同的receiver其执行顺序不确定。<br>有序广播，即从优先级别最高的广播接收器开始接收，接收完了如果没有丢弃，就下传给下一个次高优先级别的广播接收器进行处理，依次类推，直到最后。<br>这里接收短信的广播是有序广播，因此可以设置你自己的广播接收器的级别高于系统原来的级别，就可以拦截短信，并且不存收件箱，也不会有来信提示音。<br><receiver android:name=\".SmsReceiver\" ><br>   <intent-filter android:priority=\"100\"><br>    <action android:name=\"android.provider.Telephony.SMS_RECEIVED\" /><br>   </intent-filter><br></receiver></p>\n<p>7，您的代码的一个性能优化你做了什么处理<br>ListView列表滑动过程中卡顿，不流畅；应用程序自定义的某特定界面执行速度慢；<br>响应某一用户事件时长时间无响应（ANR）；操作数据库时，执行大量数据的增删改查操作，执行速度慢；<br>文件读写频繁，缓存文件过大导致卡顿；应用长时间运行后，随机出现卡顿现象。</p>\n<p>listview的滑动不流畅，这个我们第一个可以重用convertview，第二个我们要尽量减少item的层级布局，可以用merge<br>尽量复用控件，第三个getView方法中不能做复杂的逻辑计算，特别是数据库操作，否则会严重影响滑动时的性能，第四个考虑分页加载</p>\n<p>调用bitmap的时候可以适当使用软应用，不至于在图片对象没有使用的时候还没有得到内存的释放</p>\n<p>8，广播BroadCast动态注册时，记得要在调用者生命周期结束时unregisterReceiver,防止内存泄漏。这句话很重要，在onresume里面注册广播 在onpause里面注销广播 </p>\n<p>9，抽象类和接口经常都会笔试有遇到<br>其实说实话 抽象类我用都没有用过，但是接口是经常用的，所以说之前我回答的时候都是基本上靠背书上的知识<br>因为我觉得父类和接口以及够用了，所以我对抽象类的认识就停留在概念上，下面来说一下区别：<br>类都是单继承 接口可以实现多个 两个都不能被实例化 都要子类去实现 这个没得说<br>接下来说方法，抽象类中的方法可以是抽象的 也可以是非抽象的，也可以实现，有抽象方法的肯定是抽象类，抽象类不一定有抽象方法<br>接口中的方法都是抽象的，不能实现的，必须要子类去实现。<br>接下来说变量，接口中的变量都是常量，都是public static final的常量，而抽象类中的都是变量<br>这句话我觉得还是说的蛮准确的：<br>当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。</p>\n<p>10，string stringbuffer stringbuilder 也是经常考的面试知识<br>string是一个不能修改的变量，当string变量被赋值一个新值的时候就是新建了一个string变量<br>stringbuffer则是不会新建一个变量，只是修改原来的变量，所以说修改的时候stringbuffer的速度是大于string的<br>stringbuffer是线程安全，而stringbuilder是线程非安全，所谓线程安全和线程非安全就是指访问一个线程中的一个变量的时候<br>如果有锁定机制，不让另外的线程去访问这个变量就是线程安全，要不然就是线程非安全</p>\n<p>11，activity生命周期是一个老生常谈的一个问题，但是有时候考官还是会出比较奇葩的问题<br>onstart 与 onresume的区别  一个是执行先后的问题，另外一个是onstart是指用户可以看到 onresume是用户可以看到而且可以进行交互<br>例如有一个dialog在activity上面的时候 onstart是在执行的，但是onresume已经变成了onpause</p>\n<p>12，面试官很喜欢问的一个问题是你做安卓遇到的问题以及你解决的方法<br>问这个问题主要是面试官想要了解你的解决问题的方式<br>这里可以回答一个listview嵌套gridview 只能显示一个item 可以复写gridview onMeasure方法显示多行数据<br>设置viewpager高度 为屏幕的1/4 利用LinearLayout.LayoutParams动态设置高度  listview中间加多一个viewpager 奇葩要求 显示不出来！！ 只好动态设置高度<br>适配问题 使用不同布局layout 图片使用多套 使用动态设置高度</p>\n<p>13，安卓四大组件会安卓的人来说，基本上都不用说的了，这里说一下知识盲点<br>service启动的时候有两种一个是startservice，一个是onbindservice，这两种的区别是onbindservice是需要跟调用者绑定的<br>而startservice是不需要跟调用者绑定的，就是说onbindservice一旦调用者退出了，则service也关闭了。<br>service不管调用多少次onstartservice onbindservice，oncreateservice只会调用一次，就是只会生成一次service，但是会调用onstart方法多次</p>\n<p>14，handler的消息传递机制那是经常问到的东西，其实楼主对这东西了解不深，我只知道我用过这东西来做消息通知，就是异步线程子线程通知UI线程的UI更新<br>具体里面怎么实现的呢，我还真是一头雾水，所以每次问到的时候都是模棱两可，所以现在普及一下自己的认识，希望下次面试能说出点所以然来<br>Message：消息，其中包含了消息ID，消息处理对象以及处理的数据等，由MessageQueue统一列队，终由Handler处理。<br>Handler：处理者，负责Message的发送及处理。使用Handler时，需要实现handleMessage(Message msg)方法来对特定的Message进行处理，例如更新UI等。<br>MessageQueue：消息队列，用来存放Handler发送过来的消息，并按照FIFO规则执行。当然，存放Message并非实际意义的保存，而是将Message以链表的方式串联起来的，等待Looper的抽取。<br>Looper：消息泵，不断地从MessageQueue中抽取Message执行。因此，一个MessageQueue需要一个Looper。<br>Thread：线程，负责调度整个消息循环，即消息循环的执行场所。</p>\n<p>15，说到了handler那就顺便说说消息传递有哪几种吧<br>asynctask handler eventbus 广播   view.post（）</p>\n<p>16，内存溢出与内存泄露的区别，以及怎么就会产生这些问题，需要怎么优化？<br>内存溢出是指我申请了内存，但是不够存放，例如我用int型去存储long型的数值，就会内存溢出<br>内存泄露是指我对某一内存空间的使用，使用完成后没有释放。<br>内存优化：Android中容易内存溢出的部分，就是图片bitmap的加载，我们可以使用图片的压缩加上使用LruCache缓存的目的来控制图片所能够使用的内存。<br>还有对于比较耗资源的对象及时的关闭，例如Database Conn , 各种传感器 ， Service 等等。</p>\n<p>17，Androidstudio怎么检查内存使用？<br>有一个monitor的工具，打开就可以看到点击车的图标可以GC释放内存，然后看它的曲线与JavaHeap</p>\n<p>18，安卓多渠道打包<br>Android studio中<br>（一）在AndroidManifest.xml里设置动态渠道变量<br><meta-data\n    android:name=\"UMENG_CHANNEL\"\n    android:value=\"${UMENG_CHANNEL_VALUE}\" /></p>\n<p>（二）在build.gradle设置productFlavors<br>（三）执行打包操作<br><a href=\"http://blog.csdn.net/mynameishuangshuai/article/details/51783303\">http://blog.csdn.net/mynameishuangshuai/article/details/51783303</a></p>\n<p>19，view与surfaceview的区别<br>SurfaceView和View最本质的区别在于，surfaceView是在一个新起的单独线程中可以重新绘制画面而View必须在UI的主线程中更新画面，渲染速度surfaceview比view快</p>\n<p>20，屏幕旋转调用的生命周期<br>不设置activity的android:onconfigchang=oriention横屏一次，竖屏两次，设置Android：configchange=oriention横屏一次，竖屏一次，设置Android：<br>configchange:oriention|keyboardhidden不执行生命周期</p>\n<p>21安卓系统架构<br>底层是linux层次<br>之后是c++运行层<br>之后是framework框架层<br>最后是application应用层</p>\n","site":{"data":{}},"excerpt":"<p>摘要:安卓面试经验</p>","more":"<p>正文:我的第一篇<br>公司面临重组，项目重新搭建，薪资不到位，公司倒闭，都会使大家重新选择新的公司，楼主也准备重新寻找目标，希望自己能尽快找到新东家。<br>在这里写下安卓常见的面试题目：</p>\n<p>1，Linklist与Arraylist区别  hashmap 与hashset区别 arraylist与vector的区别<br>今天上午去笔试看到这题，自己也是蒙了戈壁啊，虽然楼主arraylist用的很多，但是却完全没有注意到这两个问题啊，在这里赶紧<br>代码一下，LinkList是一个链表的集合，Arraylist是一个数组的集合<br>hashmap存储的是键值对，实现了map接口，用put存储数据<br>HashSet存储的是对象，实现了set接口，用add添加数据<br>arraylist与vector都是底层基于数组实现的，vector中的元素超过它的初始大小生成多出一倍的数据，而arraylist则生成50%的空间，vector线程安全，arraylist线程非安全<br>2，windowmanager的知识<br>3，自定义view的知识<br>4，安卓view viewgroup事件分发<br>这个问题在面试的时候好常问到，但是基本上都回答不出来，这个问题要深究一下<br>view的分发机制<br>setOnClickListener与setOnTouchListener 按钮按下的时候会先执行ontouch 之后才 onclick 当ontouch返回为true时候会屏蔽掉onclick<br>只要你触摸到了任何一个控件，就一定会调用该控件的dispatchTouchEvent方法，属于view的dispatchtouchevent方法<br><a href=\"http://blog.csdn.net/guolin_blog/article/details/9097463/\">http://blog.csdn.net/guolin_blog/article/details/9097463/</a></p>\n<p>viewgroup的分发机制<br>ViewGroup就是一组View的集合，它包含很多的子View和子VewGroup，是android中所有布局的父类或间接父类像LinearLayout、RelativeLayout等都是继承自ViewGroup的。<br>只不过比起View，它多了可以包含子View和定义布局参数的功能。<br>Android中touch事件的传递，绝对是先传递到ViewGroup，再传递到View的<br>onInterceptTouchEvent<br>当你点击了某个控件，首先会去调用该控件所在布局的dispatchTouchEvent方法，<br>然后在布局的dispatchTouchEvent方法中找到被点击的相应控件，再去调用该控件的dispatchTouchEvent方法。<br>如果我们点击了MyLayout中的按钮，会先去调用MyLayout的dispatchTouchEvent方法，<br>可是你会发现MyLayout中并没有这个方法。那就再到它的父类LinearLayout中找一找，发现也没有这个方法。<br>那只好继续再找LinearLayout的父类ViewGroup，你终于在ViewGroup中看到了这个方法，<br>按钮的dispatchTouchEvent方法就是在这里调用的<br><a href=\"http://blog.csdn.net/guolin_blog/article/details/9153747\">http://blog.csdn.net/guolin_blog/article/details/9153747</a></p>\n<p>5，链表与数组的区别增删查改<br>链表的组成是地址指向  链表删除增加会好用一点<br>数组的组成是一块地址分配给它 数组查找会好一点  数组删除下标下移就行了</p>\n<p>6，安卓有序广播，无序广播<br>大家都知道广播的注册方式有两种，动态注册和静态注册，静态注册就是文件清单注册，就是退出应用都是可以收到广播的，例如别人打电话来的广播，这个时候我要关闭音乐后台播放<br>动态注册跟随activity的生命周期，只要activity关闭 则广播也就自动关闭。今天问到一个有序广播无序广播，我也是蒙了戈壁啊，然后回来查了一下<br>有序广播是通过Context.sendOrderedBroadcast来发送，可以通过在intent-filter中设置android:priority属性来设置receiver的优先级。优先级相同的receiver其执行顺序不确定。<br>有序广播，即从优先级别最高的广播接收器开始接收，接收完了如果没有丢弃，就下传给下一个次高优先级别的广播接收器进行处理，依次类推，直到最后。<br>这里接收短信的广播是有序广播，因此可以设置你自己的广播接收器的级别高于系统原来的级别，就可以拦截短信，并且不存收件箱，也不会有来信提示音。<br><receiver android:name=\".SmsReceiver\" ><br>   <intent-filter android:priority=\"100\"><br>    <action android:name=\"android.provider.Telephony.SMS_RECEIVED\" /><br>   </intent-filter><br></receiver></p>\n<p>7，您的代码的一个性能优化你做了什么处理<br>ListView列表滑动过程中卡顿，不流畅；应用程序自定义的某特定界面执行速度慢；<br>响应某一用户事件时长时间无响应（ANR）；操作数据库时，执行大量数据的增删改查操作，执行速度慢；<br>文件读写频繁，缓存文件过大导致卡顿；应用长时间运行后，随机出现卡顿现象。</p>\n<p>listview的滑动不流畅，这个我们第一个可以重用convertview，第二个我们要尽量减少item的层级布局，可以用merge<br>尽量复用控件，第三个getView方法中不能做复杂的逻辑计算，特别是数据库操作，否则会严重影响滑动时的性能，第四个考虑分页加载</p>\n<p>调用bitmap的时候可以适当使用软应用，不至于在图片对象没有使用的时候还没有得到内存的释放</p>\n<p>8，广播BroadCast动态注册时，记得要在调用者生命周期结束时unregisterReceiver,防止内存泄漏。这句话很重要，在onresume里面注册广播 在onpause里面注销广播 </p>\n<p>9，抽象类和接口经常都会笔试有遇到<br>其实说实话 抽象类我用都没有用过，但是接口是经常用的，所以说之前我回答的时候都是基本上靠背书上的知识<br>因为我觉得父类和接口以及够用了，所以我对抽象类的认识就停留在概念上，下面来说一下区别：<br>类都是单继承 接口可以实现多个 两个都不能被实例化 都要子类去实现 这个没得说<br>接下来说方法，抽象类中的方法可以是抽象的 也可以是非抽象的，也可以实现，有抽象方法的肯定是抽象类，抽象类不一定有抽象方法<br>接口中的方法都是抽象的，不能实现的，必须要子类去实现。<br>接下来说变量，接口中的变量都是常量，都是public static final的常量，而抽象类中的都是变量<br>这句话我觉得还是说的蛮准确的：<br>当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。</p>\n<p>10，string stringbuffer stringbuilder 也是经常考的面试知识<br>string是一个不能修改的变量，当string变量被赋值一个新值的时候就是新建了一个string变量<br>stringbuffer则是不会新建一个变量，只是修改原来的变量，所以说修改的时候stringbuffer的速度是大于string的<br>stringbuffer是线程安全，而stringbuilder是线程非安全，所谓线程安全和线程非安全就是指访问一个线程中的一个变量的时候<br>如果有锁定机制，不让另外的线程去访问这个变量就是线程安全，要不然就是线程非安全</p>\n<p>11，activity生命周期是一个老生常谈的一个问题，但是有时候考官还是会出比较奇葩的问题<br>onstart 与 onresume的区别  一个是执行先后的问题，另外一个是onstart是指用户可以看到 onresume是用户可以看到而且可以进行交互<br>例如有一个dialog在activity上面的时候 onstart是在执行的，但是onresume已经变成了onpause</p>\n<p>12，面试官很喜欢问的一个问题是你做安卓遇到的问题以及你解决的方法<br>问这个问题主要是面试官想要了解你的解决问题的方式<br>这里可以回答一个listview嵌套gridview 只能显示一个item 可以复写gridview onMeasure方法显示多行数据<br>设置viewpager高度 为屏幕的1/4 利用LinearLayout.LayoutParams动态设置高度  listview中间加多一个viewpager 奇葩要求 显示不出来！！ 只好动态设置高度<br>适配问题 使用不同布局layout 图片使用多套 使用动态设置高度</p>\n<p>13，安卓四大组件会安卓的人来说，基本上都不用说的了，这里说一下知识盲点<br>service启动的时候有两种一个是startservice，一个是onbindservice，这两种的区别是onbindservice是需要跟调用者绑定的<br>而startservice是不需要跟调用者绑定的，就是说onbindservice一旦调用者退出了，则service也关闭了。<br>service不管调用多少次onstartservice onbindservice，oncreateservice只会调用一次，就是只会生成一次service，但是会调用onstart方法多次</p>\n<p>14，handler的消息传递机制那是经常问到的东西，其实楼主对这东西了解不深，我只知道我用过这东西来做消息通知，就是异步线程子线程通知UI线程的UI更新<br>具体里面怎么实现的呢，我还真是一头雾水，所以每次问到的时候都是模棱两可，所以现在普及一下自己的认识，希望下次面试能说出点所以然来<br>Message：消息，其中包含了消息ID，消息处理对象以及处理的数据等，由MessageQueue统一列队，终由Handler处理。<br>Handler：处理者，负责Message的发送及处理。使用Handler时，需要实现handleMessage(Message msg)方法来对特定的Message进行处理，例如更新UI等。<br>MessageQueue：消息队列，用来存放Handler发送过来的消息，并按照FIFO规则执行。当然，存放Message并非实际意义的保存，而是将Message以链表的方式串联起来的，等待Looper的抽取。<br>Looper：消息泵，不断地从MessageQueue中抽取Message执行。因此，一个MessageQueue需要一个Looper。<br>Thread：线程，负责调度整个消息循环，即消息循环的执行场所。</p>\n<p>15，说到了handler那就顺便说说消息传递有哪几种吧<br>asynctask handler eventbus 广播   view.post（）</p>\n<p>16，内存溢出与内存泄露的区别，以及怎么就会产生这些问题，需要怎么优化？<br>内存溢出是指我申请了内存，但是不够存放，例如我用int型去存储long型的数值，就会内存溢出<br>内存泄露是指我对某一内存空间的使用，使用完成后没有释放。<br>内存优化：Android中容易内存溢出的部分，就是图片bitmap的加载，我们可以使用图片的压缩加上使用LruCache缓存的目的来控制图片所能够使用的内存。<br>还有对于比较耗资源的对象及时的关闭，例如Database Conn , 各种传感器 ， Service 等等。</p>\n<p>17，Androidstudio怎么检查内存使用？<br>有一个monitor的工具，打开就可以看到点击车的图标可以GC释放内存，然后看它的曲线与JavaHeap</p>\n<p>18，安卓多渠道打包<br>Android studio中<br>（一）在AndroidManifest.xml里设置动态渠道变量<br><meta-data\n    android:name=\"UMENG_CHANNEL\"\n    android:value=\"${UMENG_CHANNEL_VALUE}\" /></p>\n<p>（二）在build.gradle设置productFlavors<br>（三）执行打包操作<br><a href=\"http://blog.csdn.net/mynameishuangshuai/article/details/51783303\">http://blog.csdn.net/mynameishuangshuai/article/details/51783303</a></p>\n<p>19，view与surfaceview的区别<br>SurfaceView和View最本质的区别在于，surfaceView是在一个新起的单独线程中可以重新绘制画面而View必须在UI的主线程中更新画面，渲染速度surfaceview比view快</p>\n<p>20，屏幕旋转调用的生命周期<br>不设置activity的android:onconfigchang=oriention横屏一次，竖屏两次，设置Android：configchange=oriention横屏一次，竖屏一次，设置Android：<br>configchange:oriention|keyboardhidden不执行生命周期</p>\n<p>21安卓系统架构<br>底层是linux层次<br>之后是c++运行层<br>之后是framework框架层<br>最后是application应用层</p>"},{"date":"2017-01-16T03:35:00.000Z","status":"public","title":"安卓activity四种启动模式","_content":"\n摘要:安卓activity的四种启动模式在面试中也是经常会用到的\n<!--more-->\n1.standard 模式 标准模式，默认模式，每次激活都会重新创建activity，并且放到任务栈中\n2.singletop模式 要是在栈顶是你要启用的activity 那就会重用这个activity 要是不是这个就重新启动activity\n3.singletask模式 在栈里面查找要是有的话就复用 没有的话就重建\n4.signleInstance模式 外部应用也可以启动你这个activity\n\n设置启动模式的位置在 AndroidManifest.xml 文件中 Activity 元素的 android:launchMode 属性。\n\n应用场景  singleTop适合接收通知启动的内容显示页面。例如，某个新闻客户端的新闻内容页面，如果收到10个新闻推送，每次都打开一个新闻内容页面是很烦人的。\n\nsingleTask适合作为程序入口点。例如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。\n\nsingleInstance适合需要与程序分离开的页面。例如闹铃提醒，将闹铃提醒与闹铃设置分离。singleInstance不要用于中间页面，如果用于中间页面，跳转会有问题，比如：A -> B (singleInstance) -> C，完全退出后，在此启动，首先打开的是B。","source":"_posts/android/安卓四种启动模式.md","raw":"---\ndate: 2017-1-16 11:35\nstatus: public\ntitle: 安卓activity四种启动模式\ntags:\n  - 安卓\n---\n\n摘要:安卓activity的四种启动模式在面试中也是经常会用到的\n<!--more-->\n1.standard 模式 标准模式，默认模式，每次激活都会重新创建activity，并且放到任务栈中\n2.singletop模式 要是在栈顶是你要启用的activity 那就会重用这个activity 要是不是这个就重新启动activity\n3.singletask模式 在栈里面查找要是有的话就复用 没有的话就重建\n4.signleInstance模式 外部应用也可以启动你这个activity\n\n设置启动模式的位置在 AndroidManifest.xml 文件中 Activity 元素的 android:launchMode 属性。\n\n应用场景  singleTop适合接收通知启动的内容显示页面。例如，某个新闻客户端的新闻内容页面，如果收到10个新闻推送，每次都打开一个新闻内容页面是很烦人的。\n\nsingleTask适合作为程序入口点。例如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。\n\nsingleInstance适合需要与程序分离开的页面。例如闹铃提醒，将闹铃提醒与闹铃设置分离。singleInstance不要用于中间页面，如果用于中间页面，跳转会有问题，比如：A -> B (singleInstance) -> C，完全退出后，在此启动，首先打开的是B。","slug":"android/安卓四种启动模式","published":1,"updated":"2025-05-16T04:25:25.435Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrp000mskqr6m7l0wt3","content":"<p>摘要:安卓activity的四种启动模式在面试中也是经常会用到的</p>\n<span id=\"more\"></span>\n<p>1.standard 模式 标准模式，默认模式，每次激活都会重新创建activity，并且放到任务栈中<br>2.singletop模式 要是在栈顶是你要启用的activity 那就会重用这个activity 要是不是这个就重新启动activity<br>3.singletask模式 在栈里面查找要是有的话就复用 没有的话就重建<br>4.signleInstance模式 外部应用也可以启动你这个activity</p>\n<p>设置启动模式的位置在 AndroidManifest.xml 文件中 Activity 元素的 android:launchMode 属性。</p>\n<p>应用场景  singleTop适合接收通知启动的内容显示页面。例如，某个新闻客户端的新闻内容页面，如果收到10个新闻推送，每次都打开一个新闻内容页面是很烦人的。</p>\n<p>singleTask适合作为程序入口点。例如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。</p>\n<p>singleInstance适合需要与程序分离开的页面。例如闹铃提醒，将闹铃提醒与闹铃设置分离。singleInstance不要用于中间页面，如果用于中间页面，跳转会有问题，比如：A -&gt; B (singleInstance) -&gt; C，完全退出后，在此启动，首先打开的是B。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:安卓activity的四种启动模式在面试中也是经常会用到的</p>","more":"<p>1.standard 模式 标准模式，默认模式，每次激活都会重新创建activity，并且放到任务栈中<br>2.singletop模式 要是在栈顶是你要启用的activity 那就会重用这个activity 要是不是这个就重新启动activity<br>3.singletask模式 在栈里面查找要是有的话就复用 没有的话就重建<br>4.signleInstance模式 外部应用也可以启动你这个activity</p>\n<p>设置启动模式的位置在 AndroidManifest.xml 文件中 Activity 元素的 android:launchMode 属性。</p>\n<p>应用场景  singleTop适合接收通知启动的内容显示页面。例如，某个新闻客户端的新闻内容页面，如果收到10个新闻推送，每次都打开一个新闻内容页面是很烦人的。</p>\n<p>singleTask适合作为程序入口点。例如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。</p>\n<p>singleInstance适合需要与程序分离开的页面。例如闹铃提醒，将闹铃提醒与闹铃设置分离。singleInstance不要用于中间页面，如果用于中间页面，跳转会有问题，比如：A -&gt; B (singleInstance) -&gt; C，完全退出后，在此启动，首先打开的是B。</p>"},{"date":"2017-01-16T03:35:00.000Z","status":"public","title":"观察者模式","_content":"\n摘要:前几天面试的时候，说到这个问题观察者模式，面试官说setonclicklistener不是观察者模式，我当时也是楞了一下，硬是附和着面试官说不是观察者模式了~~其实点击事件是一个回调，但是同时也是一对一的观察者模式\n<!--more-->\n接下来我们看看观察者模式在android中的应用。我们从最简单的开始。还记得我们为一个Button设置点击事件的代码吗。\nButton btn=new Button(this);\nbtn.setOnClickListener(new View.OnClickListener() {\n\t@Override\n\tpublic void onClick(View v) {\n\t\tLog.e(\"TAG\",\"click\");\n\t}\n});\n其实严格意义上讲，这个最多算是回调，但是我们可以将其看成是一对一的观察者模式，即只有一个观察者。\n\n其实只要是set系列的设置监听器的方法最多都只能算《回调》，但是有一些监听器式《add》进去的，这种就是观察者模式了，比如RecyclerView中的addOnScrollListener方法\nprivate List<OnScrollListener> mScrollListeners;\npublic void addOnScrollListener(OnScrollListener listener) {\n\tif (mScrollListeners == null) {\n\t\tmScrollListeners = new ArrayList<OnScrollListener>();\n\t}\n\tmScrollListeners.add(listener);\n}\npublic void removeOnScrollListener(OnScrollListener listener) {\n\tif (mScrollListeners != null) {\n\t\tmScrollListeners.remove(listener);\n\t}\n}\npublic void clearOnScrollListeners() {\n\tif (mScrollListeners != null) {\n\t\tmScrollListeners.clear();\n\t}\n}\n然后有滚动事件时便会触发观察者进行方法回调\npublic abstract static class OnScrollListener {\n\tpublic void onScrollStateChanged(RecyclerView recyclerView, int newState){}\n\tpublic void onScrolled(RecyclerView recyclerView, int dx, int dy){}\n}\n\nvoid dispatchOnScrolled(int hresult, int vresult) {\n\t//...\n\tif (mScrollListeners != null) {\n\t\tfor (int i = mScrollListeners.size() - 1; i >= 0; i--) {\n\t\t\tmScrollListeners.get(i).onScrolled(this, hresult, vresult);\n\t\t}\n\t}\n}\nvoid dispatchOnScrollStateChanged(int state) {\n\t//...\n\tif (mScrollListeners != null) {\n\t\tfor (int i = mScrollListeners.size() - 1; i >= 0; i--) {\n\t\t\tmScrollListeners.get(i).onScrollStateChanged(this, state);\n\t\t}\n\t}\n}\n类似的方法很多很多，都是add监听器系列的方法，这里也不再举例。\n\n还有一个地方就是Android的广播机制，其本质也是观察者模式，这里为了简单方便，直接拿本地广播的代码说明，即LocalBroadcastManager。\n\n我们平时使用本地广播主要就是下面四个方法\nLocalBroadcastManager localBroadcastManager=LocalBroadcastManager.getInstance(this);\nlocalBroadcastManager.registerReceiver(BroadcastReceiver receiver, IntentFilter filter);\nlocalBroadcastManager.unregisterReceiver(BroadcastReceiver receiver);\nlocalBroadcastManager.sendBroadcast(Intent intent)\n调用registerReceiver方法注册广播，调用unregisterReceiver方法取消注册，之后直接使用sendBroadcast发送广播，发送广播之后，注册的广播会收到对应的广播信息，这就是典型的观察者模式。具体的源代码这里也不贴。\n\nandroid系统中的观察者模式还有很多很多，有兴趣的自己去挖掘，接下来我们看一下一些开源框架中的观察者模式。一说到开源框架，你首先想到的应该是EventBus。没错，EventBus也是基于观察者模式的。\n\n观察者模式的三个典型方法它都具有，即注册，取消注册，发送事件\nEventBus.getDefault().register(Object subscriber);\nEventBus.getDefault().unregister(Object subscriber);\n\nEventBus.getDefault().post(Object event);\n内部源码也不展开了。","source":"_posts/android/观察者模式.md","raw":"---\ndate:  2017-1-16 11:35\nstatus: public\ntitle: 观察者模式\ntags:\n  - 安卓\n---\n\n摘要:前几天面试的时候，说到这个问题观察者模式，面试官说setonclicklistener不是观察者模式，我当时也是楞了一下，硬是附和着面试官说不是观察者模式了~~其实点击事件是一个回调，但是同时也是一对一的观察者模式\n<!--more-->\n接下来我们看看观察者模式在android中的应用。我们从最简单的开始。还记得我们为一个Button设置点击事件的代码吗。\nButton btn=new Button(this);\nbtn.setOnClickListener(new View.OnClickListener() {\n\t@Override\n\tpublic void onClick(View v) {\n\t\tLog.e(\"TAG\",\"click\");\n\t}\n});\n其实严格意义上讲，这个最多算是回调，但是我们可以将其看成是一对一的观察者模式，即只有一个观察者。\n\n其实只要是set系列的设置监听器的方法最多都只能算《回调》，但是有一些监听器式《add》进去的，这种就是观察者模式了，比如RecyclerView中的addOnScrollListener方法\nprivate List<OnScrollListener> mScrollListeners;\npublic void addOnScrollListener(OnScrollListener listener) {\n\tif (mScrollListeners == null) {\n\t\tmScrollListeners = new ArrayList<OnScrollListener>();\n\t}\n\tmScrollListeners.add(listener);\n}\npublic void removeOnScrollListener(OnScrollListener listener) {\n\tif (mScrollListeners != null) {\n\t\tmScrollListeners.remove(listener);\n\t}\n}\npublic void clearOnScrollListeners() {\n\tif (mScrollListeners != null) {\n\t\tmScrollListeners.clear();\n\t}\n}\n然后有滚动事件时便会触发观察者进行方法回调\npublic abstract static class OnScrollListener {\n\tpublic void onScrollStateChanged(RecyclerView recyclerView, int newState){}\n\tpublic void onScrolled(RecyclerView recyclerView, int dx, int dy){}\n}\n\nvoid dispatchOnScrolled(int hresult, int vresult) {\n\t//...\n\tif (mScrollListeners != null) {\n\t\tfor (int i = mScrollListeners.size() - 1; i >= 0; i--) {\n\t\t\tmScrollListeners.get(i).onScrolled(this, hresult, vresult);\n\t\t}\n\t}\n}\nvoid dispatchOnScrollStateChanged(int state) {\n\t//...\n\tif (mScrollListeners != null) {\n\t\tfor (int i = mScrollListeners.size() - 1; i >= 0; i--) {\n\t\t\tmScrollListeners.get(i).onScrollStateChanged(this, state);\n\t\t}\n\t}\n}\n类似的方法很多很多，都是add监听器系列的方法，这里也不再举例。\n\n还有一个地方就是Android的广播机制，其本质也是观察者模式，这里为了简单方便，直接拿本地广播的代码说明，即LocalBroadcastManager。\n\n我们平时使用本地广播主要就是下面四个方法\nLocalBroadcastManager localBroadcastManager=LocalBroadcastManager.getInstance(this);\nlocalBroadcastManager.registerReceiver(BroadcastReceiver receiver, IntentFilter filter);\nlocalBroadcastManager.unregisterReceiver(BroadcastReceiver receiver);\nlocalBroadcastManager.sendBroadcast(Intent intent)\n调用registerReceiver方法注册广播，调用unregisterReceiver方法取消注册，之后直接使用sendBroadcast发送广播，发送广播之后，注册的广播会收到对应的广播信息，这就是典型的观察者模式。具体的源代码这里也不贴。\n\nandroid系统中的观察者模式还有很多很多，有兴趣的自己去挖掘，接下来我们看一下一些开源框架中的观察者模式。一说到开源框架，你首先想到的应该是EventBus。没错，EventBus也是基于观察者模式的。\n\n观察者模式的三个典型方法它都具有，即注册，取消注册，发送事件\nEventBus.getDefault().register(Object subscriber);\nEventBus.getDefault().unregister(Object subscriber);\n\nEventBus.getDefault().post(Object event);\n内部源码也不展开了。","slug":"android/观察者模式","published":1,"updated":"2025-05-16T04:25:25.439Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jrq000pskqr0llwavm9","content":"<p>摘要:前几天面试的时候，说到这个问题观察者模式，面试官说setonclicklistener不是观察者模式，我当时也是楞了一下，硬是附和着面试官说不是观察者模式了~~其实点击事件是一个回调，但是同时也是一对一的观察者模式</p>\n<span id=\"more\"></span>\n<p>接下来我们看看观察者模式在android中的应用。我们从最简单的开始。还记得我们为一个Button设置点击事件的代码吗。<br>Button btn=new Button(this);<br>btn.setOnClickListener(new View.OnClickListener() {<br>    @Override<br>    public void onClick(View v) {<br>        Log.e(“TAG”,”click”);<br>    }<br>});<br>其实严格意义上讲，这个最多算是回调，但是我们可以将其看成是一对一的观察者模式，即只有一个观察者。</p>\n<p>其实只要是set系列的设置监听器的方法最多都只能算《回调》，但是有一些监听器式《add》进去的，这种就是观察者模式了，比如RecyclerView中的addOnScrollListener方法<br>private List<OnScrollListener> mScrollListeners;<br>public void addOnScrollListener(OnScrollListener listener) {<br>    if (mScrollListeners == null) {<br>        mScrollListeners = new ArrayList<OnScrollListener>();<br>    }<br>    mScrollListeners.add(listener);<br>}<br>public void removeOnScrollListener(OnScrollListener listener) {<br>    if (mScrollListeners != null) {<br>        mScrollListeners.remove(listener);<br>    }<br>}<br>public void clearOnScrollListeners() {<br>    if (mScrollListeners != null) {<br>        mScrollListeners.clear();<br>    }<br>}<br>然后有滚动事件时便会触发观察者进行方法回调<br>public abstract static class OnScrollListener {<br>    public void onScrollStateChanged(RecyclerView recyclerView, int newState){}<br>    public void onScrolled(RecyclerView recyclerView, int dx, int dy){}<br>}</p>\n<p>void dispatchOnScrolled(int hresult, int vresult) {<br>    //…<br>    if (mScrollListeners != null) {<br>        for (int i = mScrollListeners.size() - 1; i &gt;= 0; i–) {<br>            mScrollListeners.get(i).onScrolled(this, hresult, vresult);<br>        }<br>    }<br>}<br>void dispatchOnScrollStateChanged(int state) {<br>    //…<br>    if (mScrollListeners != null) {<br>        for (int i = mScrollListeners.size() - 1; i &gt;= 0; i–) {<br>            mScrollListeners.get(i).onScrollStateChanged(this, state);<br>        }<br>    }<br>}<br>类似的方法很多很多，都是add监听器系列的方法，这里也不再举例。</p>\n<p>还有一个地方就是Android的广播机制，其本质也是观察者模式，这里为了简单方便，直接拿本地广播的代码说明，即LocalBroadcastManager。</p>\n<p>我们平时使用本地广播主要就是下面四个方法<br>LocalBroadcastManager localBroadcastManager=LocalBroadcastManager.getInstance(this);<br>localBroadcastManager.registerReceiver(BroadcastReceiver receiver, IntentFilter filter);<br>localBroadcastManager.unregisterReceiver(BroadcastReceiver receiver);<br>localBroadcastManager.sendBroadcast(Intent intent)<br>调用registerReceiver方法注册广播，调用unregisterReceiver方法取消注册，之后直接使用sendBroadcast发送广播，发送广播之后，注册的广播会收到对应的广播信息，这就是典型的观察者模式。具体的源代码这里也不贴。</p>\n<p>android系统中的观察者模式还有很多很多，有兴趣的自己去挖掘，接下来我们看一下一些开源框架中的观察者模式。一说到开源框架，你首先想到的应该是EventBus。没错，EventBus也是基于观察者模式的。</p>\n<p>观察者模式的三个典型方法它都具有，即注册，取消注册，发送事件<br>EventBus.getDefault().register(Object subscriber);<br>EventBus.getDefault().unregister(Object subscriber);</p>\n<p>EventBus.getDefault().post(Object event);<br>内部源码也不展开了。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:前几天面试的时候，说到这个问题观察者模式，面试官说setonclicklistener不是观察者模式，我当时也是楞了一下，硬是附和着面试官说不是观察者模式了~~其实点击事件是一个回调，但是同时也是一对一的观察者模式</p>","more":"<p>接下来我们看看观察者模式在android中的应用。我们从最简单的开始。还记得我们为一个Button设置点击事件的代码吗。<br>Button btn=new Button(this);<br>btn.setOnClickListener(new View.OnClickListener() {<br>    @Override<br>    public void onClick(View v) {<br>        Log.e(“TAG”,”click”);<br>    }<br>});<br>其实严格意义上讲，这个最多算是回调，但是我们可以将其看成是一对一的观察者模式，即只有一个观察者。</p>\n<p>其实只要是set系列的设置监听器的方法最多都只能算《回调》，但是有一些监听器式《add》进去的，这种就是观察者模式了，比如RecyclerView中的addOnScrollListener方法<br>private List<OnScrollListener> mScrollListeners;<br>public void addOnScrollListener(OnScrollListener listener) {<br>    if (mScrollListeners == null) {<br>        mScrollListeners = new ArrayList<OnScrollListener>();<br>    }<br>    mScrollListeners.add(listener);<br>}<br>public void removeOnScrollListener(OnScrollListener listener) {<br>    if (mScrollListeners != null) {<br>        mScrollListeners.remove(listener);<br>    }<br>}<br>public void clearOnScrollListeners() {<br>    if (mScrollListeners != null) {<br>        mScrollListeners.clear();<br>    }<br>}<br>然后有滚动事件时便会触发观察者进行方法回调<br>public abstract static class OnScrollListener {<br>    public void onScrollStateChanged(RecyclerView recyclerView, int newState){}<br>    public void onScrolled(RecyclerView recyclerView, int dx, int dy){}<br>}</p>\n<p>void dispatchOnScrolled(int hresult, int vresult) {<br>    //…<br>    if (mScrollListeners != null) {<br>        for (int i = mScrollListeners.size() - 1; i &gt;= 0; i–) {<br>            mScrollListeners.get(i).onScrolled(this, hresult, vresult);<br>        }<br>    }<br>}<br>void dispatchOnScrollStateChanged(int state) {<br>    //…<br>    if (mScrollListeners != null) {<br>        for (int i = mScrollListeners.size() - 1; i &gt;= 0; i–) {<br>            mScrollListeners.get(i).onScrollStateChanged(this, state);<br>        }<br>    }<br>}<br>类似的方法很多很多，都是add监听器系列的方法，这里也不再举例。</p>\n<p>还有一个地方就是Android的广播机制，其本质也是观察者模式，这里为了简单方便，直接拿本地广播的代码说明，即LocalBroadcastManager。</p>\n<p>我们平时使用本地广播主要就是下面四个方法<br>LocalBroadcastManager localBroadcastManager=LocalBroadcastManager.getInstance(this);<br>localBroadcastManager.registerReceiver(BroadcastReceiver receiver, IntentFilter filter);<br>localBroadcastManager.unregisterReceiver(BroadcastReceiver receiver);<br>localBroadcastManager.sendBroadcast(Intent intent)<br>调用registerReceiver方法注册广播，调用unregisterReceiver方法取消注册，之后直接使用sendBroadcast发送广播，发送广播之后，注册的广播会收到对应的广播信息，这就是典型的观察者模式。具体的源代码这里也不贴。</p>\n<p>android系统中的观察者模式还有很多很多，有兴趣的自己去挖掘，接下来我们看一下一些开源框架中的观察者模式。一说到开源框架，你首先想到的应该是EventBus。没错，EventBus也是基于观察者模式的。</p>\n<p>观察者模式的三个典型方法它都具有，即注册，取消注册，发送事件<br>EventBus.getDefault().register(Object subscriber);<br>EventBus.getDefault().unregister(Object subscriber);</p>\n<p>EventBus.getDefault().post(Object event);<br>内部源码也不展开了。</p>"},{"date":"2016-12-23T03:35:00.000Z","status":"public","title":"html5 Video标签实现","_content":"\n摘要:H5标签实现  在播放视频流的时候会自动全屏，可以实现不全屏\n<!--more-->\nvideo标签还是比较常用的，在微信浏览器里面使用video标签，\n会自动变成全屏，改成下面就好了，\n起码可以在video标签之上加入其他元素。   \n ```<video id=\"videoID\"webkit-playsinline=\"true\" \n x-webkit-airplay=\"true\"  playsinline=\"true\"\n x5-video-player-type=\"h5\"\n x5-video-player-fullscreen=\"true\"\n width=\"100%\" height=\"100%\" preload=\"auto\"  \n poster=\"\" src=\"\">\n </video>```\n\n还有个问题，在Android的微信里面，\n就算加上了上面的属性，还会出现上下有黑边，不能全屏的问题。\n解决办法：给video加上object-fit: fill;的style属性。\n实现方法：   \n```'<video id=\"videoplayer\" controls=\"controls\"'+ \n'tabindex=\"0\" preload=\"metadata\" style=\"width:100%; height: 100%; overflow: hidden;object-fit: fill;\" '+\n'poster=\"http://sun1.wxdg.sun0769.com/ImageResource/video.jpg\" '+\n'webkit-playsinline=\"true\" x-webkit-airplay=\"true\"  playsinline=\"true\" '+\n'x5-video-player-fullscreen=\"true\"></video>'```","source":"_posts/h5/video标签.md","raw":"---\ndate: 2016-12-23 11:35\nstatus: public\ntitle: html5 Video标签实现\ntags:\n  - H5\n---\n\n摘要:H5标签实现  在播放视频流的时候会自动全屏，可以实现不全屏\n<!--more-->\nvideo标签还是比较常用的，在微信浏览器里面使用video标签，\n会自动变成全屏，改成下面就好了，\n起码可以在video标签之上加入其他元素。   \n ```<video id=\"videoID\"webkit-playsinline=\"true\" \n x-webkit-airplay=\"true\"  playsinline=\"true\"\n x5-video-player-type=\"h5\"\n x5-video-player-fullscreen=\"true\"\n width=\"100%\" height=\"100%\" preload=\"auto\"  \n poster=\"\" src=\"\">\n </video>```\n\n还有个问题，在Android的微信里面，\n就算加上了上面的属性，还会出现上下有黑边，不能全屏的问题。\n解决办法：给video加上object-fit: fill;的style属性。\n实现方法：   \n```'<video id=\"videoplayer\" controls=\"controls\"'+ \n'tabindex=\"0\" preload=\"metadata\" style=\"width:100%; height: 100%; overflow: hidden;object-fit: fill;\" '+\n'poster=\"http://sun1.wxdg.sun0769.com/ImageResource/video.jpg\" '+\n'webkit-playsinline=\"true\" x-webkit-airplay=\"true\"  playsinline=\"true\" '+\n'x5-video-player-fullscreen=\"true\"></video>'```","slug":"h5/video标签","published":1,"updated":"2025-05-16T04:25:25.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jse0012skqrbb98abza","content":"<p>摘要:H5标签实现  在播放视频流的时候会自动全屏，可以实现不全屏</p>\n<span id=\"more\"></span>\n<p>video标签还是比较常用的，在微信浏览器里面使用video标签，<br>会自动变成全屏，改成下面就好了，<br>起码可以在video标签之上加入其他元素。   </p>\n<p> <code>&lt;video id=&quot;videoID&quot;webkit-playsinline=&quot;true&quot;   x-webkit-airplay=&quot;true&quot;  playsinline=&quot;true&quot;  x5-video-player-type=&quot;h5&quot;  x5-video-player-fullscreen=&quot;true&quot;  width=&quot;100%&quot; height=&quot;100%&quot; preload=&quot;auto&quot;    poster=&quot;&quot; src=&quot;&quot;&gt;  &lt;/video&gt;</code></p>\n<p>还有个问题，在Android的微信里面，<br>就算加上了上面的属性，还会出现上下有黑边，不能全屏的问题。<br>解决办法：给video加上object-fit: fill;的style属性。<br>实现方法：   </p>\n<p><code>&#39;&lt;video id=&quot;videoplayer&quot; controls=&quot;controls&quot;&#39;+  &#39;tabindex=&quot;0&quot; preload=&quot;metadata&quot; style=&quot;width:100%; height: 100%; overflow: hidden;object-fit: fill;&quot; &#39;+ &#39;poster=&quot;http://sun1.wxdg.sun0769.com/ImageResource/video.jpg&quot; &#39;+ &#39;webkit-playsinline=&quot;true&quot; x-webkit-airplay=&quot;true&quot;  playsinline=&quot;true&quot; &#39;+ &#39;x5-video-player-fullscreen=&quot;true&quot;&gt;&lt;/video&gt;&#39;</code></p>\n","site":{"data":{}},"excerpt":"<p>摘要:H5标签实现  在播放视频流的时候会自动全屏，可以实现不全屏</p>","more":"<p>video标签还是比较常用的，在微信浏览器里面使用video标签，<br>会自动变成全屏，改成下面就好了，<br>起码可以在video标签之上加入其他元素。   </p>\n<p> <code>&lt;video id=&quot;videoID&quot;webkit-playsinline=&quot;true&quot;   x-webkit-airplay=&quot;true&quot;  playsinline=&quot;true&quot;  x5-video-player-type=&quot;h5&quot;  x5-video-player-fullscreen=&quot;true&quot;  width=&quot;100%&quot; height=&quot;100%&quot; preload=&quot;auto&quot;    poster=&quot;&quot; src=&quot;&quot;&gt;  &lt;/video&gt;</code></p>\n<p>还有个问题，在Android的微信里面，<br>就算加上了上面的属性，还会出现上下有黑边，不能全屏的问题。<br>解决办法：给video加上object-fit: fill;的style属性。<br>实现方法：   </p>\n<p><code>&#39;&lt;video id=&quot;videoplayer&quot; controls=&quot;controls&quot;&#39;+  &#39;tabindex=&quot;0&quot; preload=&quot;metadata&quot; style=&quot;width:100%; height: 100%; overflow: hidden;object-fit: fill;&quot; &#39;+ &#39;poster=&quot;http://sun1.wxdg.sun0769.com/ImageResource/video.jpg&quot; &#39;+ &#39;webkit-playsinline=&quot;true&quot; x-webkit-airplay=&quot;true&quot;  playsinline=&quot;true&quot; &#39;+ &#39;x5-video-player-fullscreen=&quot;true&quot;&gt;&lt;/video&gt;&#39;</code></p>"},{"date":"2016-12-23T03:35:00.000Z","status":"public","title":"html传参数乱码","_content":"\n摘要:有时候会遇到传H5参数会乱码，就是一个页面用get方法带去参数，之后在另外一个页面获取参数会乱码，顺便写出获取参数的方法\n<!--more-->\n//获取参数的方法\nfunction getQueryString(name) {\n    var reg = new RegExp(\"(^|&)\" + name + \"=([^&]*)(&|$)\", \"i\");\n    var r = window.location.search.substr(1).match(reg);\n    if (r != null) return unescape(r[2]); return null;\n}\n在一个URL带上参数例如：http://127.0.0.1:8020/index.html?id=205&department=部门\n但是这个中文会乱码，在获取的时候，这个时候我们要先给部门两个中文字先encode  之后再获取的时候再解码：index.html?id='+id+'&department='+escape(department)+'\n然后获取的时候就直接unescape(getQueryString('department'))  获取出来的就不是乱码了。","source":"_posts/h5/传参数乱码.md","raw":"---\ndate: 2016-12-23 11:35\nstatus: public\ntitle: html传参数乱码\ntags:\n  - H5\n---\n\n摘要:有时候会遇到传H5参数会乱码，就是一个页面用get方法带去参数，之后在另外一个页面获取参数会乱码，顺便写出获取参数的方法\n<!--more-->\n//获取参数的方法\nfunction getQueryString(name) {\n    var reg = new RegExp(\"(^|&)\" + name + \"=([^&]*)(&|$)\", \"i\");\n    var r = window.location.search.substr(1).match(reg);\n    if (r != null) return unescape(r[2]); return null;\n}\n在一个URL带上参数例如：http://127.0.0.1:8020/index.html?id=205&department=部门\n但是这个中文会乱码，在获取的时候，这个时候我们要先给部门两个中文字先encode  之后再获取的时候再解码：index.html?id='+id+'&department='+escape(department)+'\n然后获取的时候就直接unescape(getQueryString('department'))  获取出来的就不是乱码了。","slug":"h5/传参数乱码","published":1,"updated":"2025-05-16T04:25:25.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsf0013skqrhf4k4t2v","content":"<p>摘要:有时候会遇到传H5参数会乱码，就是一个页面用get方法带去参数，之后在另外一个页面获取参数会乱码，顺便写出获取参数的方法</p>\n<span id=\"more\"></span>\n<p>//获取参数的方法<br>function getQueryString(name) {<br>    var reg = new RegExp(“(^|&amp;)” + name + “=([^&amp;]*)(&amp;|$)”, “i”);<br>    var r = window.location.search.substr(1).match(reg);<br>    if (r != null) return unescape(r[2]); return null;<br>}<br>在一个URL带上参数例如：<a href=\"http://127.0.0.1:8020/index.html?id=205&amp;department=%E9%83%A8%E9%97%A8\">http://127.0.0.1:8020/index.html?id=205&amp;department=部门</a><br>但是这个中文会乱码，在获取的时候，这个时候我们要先给部门两个中文字先encode  之后再获取的时候再解码：index.html?id=’+id+’&amp;department=’+escape(department)+’<br>然后获取的时候就直接unescape(getQueryString(‘department’))  获取出来的就不是乱码了。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:有时候会遇到传H5参数会乱码，就是一个页面用get方法带去参数，之后在另外一个页面获取参数会乱码，顺便写出获取参数的方法</p>","more":"<p>//获取参数的方法<br>function getQueryString(name) {<br>    var reg = new RegExp(“(^|&amp;)” + name + “=([^&amp;]*)(&amp;|$)”, “i”);<br>    var r = window.location.search.substr(1).match(reg);<br>    if (r != null) return unescape(r[2]); return null;<br>}<br>在一个URL带上参数例如：<a href=\"http://127.0.0.1:8020/index.html?id=205&amp;department=%E9%83%A8%E9%97%A8\">http://127.0.0.1:8020/index.html?id=205&amp;department=部门</a><br>但是这个中文会乱码，在获取的时候，这个时候我们要先给部门两个中文字先encode  之后再获取的时候再解码：index.html?id=’+id+’&amp;department=’+escape(department)+’<br>然后获取的时候就直接unescape(getQueryString(‘department’))  获取出来的就不是乱码了。</p>"},{"date":"2021-01-20T03:35:00.000Z","title":"java并发编程","_content":"\n摘要:java线程内存模型\n<!--more-->\n# JMM\n\n# vilotile\n\n# JUC JDK1.5之后有 java.util.concurrent \n1,AtomicInteger 保证原子加原子减 vilotile 修饰的int值\n2,ConcurrentHashMap  线程可靠的hashmap 分段锁实现\n3,Callable  定义线程 ExecutorService Executors Future\n4,ReadWriteLock 读写锁 \n5,CountDownLatch 闭锁","source":"_posts/java/JAVA并发.md","raw":"---\ndate: 2021-01-20 11:35\ntitle: java并发编程\ntags:\n  - java\n---\n\n摘要:java线程内存模型\n<!--more-->\n# JMM\n\n# vilotile\n\n# JUC JDK1.5之后有 java.util.concurrent \n1,AtomicInteger 保证原子加原子减 vilotile 修饰的int值\n2,ConcurrentHashMap  线程可靠的hashmap 分段锁实现\n3,Callable  定义线程 ExecutorService Executors Future\n4,ReadWriteLock 读写锁 \n5,CountDownLatch 闭锁","slug":"java/JAVA并发","published":1,"updated":"2025-05-16T04:25:25.413Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsh0015skqrb9h591fe","content":"<p>摘要:java线程内存模型</p>\n<span id=\"more\"></span>\n<h1 id=\"JMM\"><a href=\"#JMM\" class=\"headerlink\" title=\"JMM\"></a>JMM</h1><h1 id=\"vilotile\"><a href=\"#vilotile\" class=\"headerlink\" title=\"vilotile\"></a>vilotile</h1><h1 id=\"JUC-JDK1-5之后有-java-util-concurrent\"><a href=\"#JUC-JDK1-5之后有-java-util-concurrent\" class=\"headerlink\" title=\"JUC JDK1.5之后有 java.util.concurrent\"></a>JUC JDK1.5之后有 java.util.concurrent</h1><p>1,AtomicInteger 保证原子加原子减 vilotile 修饰的int值<br>2,ConcurrentHashMap  线程可靠的hashmap 分段锁实现<br>3,Callable  定义线程 ExecutorService Executors Future<br>4,ReadWriteLock 读写锁<br>5,CountDownLatch 闭锁</p>\n","site":{"data":{}},"excerpt":"<p>摘要:java线程内存模型</p>","more":"<h1 id=\"JMM\"><a href=\"#JMM\" class=\"headerlink\" title=\"JMM\"></a>JMM</h1><h1 id=\"vilotile\"><a href=\"#vilotile\" class=\"headerlink\" title=\"vilotile\"></a>vilotile</h1><h1 id=\"JUC-JDK1-5之后有-java-util-concurrent\"><a href=\"#JUC-JDK1-5之后有-java-util-concurrent\" class=\"headerlink\" title=\"JUC JDK1.5之后有 java.util.concurrent\"></a>JUC JDK1.5之后有 java.util.concurrent</h1><p>1,AtomicInteger 保证原子加原子减 vilotile 修饰的int值<br>2,ConcurrentHashMap  线程可靠的hashmap 分段锁实现<br>3,Callable  定义线程 ExecutorService Executors Future<br>4,ReadWriteLock 读写锁<br>5,CountDownLatch 闭锁</p>"},{"date":"2020-03-16T16:00:00.000Z","status":"public","title":"MQ机制","_content":"\n摘要:MQ机制\n<!--more-->\n# MQ 消息对接的作用\n## 解耦\n\n## 削峰\n\n## 异步\n\n# rebbitMQ\nRabbitMQ是使用Erlang编写的一个开源的消息队列，吞吐量和tps 适中，性能较好，erlang语言较难维护\n\n# activeMQ（开源给了apollo）又叫ApolloMQ\n维护较少，会丢失数据\n\n# kafka\n吞吐量，和tps 都大，适合做大数据\n\n# 三者区别\n## TPS 每秒传输的事务处理个数\nKafka最高，RabbitMq 次之， ActiveMq 最差\n## 吞吐量对比 处理事务的能力\nkafka具有高的吞吐量，内部采用消息的批量处理，rabbitMQ在吞吐量方面稍逊于kafka，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作\nActiveMq 最差\n\n# rebbitMQ Exchange分几类\n1，topic  就是direct的升级版 就是增加了一个路由的通配符\n2，direct 绑定队列和路由 只有设定了特定路由的队列才可以收到\n3，fanout  广播模式 任何队列都可以收到\n4，headers\n\n# 如何保证RabbitMQ不被重复消费？（幂等性）\n1.当拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。\n2.当拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。\n3.只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可\n4.如果消费的时候，两三个线程一起来消费，要注意这个时候要采用CAS 乐观锁的一个概念，就是说给数据库表加多一个字段，如果消费了就改变它状态，这个时候其他消费就不能消费了\n\n# 如何保证RabbitMQ消息的可靠传输？\n1，生产者报错，生产者要保证消息的可靠性传输有两个办法\n1），直接用事务的概念，报错直接rollback\n2），启用confirm模式，发送的时候会发送一个ACK 标志，一旦消息投递到队列里面就会发送 ACK，如果rabbitmq没有处理这个消息就会发送NACK 给你，这个时候你可以重试\n2，rabbitmq 本身报错，这个时候可以开启持久化机制，只要写入进来就写到硬盘里面，这个时候如果报错的话，下次重启还是可以继续读出来\n3，消费者报错，这个时候可以把ACK机制手动确认，只有消费者消费之后才返回ACK，这样就可以在消费报错的时候，让生产者重传\n\n# rabbitmq 怎么实现延迟消息队列？\n使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。\n\n# rabbitMQ 事务是怎么实现的\n通过AMQP事务机制实现，这也是AMQP协议层面提供的解决方案；\ntxSelect(), txCommit()以及txRollback(), txSelect用于将当前channel设置成transaction模式，\ntxCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，\n如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，\n这个时候我们便可以捕获异常通过txRollback回滚事务了。\n","source":"_posts/java/MQ机制.md","raw":"---\ndate: 2020-03-17\nstatus: public\ntitle: MQ机制\ntags:\n  - JAVA\n  - MQ\n---\n\n摘要:MQ机制\n<!--more-->\n# MQ 消息对接的作用\n## 解耦\n\n## 削峰\n\n## 异步\n\n# rebbitMQ\nRabbitMQ是使用Erlang编写的一个开源的消息队列，吞吐量和tps 适中，性能较好，erlang语言较难维护\n\n# activeMQ（开源给了apollo）又叫ApolloMQ\n维护较少，会丢失数据\n\n# kafka\n吞吐量，和tps 都大，适合做大数据\n\n# 三者区别\n## TPS 每秒传输的事务处理个数\nKafka最高，RabbitMq 次之， ActiveMq 最差\n## 吞吐量对比 处理事务的能力\nkafka具有高的吞吐量，内部采用消息的批量处理，rabbitMQ在吞吐量方面稍逊于kafka，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作\nActiveMq 最差\n\n# rebbitMQ Exchange分几类\n1，topic  就是direct的升级版 就是增加了一个路由的通配符\n2，direct 绑定队列和路由 只有设定了特定路由的队列才可以收到\n3，fanout  广播模式 任何队列都可以收到\n4，headers\n\n# 如何保证RabbitMQ不被重复消费？（幂等性）\n1.当拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。\n2.当拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。\n3.只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可\n4.如果消费的时候，两三个线程一起来消费，要注意这个时候要采用CAS 乐观锁的一个概念，就是说给数据库表加多一个字段，如果消费了就改变它状态，这个时候其他消费就不能消费了\n\n# 如何保证RabbitMQ消息的可靠传输？\n1，生产者报错，生产者要保证消息的可靠性传输有两个办法\n1），直接用事务的概念，报错直接rollback\n2），启用confirm模式，发送的时候会发送一个ACK 标志，一旦消息投递到队列里面就会发送 ACK，如果rabbitmq没有处理这个消息就会发送NACK 给你，这个时候你可以重试\n2，rabbitmq 本身报错，这个时候可以开启持久化机制，只要写入进来就写到硬盘里面，这个时候如果报错的话，下次重启还是可以继续读出来\n3，消费者报错，这个时候可以把ACK机制手动确认，只有消费者消费之后才返回ACK，这样就可以在消费报错的时候，让生产者重传\n\n# rabbitmq 怎么实现延迟消息队列？\n使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。\n\n# rabbitMQ 事务是怎么实现的\n通过AMQP事务机制实现，这也是AMQP协议层面提供的解决方案；\ntxSelect(), txCommit()以及txRollback(), txSelect用于将当前channel设置成transaction模式，\ntxCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，\n如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，\n这个时候我们便可以捕获异常通过txRollback回滚事务了。\n","slug":"java/MQ机制","published":1,"updated":"2025-05-16T04:25:25.415Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsi0016skqra6gdbrtp","content":"<p>摘要:MQ机制</p>\n<span id=\"more\"></span>\n<h1 id=\"MQ-消息对接的作用\"><a href=\"#MQ-消息对接的作用\" class=\"headerlink\" title=\"MQ 消息对接的作用\"></a>MQ 消息对接的作用</h1><h2 id=\"解耦\"><a href=\"#解耦\" class=\"headerlink\" title=\"解耦\"></a>解耦</h2><h2 id=\"削峰\"><a href=\"#削峰\" class=\"headerlink\" title=\"削峰\"></a>削峰</h2><h2 id=\"异步\"><a href=\"#异步\" class=\"headerlink\" title=\"异步\"></a>异步</h2><h1 id=\"rebbitMQ\"><a href=\"#rebbitMQ\" class=\"headerlink\" title=\"rebbitMQ\"></a>rebbitMQ</h1><p>RabbitMQ是使用Erlang编写的一个开源的消息队列，吞吐量和tps 适中，性能较好，erlang语言较难维护</p>\n<h1 id=\"activeMQ（开源给了apollo）又叫ApolloMQ\"><a href=\"#activeMQ（开源给了apollo）又叫ApolloMQ\" class=\"headerlink\" title=\"activeMQ（开源给了apollo）又叫ApolloMQ\"></a>activeMQ（开源给了apollo）又叫ApolloMQ</h1><p>维护较少，会丢失数据</p>\n<h1 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h1><p>吞吐量，和tps 都大，适合做大数据</p>\n<h1 id=\"三者区别\"><a href=\"#三者区别\" class=\"headerlink\" title=\"三者区别\"></a>三者区别</h1><h2 id=\"TPS-每秒传输的事务处理个数\"><a href=\"#TPS-每秒传输的事务处理个数\" class=\"headerlink\" title=\"TPS 每秒传输的事务处理个数\"></a>TPS 每秒传输的事务处理个数</h2><p>Kafka最高，RabbitMq 次之， ActiveMq 最差</p>\n<h2 id=\"吞吐量对比-处理事务的能力\"><a href=\"#吞吐量对比-处理事务的能力\" class=\"headerlink\" title=\"吞吐量对比 处理事务的能力\"></a>吞吐量对比 处理事务的能力</h2><p>kafka具有高的吞吐量，内部采用消息的批量处理，rabbitMQ在吞吐量方面稍逊于kafka，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作<br>ActiveMq 最差</p>\n<h1 id=\"rebbitMQ-Exchange分几类\"><a href=\"#rebbitMQ-Exchange分几类\" class=\"headerlink\" title=\"rebbitMQ Exchange分几类\"></a>rebbitMQ Exchange分几类</h1><p>1，topic  就是direct的升级版 就是增加了一个路由的通配符<br>2，direct 绑定队列和路由 只有设定了特定路由的队列才可以收到<br>3，fanout  广播模式 任何队列都可以收到<br>4，headers</p>\n<h1 id=\"如何保证RabbitMQ不被重复消费？（幂等性）\"><a href=\"#如何保证RabbitMQ不被重复消费？（幂等性）\" class=\"headerlink\" title=\"如何保证RabbitMQ不被重复消费？（幂等性）\"></a>如何保证RabbitMQ不被重复消费？（幂等性）</h1><p>1.当拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。<br>2.当拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。<br>3.只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可<br>4.如果消费的时候，两三个线程一起来消费，要注意这个时候要采用CAS 乐观锁的一个概念，就是说给数据库表加多一个字段，如果消费了就改变它状态，这个时候其他消费就不能消费了</p>\n<h1 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h1><p>1，生产者报错，生产者要保证消息的可靠性传输有两个办法<br>1），直接用事务的概念，报错直接rollback<br>2），启用confirm模式，发送的时候会发送一个ACK 标志，一旦消息投递到队列里面就会发送 ACK，如果rabbitmq没有处理这个消息就会发送NACK 给你，这个时候你可以重试<br>2，rabbitmq 本身报错，这个时候可以开启持久化机制，只要写入进来就写到硬盘里面，这个时候如果报错的话，下次重启还是可以继续读出来<br>3，消费者报错，这个时候可以把ACK机制手动确认，只有消费者消费之后才返回ACK，这样就可以在消费报错的时候，让生产者重传</p>\n<h1 id=\"rabbitmq-怎么实现延迟消息队列？\"><a href=\"#rabbitmq-怎么实现延迟消息队列？\" class=\"headerlink\" title=\"rabbitmq 怎么实现延迟消息队列？\"></a>rabbitmq 怎么实现延迟消息队列？</h1><p>使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。</p>\n<h1 id=\"rabbitMQ-事务是怎么实现的\"><a href=\"#rabbitMQ-事务是怎么实现的\" class=\"headerlink\" title=\"rabbitMQ 事务是怎么实现的\"></a>rabbitMQ 事务是怎么实现的</h1><p>通过AMQP事务机制实现，这也是AMQP协议层面提供的解决方案；<br>txSelect(), txCommit()以及txRollback(), txSelect用于将当前channel设置成transaction模式，<br>txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，<br>如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，<br>这个时候我们便可以捕获异常通过txRollback回滚事务了。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:MQ机制</p>","more":"<h1 id=\"MQ-消息对接的作用\"><a href=\"#MQ-消息对接的作用\" class=\"headerlink\" title=\"MQ 消息对接的作用\"></a>MQ 消息对接的作用</h1><h2 id=\"解耦\"><a href=\"#解耦\" class=\"headerlink\" title=\"解耦\"></a>解耦</h2><h2 id=\"削峰\"><a href=\"#削峰\" class=\"headerlink\" title=\"削峰\"></a>削峰</h2><h2 id=\"异步\"><a href=\"#异步\" class=\"headerlink\" title=\"异步\"></a>异步</h2><h1 id=\"rebbitMQ\"><a href=\"#rebbitMQ\" class=\"headerlink\" title=\"rebbitMQ\"></a>rebbitMQ</h1><p>RabbitMQ是使用Erlang编写的一个开源的消息队列，吞吐量和tps 适中，性能较好，erlang语言较难维护</p>\n<h1 id=\"activeMQ（开源给了apollo）又叫ApolloMQ\"><a href=\"#activeMQ（开源给了apollo）又叫ApolloMQ\" class=\"headerlink\" title=\"activeMQ（开源给了apollo）又叫ApolloMQ\"></a>activeMQ（开源给了apollo）又叫ApolloMQ</h1><p>维护较少，会丢失数据</p>\n<h1 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h1><p>吞吐量，和tps 都大，适合做大数据</p>\n<h1 id=\"三者区别\"><a href=\"#三者区别\" class=\"headerlink\" title=\"三者区别\"></a>三者区别</h1><h2 id=\"TPS-每秒传输的事务处理个数\"><a href=\"#TPS-每秒传输的事务处理个数\" class=\"headerlink\" title=\"TPS 每秒传输的事务处理个数\"></a>TPS 每秒传输的事务处理个数</h2><p>Kafka最高，RabbitMq 次之， ActiveMq 最差</p>\n<h2 id=\"吞吐量对比-处理事务的能力\"><a href=\"#吞吐量对比-处理事务的能力\" class=\"headerlink\" title=\"吞吐量对比 处理事务的能力\"></a>吞吐量对比 处理事务的能力</h2><p>kafka具有高的吞吐量，内部采用消息的批量处理，rabbitMQ在吞吐量方面稍逊于kafka，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作<br>ActiveMq 最差</p>\n<h1 id=\"rebbitMQ-Exchange分几类\"><a href=\"#rebbitMQ-Exchange分几类\" class=\"headerlink\" title=\"rebbitMQ Exchange分几类\"></a>rebbitMQ Exchange分几类</h1><p>1，topic  就是direct的升级版 就是增加了一个路由的通配符<br>2，direct 绑定队列和路由 只有设定了特定路由的队列才可以收到<br>3，fanout  广播模式 任何队列都可以收到<br>4，headers</p>\n<h1 id=\"如何保证RabbitMQ不被重复消费？（幂等性）\"><a href=\"#如何保证RabbitMQ不被重复消费？（幂等性）\" class=\"headerlink\" title=\"如何保证RabbitMQ不被重复消费？（幂等性）\"></a>如何保证RabbitMQ不被重复消费？（幂等性）</h1><p>1.当拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。<br>2.当拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。<br>3.只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可<br>4.如果消费的时候，两三个线程一起来消费，要注意这个时候要采用CAS 乐观锁的一个概念，就是说给数据库表加多一个字段，如果消费了就改变它状态，这个时候其他消费就不能消费了</p>\n<h1 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h1><p>1，生产者报错，生产者要保证消息的可靠性传输有两个办法<br>1），直接用事务的概念，报错直接rollback<br>2），启用confirm模式，发送的时候会发送一个ACK 标志，一旦消息投递到队列里面就会发送 ACK，如果rabbitmq没有处理这个消息就会发送NACK 给你，这个时候你可以重试<br>2，rabbitmq 本身报错，这个时候可以开启持久化机制，只要写入进来就写到硬盘里面，这个时候如果报错的话，下次重启还是可以继续读出来<br>3，消费者报错，这个时候可以把ACK机制手动确认，只有消费者消费之后才返回ACK，这样就可以在消费报错的时候，让生产者重传</p>\n<h1 id=\"rabbitmq-怎么实现延迟消息队列？\"><a href=\"#rabbitmq-怎么实现延迟消息队列？\" class=\"headerlink\" title=\"rabbitmq 怎么实现延迟消息队列？\"></a>rabbitmq 怎么实现延迟消息队列？</h1><p>使用 RabbitMQ-delayed-message-exchange 插件实现延迟功能。</p>\n<h1 id=\"rabbitMQ-事务是怎么实现的\"><a href=\"#rabbitMQ-事务是怎么实现的\" class=\"headerlink\" title=\"rabbitMQ 事务是怎么实现的\"></a>rabbitMQ 事务是怎么实现的</h1><p>通过AMQP事务机制实现，这也是AMQP协议层面提供的解决方案；<br>txSelect(), txCommit()以及txRollback(), txSelect用于将当前channel设置成transaction模式，<br>txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，<br>如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，<br>这个时候我们便可以捕获异常通过txRollback回滚事务了。</p>"},{"date":"2020-03-31T16:00:00.000Z","status":"public","title":"JVM","_content":"\n摘要:java\n<!--more-->\n# 一图看懂JVM\n![avatar](/img/jvm.jpg)\n\n# 类加载器 运行时数据区 执行引擎\n\n# JVM  如何判断一个对象要回收了\n## 引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\n## 可达性分析：jvm会从GC Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\n\n#引用的分类  \n## 强引用\njvm 不会回收这个对象，就算到OOM 也不回收\n## 软引用\njvm 只要内存不够的时候就会回收这个引用，一般不回收这个对象\n## 弱引用\njvm 发现之后就会回收这个对象，但是垃圾回收期是一个优先级很低的线程，所以不一定很快就会发现这些弱引用的对象\n## 虚引用\njvm 看到就会回收，虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。\n如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。\n\n#垃圾回收(GC)及垃圾回收器  GC 收集器\n垃圾回收机老年代包括：CMS  G1 \n年轻代回收器：ParNew\n\n# JVM 调优\njps jmc 阿里arthas\n\n# JVM 调优指令\n## 指令\n1.jps命令用于查询正在运行的JVM进程。\n2.jstat可以实时显示本地或者远程JVM进程中类的装载、内存、垃圾收集、JIT编译等数据。\n3.jinfo用于查询当前运行的JVM的属性和参数值。\n4.jmap用于显示当前Java堆和永久代的详细信息。\n5.jhat用于分析使用jmap生成的dump文件，是JDK自带的工具。\n6.jstack用于生成当前JVM所有线程的快照，线程快照是JVM每一个线程正在执行的方法，目的是定位出线程出现长时间停顿的原因。\n## 参数\n1.-Xmx：用于指定Java程序的最大堆内存，使用java -Xmx5000M -version判断当前系统能分配的最大堆内存。\n2.-Xms：指定最小堆内存，通常设置成跟最大堆内存一样，减少GC。\n3.-Xmn：设置新生代大小。整个堆内存 = 新生代内存 + 老年代内存，此值对系统性能影响较大，Sun官方推荐设置为堆的3/8。\n4.-Xss：指定线程的最大栈空间。该参数决定了java函数调用的深度，值越大调用深度越深，若值太小，容易发生栈溢出错误。\n5.-XX:PermSize ：指定方法区（永久区）的初始值，默认是物理内存的1/64，Java8永久区移除之后，取而代之的是元数据区，由-XX:MetaspaceSize指定。\n6.-XX:MaxPermSize ：指定方法区（永久区）的最大值，默认是物理内存的1/4，Java8永久区移除之后，取而代之的是元数据区，由-XX:MaxMetaspaceSize指定。\n7.-XX:NewRatio=n：老年代和新生代比值，n=2时，说明老年代和新生代的比值为2:1。\n8.-XX:SurvivorRatio=n：Eden区和Survivor区的比值。n=8时，说明Eden和Survivor比值为8：1：1，因为Survivor有两个（from，to）\n\n# JVM 里面有什么\n## 堆\n放对象，new关键字和构造器创建的对象\n### 堆--新生代 比例1  主要用的是复制算法  伊甸园区主要用标记清除，suviver区主要用复制算法\n新生代有伊甸园区和 suviver区-比例8:1:1  ------主要对应的是minor GC  就是把已经没有GC root引用的数据给清除掉\n### 堆--老年代 比例2  主要用的是标记-整理算法\n对应的是老年代  主要是FULL GC ----- 对应着会 STW stop the word 导致全世界停顿  如果进行full GC 之后，内存还是不够的时候，就会抛出异常OOM\n### JVM 调优主要是为了少点FULL GC 和加快FULL GC 的速度\n\n### 为什么15次之后就到老年代\n因为对象头里面有四个bit 代表的是GC的年龄 0000，每次young GC  就加一 主要是复制算法，这里到达1111 则是15次如果再加就没有位数了\n所以就是因为这样 15次GC之后就放到老年代\n\n### 还有一个问题，什么时候对象进入老年代？\n1、对象的分代年龄到了15岁\n2、大对象直接进入老年代，就是大对象在新生代放不下，进行minor GC之后还是不够的情况下，会直接放入老年代。\n\n## 栈\n放一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存\n### 局部变量表\n### 操作数栈\n### 方法出口\n## 方法区 jdk 1.6 之后 叫元空间\n主要存放常量 静态方法等\n## 程序计数器\n保存当前栈到达哪行运算位置了\n## 本地方法栈\n调用一些native方法，C++的方法都是通过本地方法栈调用的  unsafe类里面的cas\n\n# 栈内存溢出会报StackOverflowError  堆溢出会报OOM\n\n\n# JVM 和 HotSpot什么区别\nJVM 一个规范 一个标准 \n\nHotSpot 是一个产品  一个实现  sun 公司开发的 亲儿子  所以一般用的 就是这个\nJ9 是一个产品  一个实现\ntaobaovm 是一个产品  一个实现\n\nopenJDK--- 一个C++项目  编译出来就是 HotSpot   openJDK就是开源的HotSpot代码  HotSpot有20%是商业用的代码  openJDK没有\n\n\n# 遇到过OOM吗  怎么造成的，怎么处理的\n内存不够的时候  static等关键字用的多了 由于老年代不够用了 怎么old GC 都没用了 这个时候就会OOM\n\n1，使用软引用\n2，尽量少用static\n3，加内存条\n\n\n# 对象是放在哪里的\n对象实例是放在堆里面，对象引用是放在栈里面，对象静态方法是放在元空间\n\n# 主要内存回收算法\n## 复制 主要用于suviver区\n## 标记清理 主要用于young 区\n## 标记整理 主要用于old区\n\n# 大对象多大就会直接到老年代\n大于伊甸园区的50%  就直接到老年代\n\n# CMS\nCMS 垃圾回收算法，是标记清理算法 用于old 区\nCMS并非没有暂停，而是用两次短暂停来替代串行标记整理算法的长暂停，它的收集周期是这样：\n初始标记(CMS-initial-mark) -> 并发标记(CMS-concurrent-mark) -> 重新标记(CMS-remark) -> 并发清除(CMS-concurrent-sweep) \n->并发重设状态等待下次CMS的触发(CMS-concurrent-reset)。其中的1，3两个步骤需要暂停所有的应用程序线程的。\n第一次暂停从root对象开始标记存活的对象，这个阶段称为初始标记；第二次暂停是在并发标记之后， 暂停所有应用程序线程，\n重新标记并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致）。\n第一次暂停会比较短，第二次暂停通常会比较长，并且 remark这个阶段可以并行标记。\n\n# G1 \nG1 标记整理算法 \n\n# 垃圾回收器从线程运行情况分类有三种\n串行回收，Serial回收器，单线程回收，全程stw；\n并行回收，名称以Parallel开头的回收器，多线程回收，全程stw；\n并发回收，cms与G1，多线程分阶段回收，只有某阶段会stw；\n\n# CMS 处理过程有七个步骤： \n1. 初始标记(CMS-initial-mark) ,会导致swt；\n2. 并发标记(CMS-concurrent-mark)，与用户线程同时运行； \n3. 预清理（CMS-concurrent-preclean），与用户线程同时运行； \n4. 可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行； \n5. 重新标记(CMS-remark) ，会导致swt； \n6. 并发清除(CMS-concurrent-sweep)，与用户线程同时运行； \n7. 并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行； ","source":"_posts/java/JVM.md","raw":"\n---\ndate: 2020-04-1\nstatus: public\ntitle: JVM\ntags:\n  - JAVA\n---\n\n摘要:java\n<!--more-->\n# 一图看懂JVM\n![avatar](/img/jvm.jpg)\n\n# 类加载器 运行时数据区 执行引擎\n\n# JVM  如何判断一个对象要回收了\n## 引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\n## 可达性分析：jvm会从GC Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\n\n#引用的分类  \n## 强引用\njvm 不会回收这个对象，就算到OOM 也不回收\n## 软引用\njvm 只要内存不够的时候就会回收这个引用，一般不回收这个对象\n## 弱引用\njvm 发现之后就会回收这个对象，但是垃圾回收期是一个优先级很低的线程，所以不一定很快就会发现这些弱引用的对象\n## 虚引用\njvm 看到就会回收，虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。\n如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。\n\n#垃圾回收(GC)及垃圾回收器  GC 收集器\n垃圾回收机老年代包括：CMS  G1 \n年轻代回收器：ParNew\n\n# JVM 调优\njps jmc 阿里arthas\n\n# JVM 调优指令\n## 指令\n1.jps命令用于查询正在运行的JVM进程。\n2.jstat可以实时显示本地或者远程JVM进程中类的装载、内存、垃圾收集、JIT编译等数据。\n3.jinfo用于查询当前运行的JVM的属性和参数值。\n4.jmap用于显示当前Java堆和永久代的详细信息。\n5.jhat用于分析使用jmap生成的dump文件，是JDK自带的工具。\n6.jstack用于生成当前JVM所有线程的快照，线程快照是JVM每一个线程正在执行的方法，目的是定位出线程出现长时间停顿的原因。\n## 参数\n1.-Xmx：用于指定Java程序的最大堆内存，使用java -Xmx5000M -version判断当前系统能分配的最大堆内存。\n2.-Xms：指定最小堆内存，通常设置成跟最大堆内存一样，减少GC。\n3.-Xmn：设置新生代大小。整个堆内存 = 新生代内存 + 老年代内存，此值对系统性能影响较大，Sun官方推荐设置为堆的3/8。\n4.-Xss：指定线程的最大栈空间。该参数决定了java函数调用的深度，值越大调用深度越深，若值太小，容易发生栈溢出错误。\n5.-XX:PermSize ：指定方法区（永久区）的初始值，默认是物理内存的1/64，Java8永久区移除之后，取而代之的是元数据区，由-XX:MetaspaceSize指定。\n6.-XX:MaxPermSize ：指定方法区（永久区）的最大值，默认是物理内存的1/4，Java8永久区移除之后，取而代之的是元数据区，由-XX:MaxMetaspaceSize指定。\n7.-XX:NewRatio=n：老年代和新生代比值，n=2时，说明老年代和新生代的比值为2:1。\n8.-XX:SurvivorRatio=n：Eden区和Survivor区的比值。n=8时，说明Eden和Survivor比值为8：1：1，因为Survivor有两个（from，to）\n\n# JVM 里面有什么\n## 堆\n放对象，new关键字和构造器创建的对象\n### 堆--新生代 比例1  主要用的是复制算法  伊甸园区主要用标记清除，suviver区主要用复制算法\n新生代有伊甸园区和 suviver区-比例8:1:1  ------主要对应的是minor GC  就是把已经没有GC root引用的数据给清除掉\n### 堆--老年代 比例2  主要用的是标记-整理算法\n对应的是老年代  主要是FULL GC ----- 对应着会 STW stop the word 导致全世界停顿  如果进行full GC 之后，内存还是不够的时候，就会抛出异常OOM\n### JVM 调优主要是为了少点FULL GC 和加快FULL GC 的速度\n\n### 为什么15次之后就到老年代\n因为对象头里面有四个bit 代表的是GC的年龄 0000，每次young GC  就加一 主要是复制算法，这里到达1111 则是15次如果再加就没有位数了\n所以就是因为这样 15次GC之后就放到老年代\n\n### 还有一个问题，什么时候对象进入老年代？\n1、对象的分代年龄到了15岁\n2、大对象直接进入老年代，就是大对象在新生代放不下，进行minor GC之后还是不够的情况下，会直接放入老年代。\n\n## 栈\n放一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存\n### 局部变量表\n### 操作数栈\n### 方法出口\n## 方法区 jdk 1.6 之后 叫元空间\n主要存放常量 静态方法等\n## 程序计数器\n保存当前栈到达哪行运算位置了\n## 本地方法栈\n调用一些native方法，C++的方法都是通过本地方法栈调用的  unsafe类里面的cas\n\n# 栈内存溢出会报StackOverflowError  堆溢出会报OOM\n\n\n# JVM 和 HotSpot什么区别\nJVM 一个规范 一个标准 \n\nHotSpot 是一个产品  一个实现  sun 公司开发的 亲儿子  所以一般用的 就是这个\nJ9 是一个产品  一个实现\ntaobaovm 是一个产品  一个实现\n\nopenJDK--- 一个C++项目  编译出来就是 HotSpot   openJDK就是开源的HotSpot代码  HotSpot有20%是商业用的代码  openJDK没有\n\n\n# 遇到过OOM吗  怎么造成的，怎么处理的\n内存不够的时候  static等关键字用的多了 由于老年代不够用了 怎么old GC 都没用了 这个时候就会OOM\n\n1，使用软引用\n2，尽量少用static\n3，加内存条\n\n\n# 对象是放在哪里的\n对象实例是放在堆里面，对象引用是放在栈里面，对象静态方法是放在元空间\n\n# 主要内存回收算法\n## 复制 主要用于suviver区\n## 标记清理 主要用于young 区\n## 标记整理 主要用于old区\n\n# 大对象多大就会直接到老年代\n大于伊甸园区的50%  就直接到老年代\n\n# CMS\nCMS 垃圾回收算法，是标记清理算法 用于old 区\nCMS并非没有暂停，而是用两次短暂停来替代串行标记整理算法的长暂停，它的收集周期是这样：\n初始标记(CMS-initial-mark) -> 并发标记(CMS-concurrent-mark) -> 重新标记(CMS-remark) -> 并发清除(CMS-concurrent-sweep) \n->并发重设状态等待下次CMS的触发(CMS-concurrent-reset)。其中的1，3两个步骤需要暂停所有的应用程序线程的。\n第一次暂停从root对象开始标记存活的对象，这个阶段称为初始标记；第二次暂停是在并发标记之后， 暂停所有应用程序线程，\n重新标记并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致）。\n第一次暂停会比较短，第二次暂停通常会比较长，并且 remark这个阶段可以并行标记。\n\n# G1 \nG1 标记整理算法 \n\n# 垃圾回收器从线程运行情况分类有三种\n串行回收，Serial回收器，单线程回收，全程stw；\n并行回收，名称以Parallel开头的回收器，多线程回收，全程stw；\n并发回收，cms与G1，多线程分阶段回收，只有某阶段会stw；\n\n# CMS 处理过程有七个步骤： \n1. 初始标记(CMS-initial-mark) ,会导致swt；\n2. 并发标记(CMS-concurrent-mark)，与用户线程同时运行； \n3. 预清理（CMS-concurrent-preclean），与用户线程同时运行； \n4. 可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行； \n5. 重新标记(CMS-remark) ，会导致swt； \n6. 并发清除(CMS-concurrent-sweep)，与用户线程同时运行； \n7. 并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行； ","slug":"java/JVM","published":1,"updated":"2025-05-16T04:25:25.414Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsi0017skqr8y98gda1","content":"<p>摘要:java</p>\n<span id=\"more\"></span>\n<h1 id=\"一图看懂JVM\"><a href=\"#一图看懂JVM\" class=\"headerlink\" title=\"一图看懂JVM\"></a>一图看懂JVM</h1><p><img src=\"/img/jvm.jpg\" alt=\"avatar\"></p>\n<h1 id=\"类加载器-运行时数据区-执行引擎\"><a href=\"#类加载器-运行时数据区-执行引擎\" class=\"headerlink\" title=\"类加载器 运行时数据区 执行引擎\"></a>类加载器 运行时数据区 执行引擎</h1><h1 id=\"JVM-如何判断一个对象要回收了\"><a href=\"#JVM-如何判断一个对象要回收了\" class=\"headerlink\" title=\"JVM  如何判断一个对象要回收了\"></a>JVM  如何判断一个对象要回收了</h1><h2 id=\"引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\"><a href=\"#引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\" class=\"headerlink\" title=\"引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\"></a>引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收</h2><h2 id=\"可达性分析：jvm会从GC-Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC-ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\"><a href=\"#可达性分析：jvm会从GC-Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC-ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\" class=\"headerlink\" title=\"可达性分析：jvm会从GC Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\"></a>可达性分析：jvm会从GC Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收</h2><p>#引用的分类  </p>\n<h2 id=\"强引用\"><a href=\"#强引用\" class=\"headerlink\" title=\"强引用\"></a>强引用</h2><p>jvm 不会回收这个对象，就算到OOM 也不回收</p>\n<h2 id=\"软引用\"><a href=\"#软引用\" class=\"headerlink\" title=\"软引用\"></a>软引用</h2><p>jvm 只要内存不够的时候就会回收这个引用，一般不回收这个对象</p>\n<h2 id=\"弱引用\"><a href=\"#弱引用\" class=\"headerlink\" title=\"弱引用\"></a>弱引用</h2><p>jvm 发现之后就会回收这个对象，但是垃圾回收期是一个优先级很低的线程，所以不一定很快就会发现这些弱引用的对象</p>\n<h2 id=\"虚引用\"><a href=\"#虚引用\" class=\"headerlink\" title=\"虚引用\"></a>虚引用</h2><p>jvm 看到就会回收，虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。<br>如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</p>\n<p>#垃圾回收(GC)及垃圾回收器  GC 收集器<br>垃圾回收机老年代包括：CMS  G1<br>年轻代回收器：ParNew</p>\n<h1 id=\"JVM-调优\"><a href=\"#JVM-调优\" class=\"headerlink\" title=\"JVM 调优\"></a>JVM 调优</h1><p>jps jmc 阿里arthas</p>\n<h1 id=\"JVM-调优指令\"><a href=\"#JVM-调优指令\" class=\"headerlink\" title=\"JVM 调优指令\"></a>JVM 调优指令</h1><h2 id=\"指令\"><a href=\"#指令\" class=\"headerlink\" title=\"指令\"></a>指令</h2><p>1.jps命令用于查询正在运行的JVM进程。<br>2.jstat可以实时显示本地或者远程JVM进程中类的装载、内存、垃圾收集、JIT编译等数据。<br>3.jinfo用于查询当前运行的JVM的属性和参数值。<br>4.jmap用于显示当前Java堆和永久代的详细信息。<br>5.jhat用于分析使用jmap生成的dump文件，是JDK自带的工具。<br>6.jstack用于生成当前JVM所有线程的快照，线程快照是JVM每一个线程正在执行的方法，目的是定位出线程出现长时间停顿的原因。</p>\n<h2 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h2><p>1.-Xmx：用于指定Java程序的最大堆内存，使用java -Xmx5000M -version判断当前系统能分配的最大堆内存。<br>2.-Xms：指定最小堆内存，通常设置成跟最大堆内存一样，减少GC。<br>3.-Xmn：设置新生代大小。整个堆内存 = 新生代内存 + 老年代内存，此值对系统性能影响较大，Sun官方推荐设置为堆的3/8。<br>4.-Xss：指定线程的最大栈空间。该参数决定了java函数调用的深度，值越大调用深度越深，若值太小，容易发生栈溢出错误。<br>5.-XX:PermSize ：指定方法区（永久区）的初始值，默认是物理内存的1/64，Java8永久区移除之后，取而代之的是元数据区，由-XX:MetaspaceSize指定。<br>6.-XX:MaxPermSize ：指定方法区（永久区）的最大值，默认是物理内存的1/4，Java8永久区移除之后，取而代之的是元数据区，由-XX:MaxMetaspaceSize指定。<br>7.-XX:NewRatio=n：老年代和新生代比值，n=2时，说明老年代和新生代的比值为2:1。<br>8.-XX:SurvivorRatio=n：Eden区和Survivor区的比值。n=8时，说明Eden和Survivor比值为8：1：1，因为Survivor有两个（from，to）</p>\n<h1 id=\"JVM-里面有什么\"><a href=\"#JVM-里面有什么\" class=\"headerlink\" title=\"JVM 里面有什么\"></a>JVM 里面有什么</h1><h2 id=\"堆\"><a href=\"#堆\" class=\"headerlink\" title=\"堆\"></a>堆</h2><p>放对象，new关键字和构造器创建的对象</p>\n<h3 id=\"堆–新生代-比例1-主要用的是复制算法-伊甸园区主要用标记清除，suviver区主要用复制算法\"><a href=\"#堆–新生代-比例1-主要用的是复制算法-伊甸园区主要用标记清除，suviver区主要用复制算法\" class=\"headerlink\" title=\"堆–新生代 比例1  主要用的是复制算法  伊甸园区主要用标记清除，suviver区主要用复制算法\"></a>堆–新生代 比例1  主要用的是复制算法  伊甸园区主要用标记清除，suviver区主要用复制算法</h3><p>新生代有伊甸园区和 suviver区-比例8:1:1  ——主要对应的是minor GC  就是把已经没有GC root引用的数据给清除掉</p>\n<h3 id=\"堆–老年代-比例2-主要用的是标记-整理算法\"><a href=\"#堆–老年代-比例2-主要用的是标记-整理算法\" class=\"headerlink\" title=\"堆–老年代 比例2  主要用的是标记-整理算法\"></a>堆–老年代 比例2  主要用的是标记-整理算法</h3><p>对应的是老年代  主要是FULL GC —– 对应着会 STW stop the word 导致全世界停顿  如果进行full GC 之后，内存还是不够的时候，就会抛出异常OOM</p>\n<h3 id=\"JVM-调优主要是为了少点FULL-GC-和加快FULL-GC-的速度\"><a href=\"#JVM-调优主要是为了少点FULL-GC-和加快FULL-GC-的速度\" class=\"headerlink\" title=\"JVM 调优主要是为了少点FULL GC 和加快FULL GC 的速度\"></a>JVM 调优主要是为了少点FULL GC 和加快FULL GC 的速度</h3><h3 id=\"为什么15次之后就到老年代\"><a href=\"#为什么15次之后就到老年代\" class=\"headerlink\" title=\"为什么15次之后就到老年代\"></a>为什么15次之后就到老年代</h3><p>因为对象头里面有四个bit 代表的是GC的年龄 0000，每次young GC  就加一 主要是复制算法，这里到达1111 则是15次如果再加就没有位数了<br>所以就是因为这样 15次GC之后就放到老年代</p>\n<h3 id=\"还有一个问题，什么时候对象进入老年代？\"><a href=\"#还有一个问题，什么时候对象进入老年代？\" class=\"headerlink\" title=\"还有一个问题，什么时候对象进入老年代？\"></a>还有一个问题，什么时候对象进入老年代？</h3><p>1、对象的分代年龄到了15岁<br>2、大对象直接进入老年代，就是大对象在新生代放不下，进行minor GC之后还是不够的情况下，会直接放入老年代。</p>\n<h2 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h2><p>放一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存</p>\n<h3 id=\"局部变量表\"><a href=\"#局部变量表\" class=\"headerlink\" title=\"局部变量表\"></a>局部变量表</h3><h3 id=\"操作数栈\"><a href=\"#操作数栈\" class=\"headerlink\" title=\"操作数栈\"></a>操作数栈</h3><h3 id=\"方法出口\"><a href=\"#方法出口\" class=\"headerlink\" title=\"方法出口\"></a>方法出口</h3><h2 id=\"方法区-jdk-1-6-之后-叫元空间\"><a href=\"#方法区-jdk-1-6-之后-叫元空间\" class=\"headerlink\" title=\"方法区 jdk 1.6 之后 叫元空间\"></a>方法区 jdk 1.6 之后 叫元空间</h2><p>主要存放常量 静态方法等</p>\n<h2 id=\"程序计数器\"><a href=\"#程序计数器\" class=\"headerlink\" title=\"程序计数器\"></a>程序计数器</h2><p>保存当前栈到达哪行运算位置了</p>\n<h2 id=\"本地方法栈\"><a href=\"#本地方法栈\" class=\"headerlink\" title=\"本地方法栈\"></a>本地方法栈</h2><p>调用一些native方法，C++的方法都是通过本地方法栈调用的  unsafe类里面的cas</p>\n<h1 id=\"栈内存溢出会报StackOverflowError-堆溢出会报OOM\"><a href=\"#栈内存溢出会报StackOverflowError-堆溢出会报OOM\" class=\"headerlink\" title=\"栈内存溢出会报StackOverflowError  堆溢出会报OOM\"></a>栈内存溢出会报StackOverflowError  堆溢出会报OOM</h1><h1 id=\"JVM-和-HotSpot什么区别\"><a href=\"#JVM-和-HotSpot什么区别\" class=\"headerlink\" title=\"JVM 和 HotSpot什么区别\"></a>JVM 和 HotSpot什么区别</h1><p>JVM 一个规范 一个标准 </p>\n<p>HotSpot 是一个产品  一个实现  sun 公司开发的 亲儿子  所以一般用的 就是这个<br>J9 是一个产品  一个实现<br>taobaovm 是一个产品  一个实现</p>\n<p>openJDK— 一个C++项目  编译出来就是 HotSpot   openJDK就是开源的HotSpot代码  HotSpot有20%是商业用的代码  openJDK没有</p>\n<h1 id=\"遇到过OOM吗-怎么造成的，怎么处理的\"><a href=\"#遇到过OOM吗-怎么造成的，怎么处理的\" class=\"headerlink\" title=\"遇到过OOM吗  怎么造成的，怎么处理的\"></a>遇到过OOM吗  怎么造成的，怎么处理的</h1><p>内存不够的时候  static等关键字用的多了 由于老年代不够用了 怎么old GC 都没用了 这个时候就会OOM</p>\n<p>1，使用软引用<br>2，尽量少用static<br>3，加内存条</p>\n<h1 id=\"对象是放在哪里的\"><a href=\"#对象是放在哪里的\" class=\"headerlink\" title=\"对象是放在哪里的\"></a>对象是放在哪里的</h1><p>对象实例是放在堆里面，对象引用是放在栈里面，对象静态方法是放在元空间</p>\n<h1 id=\"主要内存回收算法\"><a href=\"#主要内存回收算法\" class=\"headerlink\" title=\"主要内存回收算法\"></a>主要内存回收算法</h1><h2 id=\"复制-主要用于suviver区\"><a href=\"#复制-主要用于suviver区\" class=\"headerlink\" title=\"复制 主要用于suviver区\"></a>复制 主要用于suviver区</h2><h2 id=\"标记清理-主要用于young-区\"><a href=\"#标记清理-主要用于young-区\" class=\"headerlink\" title=\"标记清理 主要用于young 区\"></a>标记清理 主要用于young 区</h2><h2 id=\"标记整理-主要用于old区\"><a href=\"#标记整理-主要用于old区\" class=\"headerlink\" title=\"标记整理 主要用于old区\"></a>标记整理 主要用于old区</h2><h1 id=\"大对象多大就会直接到老年代\"><a href=\"#大对象多大就会直接到老年代\" class=\"headerlink\" title=\"大对象多大就会直接到老年代\"></a>大对象多大就会直接到老年代</h1><p>大于伊甸园区的50%  就直接到老年代</p>\n<h1 id=\"CMS\"><a href=\"#CMS\" class=\"headerlink\" title=\"CMS\"></a>CMS</h1><p>CMS 垃圾回收算法，是标记清理算法 用于old 区<br>CMS并非没有暂停，而是用两次短暂停来替代串行标记整理算法的长暂停，它的收集周期是这样：<br>初始标记(CMS-initial-mark) -&gt; 并发标记(CMS-concurrent-mark) -&gt; 重新标记(CMS-remark) -&gt; 并发清除(CMS-concurrent-sweep)<br>-&gt;并发重设状态等待下次CMS的触发(CMS-concurrent-reset)。其中的1，3两个步骤需要暂停所有的应用程序线程的。<br>第一次暂停从root对象开始标记存活的对象，这个阶段称为初始标记；第二次暂停是在并发标记之后， 暂停所有应用程序线程，<br>重新标记并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致）。<br>第一次暂停会比较短，第二次暂停通常会比较长，并且 remark这个阶段可以并行标记。</p>\n<h1 id=\"G1\"><a href=\"#G1\" class=\"headerlink\" title=\"G1\"></a>G1</h1><p>G1 标记整理算法 </p>\n<h1 id=\"垃圾回收器从线程运行情况分类有三种\"><a href=\"#垃圾回收器从线程运行情况分类有三种\" class=\"headerlink\" title=\"垃圾回收器从线程运行情况分类有三种\"></a>垃圾回收器从线程运行情况分类有三种</h1><p>串行回收，Serial回收器，单线程回收，全程stw；<br>并行回收，名称以Parallel开头的回收器，多线程回收，全程stw；<br>并发回收，cms与G1，多线程分阶段回收，只有某阶段会stw；</p>\n<h1 id=\"CMS-处理过程有七个步骤：\"><a href=\"#CMS-处理过程有七个步骤：\" class=\"headerlink\" title=\"CMS 处理过程有七个步骤：\"></a>CMS 处理过程有七个步骤：</h1><ol>\n<li>初始标记(CMS-initial-mark) ,会导致swt；</li>\n<li>并发标记(CMS-concurrent-mark)，与用户线程同时运行； </li>\n<li>预清理（CMS-concurrent-preclean），与用户线程同时运行； </li>\n<li>可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行； </li>\n<li>重新标记(CMS-remark) ，会导致swt； </li>\n<li>并发清除(CMS-concurrent-sweep)，与用户线程同时运行； </li>\n<li>并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行； </li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>摘要:java</p>","more":"<h1 id=\"一图看懂JVM\"><a href=\"#一图看懂JVM\" class=\"headerlink\" title=\"一图看懂JVM\"></a>一图看懂JVM</h1><p><img src=\"/img/jvm.jpg\" alt=\"avatar\"></p>\n<h1 id=\"类加载器-运行时数据区-执行引擎\"><a href=\"#类加载器-运行时数据区-执行引擎\" class=\"headerlink\" title=\"类加载器 运行时数据区 执行引擎\"></a>类加载器 运行时数据区 执行引擎</h1><h1 id=\"JVM-如何判断一个对象要回收了\"><a href=\"#JVM-如何判断一个对象要回收了\" class=\"headerlink\" title=\"JVM  如何判断一个对象要回收了\"></a>JVM  如何判断一个对象要回收了</h1><h2 id=\"引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\"><a href=\"#引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\" class=\"headerlink\" title=\"引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收\"></a>引用计数：jvm对象有一个计数器，每次有人引用它的时候计数器加一，如果取消引用的话计数器减一，JVM判断如果引用计数为0的时候就回收</h2><h2 id=\"可达性分析：jvm会从GC-Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC-ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\"><a href=\"#可达性分析：jvm会从GC-Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC-ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\" class=\"headerlink\" title=\"可达性分析：jvm会从GC Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收\"></a>可达性分析：jvm会从GC Roots开始向下搜索，搜索所走过的路劲叫引用链，当一个对象到GC ROOTS没有任何引用链的时候，证明对象不可用了，为不可达对象，这个时候会被垃圾回收器回收</h2><p>#引用的分类  </p>\n<h2 id=\"强引用\"><a href=\"#强引用\" class=\"headerlink\" title=\"强引用\"></a>强引用</h2><p>jvm 不会回收这个对象，就算到OOM 也不回收</p>\n<h2 id=\"软引用\"><a href=\"#软引用\" class=\"headerlink\" title=\"软引用\"></a>软引用</h2><p>jvm 只要内存不够的时候就会回收这个引用，一般不回收这个对象</p>\n<h2 id=\"弱引用\"><a href=\"#弱引用\" class=\"headerlink\" title=\"弱引用\"></a>弱引用</h2><p>jvm 发现之后就会回收这个对象，但是垃圾回收期是一个优先级很低的线程，所以不一定很快就会发现这些弱引用的对象</p>\n<h2 id=\"虚引用\"><a href=\"#虚引用\" class=\"headerlink\" title=\"虚引用\"></a>虚引用</h2><p>jvm 看到就会回收，虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。<br>如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</p>\n<p>#垃圾回收(GC)及垃圾回收器  GC 收集器<br>垃圾回收机老年代包括：CMS  G1<br>年轻代回收器：ParNew</p>\n<h1 id=\"JVM-调优\"><a href=\"#JVM-调优\" class=\"headerlink\" title=\"JVM 调优\"></a>JVM 调优</h1><p>jps jmc 阿里arthas</p>\n<h1 id=\"JVM-调优指令\"><a href=\"#JVM-调优指令\" class=\"headerlink\" title=\"JVM 调优指令\"></a>JVM 调优指令</h1><h2 id=\"指令\"><a href=\"#指令\" class=\"headerlink\" title=\"指令\"></a>指令</h2><p>1.jps命令用于查询正在运行的JVM进程。<br>2.jstat可以实时显示本地或者远程JVM进程中类的装载、内存、垃圾收集、JIT编译等数据。<br>3.jinfo用于查询当前运行的JVM的属性和参数值。<br>4.jmap用于显示当前Java堆和永久代的详细信息。<br>5.jhat用于分析使用jmap生成的dump文件，是JDK自带的工具。<br>6.jstack用于生成当前JVM所有线程的快照，线程快照是JVM每一个线程正在执行的方法，目的是定位出线程出现长时间停顿的原因。</p>\n<h2 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a>参数</h2><p>1.-Xmx：用于指定Java程序的最大堆内存，使用java -Xmx5000M -version判断当前系统能分配的最大堆内存。<br>2.-Xms：指定最小堆内存，通常设置成跟最大堆内存一样，减少GC。<br>3.-Xmn：设置新生代大小。整个堆内存 = 新生代内存 + 老年代内存，此值对系统性能影响较大，Sun官方推荐设置为堆的3/8。<br>4.-Xss：指定线程的最大栈空间。该参数决定了java函数调用的深度，值越大调用深度越深，若值太小，容易发生栈溢出错误。<br>5.-XX:PermSize ：指定方法区（永久区）的初始值，默认是物理内存的1/64，Java8永久区移除之后，取而代之的是元数据区，由-XX:MetaspaceSize指定。<br>6.-XX:MaxPermSize ：指定方法区（永久区）的最大值，默认是物理内存的1/4，Java8永久区移除之后，取而代之的是元数据区，由-XX:MaxMetaspaceSize指定。<br>7.-XX:NewRatio=n：老年代和新生代比值，n=2时，说明老年代和新生代的比值为2:1。<br>8.-XX:SurvivorRatio=n：Eden区和Survivor区的比值。n=8时，说明Eden和Survivor比值为8：1：1，因为Survivor有两个（from，to）</p>\n<h1 id=\"JVM-里面有什么\"><a href=\"#JVM-里面有什么\" class=\"headerlink\" title=\"JVM 里面有什么\"></a>JVM 里面有什么</h1><h2 id=\"堆\"><a href=\"#堆\" class=\"headerlink\" title=\"堆\"></a>堆</h2><p>放对象，new关键字和构造器创建的对象</p>\n<h3 id=\"堆–新生代-比例1-主要用的是复制算法-伊甸园区主要用标记清除，suviver区主要用复制算法\"><a href=\"#堆–新生代-比例1-主要用的是复制算法-伊甸园区主要用标记清除，suviver区主要用复制算法\" class=\"headerlink\" title=\"堆–新生代 比例1  主要用的是复制算法  伊甸园区主要用标记清除，suviver区主要用复制算法\"></a>堆–新生代 比例1  主要用的是复制算法  伊甸园区主要用标记清除，suviver区主要用复制算法</h3><p>新生代有伊甸园区和 suviver区-比例8:1:1  ——主要对应的是minor GC  就是把已经没有GC root引用的数据给清除掉</p>\n<h3 id=\"堆–老年代-比例2-主要用的是标记-整理算法\"><a href=\"#堆–老年代-比例2-主要用的是标记-整理算法\" class=\"headerlink\" title=\"堆–老年代 比例2  主要用的是标记-整理算法\"></a>堆–老年代 比例2  主要用的是标记-整理算法</h3><p>对应的是老年代  主要是FULL GC —– 对应着会 STW stop the word 导致全世界停顿  如果进行full GC 之后，内存还是不够的时候，就会抛出异常OOM</p>\n<h3 id=\"JVM-调优主要是为了少点FULL-GC-和加快FULL-GC-的速度\"><a href=\"#JVM-调优主要是为了少点FULL-GC-和加快FULL-GC-的速度\" class=\"headerlink\" title=\"JVM 调优主要是为了少点FULL GC 和加快FULL GC 的速度\"></a>JVM 调优主要是为了少点FULL GC 和加快FULL GC 的速度</h3><h3 id=\"为什么15次之后就到老年代\"><a href=\"#为什么15次之后就到老年代\" class=\"headerlink\" title=\"为什么15次之后就到老年代\"></a>为什么15次之后就到老年代</h3><p>因为对象头里面有四个bit 代表的是GC的年龄 0000，每次young GC  就加一 主要是复制算法，这里到达1111 则是15次如果再加就没有位数了<br>所以就是因为这样 15次GC之后就放到老年代</p>\n<h3 id=\"还有一个问题，什么时候对象进入老年代？\"><a href=\"#还有一个问题，什么时候对象进入老年代？\" class=\"headerlink\" title=\"还有一个问题，什么时候对象进入老年代？\"></a>还有一个问题，什么时候对象进入老年代？</h3><p>1、对象的分代年龄到了15岁<br>2、大对象直接进入老年代，就是大对象在新生代放不下，进行minor GC之后还是不够的情况下，会直接放入老年代。</p>\n<h2 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h2><p>放一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存</p>\n<h3 id=\"局部变量表\"><a href=\"#局部变量表\" class=\"headerlink\" title=\"局部变量表\"></a>局部变量表</h3><h3 id=\"操作数栈\"><a href=\"#操作数栈\" class=\"headerlink\" title=\"操作数栈\"></a>操作数栈</h3><h3 id=\"方法出口\"><a href=\"#方法出口\" class=\"headerlink\" title=\"方法出口\"></a>方法出口</h3><h2 id=\"方法区-jdk-1-6-之后-叫元空间\"><a href=\"#方法区-jdk-1-6-之后-叫元空间\" class=\"headerlink\" title=\"方法区 jdk 1.6 之后 叫元空间\"></a>方法区 jdk 1.6 之后 叫元空间</h2><p>主要存放常量 静态方法等</p>\n<h2 id=\"程序计数器\"><a href=\"#程序计数器\" class=\"headerlink\" title=\"程序计数器\"></a>程序计数器</h2><p>保存当前栈到达哪行运算位置了</p>\n<h2 id=\"本地方法栈\"><a href=\"#本地方法栈\" class=\"headerlink\" title=\"本地方法栈\"></a>本地方法栈</h2><p>调用一些native方法，C++的方法都是通过本地方法栈调用的  unsafe类里面的cas</p>\n<h1 id=\"栈内存溢出会报StackOverflowError-堆溢出会报OOM\"><a href=\"#栈内存溢出会报StackOverflowError-堆溢出会报OOM\" class=\"headerlink\" title=\"栈内存溢出会报StackOverflowError  堆溢出会报OOM\"></a>栈内存溢出会报StackOverflowError  堆溢出会报OOM</h1><h1 id=\"JVM-和-HotSpot什么区别\"><a href=\"#JVM-和-HotSpot什么区别\" class=\"headerlink\" title=\"JVM 和 HotSpot什么区别\"></a>JVM 和 HotSpot什么区别</h1><p>JVM 一个规范 一个标准 </p>\n<p>HotSpot 是一个产品  一个实现  sun 公司开发的 亲儿子  所以一般用的 就是这个<br>J9 是一个产品  一个实现<br>taobaovm 是一个产品  一个实现</p>\n<p>openJDK— 一个C++项目  编译出来就是 HotSpot   openJDK就是开源的HotSpot代码  HotSpot有20%是商业用的代码  openJDK没有</p>\n<h1 id=\"遇到过OOM吗-怎么造成的，怎么处理的\"><a href=\"#遇到过OOM吗-怎么造成的，怎么处理的\" class=\"headerlink\" title=\"遇到过OOM吗  怎么造成的，怎么处理的\"></a>遇到过OOM吗  怎么造成的，怎么处理的</h1><p>内存不够的时候  static等关键字用的多了 由于老年代不够用了 怎么old GC 都没用了 这个时候就会OOM</p>\n<p>1，使用软引用<br>2，尽量少用static<br>3，加内存条</p>\n<h1 id=\"对象是放在哪里的\"><a href=\"#对象是放在哪里的\" class=\"headerlink\" title=\"对象是放在哪里的\"></a>对象是放在哪里的</h1><p>对象实例是放在堆里面，对象引用是放在栈里面，对象静态方法是放在元空间</p>\n<h1 id=\"主要内存回收算法\"><a href=\"#主要内存回收算法\" class=\"headerlink\" title=\"主要内存回收算法\"></a>主要内存回收算法</h1><h2 id=\"复制-主要用于suviver区\"><a href=\"#复制-主要用于suviver区\" class=\"headerlink\" title=\"复制 主要用于suviver区\"></a>复制 主要用于suviver区</h2><h2 id=\"标记清理-主要用于young-区\"><a href=\"#标记清理-主要用于young-区\" class=\"headerlink\" title=\"标记清理 主要用于young 区\"></a>标记清理 主要用于young 区</h2><h2 id=\"标记整理-主要用于old区\"><a href=\"#标记整理-主要用于old区\" class=\"headerlink\" title=\"标记整理 主要用于old区\"></a>标记整理 主要用于old区</h2><h1 id=\"大对象多大就会直接到老年代\"><a href=\"#大对象多大就会直接到老年代\" class=\"headerlink\" title=\"大对象多大就会直接到老年代\"></a>大对象多大就会直接到老年代</h1><p>大于伊甸园区的50%  就直接到老年代</p>\n<h1 id=\"CMS\"><a href=\"#CMS\" class=\"headerlink\" title=\"CMS\"></a>CMS</h1><p>CMS 垃圾回收算法，是标记清理算法 用于old 区<br>CMS并非没有暂停，而是用两次短暂停来替代串行标记整理算法的长暂停，它的收集周期是这样：<br>初始标记(CMS-initial-mark) -&gt; 并发标记(CMS-concurrent-mark) -&gt; 重新标记(CMS-remark) -&gt; 并发清除(CMS-concurrent-sweep)<br>-&gt;并发重设状态等待下次CMS的触发(CMS-concurrent-reset)。其中的1，3两个步骤需要暂停所有的应用程序线程的。<br>第一次暂停从root对象开始标记存活的对象，这个阶段称为初始标记；第二次暂停是在并发标记之后， 暂停所有应用程序线程，<br>重新标记并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致）。<br>第一次暂停会比较短，第二次暂停通常会比较长，并且 remark这个阶段可以并行标记。</p>\n<h1 id=\"G1\"><a href=\"#G1\" class=\"headerlink\" title=\"G1\"></a>G1</h1><p>G1 标记整理算法 </p>\n<h1 id=\"垃圾回收器从线程运行情况分类有三种\"><a href=\"#垃圾回收器从线程运行情况分类有三种\" class=\"headerlink\" title=\"垃圾回收器从线程运行情况分类有三种\"></a>垃圾回收器从线程运行情况分类有三种</h1><p>串行回收，Serial回收器，单线程回收，全程stw；<br>并行回收，名称以Parallel开头的回收器，多线程回收，全程stw；<br>并发回收，cms与G1，多线程分阶段回收，只有某阶段会stw；</p>\n<h1 id=\"CMS-处理过程有七个步骤：\"><a href=\"#CMS-处理过程有七个步骤：\" class=\"headerlink\" title=\"CMS 处理过程有七个步骤：\"></a>CMS 处理过程有七个步骤：</h1><ol>\n<li>初始标记(CMS-initial-mark) ,会导致swt；</li>\n<li>并发标记(CMS-concurrent-mark)，与用户线程同时运行； </li>\n<li>预清理（CMS-concurrent-preclean），与用户线程同时运行； </li>\n<li>可被终止的预清理（CMS-concurrent-abortable-preclean） 与用户线程同时运行； </li>\n<li>重新标记(CMS-remark) ，会导致swt； </li>\n<li>并发清除(CMS-concurrent-sweep)，与用户线程同时运行； </li>\n<li>并发重置状态等待下次CMS的触发(CMS-concurrent-reset)，与用户线程同时运行； </li>\n</ol>"},{"title":"arthas使用","date":"2025-05-16T07:06:47.000Z","_content":"摘要:arthas使用小技巧\n<!--more-->\n# arthas的使用去排查线上问题\n\n## 安装\n直接解压arthas包，[arthas下载包](https://arthas.aliyun.com/doc/download.html)，\n点击之后进入阿里的下载页面\n### 用 as.sh 启动\n```./as.sh ```\n### 用 arthas-boot 启动\n```java -jar arthas-boot.jar```\n\n#线上问题排查\n## 查看线上代码跟本地代码是否一致\n通过jad命令编译远程代码可以查看当前代码是否跟本地一致\n```jad org.hibernate.EmptyInterceptor```\n\n## 通过watch命令可以查看方法的出参，入参\n\n```watch com.midea.ext.common.util.WFCommonUtil getQueueStatus  '{params,returnObj}'  -x 3 -m 140```\n\n## 打印当前的dump日志\ndump java heap, 类似 jmap 命令的 heap dump 功能。\n\n```heapdump arthas-output/dump.hprof```\n生成文件在arthas-output目录\n\n\n","source":"_posts/java/arthas使用.md","raw":"---\ntitle: arthas使用\ndate: 2025-05-16 15:06:47\ntags:\n  - JAVA\n  - arthas\n---\n摘要:arthas使用小技巧\n<!--more-->\n# arthas的使用去排查线上问题\n\n## 安装\n直接解压arthas包，[arthas下载包](https://arthas.aliyun.com/doc/download.html)，\n点击之后进入阿里的下载页面\n### 用 as.sh 启动\n```./as.sh ```\n### 用 arthas-boot 启动\n```java -jar arthas-boot.jar```\n\n#线上问题排查\n## 查看线上代码跟本地代码是否一致\n通过jad命令编译远程代码可以查看当前代码是否跟本地一致\n```jad org.hibernate.EmptyInterceptor```\n\n## 通过watch命令可以查看方法的出参，入参\n\n```watch com.midea.ext.common.util.WFCommonUtil getQueueStatus  '{params,returnObj}'  -x 3 -m 140```\n\n## 打印当前的dump日志\ndump java heap, 类似 jmap 命令的 heap dump 功能。\n\n```heapdump arthas-output/dump.hprof```\n生成文件在arthas-output目录\n\n\n","slug":"java/arthas使用","published":1,"updated":"2025-05-16T08:47:22.387Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsk001askqr8prybngo","content":"<p>摘要:arthas使用小技巧</p>\n<span id=\"more\"></span>\n<h1 id=\"arthas的使用去排查线上问题\"><a href=\"#arthas的使用去排查线上问题\" class=\"headerlink\" title=\"arthas的使用去排查线上问题\"></a>arthas的使用去排查线上问题</h1><h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>直接解压arthas包，<a href=\"https://arthas.aliyun.com/doc/download.html\">arthas下载包</a>，<br>点击之后进入阿里的下载页面</p>\n<h3 id=\"用-as-sh-启动\"><a href=\"#用-as-sh-启动\" class=\"headerlink\" title=\"用 as.sh 启动\"></a>用 as.sh 启动</h3><p><code>./as.sh </code></p>\n<h3 id=\"用-arthas-boot-启动\"><a href=\"#用-arthas-boot-启动\" class=\"headerlink\" title=\"用 arthas-boot 启动\"></a>用 arthas-boot 启动</h3><p><code>java -jar arthas-boot.jar</code></p>\n<p>#线上问题排查</p>\n<h2 id=\"查看线上代码跟本地代码是否一致\"><a href=\"#查看线上代码跟本地代码是否一致\" class=\"headerlink\" title=\"查看线上代码跟本地代码是否一致\"></a>查看线上代码跟本地代码是否一致</h2><p>通过jad命令编译远程代码可以查看当前代码是否跟本地一致<br><code>jad org.hibernate.EmptyInterceptor</code></p>\n<h2 id=\"通过watch命令可以查看方法的出参，入参\"><a href=\"#通过watch命令可以查看方法的出参，入参\" class=\"headerlink\" title=\"通过watch命令可以查看方法的出参，入参\"></a>通过watch命令可以查看方法的出参，入参</h2><p><code>watch com.midea.ext.common.util.WFCommonUtil getQueueStatus  &#39;&#123;params,returnObj&#125;&#39;  -x 3 -m 140</code></p>\n<h2 id=\"打印当前的dump日志\"><a href=\"#打印当前的dump日志\" class=\"headerlink\" title=\"打印当前的dump日志\"></a>打印当前的dump日志</h2><p>dump java heap, 类似 jmap 命令的 heap dump 功能。</p>\n<p><code>heapdump arthas-output/dump.hprof</code><br>生成文件在arthas-output目录</p>\n","site":{"data":{}},"excerpt":"<p>摘要:arthas使用小技巧</p>","more":"<h1 id=\"arthas的使用去排查线上问题\"><a href=\"#arthas的使用去排查线上问题\" class=\"headerlink\" title=\"arthas的使用去排查线上问题\"></a>arthas的使用去排查线上问题</h1><h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>直接解压arthas包，<a href=\"https://arthas.aliyun.com/doc/download.html\">arthas下载包</a>，<br>点击之后进入阿里的下载页面</p>\n<h3 id=\"用-as-sh-启动\"><a href=\"#用-as-sh-启动\" class=\"headerlink\" title=\"用 as.sh 启动\"></a>用 as.sh 启动</h3><p><code>./as.sh </code></p>\n<h3 id=\"用-arthas-boot-启动\"><a href=\"#用-arthas-boot-启动\" class=\"headerlink\" title=\"用 arthas-boot 启动\"></a>用 arthas-boot 启动</h3><p><code>java -jar arthas-boot.jar</code></p>\n<p>#线上问题排查</p>\n<h2 id=\"查看线上代码跟本地代码是否一致\"><a href=\"#查看线上代码跟本地代码是否一致\" class=\"headerlink\" title=\"查看线上代码跟本地代码是否一致\"></a>查看线上代码跟本地代码是否一致</h2><p>通过jad命令编译远程代码可以查看当前代码是否跟本地一致<br><code>jad org.hibernate.EmptyInterceptor</code></p>\n<h2 id=\"通过watch命令可以查看方法的出参，入参\"><a href=\"#通过watch命令可以查看方法的出参，入参\" class=\"headerlink\" title=\"通过watch命令可以查看方法的出参，入参\"></a>通过watch命令可以查看方法的出参，入参</h2><p><code>watch com.midea.ext.common.util.WFCommonUtil getQueueStatus  &#39;&#123;params,returnObj&#125;&#39;  -x 3 -m 140</code></p>\n<h2 id=\"打印当前的dump日志\"><a href=\"#打印当前的dump日志\" class=\"headerlink\" title=\"打印当前的dump日志\"></a>打印当前的dump日志</h2><p>dump java heap, 类似 jmap 命令的 heap dump 功能。</p>\n<p><code>heapdump arthas-output/dump.hprof</code><br>生成文件在arthas-output目录</p>"},{"date":"2020-03-26T16:00:00.000Z","status":"public","title":"hashmap原理","_content":"\n摘要:hashmap原理\n<!--more-->\n# hashmap原理\n首先1.7之前它是数组加链表的方式来实现的，这个数组就是哈希桶，默认哈希桶的长度是16（2*次方）\n\n# put方法\n把数据的key先哈希然后获取到对应值，然后对数组长度进行取模，然后获取到下标，然后把数据的key，value，next，head，都存到entry里面作为一个节点\n当在一个哈希桶里面有值的时候，就对比key是否相同，相同的话就替换，不相同的话就存到下一个节点，然后把节点entry保存形成链表。\n\n# 扩容\n有个扩容因子是0.75，扩容因子可以形成一个阀值，当这个值达到之后，就会扩容，就是表示放不下了，扩容的话先把哈希桶加倍16->32，然后再把所有的原有哈希\n节点再rehash一遍到新的哈希桶里面，阀值计算公式就是哈希桶的长度乘以扩容因子，当size就是整个hashmap的数据长度，如果大于等于这个阀值的话就扩容\n\n# get方法\n比较简单，就是通过获取到key值然后哈希之后获取到的值对数组长度进行取模，然后获取到对应的下标，然后逐一对比，如果有相同就取出\n\n# hashmap的for循环方式\n1,iterator\n2,for (Map.Entry<String, Integer> entry : testMap.entrySet()) \n3,使用foreach方式（JDK1.8才有）\n\n# jdk1.8之后不同点\njdk1.7链表不断增加，查询效率也在不断减慢，这个时候优化查询是关键\n引入了红黑树\nentry 也变成了 node\n数据插入跟jdk1.7有区别，1.7是头插法，1.8是尾插法\n\n步骤①：若哈希table为null，或长度为0，则做一次扩容操作；\n步骤②：根据index找到目标bucket后，若当前bucket上没有结点，那么直接新增一个结点，赋值给该bucket；\n步骤③：若当前bucket上有链表，且头结点就匹配，那么直接做替换即可；\n步骤④：若当前bucket上的是树结构，则转为红黑树的插入操作；\n步骤⑤：若步骤①、②、③、④都不成立，则对链表做遍历操作。\n    a) 若链表中有结点匹配，则做value替换；\n    b）若没有结点匹配，则在链表末尾追加。同时，执行以下操作：\n       i) 若链表长度大于TREEIFY_THRESHOLD，则执行红黑树转换操作；\n       ii) 若条件i) 不成立，则执行扩容resize()操作。\n以上5步都执行完后，再看当前Map中存储的k-v对的数量是否超出了threshold，若超出，还需再次扩容。\n\n# hashmap   hashtable  ConcurrentHashMap\nhashmap线程不安全，hashtable用了synchronized关键字，线程安全，但是效率不高\n在JDK7版本及以前，ConcurrentHashMap类使用了分段锁的技术（segment + Lock），segment 又用了ReentrantLock\n但在jdk8中，也做了较大改动，使用回了synchronized修饰符+cas技术\n\n# hashset原理\nhashset原理，底层是hashmap实现的，但是把所有的value放到key 里面存放，这样就会保证key 不重复，然后value的值都是private static final Object PRESENT = new Object();\n\n","source":"_posts/java/hashmap原理.md","raw":"---\ndate: 2020-03-27\nstatus: public\ntitle: hashmap原理\ntags:\n  - JAVA\n  - hashmap\n---\n\n摘要:hashmap原理\n<!--more-->\n# hashmap原理\n首先1.7之前它是数组加链表的方式来实现的，这个数组就是哈希桶，默认哈希桶的长度是16（2*次方）\n\n# put方法\n把数据的key先哈希然后获取到对应值，然后对数组长度进行取模，然后获取到下标，然后把数据的key，value，next，head，都存到entry里面作为一个节点\n当在一个哈希桶里面有值的时候，就对比key是否相同，相同的话就替换，不相同的话就存到下一个节点，然后把节点entry保存形成链表。\n\n# 扩容\n有个扩容因子是0.75，扩容因子可以形成一个阀值，当这个值达到之后，就会扩容，就是表示放不下了，扩容的话先把哈希桶加倍16->32，然后再把所有的原有哈希\n节点再rehash一遍到新的哈希桶里面，阀值计算公式就是哈希桶的长度乘以扩容因子，当size就是整个hashmap的数据长度，如果大于等于这个阀值的话就扩容\n\n# get方法\n比较简单，就是通过获取到key值然后哈希之后获取到的值对数组长度进行取模，然后获取到对应的下标，然后逐一对比，如果有相同就取出\n\n# hashmap的for循环方式\n1,iterator\n2,for (Map.Entry<String, Integer> entry : testMap.entrySet()) \n3,使用foreach方式（JDK1.8才有）\n\n# jdk1.8之后不同点\njdk1.7链表不断增加，查询效率也在不断减慢，这个时候优化查询是关键\n引入了红黑树\nentry 也变成了 node\n数据插入跟jdk1.7有区别，1.7是头插法，1.8是尾插法\n\n步骤①：若哈希table为null，或长度为0，则做一次扩容操作；\n步骤②：根据index找到目标bucket后，若当前bucket上没有结点，那么直接新增一个结点，赋值给该bucket；\n步骤③：若当前bucket上有链表，且头结点就匹配，那么直接做替换即可；\n步骤④：若当前bucket上的是树结构，则转为红黑树的插入操作；\n步骤⑤：若步骤①、②、③、④都不成立，则对链表做遍历操作。\n    a) 若链表中有结点匹配，则做value替换；\n    b）若没有结点匹配，则在链表末尾追加。同时，执行以下操作：\n       i) 若链表长度大于TREEIFY_THRESHOLD，则执行红黑树转换操作；\n       ii) 若条件i) 不成立，则执行扩容resize()操作。\n以上5步都执行完后，再看当前Map中存储的k-v对的数量是否超出了threshold，若超出，还需再次扩容。\n\n# hashmap   hashtable  ConcurrentHashMap\nhashmap线程不安全，hashtable用了synchronized关键字，线程安全，但是效率不高\n在JDK7版本及以前，ConcurrentHashMap类使用了分段锁的技术（segment + Lock），segment 又用了ReentrantLock\n但在jdk8中，也做了较大改动，使用回了synchronized修饰符+cas技术\n\n# hashset原理\nhashset原理，底层是hashmap实现的，但是把所有的value放到key 里面存放，这样就会保证key 不重复，然后value的值都是private static final Object PRESENT = new Object();\n\n","slug":"java/hashmap原理","published":1,"updated":"2025-05-16T04:25:25.419Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsk001bskqrecwi8yua","content":"<p>摘要:hashmap原理</p>\n<span id=\"more\"></span>\n<h1 id=\"hashmap原理\"><a href=\"#hashmap原理\" class=\"headerlink\" title=\"hashmap原理\"></a>hashmap原理</h1><p>首先1.7之前它是数组加链表的方式来实现的，这个数组就是哈希桶，默认哈希桶的长度是16（2*次方）</p>\n<h1 id=\"put方法\"><a href=\"#put方法\" class=\"headerlink\" title=\"put方法\"></a>put方法</h1><p>把数据的key先哈希然后获取到对应值，然后对数组长度进行取模，然后获取到下标，然后把数据的key，value，next，head，都存到entry里面作为一个节点<br>当在一个哈希桶里面有值的时候，就对比key是否相同，相同的话就替换，不相同的话就存到下一个节点，然后把节点entry保存形成链表。</p>\n<h1 id=\"扩容\"><a href=\"#扩容\" class=\"headerlink\" title=\"扩容\"></a>扩容</h1><p>有个扩容因子是0.75，扩容因子可以形成一个阀值，当这个值达到之后，就会扩容，就是表示放不下了，扩容的话先把哈希桶加倍16-&gt;32，然后再把所有的原有哈希<br>节点再rehash一遍到新的哈希桶里面，阀值计算公式就是哈希桶的长度乘以扩容因子，当size就是整个hashmap的数据长度，如果大于等于这个阀值的话就扩容</p>\n<h1 id=\"get方法\"><a href=\"#get方法\" class=\"headerlink\" title=\"get方法\"></a>get方法</h1><p>比较简单，就是通过获取到key值然后哈希之后获取到的值对数组长度进行取模，然后获取到对应的下标，然后逐一对比，如果有相同就取出</p>\n<h1 id=\"hashmap的for循环方式\"><a href=\"#hashmap的for循环方式\" class=\"headerlink\" title=\"hashmap的for循环方式\"></a>hashmap的for循环方式</h1><p>1,iterator<br>2,for (Map.Entry&lt;String, Integer&gt; entry : testMap.entrySet())<br>3,使用foreach方式（JDK1.8才有）</p>\n<h1 id=\"jdk1-8之后不同点\"><a href=\"#jdk1-8之后不同点\" class=\"headerlink\" title=\"jdk1.8之后不同点\"></a>jdk1.8之后不同点</h1><p>jdk1.7链表不断增加，查询效率也在不断减慢，这个时候优化查询是关键<br>引入了红黑树<br>entry 也变成了 node<br>数据插入跟jdk1.7有区别，1.7是头插法，1.8是尾插法</p>\n<p>步骤①：若哈希table为null，或长度为0，则做一次扩容操作；<br>步骤②：根据index找到目标bucket后，若当前bucket上没有结点，那么直接新增一个结点，赋值给该bucket；<br>步骤③：若当前bucket上有链表，且头结点就匹配，那么直接做替换即可；<br>步骤④：若当前bucket上的是树结构，则转为红黑树的插入操作；<br>步骤⑤：若步骤①、②、③、④都不成立，则对链表做遍历操作。<br>    a) 若链表中有结点匹配，则做value替换；<br>    b）若没有结点匹配，则在链表末尾追加。同时，执行以下操作：<br>       i) 若链表长度大于TREEIFY_THRESHOLD，则执行红黑树转换操作；<br>       ii) 若条件i) 不成立，则执行扩容resize()操作。<br>以上5步都执行完后，再看当前Map中存储的k-v对的数量是否超出了threshold，若超出，还需再次扩容。</p>\n<h1 id=\"hashmap-hashtable-ConcurrentHashMap\"><a href=\"#hashmap-hashtable-ConcurrentHashMap\" class=\"headerlink\" title=\"hashmap   hashtable  ConcurrentHashMap\"></a>hashmap   hashtable  ConcurrentHashMap</h1><p>hashmap线程不安全，hashtable用了synchronized关键字，线程安全，但是效率不高<br>在JDK7版本及以前，ConcurrentHashMap类使用了分段锁的技术（segment + Lock），segment 又用了ReentrantLock<br>但在jdk8中，也做了较大改动，使用回了synchronized修饰符+cas技术</p>\n<h1 id=\"hashset原理\"><a href=\"#hashset原理\" class=\"headerlink\" title=\"hashset原理\"></a>hashset原理</h1><p>hashset原理，底层是hashmap实现的，但是把所有的value放到key 里面存放，这样就会保证key 不重复，然后value的值都是private static final Object PRESENT = new Object();</p>\n","site":{"data":{}},"excerpt":"<p>摘要:hashmap原理</p>","more":"<h1 id=\"hashmap原理\"><a href=\"#hashmap原理\" class=\"headerlink\" title=\"hashmap原理\"></a>hashmap原理</h1><p>首先1.7之前它是数组加链表的方式来实现的，这个数组就是哈希桶，默认哈希桶的长度是16（2*次方）</p>\n<h1 id=\"put方法\"><a href=\"#put方法\" class=\"headerlink\" title=\"put方法\"></a>put方法</h1><p>把数据的key先哈希然后获取到对应值，然后对数组长度进行取模，然后获取到下标，然后把数据的key，value，next，head，都存到entry里面作为一个节点<br>当在一个哈希桶里面有值的时候，就对比key是否相同，相同的话就替换，不相同的话就存到下一个节点，然后把节点entry保存形成链表。</p>\n<h1 id=\"扩容\"><a href=\"#扩容\" class=\"headerlink\" title=\"扩容\"></a>扩容</h1><p>有个扩容因子是0.75，扩容因子可以形成一个阀值，当这个值达到之后，就会扩容，就是表示放不下了，扩容的话先把哈希桶加倍16-&gt;32，然后再把所有的原有哈希<br>节点再rehash一遍到新的哈希桶里面，阀值计算公式就是哈希桶的长度乘以扩容因子，当size就是整个hashmap的数据长度，如果大于等于这个阀值的话就扩容</p>\n<h1 id=\"get方法\"><a href=\"#get方法\" class=\"headerlink\" title=\"get方法\"></a>get方法</h1><p>比较简单，就是通过获取到key值然后哈希之后获取到的值对数组长度进行取模，然后获取到对应的下标，然后逐一对比，如果有相同就取出</p>\n<h1 id=\"hashmap的for循环方式\"><a href=\"#hashmap的for循环方式\" class=\"headerlink\" title=\"hashmap的for循环方式\"></a>hashmap的for循环方式</h1><p>1,iterator<br>2,for (Map.Entry&lt;String, Integer&gt; entry : testMap.entrySet())<br>3,使用foreach方式（JDK1.8才有）</p>\n<h1 id=\"jdk1-8之后不同点\"><a href=\"#jdk1-8之后不同点\" class=\"headerlink\" title=\"jdk1.8之后不同点\"></a>jdk1.8之后不同点</h1><p>jdk1.7链表不断增加，查询效率也在不断减慢，这个时候优化查询是关键<br>引入了红黑树<br>entry 也变成了 node<br>数据插入跟jdk1.7有区别，1.7是头插法，1.8是尾插法</p>\n<p>步骤①：若哈希table为null，或长度为0，则做一次扩容操作；<br>步骤②：根据index找到目标bucket后，若当前bucket上没有结点，那么直接新增一个结点，赋值给该bucket；<br>步骤③：若当前bucket上有链表，且头结点就匹配，那么直接做替换即可；<br>步骤④：若当前bucket上的是树结构，则转为红黑树的插入操作；<br>步骤⑤：若步骤①、②、③、④都不成立，则对链表做遍历操作。<br>    a) 若链表中有结点匹配，则做value替换；<br>    b）若没有结点匹配，则在链表末尾追加。同时，执行以下操作：<br>       i) 若链表长度大于TREEIFY_THRESHOLD，则执行红黑树转换操作；<br>       ii) 若条件i) 不成立，则执行扩容resize()操作。<br>以上5步都执行完后，再看当前Map中存储的k-v对的数量是否超出了threshold，若超出，还需再次扩容。</p>\n<h1 id=\"hashmap-hashtable-ConcurrentHashMap\"><a href=\"#hashmap-hashtable-ConcurrentHashMap\" class=\"headerlink\" title=\"hashmap   hashtable  ConcurrentHashMap\"></a>hashmap   hashtable  ConcurrentHashMap</h1><p>hashmap线程不安全，hashtable用了synchronized关键字，线程安全，但是效率不高<br>在JDK7版本及以前，ConcurrentHashMap类使用了分段锁的技术（segment + Lock），segment 又用了ReentrantLock<br>但在jdk8中，也做了较大改动，使用回了synchronized修饰符+cas技术</p>\n<h1 id=\"hashset原理\"><a href=\"#hashset原理\" class=\"headerlink\" title=\"hashset原理\"></a>hashset原理</h1><p>hashset原理，底层是hashmap实现的，但是把所有的value放到key 里面存放，这样就会保证key 不重复，然后value的值都是private static final Object PRESENT = new Object();</p>"},{"date":"2020-03-31T16:00:00.000Z","status":"public","title":"dubbo","_content":"\n摘要:java\n<!--more-->\n# dubbo 序列化\n默认序列化 hassian2序列化\n还有其他序列化，json序列化，java序列化java.io.Serializable，FastJson\n\n##浅谈Java序列化和hessian序列化的差异\n首先，hessian序列化比Java序列化高效很多，而且生成的字节流也要短很多。但相对来说没有Java序列化可靠，而且也不如Java序列化支持的全面；\n先说Java序列化，具体工作原理就不说了，Java序列化会把要序列化的对象类的元数据和业务数据全部序列化从字节流，而且是把整个继承关系上的东西全部序列化了。\n它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。但是由于确实是序列化了所有内容，\n所以可以说什么都可以传输，因此也更可用和可靠。\n\n而hessian序列化，它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，hessian会序列化成I 1这样的流，\nI表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，hessian把对象所有的属性当成一个Map来序列化，\n产生类似M className propertyName1 I 1 propertyName S stringValue（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。\n而在序列化过程中，如果一个对象之前出现过，hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。\n这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。\n而且同时因为并没有深入到实现内部去进行序列化，所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。\n\n## 为什么需要序列化\n序列化是将一个对象变成一个二进制流就是序列化， 反序列化是将二进制流转换成对象。\n1. 减小内存空间和网络传输的带宽\n2. 分布式的可扩展性\n3. 通用性，接口可共用\n\n## dubbo 跟 springcloud 有什么区别\n一个走rpc 远程过程调用服务，另外一个走http协议，底层rpc 服务直接调用另外一个服务的方法，就想调用本地方法一样，有个长连接\n这样就减少了http三次握手四次挥手的网络带宽，\n\nRPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http 一样去3次握手什么的，减少了网络开销；其次就是RPC框架一般都有注册中心，有丰富的监控管理；\n发布、下线接口、动态扩展等，对调用方来说是无感知、统 一化的操作。第三个来说就是安全性。最后就是最近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑\n\n\n\n# rpc服务\n## 为什么需要rpc服务\nrpc服务是远程进程间通信，就是允许程序调用另一个地址空间的过程或者函数，因为现在很多公司内部有很多大大小小的许多服务，部署在不同机器，\n如果服务间都走网络通信，那未免太复杂，太过繁琐而且容易出错，如果能像本地调用一个远程连接一样就好了，这就是rpc远程调用\n\n## 如何通信\n1，事先已经写好通信地址，类似于服务注册\n2，通过tcp直接调用传输到对应地址\n3，然后通过序列化和反反序列化传输数据\n\n## 一个基本的RPC架构里面应该至少包含以下4个组件：\n1、客户端（Client）:服务调用方（服务消费者）\n2、客户端存根（Client Stub）:存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端\n3、服务端存根（Server Stub）:接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理\n4、服务端（Server）:服务的真正提供者\n\n## RPC的三个过程\n1通信协议\n2寻址\n3序列化(将对象转换成网络可以传输的二进制)\n\n## zk服务注册发现过程，如果一个断了，怎么通知到对方\n这里写的非常清楚[zk服务注册发现过程](https://blog.csdn.net/zyhlwzy/article/details/101847565)\n1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode\n2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示\n3，具体流程\n1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。\n服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；\n2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，\n异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；\n4，zk的服务注册和发现流程\n1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，\n即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），\n比如注册一个用户注册服务（user/register）:\n2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，\n获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，\n比如发现用户注册服务（user/register）并调用。\n3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，\n因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，\nZookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。\n\n## zk节点类型\n1.持久节点(PERSISTENT)\n持久节点，创建后一直存在，直到主动删除此节点。\n2.持久顺序节点(PERSISTENT_SEQUENTIAL)\n持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。\n3.临时节点(EPHEMERAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。\n4.顺序临时节点(EPHEMERAL_SEQUENTIAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。\n\n## zk还可以用来做什么，具体怎么实现\n1,分布式锁，具体实现方式\n1）znode 可以被监控。\n节点数据修改、子节点变化、节点删除等。\n一旦变化可以通知设置监控的客户端。\n通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。\n2）分布式锁步骤。\n注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器\n\t1. 父节点持久节点/lock\n\t2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推\n\t3. 获取/lock下所有子节点getChildren(\"/lock\")方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，\n\t获得通知后重复该步骤。\n\t4. 执行代码。完成后释放锁。\n3）使用zookeeper + curator，完成分布式锁。\n\n\n\n## zk集群架构\nzk集群由多个节点组成，其中有且仅有一个leader，处理所有事务请求；follower及observer统称learner。learner需要同步leader的数据。follower还参与选举及事务决策过程。\nzk客户端会打散配置文件中的serverAddress 顺序并随机组成新的list，然后循环按序取一个服务器地址进行连接，直到成功。follower及observer会将事务请求转交给leader处理。\nZXID：每次对Zookeeper的状态的改变都会产生一个zxid（ZooKeeper Transaction Id），zxid是全局有序的，如果zxid1小于zxid2，则zxid1在zxid2之前发生。\n## 事务ID 概念\nZooKeeper状态的每次变化都接收一个ZXID（ZooKeeper事务id）形式的标记。ZXID是一个64位的数字，由Leader统一分配，全局唯一，不断递增。\nZXID展示了所有的ZooKeeper的变更顺序。每次变更会有一个唯一的zxid，如果zxid1小于zxid2说明zxid1在zxid2之前发生。\n## ZK 选举过程\n### zk启动节点的时候的选举过程\n(1) 每个Server发出一个投票。由于是初始情况，ZK1和ZK2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时ZK1的投票为(1, 0)，ZK2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。\n(2) 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。\n(3) 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行比较，规则如下\n　　　　· 优先检查ZXID。ZXID比较大的服务器优先作为Leader。\n　　　　· 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。\n对于ZK1而言，它的投票是(1, 0)，接收ZK2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时ZK2的myid最大，于是ZK2胜。ZK1更新自己的投票为(2, 0)，并将投票重新发送给ZK2。\n(4) 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于ZK1、ZK2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出ZK2作为Leader。\n(5) 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。当新的Zookeeper节点ZK3启动时，发现已经有Leader了，不再选举，直接将直接的状态从LOOKING改为FOLLOWING。\n### zk 一台机器挂了之后怎么选举\n(1) 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。\n(2) 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定ZK1的ZXID为124，ZK3的ZXID为123；在第一轮投票中，ZK1和ZK3都会投自己，产生投票(1, 124)，(3, 123)，然后各自将投票发送给集群中所有机器。\n(3) 接收来自各个服务器的投票。与启动时过程相同。\n(4) 处理投票。与启动时过程相同，由于ZK1事务ID大，ZK1将会成为Leader。\n(5) 统计投票。与启动时过程相同。\n(6) 改变服务器的状态。与启动时过程相同。\n\n\n## Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\n实现这个机制的协议叫做Zab协议（ZooKeeper Atomic Broadcast protocol）。\nZab协议有两种模式，它们分别是恢复模式（Recovery选主）和广播模式（Broadcast同步）。\n\n","source":"_posts/java/dubbo.md","raw":"\n---\ndate: 2020-04-1\nstatus: public\ntitle: dubbo\ntags:\n  - JAVA\n---\n\n摘要:java\n<!--more-->\n# dubbo 序列化\n默认序列化 hassian2序列化\n还有其他序列化，json序列化，java序列化java.io.Serializable，FastJson\n\n##浅谈Java序列化和hessian序列化的差异\n首先，hessian序列化比Java序列化高效很多，而且生成的字节流也要短很多。但相对来说没有Java序列化可靠，而且也不如Java序列化支持的全面；\n先说Java序列化，具体工作原理就不说了，Java序列化会把要序列化的对象类的元数据和业务数据全部序列化从字节流，而且是把整个继承关系上的东西全部序列化了。\n它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。但是由于确实是序列化了所有内容，\n所以可以说什么都可以传输，因此也更可用和可靠。\n\n而hessian序列化，它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，hessian会序列化成I 1这样的流，\nI表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，hessian把对象所有的属性当成一个Map来序列化，\n产生类似M className propertyName1 I 1 propertyName S stringValue（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。\n而在序列化过程中，如果一个对象之前出现过，hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。\n这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。\n而且同时因为并没有深入到实现内部去进行序列化，所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。\n\n## 为什么需要序列化\n序列化是将一个对象变成一个二进制流就是序列化， 反序列化是将二进制流转换成对象。\n1. 减小内存空间和网络传输的带宽\n2. 分布式的可扩展性\n3. 通用性，接口可共用\n\n## dubbo 跟 springcloud 有什么区别\n一个走rpc 远程过程调用服务，另外一个走http协议，底层rpc 服务直接调用另外一个服务的方法，就想调用本地方法一样，有个长连接\n这样就减少了http三次握手四次挥手的网络带宽，\n\nRPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http 一样去3次握手什么的，减少了网络开销；其次就是RPC框架一般都有注册中心，有丰富的监控管理；\n发布、下线接口、动态扩展等，对调用方来说是无感知、统 一化的操作。第三个来说就是安全性。最后就是最近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑\n\n\n\n# rpc服务\n## 为什么需要rpc服务\nrpc服务是远程进程间通信，就是允许程序调用另一个地址空间的过程或者函数，因为现在很多公司内部有很多大大小小的许多服务，部署在不同机器，\n如果服务间都走网络通信，那未免太复杂，太过繁琐而且容易出错，如果能像本地调用一个远程连接一样就好了，这就是rpc远程调用\n\n## 如何通信\n1，事先已经写好通信地址，类似于服务注册\n2，通过tcp直接调用传输到对应地址\n3，然后通过序列化和反反序列化传输数据\n\n## 一个基本的RPC架构里面应该至少包含以下4个组件：\n1、客户端（Client）:服务调用方（服务消费者）\n2、客户端存根（Client Stub）:存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端\n3、服务端存根（Server Stub）:接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理\n4、服务端（Server）:服务的真正提供者\n\n## RPC的三个过程\n1通信协议\n2寻址\n3序列化(将对象转换成网络可以传输的二进制)\n\n## zk服务注册发现过程，如果一个断了，怎么通知到对方\n这里写的非常清楚[zk服务注册发现过程](https://blog.csdn.net/zyhlwzy/article/details/101847565)\n1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode\n2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示\n3，具体流程\n1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。\n服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；\n2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，\n异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；\n4，zk的服务注册和发现流程\n1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，\n即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），\n比如注册一个用户注册服务（user/register）:\n2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，\n获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，\n比如发现用户注册服务（user/register）并调用。\n3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，\n因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，\nZookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。\n\n## zk节点类型\n1.持久节点(PERSISTENT)\n持久节点，创建后一直存在，直到主动删除此节点。\n2.持久顺序节点(PERSISTENT_SEQUENTIAL)\n持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。\n3.临时节点(EPHEMERAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。\n4.顺序临时节点(EPHEMERAL_SEQUENTIAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。\n\n## zk还可以用来做什么，具体怎么实现\n1,分布式锁，具体实现方式\n1）znode 可以被监控。\n节点数据修改、子节点变化、节点删除等。\n一旦变化可以通知设置监控的客户端。\n通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。\n2）分布式锁步骤。\n注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器\n\t1. 父节点持久节点/lock\n\t2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推\n\t3. 获取/lock下所有子节点getChildren(\"/lock\")方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，\n\t获得通知后重复该步骤。\n\t4. 执行代码。完成后释放锁。\n3）使用zookeeper + curator，完成分布式锁。\n\n\n\n## zk集群架构\nzk集群由多个节点组成，其中有且仅有一个leader，处理所有事务请求；follower及observer统称learner。learner需要同步leader的数据。follower还参与选举及事务决策过程。\nzk客户端会打散配置文件中的serverAddress 顺序并随机组成新的list，然后循环按序取一个服务器地址进行连接，直到成功。follower及observer会将事务请求转交给leader处理。\nZXID：每次对Zookeeper的状态的改变都会产生一个zxid（ZooKeeper Transaction Id），zxid是全局有序的，如果zxid1小于zxid2，则zxid1在zxid2之前发生。\n## 事务ID 概念\nZooKeeper状态的每次变化都接收一个ZXID（ZooKeeper事务id）形式的标记。ZXID是一个64位的数字，由Leader统一分配，全局唯一，不断递增。\nZXID展示了所有的ZooKeeper的变更顺序。每次变更会有一个唯一的zxid，如果zxid1小于zxid2说明zxid1在zxid2之前发生。\n## ZK 选举过程\n### zk启动节点的时候的选举过程\n(1) 每个Server发出一个投票。由于是初始情况，ZK1和ZK2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时ZK1的投票为(1, 0)，ZK2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。\n(2) 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。\n(3) 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行比较，规则如下\n　　　　· 优先检查ZXID。ZXID比较大的服务器优先作为Leader。\n　　　　· 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。\n对于ZK1而言，它的投票是(1, 0)，接收ZK2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时ZK2的myid最大，于是ZK2胜。ZK1更新自己的投票为(2, 0)，并将投票重新发送给ZK2。\n(4) 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于ZK1、ZK2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出ZK2作为Leader。\n(5) 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。当新的Zookeeper节点ZK3启动时，发现已经有Leader了，不再选举，直接将直接的状态从LOOKING改为FOLLOWING。\n### zk 一台机器挂了之后怎么选举\n(1) 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。\n(2) 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定ZK1的ZXID为124，ZK3的ZXID为123；在第一轮投票中，ZK1和ZK3都会投自己，产生投票(1, 124)，(3, 123)，然后各自将投票发送给集群中所有机器。\n(3) 接收来自各个服务器的投票。与启动时过程相同。\n(4) 处理投票。与启动时过程相同，由于ZK1事务ID大，ZK1将会成为Leader。\n(5) 统计投票。与启动时过程相同。\n(6) 改变服务器的状态。与启动时过程相同。\n\n\n## Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\n实现这个机制的协议叫做Zab协议（ZooKeeper Atomic Broadcast protocol）。\nZab协议有两种模式，它们分别是恢复模式（Recovery选主）和广播模式（Broadcast同步）。\n\n","slug":"java/dubbo","published":1,"updated":"2025-05-16T08:47:17.360Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jso001eskqr7mmo7qq6","content":"<p>摘要:java</p>\n<span id=\"more\"></span>\n<h1 id=\"dubbo-序列化\"><a href=\"#dubbo-序列化\" class=\"headerlink\" title=\"dubbo 序列化\"></a>dubbo 序列化</h1><p>默认序列化 hassian2序列化<br>还有其他序列化，json序列化，java序列化java.io.Serializable，FastJson</p>\n<p>##浅谈Java序列化和hessian序列化的差异<br>首先，hessian序列化比Java序列化高效很多，而且生成的字节流也要短很多。但相对来说没有Java序列化可靠，而且也不如Java序列化支持的全面；<br>先说Java序列化，具体工作原理就不说了，Java序列化会把要序列化的对象类的元数据和业务数据全部序列化从字节流，而且是把整个继承关系上的东西全部序列化了。<br>它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。但是由于确实是序列化了所有内容，<br>所以可以说什么都可以传输，因此也更可用和可靠。</p>\n<p>而hessian序列化，它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，hessian会序列化成I 1这样的流，<br>I表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，hessian把对象所有的属性当成一个Map来序列化，<br>产生类似M className propertyName1 I 1 propertyName S stringValue（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。<br>而在序列化过程中，如果一个对象之前出现过，hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。<br>这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。<br>而且同时因为并没有深入到实现内部去进行序列化，所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。</p>\n<h2 id=\"为什么需要序列化\"><a href=\"#为什么需要序列化\" class=\"headerlink\" title=\"为什么需要序列化\"></a>为什么需要序列化</h2><p>序列化是将一个对象变成一个二进制流就是序列化， 反序列化是将二进制流转换成对象。</p>\n<ol>\n<li>减小内存空间和网络传输的带宽</li>\n<li>分布式的可扩展性</li>\n<li>通用性，接口可共用</li>\n</ol>\n<h2 id=\"dubbo-跟-springcloud-有什么区别\"><a href=\"#dubbo-跟-springcloud-有什么区别\" class=\"headerlink\" title=\"dubbo 跟 springcloud 有什么区别\"></a>dubbo 跟 springcloud 有什么区别</h2><p>一个走rpc 远程过程调用服务，另外一个走http协议，底层rpc 服务直接调用另外一个服务的方法，就想调用本地方法一样，有个长连接<br>这样就减少了http三次握手四次挥手的网络带宽，</p>\n<p>RPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http 一样去3次握手什么的，减少了网络开销；其次就是RPC框架一般都有注册中心，有丰富的监控管理；<br>发布、下线接口、动态扩展等，对调用方来说是无感知、统 一化的操作。第三个来说就是安全性。最后就是最近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑</p>\n<h1 id=\"rpc服务\"><a href=\"#rpc服务\" class=\"headerlink\" title=\"rpc服务\"></a>rpc服务</h1><h2 id=\"为什么需要rpc服务\"><a href=\"#为什么需要rpc服务\" class=\"headerlink\" title=\"为什么需要rpc服务\"></a>为什么需要rpc服务</h2><p>rpc服务是远程进程间通信，就是允许程序调用另一个地址空间的过程或者函数，因为现在很多公司内部有很多大大小小的许多服务，部署在不同机器，<br>如果服务间都走网络通信，那未免太复杂，太过繁琐而且容易出错，如果能像本地调用一个远程连接一样就好了，这就是rpc远程调用</p>\n<h2 id=\"如何通信\"><a href=\"#如何通信\" class=\"headerlink\" title=\"如何通信\"></a>如何通信</h2><p>1，事先已经写好通信地址，类似于服务注册<br>2，通过tcp直接调用传输到对应地址<br>3，然后通过序列化和反反序列化传输数据</p>\n<h2 id=\"一个基本的RPC架构里面应该至少包含以下4个组件：\"><a href=\"#一个基本的RPC架构里面应该至少包含以下4个组件：\" class=\"headerlink\" title=\"一个基本的RPC架构里面应该至少包含以下4个组件：\"></a>一个基本的RPC架构里面应该至少包含以下4个组件：</h2><p>1、客户端（Client）:服务调用方（服务消费者）<br>2、客户端存根（Client Stub）:存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端<br>3、服务端存根（Server Stub）:接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理<br>4、服务端（Server）:服务的真正提供者</p>\n<h2 id=\"RPC的三个过程\"><a href=\"#RPC的三个过程\" class=\"headerlink\" title=\"RPC的三个过程\"></a>RPC的三个过程</h2><p>1通信协议<br>2寻址<br>3序列化(将对象转换成网络可以传输的二进制)</p>\n<h2 id=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"><a href=\"#zk服务注册发现过程，如果一个断了，怎么通知到对方\" class=\"headerlink\" title=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"></a>zk服务注册发现过程，如果一个断了，怎么通知到对方</h2><p>这里写的非常清楚<a href=\"https://blog.csdn.net/zyhlwzy/article/details/101847565\">zk服务注册发现过程</a><br>1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode<br>2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示<br>3，具体流程<br>1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。<br>服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；<br>2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，<br>异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；<br>4，zk的服务注册和发现流程<br>1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，<br>即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），<br>比如注册一个用户注册服务（user/register）:<br>2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，<br>获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，<br>比如发现用户注册服务（user/register）并调用。<br>3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，<br>因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，<br>Zookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。</p>\n<h2 id=\"zk节点类型\"><a href=\"#zk节点类型\" class=\"headerlink\" title=\"zk节点类型\"></a>zk节点类型</h2><p>1.持久节点(PERSISTENT)<br>持久节点，创建后一直存在，直到主动删除此节点。<br>2.持久顺序节点(PERSISTENT_SEQUENTIAL)<br>持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。<br>3.临时节点(EPHEMERAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。<br>4.顺序临时节点(EPHEMERAL_SEQUENTIAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。</p>\n<h2 id=\"zk还可以用来做什么，具体怎么实现\"><a href=\"#zk还可以用来做什么，具体怎么实现\" class=\"headerlink\" title=\"zk还可以用来做什么，具体怎么实现\"></a>zk还可以用来做什么，具体怎么实现</h2><p>1,分布式锁，具体实现方式<br>1）znode 可以被监控。<br>节点数据修改、子节点变化、节点删除等。<br>一旦变化可以通知设置监控的客户端。<br>通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。<br>2）分布式锁步骤。<br>注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器<br>    1. 父节点持久节点/lock<br>    2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推<br>    3. 获取/lock下所有子节点getChildren(“/lock”)方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，<br>    获得通知后重复该步骤。<br>    4. 执行代码。完成后释放锁。<br>3）使用zookeeper + curator，完成分布式锁。</p>\n<h2 id=\"zk集群架构\"><a href=\"#zk集群架构\" class=\"headerlink\" title=\"zk集群架构\"></a>zk集群架构</h2><p>zk集群由多个节点组成，其中有且仅有一个leader，处理所有事务请求；follower及observer统称learner。learner需要同步leader的数据。follower还参与选举及事务决策过程。<br>zk客户端会打散配置文件中的serverAddress 顺序并随机组成新的list，然后循环按序取一个服务器地址进行连接，直到成功。follower及observer会将事务请求转交给leader处理。<br>ZXID：每次对Zookeeper的状态的改变都会产生一个zxid（ZooKeeper Transaction Id），zxid是全局有序的，如果zxid1小于zxid2，则zxid1在zxid2之前发生。</p>\n<h2 id=\"事务ID-概念\"><a href=\"#事务ID-概念\" class=\"headerlink\" title=\"事务ID 概念\"></a>事务ID 概念</h2><p>ZooKeeper状态的每次变化都接收一个ZXID（ZooKeeper事务id）形式的标记。ZXID是一个64位的数字，由Leader统一分配，全局唯一，不断递增。<br>ZXID展示了所有的ZooKeeper的变更顺序。每次变更会有一个唯一的zxid，如果zxid1小于zxid2说明zxid1在zxid2之前发生。</p>\n<h2 id=\"ZK-选举过程\"><a href=\"#ZK-选举过程\" class=\"headerlink\" title=\"ZK 选举过程\"></a>ZK 选举过程</h2><h3 id=\"zk启动节点的时候的选举过程\"><a href=\"#zk启动节点的时候的选举过程\" class=\"headerlink\" title=\"zk启动节点的时候的选举过程\"></a>zk启动节点的时候的选举过程</h3><p>(1) 每个Server发出一个投票。由于是初始情况，ZK1和ZK2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时ZK1的投票为(1, 0)，ZK2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。<br>(2) 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。<br>(3) 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行比较，规则如下<br>　　　　· 优先检查ZXID。ZXID比较大的服务器优先作为Leader。<br>　　　　· 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。<br>对于ZK1而言，它的投票是(1, 0)，接收ZK2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时ZK2的myid最大，于是ZK2胜。ZK1更新自己的投票为(2, 0)，并将投票重新发送给ZK2。<br>(4) 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于ZK1、ZK2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出ZK2作为Leader。<br>(5) 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。当新的Zookeeper节点ZK3启动时，发现已经有Leader了，不再选举，直接将直接的状态从LOOKING改为FOLLOWING。</p>\n<h3 id=\"zk-一台机器挂了之后怎么选举\"><a href=\"#zk-一台机器挂了之后怎么选举\" class=\"headerlink\" title=\"zk 一台机器挂了之后怎么选举\"></a>zk 一台机器挂了之后怎么选举</h3><p>(1) 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。<br>(2) 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定ZK1的ZXID为124，ZK3的ZXID为123；在第一轮投票中，ZK1和ZK3都会投自己，产生投票(1, 124)，(3, 123)，然后各自将投票发送给集群中所有机器。<br>(3) 接收来自各个服务器的投票。与启动时过程相同。<br>(4) 处理投票。与启动时过程相同，由于ZK1事务ID大，ZK1将会成为Leader。<br>(5) 统计投票。与启动时过程相同。<br>(6) 改变服务器的状态。与启动时过程相同。</p>\n<h2 id=\"Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\"><a href=\"#Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\" class=\"headerlink\" title=\"Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\"></a>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。</h2><p>实现这个机制的协议叫做Zab协议（ZooKeeper Atomic Broadcast protocol）。<br>Zab协议有两种模式，它们分别是恢复模式（Recovery选主）和广播模式（Broadcast同步）。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:java</p>","more":"<h1 id=\"dubbo-序列化\"><a href=\"#dubbo-序列化\" class=\"headerlink\" title=\"dubbo 序列化\"></a>dubbo 序列化</h1><p>默认序列化 hassian2序列化<br>还有其他序列化，json序列化，java序列化java.io.Serializable，FastJson</p>\n<p>##浅谈Java序列化和hessian序列化的差异<br>首先，hessian序列化比Java序列化高效很多，而且生成的字节流也要短很多。但相对来说没有Java序列化可靠，而且也不如Java序列化支持的全面；<br>先说Java序列化，具体工作原理就不说了，Java序列化会把要序列化的对象类的元数据和业务数据全部序列化从字节流，而且是把整个继承关系上的东西全部序列化了。<br>它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。但是由于确实是序列化了所有内容，<br>所以可以说什么都可以传输，因此也更可用和可靠。</p>\n<p>而hessian序列化，它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，hessian会序列化成I 1这样的流，<br>I表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，hessian把对象所有的属性当成一个Map来序列化，<br>产生类似M className propertyName1 I 1 propertyName S stringValue（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。<br>而在序列化过程中，如果一个对象之前出现过，hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。<br>这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。<br>而且同时因为并没有深入到实现内部去进行序列化，所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。</p>\n<h2 id=\"为什么需要序列化\"><a href=\"#为什么需要序列化\" class=\"headerlink\" title=\"为什么需要序列化\"></a>为什么需要序列化</h2><p>序列化是将一个对象变成一个二进制流就是序列化， 反序列化是将二进制流转换成对象。</p>\n<ol>\n<li>减小内存空间和网络传输的带宽</li>\n<li>分布式的可扩展性</li>\n<li>通用性，接口可共用</li>\n</ol>\n<h2 id=\"dubbo-跟-springcloud-有什么区别\"><a href=\"#dubbo-跟-springcloud-有什么区别\" class=\"headerlink\" title=\"dubbo 跟 springcloud 有什么区别\"></a>dubbo 跟 springcloud 有什么区别</h2><p>一个走rpc 远程过程调用服务，另外一个走http协议，底层rpc 服务直接调用另外一个服务的方法，就想调用本地方法一样，有个长连接<br>这样就减少了http三次握手四次挥手的网络带宽，</p>\n<p>RPC框架的好处就显示出来了，首先就是长链接，不必每次通信都要像http 一样去3次握手什么的，减少了网络开销；其次就是RPC框架一般都有注册中心，有丰富的监控管理；<br>发布、下线接口、动态扩展等，对调用方来说是无感知、统 一化的操作。第三个来说就是安全性。最后就是最近流行的服务化架构、服务化治理，RPC框架是一个强力的支撑</p>\n<h1 id=\"rpc服务\"><a href=\"#rpc服务\" class=\"headerlink\" title=\"rpc服务\"></a>rpc服务</h1><h2 id=\"为什么需要rpc服务\"><a href=\"#为什么需要rpc服务\" class=\"headerlink\" title=\"为什么需要rpc服务\"></a>为什么需要rpc服务</h2><p>rpc服务是远程进程间通信，就是允许程序调用另一个地址空间的过程或者函数，因为现在很多公司内部有很多大大小小的许多服务，部署在不同机器，<br>如果服务间都走网络通信，那未免太复杂，太过繁琐而且容易出错，如果能像本地调用一个远程连接一样就好了，这就是rpc远程调用</p>\n<h2 id=\"如何通信\"><a href=\"#如何通信\" class=\"headerlink\" title=\"如何通信\"></a>如何通信</h2><p>1，事先已经写好通信地址，类似于服务注册<br>2，通过tcp直接调用传输到对应地址<br>3，然后通过序列化和反反序列化传输数据</p>\n<h2 id=\"一个基本的RPC架构里面应该至少包含以下4个组件：\"><a href=\"#一个基本的RPC架构里面应该至少包含以下4个组件：\" class=\"headerlink\" title=\"一个基本的RPC架构里面应该至少包含以下4个组件：\"></a>一个基本的RPC架构里面应该至少包含以下4个组件：</h2><p>1、客户端（Client）:服务调用方（服务消费者）<br>2、客户端存根（Client Stub）:存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端<br>3、服务端存根（Server Stub）:接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理<br>4、服务端（Server）:服务的真正提供者</p>\n<h2 id=\"RPC的三个过程\"><a href=\"#RPC的三个过程\" class=\"headerlink\" title=\"RPC的三个过程\"></a>RPC的三个过程</h2><p>1通信协议<br>2寻址<br>3序列化(将对象转换成网络可以传输的二进制)</p>\n<h2 id=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"><a href=\"#zk服务注册发现过程，如果一个断了，怎么通知到对方\" class=\"headerlink\" title=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"></a>zk服务注册发现过程，如果一个断了，怎么通知到对方</h2><p>这里写的非常清楚<a href=\"https://blog.csdn.net/zyhlwzy/article/details/101847565\">zk服务注册发现过程</a><br>1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode<br>2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示<br>3，具体流程<br>1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。<br>服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；<br>2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，<br>异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；<br>4，zk的服务注册和发现流程<br>1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，<br>即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），<br>比如注册一个用户注册服务（user/register）:<br>2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，<br>获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，<br>比如发现用户注册服务（user/register）并调用。<br>3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，<br>因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，<br>Zookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。</p>\n<h2 id=\"zk节点类型\"><a href=\"#zk节点类型\" class=\"headerlink\" title=\"zk节点类型\"></a>zk节点类型</h2><p>1.持久节点(PERSISTENT)<br>持久节点，创建后一直存在，直到主动删除此节点。<br>2.持久顺序节点(PERSISTENT_SEQUENTIAL)<br>持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。<br>3.临时节点(EPHEMERAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。<br>4.顺序临时节点(EPHEMERAL_SEQUENTIAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。</p>\n<h2 id=\"zk还可以用来做什么，具体怎么实现\"><a href=\"#zk还可以用来做什么，具体怎么实现\" class=\"headerlink\" title=\"zk还可以用来做什么，具体怎么实现\"></a>zk还可以用来做什么，具体怎么实现</h2><p>1,分布式锁，具体实现方式<br>1）znode 可以被监控。<br>节点数据修改、子节点变化、节点删除等。<br>一旦变化可以通知设置监控的客户端。<br>通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。<br>2）分布式锁步骤。<br>注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器<br>    1. 父节点持久节点/lock<br>    2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推<br>    3. 获取/lock下所有子节点getChildren(“/lock”)方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，<br>    获得通知后重复该步骤。<br>    4. 执行代码。完成后释放锁。<br>3）使用zookeeper + curator，完成分布式锁。</p>\n<h2 id=\"zk集群架构\"><a href=\"#zk集群架构\" class=\"headerlink\" title=\"zk集群架构\"></a>zk集群架构</h2><p>zk集群由多个节点组成，其中有且仅有一个leader，处理所有事务请求；follower及observer统称learner。learner需要同步leader的数据。follower还参与选举及事务决策过程。<br>zk客户端会打散配置文件中的serverAddress 顺序并随机组成新的list，然后循环按序取一个服务器地址进行连接，直到成功。follower及observer会将事务请求转交给leader处理。<br>ZXID：每次对Zookeeper的状态的改变都会产生一个zxid（ZooKeeper Transaction Id），zxid是全局有序的，如果zxid1小于zxid2，则zxid1在zxid2之前发生。</p>\n<h2 id=\"事务ID-概念\"><a href=\"#事务ID-概念\" class=\"headerlink\" title=\"事务ID 概念\"></a>事务ID 概念</h2><p>ZooKeeper状态的每次变化都接收一个ZXID（ZooKeeper事务id）形式的标记。ZXID是一个64位的数字，由Leader统一分配，全局唯一，不断递增。<br>ZXID展示了所有的ZooKeeper的变更顺序。每次变更会有一个唯一的zxid，如果zxid1小于zxid2说明zxid1在zxid2之前发生。</p>\n<h2 id=\"ZK-选举过程\"><a href=\"#ZK-选举过程\" class=\"headerlink\" title=\"ZK 选举过程\"></a>ZK 选举过程</h2><h3 id=\"zk启动节点的时候的选举过程\"><a href=\"#zk启动节点的时候的选举过程\" class=\"headerlink\" title=\"zk启动节点的时候的选举过程\"></a>zk启动节点的时候的选举过程</h3><p>(1) 每个Server发出一个投票。由于是初始情况，ZK1和ZK2都会将自己作为Leader服务器来进行投票，每次投票会包含所推举的服务器的myid和ZXID，使用(myid, ZXID)来表示，此时ZK1的投票为(1, 0)，ZK2的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。<br>(2) 接受来自各个服务器的投票。集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票、是否来自LOOKING状态的服务器。<br>(3) 处理投票。针对每一个投票，服务器都需要将别人的投票和自己的投票进行比较，规则如下<br>　　　　· 优先检查ZXID。ZXID比较大的服务器优先作为Leader。<br>　　　　· 如果ZXID相同，那么就比较myid。myid较大的服务器作为Leader服务器。<br>对于ZK1而言，它的投票是(1, 0)，接收ZK2的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此时ZK2的myid最大，于是ZK2胜。ZK1更新自己的投票为(2, 0)，并将投票重新发送给ZK2。<br>(4) 统计投票。每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于ZK1、ZK2而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出ZK2作为Leader。<br>(5) 改变服务器状态。一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。当新的Zookeeper节点ZK3启动时，发现已经有Leader了，不再选举，直接将直接的状态从LOOKING改为FOLLOWING。</p>\n<h3 id=\"zk-一台机器挂了之后怎么选举\"><a href=\"#zk-一台机器挂了之后怎么选举\" class=\"headerlink\" title=\"zk 一台机器挂了之后怎么选举\"></a>zk 一台机器挂了之后怎么选举</h3><p>(1) 变更状态。Leader挂后，余下的非Observer服务器都会讲自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。<br>(2) 每个Server会发出一个投票。在运行期间，每个服务器上的ZXID可能不同，此时假定ZK1的ZXID为124，ZK3的ZXID为123；在第一轮投票中，ZK1和ZK3都会投自己，产生投票(1, 124)，(3, 123)，然后各自将投票发送给集群中所有机器。<br>(3) 接收来自各个服务器的投票。与启动时过程相同。<br>(4) 处理投票。与启动时过程相同，由于ZK1事务ID大，ZK1将会成为Leader。<br>(5) 统计投票。与启动时过程相同。<br>(6) 改变服务器的状态。与启动时过程相同。</p>\n<h2 id=\"Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\"><a href=\"#Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\" class=\"headerlink\" title=\"Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。\"></a>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。</h2><p>实现这个机制的协议叫做Zab协议（ZooKeeper Atomic Broadcast protocol）。<br>Zab协议有两种模式，它们分别是恢复模式（Recovery选主）和广播模式（Broadcast同步）。</p>"},{"date":"2021-01-11T16:00:00.000Z","status":"public","title":"Netty","_content":"\n摘要:Netty底层原理\n<!--more-->\n# Netty 线程模型  对NIO的封装\nReactor模型 ---》NIO模型   默认是一个主从多路复用模型\n不过也要看这个EventLoopGroup设置\nNioEventLoopGroup默认线程数为CPU核心数的两倍\n如果new了两个NioEventLoopGroup，且指定工作线程数不为1，则是主从多线程模型\n如果new了两个NioEventLoopGroup，且指定工作线程数为1，则是主从单线程模型\n如果new了一个NioEventLoopGroup，且指定工作线程数不为1，则是多线程模型\n如果new了一个NioEventLoopGroup，且指定工作线程数为1，则是单线程模型\n\n# Reactor模型\n事件监听  selector  多路复用    先注册到selector 然后来一个事件就监听起来    用一个selector去接受线程  另外一个是去执行io\n\n# Nio Bio Aio\nnio 单线程然后通过selector 获取进入队列，然后通过一个线程去循环查询当前是否释放资源，就可以去执行   channel 非阻塞的\nServerSocketChannel  SocketChannel  buffer Selector多路复用选择器里面注册  nio 是一个线程selector 去做连接，连接好了的socket 就注册进另外一个selector\n\n## NIO 组成\nselector channel（ServerSocketChannel SocketChannel） buffer\n\n## EventLoop 与EventLoopGroup什么关系\nNioEventLoopGroup 是NioEventLoop的组合，用于管理NioEventLoop\n\nbio 来一个服务就搞一个socket  然后把这些线程都存在arraylist里面    来一个服务就起一个线程，对CPU伤害极大\naio 异步\n\n\n","source":"_posts/java/Netty.md","raw":"\n---\ndate: 2021-01-12\nstatus: public\ntitle: Netty\ntags:\n  - JAVA\n---\n\n摘要:Netty底层原理\n<!--more-->\n# Netty 线程模型  对NIO的封装\nReactor模型 ---》NIO模型   默认是一个主从多路复用模型\n不过也要看这个EventLoopGroup设置\nNioEventLoopGroup默认线程数为CPU核心数的两倍\n如果new了两个NioEventLoopGroup，且指定工作线程数不为1，则是主从多线程模型\n如果new了两个NioEventLoopGroup，且指定工作线程数为1，则是主从单线程模型\n如果new了一个NioEventLoopGroup，且指定工作线程数不为1，则是多线程模型\n如果new了一个NioEventLoopGroup，且指定工作线程数为1，则是单线程模型\n\n# Reactor模型\n事件监听  selector  多路复用    先注册到selector 然后来一个事件就监听起来    用一个selector去接受线程  另外一个是去执行io\n\n# Nio Bio Aio\nnio 单线程然后通过selector 获取进入队列，然后通过一个线程去循环查询当前是否释放资源，就可以去执行   channel 非阻塞的\nServerSocketChannel  SocketChannel  buffer Selector多路复用选择器里面注册  nio 是一个线程selector 去做连接，连接好了的socket 就注册进另外一个selector\n\n## NIO 组成\nselector channel（ServerSocketChannel SocketChannel） buffer\n\n## EventLoop 与EventLoopGroup什么关系\nNioEventLoopGroup 是NioEventLoop的组合，用于管理NioEventLoop\n\nbio 来一个服务就搞一个socket  然后把这些线程都存在arraylist里面    来一个服务就起一个线程，对CPU伤害极大\naio 异步\n\n\n","slug":"java/Netty","published":1,"updated":"2025-05-16T04:25:25.415Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsp001fskqre85h6qop","content":"<p>摘要:Netty底层原理</p>\n<span id=\"more\"></span>\n<h1 id=\"Netty-线程模型-对NIO的封装\"><a href=\"#Netty-线程模型-对NIO的封装\" class=\"headerlink\" title=\"Netty 线程模型  对NIO的封装\"></a>Netty 线程模型  对NIO的封装</h1><p>Reactor模型 —》NIO模型   默认是一个主从多路复用模型<br>不过也要看这个EventLoopGroup设置<br>NioEventLoopGroup默认线程数为CPU核心数的两倍<br>如果new了两个NioEventLoopGroup，且指定工作线程数不为1，则是主从多线程模型<br>如果new了两个NioEventLoopGroup，且指定工作线程数为1，则是主从单线程模型<br>如果new了一个NioEventLoopGroup，且指定工作线程数不为1，则是多线程模型<br>如果new了一个NioEventLoopGroup，且指定工作线程数为1，则是单线程模型</p>\n<h1 id=\"Reactor模型\"><a href=\"#Reactor模型\" class=\"headerlink\" title=\"Reactor模型\"></a>Reactor模型</h1><p>事件监听  selector  多路复用    先注册到selector 然后来一个事件就监听起来    用一个selector去接受线程  另外一个是去执行io</p>\n<h1 id=\"Nio-Bio-Aio\"><a href=\"#Nio-Bio-Aio\" class=\"headerlink\" title=\"Nio Bio Aio\"></a>Nio Bio Aio</h1><p>nio 单线程然后通过selector 获取进入队列，然后通过一个线程去循环查询当前是否释放资源，就可以去执行   channel 非阻塞的<br>ServerSocketChannel  SocketChannel  buffer Selector多路复用选择器里面注册  nio 是一个线程selector 去做连接，连接好了的socket 就注册进另外一个selector</p>\n<h2 id=\"NIO-组成\"><a href=\"#NIO-组成\" class=\"headerlink\" title=\"NIO 组成\"></a>NIO 组成</h2><p>selector channel（ServerSocketChannel SocketChannel） buffer</p>\n<h2 id=\"EventLoop-与EventLoopGroup什么关系\"><a href=\"#EventLoop-与EventLoopGroup什么关系\" class=\"headerlink\" title=\"EventLoop 与EventLoopGroup什么关系\"></a>EventLoop 与EventLoopGroup什么关系</h2><p>NioEventLoopGroup 是NioEventLoop的组合，用于管理NioEventLoop</p>\n<p>bio 来一个服务就搞一个socket  然后把这些线程都存在arraylist里面    来一个服务就起一个线程，对CPU伤害极大<br>aio 异步</p>\n","site":{"data":{}},"excerpt":"<p>摘要:Netty底层原理</p>","more":"<h1 id=\"Netty-线程模型-对NIO的封装\"><a href=\"#Netty-线程模型-对NIO的封装\" class=\"headerlink\" title=\"Netty 线程模型  对NIO的封装\"></a>Netty 线程模型  对NIO的封装</h1><p>Reactor模型 —》NIO模型   默认是一个主从多路复用模型<br>不过也要看这个EventLoopGroup设置<br>NioEventLoopGroup默认线程数为CPU核心数的两倍<br>如果new了两个NioEventLoopGroup，且指定工作线程数不为1，则是主从多线程模型<br>如果new了两个NioEventLoopGroup，且指定工作线程数为1，则是主从单线程模型<br>如果new了一个NioEventLoopGroup，且指定工作线程数不为1，则是多线程模型<br>如果new了一个NioEventLoopGroup，且指定工作线程数为1，则是单线程模型</p>\n<h1 id=\"Reactor模型\"><a href=\"#Reactor模型\" class=\"headerlink\" title=\"Reactor模型\"></a>Reactor模型</h1><p>事件监听  selector  多路复用    先注册到selector 然后来一个事件就监听起来    用一个selector去接受线程  另外一个是去执行io</p>\n<h1 id=\"Nio-Bio-Aio\"><a href=\"#Nio-Bio-Aio\" class=\"headerlink\" title=\"Nio Bio Aio\"></a>Nio Bio Aio</h1><p>nio 单线程然后通过selector 获取进入队列，然后通过一个线程去循环查询当前是否释放资源，就可以去执行   channel 非阻塞的<br>ServerSocketChannel  SocketChannel  buffer Selector多路复用选择器里面注册  nio 是一个线程selector 去做连接，连接好了的socket 就注册进另外一个selector</p>\n<h2 id=\"NIO-组成\"><a href=\"#NIO-组成\" class=\"headerlink\" title=\"NIO 组成\"></a>NIO 组成</h2><p>selector channel（ServerSocketChannel SocketChannel） buffer</p>\n<h2 id=\"EventLoop-与EventLoopGroup什么关系\"><a href=\"#EventLoop-与EventLoopGroup什么关系\" class=\"headerlink\" title=\"EventLoop 与EventLoopGroup什么关系\"></a>EventLoop 与EventLoopGroup什么关系</h2><p>NioEventLoopGroup 是NioEventLoop的组合，用于管理NioEventLoop</p>\n<p>bio 来一个服务就搞一个socket  然后把这些线程都存在arraylist里面    来一个服务就起一个线程，对CPU伤害极大<br>aio 异步</p>"},{"date":"2020-03-31T16:00:00.000Z","status":"public","title":"java面试","_content":"\n摘要:java\n<!--more-->\n\n# BIO NIO AIO \nBIO 同步阻塞式IO NIO 同步非阻塞IO  AIO 异步非阻塞IO\nBIO 就是一个连接就是一个线程，每来一个连接就起一个新线程，线程开销很大，这样子就导致服务器变慢或者崩溃\nNIO 就是全部都用selector()接口连接，全部都用一个线程来接收，其中netty zk 都是用的NIO ，这个时候会有一个线程去轮询当前连接的状态，\nAIO 就是一个线程，但是全部连接都到channel，如果有状态可以了，自动就会通知对应的线程来处理\nIO多路复用，Mio \n\n# 单例模式 内存可见性 互斥性  重排序 volatile   synchronized\n\n# IOC 和 AOP DI\n依赖注入和切面编程\n所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是<font color=red>耦合性</font>太强，\nIOC则是统一交给spring来管理创建，将对象交给容器管理，\n你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。\n在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，\n就把它已经初始化好的那些bean分配给你需要调用这些bean的类。\n\nDI 就是依赖注入，当你需要哪个bean的时候，你就通过注解注入某个对象所需要的外部资源（包括对象、资源、常量数据）\n\nAOP对OOP的一个补充，例如你管理后台要登录，你要验证身份token，你不可能每个接口都写一个验证，这个时候你可以在切面写一个拦截，就可以了\n\n# 对BeanFactory ApplicationContext的理解\n1，Spring实现了工厂模式的工厂类，这个类名为BeanFactory(接口)，\n在程序中通常用他的子类ApplicationContext。\nSpring相当于一个大的工厂类，在其配置文件中通过<bean>元素配置用于\n创建实例对象的类名和实例对象的属性\n2，ApplicationContext包含BeanFactory的所有功能，ApplicationContext还有加载配置文件，触发类路径扫描等功能\n\n# springboot 自动配置 @springbootapplication\n这里包括三个配置，@SpringBootConfiguration @EnableAutoConfiguration @ComponentScan\nspringbootconfiguration enableautoconfiguration compomemtscan\n\n# spring bean 生命周期\n1Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化\n2Bean实例化后对将Bean的引入和值注入到Bean的属性中\n3如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法\n4如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入\n5如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。\n6如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。\n7如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用\n8如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。\n9此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。\n10如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。\n\n# spring bean 作用域\n1，singleton 单例模式，每个容器中只有一个bean\n2，prototype 为每一个bean 请求创建一个实例\n3，request 为每一个request请求创建一个实例，在请求完成之后会失效然后被垃圾回收\n4，session 与request 范围类似  同一个session回话共享一个实例，不听会话使用不通过实例\n5，global-session 全局作用域，所有会话共享一个实例","source":"_posts/java/java.md","raw":"---\ndate: 2020-04-1\nstatus: public\ntitle: java面试\ntags:\n  - JAVA\n---\n\n摘要:java\n<!--more-->\n\n# BIO NIO AIO \nBIO 同步阻塞式IO NIO 同步非阻塞IO  AIO 异步非阻塞IO\nBIO 就是一个连接就是一个线程，每来一个连接就起一个新线程，线程开销很大，这样子就导致服务器变慢或者崩溃\nNIO 就是全部都用selector()接口连接，全部都用一个线程来接收，其中netty zk 都是用的NIO ，这个时候会有一个线程去轮询当前连接的状态，\nAIO 就是一个线程，但是全部连接都到channel，如果有状态可以了，自动就会通知对应的线程来处理\nIO多路复用，Mio \n\n# 单例模式 内存可见性 互斥性  重排序 volatile   synchronized\n\n# IOC 和 AOP DI\n依赖注入和切面编程\n所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是<font color=red>耦合性</font>太强，\nIOC则是统一交给spring来管理创建，将对象交给容器管理，\n你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。\n在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，\n就把它已经初始化好的那些bean分配给你需要调用这些bean的类。\n\nDI 就是依赖注入，当你需要哪个bean的时候，你就通过注解注入某个对象所需要的外部资源（包括对象、资源、常量数据）\n\nAOP对OOP的一个补充，例如你管理后台要登录，你要验证身份token，你不可能每个接口都写一个验证，这个时候你可以在切面写一个拦截，就可以了\n\n# 对BeanFactory ApplicationContext的理解\n1，Spring实现了工厂模式的工厂类，这个类名为BeanFactory(接口)，\n在程序中通常用他的子类ApplicationContext。\nSpring相当于一个大的工厂类，在其配置文件中通过<bean>元素配置用于\n创建实例对象的类名和实例对象的属性\n2，ApplicationContext包含BeanFactory的所有功能，ApplicationContext还有加载配置文件，触发类路径扫描等功能\n\n# springboot 自动配置 @springbootapplication\n这里包括三个配置，@SpringBootConfiguration @EnableAutoConfiguration @ComponentScan\nspringbootconfiguration enableautoconfiguration compomemtscan\n\n# spring bean 生命周期\n1Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化\n2Bean实例化后对将Bean的引入和值注入到Bean的属性中\n3如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法\n4如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入\n5如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。\n6如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。\n7如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用\n8如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。\n9此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。\n10如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。\n\n# spring bean 作用域\n1，singleton 单例模式，每个容器中只有一个bean\n2，prototype 为每一个bean 请求创建一个实例\n3，request 为每一个request请求创建一个实例，在请求完成之后会失效然后被垃圾回收\n4，session 与request 范围类似  同一个session回话共享一个实例，不听会话使用不通过实例\n5，global-session 全局作用域，所有会话共享一个实例","slug":"java/java","published":1,"updated":"2025-05-16T04:25:25.421Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsq001hskqre57rabdt","content":"<p>摘要:java</p>\n<span id=\"more\"></span>\n\n<h1 id=\"BIO-NIO-AIO\"><a href=\"#BIO-NIO-AIO\" class=\"headerlink\" title=\"BIO NIO AIO\"></a>BIO NIO AIO</h1><p>BIO 同步阻塞式IO NIO 同步非阻塞IO  AIO 异步非阻塞IO<br>BIO 就是一个连接就是一个线程，每来一个连接就起一个新线程，线程开销很大，这样子就导致服务器变慢或者崩溃<br>NIO 就是全部都用selector()接口连接，全部都用一个线程来接收，其中netty zk 都是用的NIO ，这个时候会有一个线程去轮询当前连接的状态，<br>AIO 就是一个线程，但是全部连接都到channel，如果有状态可以了，自动就会通知对应的线程来处理<br>IO多路复用，Mio </p>\n<h1 id=\"单例模式-内存可见性-互斥性-重排序-volatile-synchronized\"><a href=\"#单例模式-内存可见性-互斥性-重排序-volatile-synchronized\" class=\"headerlink\" title=\"单例模式 内存可见性 互斥性  重排序 volatile   synchronized\"></a>单例模式 内存可见性 互斥性  重排序 volatile   synchronized</h1><h1 id=\"IOC-和-AOP-DI\"><a href=\"#IOC-和-AOP-DI\" class=\"headerlink\" title=\"IOC 和 AOP DI\"></a>IOC 和 AOP DI</h1><p>依赖注入和切面编程<br>所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是<font color=red>耦合性</font>太强，<br>IOC则是统一交给spring来管理创建，将对象交给容器管理，<br>你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。<br>在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，<br>就把它已经初始化好的那些bean分配给你需要调用这些bean的类。</p>\n<p>DI 就是依赖注入，当你需要哪个bean的时候，你就通过注解注入某个对象所需要的外部资源（包括对象、资源、常量数据）</p>\n<p>AOP对OOP的一个补充，例如你管理后台要登录，你要验证身份token，你不可能每个接口都写一个验证，这个时候你可以在切面写一个拦截，就可以了</p>\n<h1 id=\"对BeanFactory-ApplicationContext的理解\"><a href=\"#对BeanFactory-ApplicationContext的理解\" class=\"headerlink\" title=\"对BeanFactory ApplicationContext的理解\"></a>对BeanFactory ApplicationContext的理解</h1><p>1，Spring实现了工厂模式的工厂类，这个类名为BeanFactory(接口)，<br>在程序中通常用他的子类ApplicationContext。<br>Spring相当于一个大的工厂类，在其配置文件中通过<bean>元素配置用于<br>创建实例对象的类名和实例对象的属性<br>2，ApplicationContext包含BeanFactory的所有功能，ApplicationContext还有加载配置文件，触发类路径扫描等功能</p>\n<h1 id=\"springboot-自动配置-springbootapplication\"><a href=\"#springboot-自动配置-springbootapplication\" class=\"headerlink\" title=\"springboot 自动配置 @springbootapplication\"></a>springboot 自动配置 @springbootapplication</h1><p>这里包括三个配置，@SpringBootConfiguration @EnableAutoConfiguration @ComponentScan<br>springbootconfiguration enableautoconfiguration compomemtscan</p>\n<h1 id=\"spring-bean-生命周期\"><a href=\"#spring-bean-生命周期\" class=\"headerlink\" title=\"spring bean 生命周期\"></a>spring bean 生命周期</h1><p>1Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化<br>2Bean实例化后对将Bean的引入和值注入到Bean的属性中<br>3如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法<br>4如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入<br>5如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。<br>6如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。<br>7如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用<br>8如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。<br>9此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。<br>10如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。</p>\n<h1 id=\"spring-bean-作用域\"><a href=\"#spring-bean-作用域\" class=\"headerlink\" title=\"spring bean 作用域\"></a>spring bean 作用域</h1><p>1，singleton 单例模式，每个容器中只有一个bean<br>2，prototype 为每一个bean 请求创建一个实例<br>3，request 为每一个request请求创建一个实例，在请求完成之后会失效然后被垃圾回收<br>4，session 与request 范围类似  同一个session回话共享一个实例，不听会话使用不通过实例<br>5，global-session 全局作用域，所有会话共享一个实例</p>\n","site":{"data":{}},"excerpt":"<p>摘要:java</p>","more":"<h1 id=\"BIO-NIO-AIO\"><a href=\"#BIO-NIO-AIO\" class=\"headerlink\" title=\"BIO NIO AIO\"></a>BIO NIO AIO</h1><p>BIO 同步阻塞式IO NIO 同步非阻塞IO  AIO 异步非阻塞IO<br>BIO 就是一个连接就是一个线程，每来一个连接就起一个新线程，线程开销很大，这样子就导致服务器变慢或者崩溃<br>NIO 就是全部都用selector()接口连接，全部都用一个线程来接收，其中netty zk 都是用的NIO ，这个时候会有一个线程去轮询当前连接的状态，<br>AIO 就是一个线程，但是全部连接都到channel，如果有状态可以了，自动就会通知对应的线程来处理<br>IO多路复用，Mio </p>\n<h1 id=\"单例模式-内存可见性-互斥性-重排序-volatile-synchronized\"><a href=\"#单例模式-内存可见性-互斥性-重排序-volatile-synchronized\" class=\"headerlink\" title=\"单例模式 内存可见性 互斥性  重排序 volatile   synchronized\"></a>单例模式 内存可见性 互斥性  重排序 volatile   synchronized</h1><h1 id=\"IOC-和-AOP-DI\"><a href=\"#IOC-和-AOP-DI\" class=\"headerlink\" title=\"IOC 和 AOP DI\"></a>IOC 和 AOP DI</h1><p>依赖注入和切面编程<br>所谓控制反转是指，本来被调用者的实例是由调用者来创建的，这样的缺点是<font color=red>耦合性</font>太强，<br>IOC则是统一交给spring来管理创建，将对象交给容器管理，<br>你只需要在spring配置文件总配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。<br>在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，<br>就把它已经初始化好的那些bean分配给你需要调用这些bean的类。</p>\n<p>DI 就是依赖注入，当你需要哪个bean的时候，你就通过注解注入某个对象所需要的外部资源（包括对象、资源、常量数据）</p>\n<p>AOP对OOP的一个补充，例如你管理后台要登录，你要验证身份token，你不可能每个接口都写一个验证，这个时候你可以在切面写一个拦截，就可以了</p>\n<h1 id=\"对BeanFactory-ApplicationContext的理解\"><a href=\"#对BeanFactory-ApplicationContext的理解\" class=\"headerlink\" title=\"对BeanFactory ApplicationContext的理解\"></a>对BeanFactory ApplicationContext的理解</h1><p>1，Spring实现了工厂模式的工厂类，这个类名为BeanFactory(接口)，<br>在程序中通常用他的子类ApplicationContext。<br>Spring相当于一个大的工厂类，在其配置文件中通过<bean>元素配置用于<br>创建实例对象的类名和实例对象的属性<br>2，ApplicationContext包含BeanFactory的所有功能，ApplicationContext还有加载配置文件，触发类路径扫描等功能</p>\n<h1 id=\"springboot-自动配置-springbootapplication\"><a href=\"#springboot-自动配置-springbootapplication\" class=\"headerlink\" title=\"springboot 自动配置 @springbootapplication\"></a>springboot 自动配置 @springbootapplication</h1><p>这里包括三个配置，@SpringBootConfiguration @EnableAutoConfiguration @ComponentScan<br>springbootconfiguration enableautoconfiguration compomemtscan</p>\n<h1 id=\"spring-bean-生命周期\"><a href=\"#spring-bean-生命周期\" class=\"headerlink\" title=\"spring bean 生命周期\"></a>spring bean 生命周期</h1><p>1Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化<br>2Bean实例化后对将Bean的引入和值注入到Bean的属性中<br>3如果Bean实现了BeanNameAware接口的话，Spring将Bean的Id传递给setBeanName()方法<br>4如果Bean实现了BeanFactoryAware接口的话，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入<br>5如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将bean所在应用上下文引用传入进来。<br>6如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。<br>7如果Bean 实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。类似的，如果bean使用init-method声明了初始化方法，该方法也会被调用<br>8如果Bean 实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。<br>9此时，Bean已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。<br>10如果bean实现了DisposableBean接口，Spring将调用它的destory()接口方法，同样，如果bean使用了destory-method 声明销毁方法，该方法也会被调用。</p>\n<h1 id=\"spring-bean-作用域\"><a href=\"#spring-bean-作用域\" class=\"headerlink\" title=\"spring bean 作用域\"></a>spring bean 作用域</h1><p>1，singleton 单例模式，每个容器中只有一个bean<br>2，prototype 为每一个bean 请求创建一个实例<br>3，request 为每一个request请求创建一个实例，在请求完成之后会失效然后被垃圾回收<br>4，session 与request 范围类似  同一个session回话共享一个实例，不听会话使用不通过实例<br>5，global-session 全局作用域，所有会话共享一个实例</p>"},{"date":"2020-11-25T16:00:00.000Z","status":"public","title":"aop","_content":"\n摘要:aop\n<!--more-->\n# aop 实现\nAspectJ 注解实现  @Around @after @before\n\n# aop 是怎么获取参数的\naopAspect 里面可以通过Autowired 获取到 HttpServletRequest  然后可以获取到参数 和对应的ip 等等\n\n# 过滤器filter、拦截器interceptor、和AOP的区别与联系\n## Filter过滤器\n过滤器拦截web访问url地址。 严格意义上讲，filter只是适用于web中，依赖于Servlet容器，利用Java的回调机制进行实现。\nFilter过滤器：和框架无关，可以控制最初的http请求，但是更细一点的类和方法控制不了。\n过滤器可以拦截到方法的请求和响应(ServletRequest request, ServletResponse response)，并对请求响应做出像响应的过滤操作，\n比如设置字符编码，鉴权操作等\n\n## Interceptor拦截器\n拦截器拦截以 .action结尾的url，拦截Action的访问。 Interfactor是基于Java的反射机制（APO思想）进行实现，不依赖Servlet容器。\n拦截器可以在方法执行之前(preHandle)和方法执行之后(afterCompletion)进行操作，回调操作(postHandle)，可以获取执行的方法的名称，\n请求(HttpServletRequest)\nInterceptor：可以控制请求的控制器和方法，但控制不了请求方法里的参数(只能获取参数的名称，不能获取到参数的值)\n（用于处理页面提交的请求响应并进行处理，例如做国际化，做主题更换，过滤等）。\n\n## Spring AOP拦截器\n只能拦截Spring管理Bean的访问（业务层Service）。 具体AOP详情参照 Spring AOP：原理、 通知、连接点、切点、切面、表达式\n实际开发中，AOP常和事务结合：Spring的事务管理:声明式事务管理(切面)\nAOP操作可以对操作进行横向的拦截，最大的优势在于他可以获取执行方法的参数( ProceedingJoinPoint.getArgs() )，对方法进行统一的处理。\nAspect : 可以自定义切入的点，有方法的参数，但是拿不到http请求，可以通过其他方式如RequestContextHolder获得(\nServletRequestAttributes servletRequestAttributes= (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();\n)。\n常见使用日志，事务，请求参数安全验证等\n\n##简单总结一下，拦截器相比过滤器有更细粒度的控制，依赖于Spring容器，可以在请求之前或之后启动，过滤器主要依赖于servlet，过滤器能做的，拦截器基本上都能做。\n\n## Filter与Interceptor联系与区别\n拦截器是基于java的反射机制，使用代理模式，而过滤器是基于函数回调。\n拦截器不依赖servlet容器，过滤器依赖于servlet容器。\n拦截器只能对action起作用，而过滤器可以对几乎所有的请求起作用（可以保护资源）。\n拦截器可以访问action上下文，堆栈里面的对象，而过滤器不可以。\n执行顺序：过滤前-拦截前-Action处理-拦截后-过滤后。\n\n\n## AOP 原理 （动态代理）\n### JDK动态代理\n### Cglib 动态代理\n\n## 动态代理怎么选择\n### 接口走Cglib，其他走JDK 还有个参数isProxyTarget可以设置 EnableAspectJAutoProxy\n\n## 什么是动态代理\n动态生成类，不再需要代理\n## 动态代理和静态代理区别\n静态代理是你写一个接口 然后 一个类继承这个接口，然后要代理这个类 你要额外写一个类然后继承这个接口，然后去代理你原来这个类，需要实现所有接口方法\n动态代理你写一个接口，然后 一个类继承这个接口，利用反射机制在运行时创建代理类，我们构建一个handler类来实现InvocationHandler接口，实现invoke方法\n然后调用newProxyInstance 强制转换成这个接口，就可以代理这个类了","source":"_posts/java/java切面.md","raw":"---\ndate: 2020-11-26\nstatus: public\ntitle: aop\ntags:\n  - JAVA\n---\n\n摘要:aop\n<!--more-->\n# aop 实现\nAspectJ 注解实现  @Around @after @before\n\n# aop 是怎么获取参数的\naopAspect 里面可以通过Autowired 获取到 HttpServletRequest  然后可以获取到参数 和对应的ip 等等\n\n# 过滤器filter、拦截器interceptor、和AOP的区别与联系\n## Filter过滤器\n过滤器拦截web访问url地址。 严格意义上讲，filter只是适用于web中，依赖于Servlet容器，利用Java的回调机制进行实现。\nFilter过滤器：和框架无关，可以控制最初的http请求，但是更细一点的类和方法控制不了。\n过滤器可以拦截到方法的请求和响应(ServletRequest request, ServletResponse response)，并对请求响应做出像响应的过滤操作，\n比如设置字符编码，鉴权操作等\n\n## Interceptor拦截器\n拦截器拦截以 .action结尾的url，拦截Action的访问。 Interfactor是基于Java的反射机制（APO思想）进行实现，不依赖Servlet容器。\n拦截器可以在方法执行之前(preHandle)和方法执行之后(afterCompletion)进行操作，回调操作(postHandle)，可以获取执行的方法的名称，\n请求(HttpServletRequest)\nInterceptor：可以控制请求的控制器和方法，但控制不了请求方法里的参数(只能获取参数的名称，不能获取到参数的值)\n（用于处理页面提交的请求响应并进行处理，例如做国际化，做主题更换，过滤等）。\n\n## Spring AOP拦截器\n只能拦截Spring管理Bean的访问（业务层Service）。 具体AOP详情参照 Spring AOP：原理、 通知、连接点、切点、切面、表达式\n实际开发中，AOP常和事务结合：Spring的事务管理:声明式事务管理(切面)\nAOP操作可以对操作进行横向的拦截，最大的优势在于他可以获取执行方法的参数( ProceedingJoinPoint.getArgs() )，对方法进行统一的处理。\nAspect : 可以自定义切入的点，有方法的参数，但是拿不到http请求，可以通过其他方式如RequestContextHolder获得(\nServletRequestAttributes servletRequestAttributes= (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();\n)。\n常见使用日志，事务，请求参数安全验证等\n\n##简单总结一下，拦截器相比过滤器有更细粒度的控制，依赖于Spring容器，可以在请求之前或之后启动，过滤器主要依赖于servlet，过滤器能做的，拦截器基本上都能做。\n\n## Filter与Interceptor联系与区别\n拦截器是基于java的反射机制，使用代理模式，而过滤器是基于函数回调。\n拦截器不依赖servlet容器，过滤器依赖于servlet容器。\n拦截器只能对action起作用，而过滤器可以对几乎所有的请求起作用（可以保护资源）。\n拦截器可以访问action上下文，堆栈里面的对象，而过滤器不可以。\n执行顺序：过滤前-拦截前-Action处理-拦截后-过滤后。\n\n\n## AOP 原理 （动态代理）\n### JDK动态代理\n### Cglib 动态代理\n\n## 动态代理怎么选择\n### 接口走Cglib，其他走JDK 还有个参数isProxyTarget可以设置 EnableAspectJAutoProxy\n\n## 什么是动态代理\n动态生成类，不再需要代理\n## 动态代理和静态代理区别\n静态代理是你写一个接口 然后 一个类继承这个接口，然后要代理这个类 你要额外写一个类然后继承这个接口，然后去代理你原来这个类，需要实现所有接口方法\n动态代理你写一个接口，然后 一个类继承这个接口，利用反射机制在运行时创建代理类，我们构建一个handler类来实现InvocationHandler接口，实现invoke方法\n然后调用newProxyInstance 强制转换成这个接口，就可以代理这个类了","slug":"java/java切面","published":1,"updated":"2025-05-16T04:25:25.422Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsr001jskqr67iafzhm","content":"<p>摘要:aop</p>\n<span id=\"more\"></span>\n<h1 id=\"aop-实现\"><a href=\"#aop-实现\" class=\"headerlink\" title=\"aop 实现\"></a>aop 实现</h1><p>AspectJ 注解实现  @Around @after @before</p>\n<h1 id=\"aop-是怎么获取参数的\"><a href=\"#aop-是怎么获取参数的\" class=\"headerlink\" title=\"aop 是怎么获取参数的\"></a>aop 是怎么获取参数的</h1><p>aopAspect 里面可以通过Autowired 获取到 HttpServletRequest  然后可以获取到参数 和对应的ip 等等</p>\n<h1 id=\"过滤器filter、拦截器interceptor、和AOP的区别与联系\"><a href=\"#过滤器filter、拦截器interceptor、和AOP的区别与联系\" class=\"headerlink\" title=\"过滤器filter、拦截器interceptor、和AOP的区别与联系\"></a>过滤器filter、拦截器interceptor、和AOP的区别与联系</h1><h2 id=\"Filter过滤器\"><a href=\"#Filter过滤器\" class=\"headerlink\" title=\"Filter过滤器\"></a>Filter过滤器</h2><p>过滤器拦截web访问url地址。 严格意义上讲，filter只是适用于web中，依赖于Servlet容器，利用Java的回调机制进行实现。<br>Filter过滤器：和框架无关，可以控制最初的http请求，但是更细一点的类和方法控制不了。<br>过滤器可以拦截到方法的请求和响应(ServletRequest request, ServletResponse response)，并对请求响应做出像响应的过滤操作，<br>比如设置字符编码，鉴权操作等</p>\n<h2 id=\"Interceptor拦截器\"><a href=\"#Interceptor拦截器\" class=\"headerlink\" title=\"Interceptor拦截器\"></a>Interceptor拦截器</h2><p>拦截器拦截以 .action结尾的url，拦截Action的访问。 Interfactor是基于Java的反射机制（APO思想）进行实现，不依赖Servlet容器。<br>拦截器可以在方法执行之前(preHandle)和方法执行之后(afterCompletion)进行操作，回调操作(postHandle)，可以获取执行的方法的名称，<br>请求(HttpServletRequest)<br>Interceptor：可以控制请求的控制器和方法，但控制不了请求方法里的参数(只能获取参数的名称，不能获取到参数的值)<br>（用于处理页面提交的请求响应并进行处理，例如做国际化，做主题更换，过滤等）。</p>\n<h2 id=\"Spring-AOP拦截器\"><a href=\"#Spring-AOP拦截器\" class=\"headerlink\" title=\"Spring AOP拦截器\"></a>Spring AOP拦截器</h2><p>只能拦截Spring管理Bean的访问（业务层Service）。 具体AOP详情参照 Spring AOP：原理、 通知、连接点、切点、切面、表达式<br>实际开发中，AOP常和事务结合：Spring的事务管理:声明式事务管理(切面)<br>AOP操作可以对操作进行横向的拦截，最大的优势在于他可以获取执行方法的参数( ProceedingJoinPoint.getArgs() )，对方法进行统一的处理。<br>Aspect : 可以自定义切入的点，有方法的参数，但是拿不到http请求，可以通过其他方式如RequestContextHolder获得(<br>ServletRequestAttributes servletRequestAttributes= (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();<br>)。<br>常见使用日志，事务，请求参数安全验证等</p>\n<p>##简单总结一下，拦截器相比过滤器有更细粒度的控制，依赖于Spring容器，可以在请求之前或之后启动，过滤器主要依赖于servlet，过滤器能做的，拦截器基本上都能做。</p>\n<h2 id=\"Filter与Interceptor联系与区别\"><a href=\"#Filter与Interceptor联系与区别\" class=\"headerlink\" title=\"Filter与Interceptor联系与区别\"></a>Filter与Interceptor联系与区别</h2><p>拦截器是基于java的反射机制，使用代理模式，而过滤器是基于函数回调。<br>拦截器不依赖servlet容器，过滤器依赖于servlet容器。<br>拦截器只能对action起作用，而过滤器可以对几乎所有的请求起作用（可以保护资源）。<br>拦截器可以访问action上下文，堆栈里面的对象，而过滤器不可以。<br>执行顺序：过滤前-拦截前-Action处理-拦截后-过滤后。</p>\n<h2 id=\"AOP-原理-（动态代理）\"><a href=\"#AOP-原理-（动态代理）\" class=\"headerlink\" title=\"AOP 原理 （动态代理）\"></a>AOP 原理 （动态代理）</h2><h3 id=\"JDK动态代理\"><a href=\"#JDK动态代理\" class=\"headerlink\" title=\"JDK动态代理\"></a>JDK动态代理</h3><h3 id=\"Cglib-动态代理\"><a href=\"#Cglib-动态代理\" class=\"headerlink\" title=\"Cglib 动态代理\"></a>Cglib 动态代理</h3><h2 id=\"动态代理怎么选择\"><a href=\"#动态代理怎么选择\" class=\"headerlink\" title=\"动态代理怎么选择\"></a>动态代理怎么选择</h2><h3 id=\"接口走Cglib，其他走JDK-还有个参数isProxyTarget可以设置-EnableAspectJAutoProxy\"><a href=\"#接口走Cglib，其他走JDK-还有个参数isProxyTarget可以设置-EnableAspectJAutoProxy\" class=\"headerlink\" title=\"接口走Cglib，其他走JDK 还有个参数isProxyTarget可以设置 EnableAspectJAutoProxy\"></a>接口走Cglib，其他走JDK 还有个参数isProxyTarget可以设置 EnableAspectJAutoProxy</h3><h2 id=\"什么是动态代理\"><a href=\"#什么是动态代理\" class=\"headerlink\" title=\"什么是动态代理\"></a>什么是动态代理</h2><p>动态生成类，不再需要代理</p>\n<h2 id=\"动态代理和静态代理区别\"><a href=\"#动态代理和静态代理区别\" class=\"headerlink\" title=\"动态代理和静态代理区别\"></a>动态代理和静态代理区别</h2><p>静态代理是你写一个接口 然后 一个类继承这个接口，然后要代理这个类 你要额外写一个类然后继承这个接口，然后去代理你原来这个类，需要实现所有接口方法<br>动态代理你写一个接口，然后 一个类继承这个接口，利用反射机制在运行时创建代理类，我们构建一个handler类来实现InvocationHandler接口，实现invoke方法<br>然后调用newProxyInstance 强制转换成这个接口，就可以代理这个类了</p>\n","site":{"data":{}},"excerpt":"<p>摘要:aop</p>","more":"<h1 id=\"aop-实现\"><a href=\"#aop-实现\" class=\"headerlink\" title=\"aop 实现\"></a>aop 实现</h1><p>AspectJ 注解实现  @Around @after @before</p>\n<h1 id=\"aop-是怎么获取参数的\"><a href=\"#aop-是怎么获取参数的\" class=\"headerlink\" title=\"aop 是怎么获取参数的\"></a>aop 是怎么获取参数的</h1><p>aopAspect 里面可以通过Autowired 获取到 HttpServletRequest  然后可以获取到参数 和对应的ip 等等</p>\n<h1 id=\"过滤器filter、拦截器interceptor、和AOP的区别与联系\"><a href=\"#过滤器filter、拦截器interceptor、和AOP的区别与联系\" class=\"headerlink\" title=\"过滤器filter、拦截器interceptor、和AOP的区别与联系\"></a>过滤器filter、拦截器interceptor、和AOP的区别与联系</h1><h2 id=\"Filter过滤器\"><a href=\"#Filter过滤器\" class=\"headerlink\" title=\"Filter过滤器\"></a>Filter过滤器</h2><p>过滤器拦截web访问url地址。 严格意义上讲，filter只是适用于web中，依赖于Servlet容器，利用Java的回调机制进行实现。<br>Filter过滤器：和框架无关，可以控制最初的http请求，但是更细一点的类和方法控制不了。<br>过滤器可以拦截到方法的请求和响应(ServletRequest request, ServletResponse response)，并对请求响应做出像响应的过滤操作，<br>比如设置字符编码，鉴权操作等</p>\n<h2 id=\"Interceptor拦截器\"><a href=\"#Interceptor拦截器\" class=\"headerlink\" title=\"Interceptor拦截器\"></a>Interceptor拦截器</h2><p>拦截器拦截以 .action结尾的url，拦截Action的访问。 Interfactor是基于Java的反射机制（APO思想）进行实现，不依赖Servlet容器。<br>拦截器可以在方法执行之前(preHandle)和方法执行之后(afterCompletion)进行操作，回调操作(postHandle)，可以获取执行的方法的名称，<br>请求(HttpServletRequest)<br>Interceptor：可以控制请求的控制器和方法，但控制不了请求方法里的参数(只能获取参数的名称，不能获取到参数的值)<br>（用于处理页面提交的请求响应并进行处理，例如做国际化，做主题更换，过滤等）。</p>\n<h2 id=\"Spring-AOP拦截器\"><a href=\"#Spring-AOP拦截器\" class=\"headerlink\" title=\"Spring AOP拦截器\"></a>Spring AOP拦截器</h2><p>只能拦截Spring管理Bean的访问（业务层Service）。 具体AOP详情参照 Spring AOP：原理、 通知、连接点、切点、切面、表达式<br>实际开发中，AOP常和事务结合：Spring的事务管理:声明式事务管理(切面)<br>AOP操作可以对操作进行横向的拦截，最大的优势在于他可以获取执行方法的参数( ProceedingJoinPoint.getArgs() )，对方法进行统一的处理。<br>Aspect : 可以自定义切入的点，有方法的参数，但是拿不到http请求，可以通过其他方式如RequestContextHolder获得(<br>ServletRequestAttributes servletRequestAttributes= (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();<br>)。<br>常见使用日志，事务，请求参数安全验证等</p>\n<p>##简单总结一下，拦截器相比过滤器有更细粒度的控制，依赖于Spring容器，可以在请求之前或之后启动，过滤器主要依赖于servlet，过滤器能做的，拦截器基本上都能做。</p>\n<h2 id=\"Filter与Interceptor联系与区别\"><a href=\"#Filter与Interceptor联系与区别\" class=\"headerlink\" title=\"Filter与Interceptor联系与区别\"></a>Filter与Interceptor联系与区别</h2><p>拦截器是基于java的反射机制，使用代理模式，而过滤器是基于函数回调。<br>拦截器不依赖servlet容器，过滤器依赖于servlet容器。<br>拦截器只能对action起作用，而过滤器可以对几乎所有的请求起作用（可以保护资源）。<br>拦截器可以访问action上下文，堆栈里面的对象，而过滤器不可以。<br>执行顺序：过滤前-拦截前-Action处理-拦截后-过滤后。</p>\n<h2 id=\"AOP-原理-（动态代理）\"><a href=\"#AOP-原理-（动态代理）\" class=\"headerlink\" title=\"AOP 原理 （动态代理）\"></a>AOP 原理 （动态代理）</h2><h3 id=\"JDK动态代理\"><a href=\"#JDK动态代理\" class=\"headerlink\" title=\"JDK动态代理\"></a>JDK动态代理</h3><h3 id=\"Cglib-动态代理\"><a href=\"#Cglib-动态代理\" class=\"headerlink\" title=\"Cglib 动态代理\"></a>Cglib 动态代理</h3><h2 id=\"动态代理怎么选择\"><a href=\"#动态代理怎么选择\" class=\"headerlink\" title=\"动态代理怎么选择\"></a>动态代理怎么选择</h2><h3 id=\"接口走Cglib，其他走JDK-还有个参数isProxyTarget可以设置-EnableAspectJAutoProxy\"><a href=\"#接口走Cglib，其他走JDK-还有个参数isProxyTarget可以设置-EnableAspectJAutoProxy\" class=\"headerlink\" title=\"接口走Cglib，其他走JDK 还有个参数isProxyTarget可以设置 EnableAspectJAutoProxy\"></a>接口走Cglib，其他走JDK 还有个参数isProxyTarget可以设置 EnableAspectJAutoProxy</h3><h2 id=\"什么是动态代理\"><a href=\"#什么是动态代理\" class=\"headerlink\" title=\"什么是动态代理\"></a>什么是动态代理</h2><p>动态生成类，不再需要代理</p>\n<h2 id=\"动态代理和静态代理区别\"><a href=\"#动态代理和静态代理区别\" class=\"headerlink\" title=\"动态代理和静态代理区别\"></a>动态代理和静态代理区别</h2><p>静态代理是你写一个接口 然后 一个类继承这个接口，然后要代理这个类 你要额外写一个类然后继承这个接口，然后去代理你原来这个类，需要实现所有接口方法<br>动态代理你写一个接口，然后 一个类继承这个接口，利用反射机制在运行时创建代理类，我们构建一个handler类来实现InvocationHandler接口，实现invoke方法<br>然后调用newProxyInstance 强制转换成这个接口，就可以代理这个类了</p>"},{"date":"2020-03-26T16:00:00.000Z","status":"public","title":"mysql对比小工具","_content":"\n摘要:mysql对比小工具\n<!--more-->\n# mysql对比小工具\n# 现在测试库跟正式库要做对比，麻烦了 发现了一个小工具很牛逼\n下载mysqldiff\n下载地址：http://downloads.mysql.com/archives/utilities/\n\n命令模板\n\n     mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\n      这里讲的是两种用法。可以直接对比库，db3:db4 ,也可以对比表 db1.table1:db2.table2\n\n      --server1：配置server1的连接。\n      --server2：配置server2的连接。\n      --character-set：配置连接时用的字符集，如果不显示配置默认使用character_set_client。\n      --width：配置显示的宽度。\n      --skip-table-options：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。 这个一定要加，否则肯定对比失败。测试环境和正式环境自增字段的当前值肯定不一样。如果是主从对比，就不要加。\n      -d DIFFTYPE,--difftype=DIFFTYPE：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用sql，那么就直接生成差异的SQL，这样非常方便。\n      --changes-for=：修改对象。例如 –changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。\n      --show-reverse：在生成的差异修改里面，同时会包含server2和server1的修改。\n      --force：完成所有的比较，不会在遇到一个差异之后退出\n      -vv：便于调试，输出许多信息\n      -q：quiet模式，关闭多余的信息输出\n\n\n# 例子 \nmysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\n","source":"_posts/java/mysql对比小工具.md","raw":"---\ndate: 2020-03-27\nstatus: public\ntitle: mysql对比小工具\ntags:\n  - JAVA\n  - mysql\n---\n\n摘要:mysql对比小工具\n<!--more-->\n# mysql对比小工具\n# 现在测试库跟正式库要做对比，麻烦了 发现了一个小工具很牛逼\n下载mysqldiff\n下载地址：http://downloads.mysql.com/archives/utilities/\n\n命令模板\n\n     mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\n      这里讲的是两种用法。可以直接对比库，db3:db4 ,也可以对比表 db1.table1:db2.table2\n\n      --server1：配置server1的连接。\n      --server2：配置server2的连接。\n      --character-set：配置连接时用的字符集，如果不显示配置默认使用character_set_client。\n      --width：配置显示的宽度。\n      --skip-table-options：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。 这个一定要加，否则肯定对比失败。测试环境和正式环境自增字段的当前值肯定不一样。如果是主从对比，就不要加。\n      -d DIFFTYPE,--difftype=DIFFTYPE：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用sql，那么就直接生成差异的SQL，这样非常方便。\n      --changes-for=：修改对象。例如 –changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。\n      --show-reverse：在生成的差异修改里面，同时会包含server2和server1的修改。\n      --force：完成所有的比较，不会在遇到一个差异之后退出\n      -vv：便于调试，输出许多信息\n      -q：quiet模式，关闭多余的信息输出\n\n\n# 例子 \nmysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\n","slug":"java/mysql对比小工具","published":1,"updated":"2025-05-16T04:25:25.424Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jss001mskqr6mstb62m","content":"<p>摘要:mysql对比小工具</p>\n<span id=\"more\"></span>\n<h1 id=\"mysql对比小工具\"><a href=\"#mysql对比小工具\" class=\"headerlink\" title=\"mysql对比小工具\"></a>mysql对比小工具</h1><h1 id=\"现在测试库跟正式库要做对比，麻烦了-发现了一个小工具很牛逼\"><a href=\"#现在测试库跟正式库要做对比，麻烦了-发现了一个小工具很牛逼\" class=\"headerlink\" title=\"现在测试库跟正式库要做对比，麻烦了 发现了一个小工具很牛逼\"></a>现在测试库跟正式库要做对比，麻烦了 发现了一个小工具很牛逼</h1><p>下载mysqldiff<br>下载地址：<a href=\"http://downloads.mysql.com/archives/utilities/\">http://downloads.mysql.com/archives/utilities/</a></p>\n<p>命令模板</p>\n<pre><code> mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\n  这里讲的是两种用法。可以直接对比库，db3:db4 ,也可以对比表 db1.table1:db2.table2\n\n  --server1：配置server1的连接。\n  --server2：配置server2的连接。\n  --character-set：配置连接时用的字符集，如果不显示配置默认使用character_set_client。\n  --width：配置显示的宽度。\n  --skip-table-options：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。 这个一定要加，否则肯定对比失败。测试环境和正式环境自增字段的当前值肯定不一样。如果是主从对比，就不要加。\n  -d DIFFTYPE,--difftype=DIFFTYPE：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用sql，那么就直接生成差异的SQL，这样非常方便。\n  --changes-for=：修改对象。例如 –changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。\n  --show-reverse：在生成的差异修改里面，同时会包含server2和server1的修改。\n  --force：完成所有的比较，不会在遇到一个差异之后退出\n  -vv：便于调试，输出许多信息\n  -q：quiet模式，关闭多余的信息输出\n</code></pre>\n<h1 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h1><p>mysqldiff –server1=user:pass@host:port:socket –server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4</p>\n","site":{"data":{}},"excerpt":"<p>摘要:mysql对比小工具</p>","more":"<h1 id=\"mysql对比小工具\"><a href=\"#mysql对比小工具\" class=\"headerlink\" title=\"mysql对比小工具\"></a>mysql对比小工具</h1><h1 id=\"现在测试库跟正式库要做对比，麻烦了-发现了一个小工具很牛逼\"><a href=\"#现在测试库跟正式库要做对比，麻烦了-发现了一个小工具很牛逼\" class=\"headerlink\" title=\"现在测试库跟正式库要做对比，麻烦了 发现了一个小工具很牛逼\"></a>现在测试库跟正式库要做对比，麻烦了 发现了一个小工具很牛逼</h1><p>下载mysqldiff<br>下载地址：<a href=\"http://downloads.mysql.com/archives/utilities/\">http://downloads.mysql.com/archives/utilities/</a></p>\n<p>命令模板</p>\n<pre><code> mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\n  这里讲的是两种用法。可以直接对比库，db3:db4 ,也可以对比表 db1.table1:db2.table2\n\n  --server1：配置server1的连接。\n  --server2：配置server2的连接。\n  --character-set：配置连接时用的字符集，如果不显示配置默认使用character_set_client。\n  --width：配置显示的宽度。\n  --skip-table-options：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。 这个一定要加，否则肯定对比失败。测试环境和正式环境自增字段的当前值肯定不一样。如果是主从对比，就不要加。\n  -d DIFFTYPE,--difftype=DIFFTYPE：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用sql，那么就直接生成差异的SQL，这样非常方便。\n  --changes-for=：修改对象。例如 –changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。\n  --show-reverse：在生成的差异修改里面，同时会包含server2和server1的修改。\n  --force：完成所有的比较，不会在遇到一个差异之后退出\n  -vv：便于调试，输出许多信息\n  -q：quiet模式，关闭多余的信息输出\n</code></pre>\n<h1 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h1><p>mysqldiff –server1=user:pass@host:port:socket –server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4</p>"},{"date":"2021-01-08T16:00:00.000Z","status":"public","title":"mybatis源码解析","_content":"\n摘要:mybatis源码解析\n<!--more-->\n#写在前面-------------------------上次面试的时候问到mybatis源码，自感没看过，有点虚，就去看了源码\n# mybatis源码解析\nmybatis工作原理\n1，XmlConfigBuilder加载property文件获取url password等配置 到Configuration\n2，XmlMapperBuilder加载xml文件获取mapper\n3，返回SqlSessionFactory.opensession  获取 SqlSession 调用Executor执行数据库操作\n4，连接sql，执行mapper，最底层也是通过sql jdbc  SqlSession包含了执行sql所需要的所有方法\n\n\n# mybatis一级二级缓存\n\n1，一级缓存的粒度较小，是与某个SqlSession绑定的，只对该SqlSession的相关查询操作进行缓存，\n不同SqlSession实例之间相互不影响，缓存为使用本地内存实现；mybatis的一级缓存是默认开启的。LocalCache\n默认开启不用配置 ；xml setting 配置为localCacheScope 为STATEMENT 则关闭一级缓存\n\n2，二级缓存是一种全局缓存，是由所有SqlSession实例所共享的，即不同SqlSession实例查询时产生的缓存，对其他SqlSession实例可见。\nmybatis默认没有开启二级缓存，二级缓存支持在配置中自定义底层所用的缓存实现，包括使用本地内存和分布式缓存。\n\n3，二级缓存是基于namespace的，即作用域为mapper，故需要在每个mapper中配置自身所使用的二级缓存实现以及缓存策略。\n同时由于二级缓存是基于namespace的，所以不同namespace之间的相互不影响的，如一个namespace使用的本地内存，\n另外一个namespace使用的是分布式缓存，如果不同namespace对同一张数据表的数据进行了操作，则可能会存在数据不一致问题。\n\n## SESSION级别\n1,对该SqlSession实例发起的查询操作进行缓存，即由同一SqlSession实例发起的多次相同（SQL和SQL的参数值都相同）的查询操作，\n第一次是查询数据库，后续则查询缓存；但是如果另外一个SqlSession实例进行相同的查询操作，则需要进行数据库查询。\n2,针对更新操作，如果是该SqlSession自身进行了更新操作，则该SqlSession对应的一级缓存会被清空；\n但是如果是其他SqlSession实例进行了更新操作，则此更新操作对该SqlSession不可见。\n所以该SqlSession的缓存数据是过期失效数据，所以SqlSession实例的生命周期不能过长，否则可能出现数据不一致现象。\n## STATEMENT级别\n该级别是指缓存只针对当前执行的查询语句有效，故每次语句执行完之后都会清空缓存，其实是相当于没有缓存，\n即该sqlSession实例下次调用相同的SQL语句和相同参数值时，由于上一次语句执行后，缓存被清空了，故需要继续查询数据库\n\n## 怎么才能每次都去数据库查询\n配置xml文件flushcacherequired\n\n## 什么时候会清理缓存\n1，SqlSession内执行更新操作，包括insert/update/delete，都通过PerpetualCache的clear方法清空localCache\n2，执行commit/rollback时也会清空缓存\n3，配置中设置localCacheScope为STATEMENT，执行完查询后再清空缓存\n4，配置xml设置flushcacherequired，每次查询都清空LocalCache\n\n##  LruCache实现原理\nLru算法，就是超量时移除最长时间不被使用的对象。LruCache使用有序集合LinkedHashMap来实现。\n在setSize方法时，将内部的keyMap创建为LinkedHashMap，同时重写了removeEldestEntry方法，\n判断如果超过size，则返回最早的元素。\n\n## mybatis ORM框架，用于java 与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射 \n\n## mybatis 加载mapper 有几种方式  \n四种 resource url class package  package优先级最高\n\n##  mybatis 有多少种执行器\n三种 simple reuse batch  默认 simple","source":"_posts/java/mybatis源码解析.md","raw":"---\ndate: 2021-01-09\nstatus: public\ntitle: mybatis源码解析\ntags:\n  - JAVA\n  - mysql\n  - mybatis\n---\n\n摘要:mybatis源码解析\n<!--more-->\n#写在前面-------------------------上次面试的时候问到mybatis源码，自感没看过，有点虚，就去看了源码\n# mybatis源码解析\nmybatis工作原理\n1，XmlConfigBuilder加载property文件获取url password等配置 到Configuration\n2，XmlMapperBuilder加载xml文件获取mapper\n3，返回SqlSessionFactory.opensession  获取 SqlSession 调用Executor执行数据库操作\n4，连接sql，执行mapper，最底层也是通过sql jdbc  SqlSession包含了执行sql所需要的所有方法\n\n\n# mybatis一级二级缓存\n\n1，一级缓存的粒度较小，是与某个SqlSession绑定的，只对该SqlSession的相关查询操作进行缓存，\n不同SqlSession实例之间相互不影响，缓存为使用本地内存实现；mybatis的一级缓存是默认开启的。LocalCache\n默认开启不用配置 ；xml setting 配置为localCacheScope 为STATEMENT 则关闭一级缓存\n\n2，二级缓存是一种全局缓存，是由所有SqlSession实例所共享的，即不同SqlSession实例查询时产生的缓存，对其他SqlSession实例可见。\nmybatis默认没有开启二级缓存，二级缓存支持在配置中自定义底层所用的缓存实现，包括使用本地内存和分布式缓存。\n\n3，二级缓存是基于namespace的，即作用域为mapper，故需要在每个mapper中配置自身所使用的二级缓存实现以及缓存策略。\n同时由于二级缓存是基于namespace的，所以不同namespace之间的相互不影响的，如一个namespace使用的本地内存，\n另外一个namespace使用的是分布式缓存，如果不同namespace对同一张数据表的数据进行了操作，则可能会存在数据不一致问题。\n\n## SESSION级别\n1,对该SqlSession实例发起的查询操作进行缓存，即由同一SqlSession实例发起的多次相同（SQL和SQL的参数值都相同）的查询操作，\n第一次是查询数据库，后续则查询缓存；但是如果另外一个SqlSession实例进行相同的查询操作，则需要进行数据库查询。\n2,针对更新操作，如果是该SqlSession自身进行了更新操作，则该SqlSession对应的一级缓存会被清空；\n但是如果是其他SqlSession实例进行了更新操作，则此更新操作对该SqlSession不可见。\n所以该SqlSession的缓存数据是过期失效数据，所以SqlSession实例的生命周期不能过长，否则可能出现数据不一致现象。\n## STATEMENT级别\n该级别是指缓存只针对当前执行的查询语句有效，故每次语句执行完之后都会清空缓存，其实是相当于没有缓存，\n即该sqlSession实例下次调用相同的SQL语句和相同参数值时，由于上一次语句执行后，缓存被清空了，故需要继续查询数据库\n\n## 怎么才能每次都去数据库查询\n配置xml文件flushcacherequired\n\n## 什么时候会清理缓存\n1，SqlSession内执行更新操作，包括insert/update/delete，都通过PerpetualCache的clear方法清空localCache\n2，执行commit/rollback时也会清空缓存\n3，配置中设置localCacheScope为STATEMENT，执行完查询后再清空缓存\n4，配置xml设置flushcacherequired，每次查询都清空LocalCache\n\n##  LruCache实现原理\nLru算法，就是超量时移除最长时间不被使用的对象。LruCache使用有序集合LinkedHashMap来实现。\n在setSize方法时，将内部的keyMap创建为LinkedHashMap，同时重写了removeEldestEntry方法，\n判断如果超过size，则返回最早的元素。\n\n## mybatis ORM框架，用于java 与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射 \n\n## mybatis 加载mapper 有几种方式  \n四种 resource url class package  package优先级最高\n\n##  mybatis 有多少种执行器\n三种 simple reuse batch  默认 simple","slug":"java/mybatis源码解析","published":1,"updated":"2025-05-16T04:25:25.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jst001oskqr8mq6emro","content":"<p>摘要:mybatis源码解析</p>\n<span id=\"more\"></span>\n<p>#写在前面————————-上次面试的时候问到mybatis源码，自感没看过，有点虚，就去看了源码</p>\n<h1 id=\"mybatis源码解析\"><a href=\"#mybatis源码解析\" class=\"headerlink\" title=\"mybatis源码解析\"></a>mybatis源码解析</h1><p>mybatis工作原理<br>1，XmlConfigBuilder加载property文件获取url password等配置 到Configuration<br>2，XmlMapperBuilder加载xml文件获取mapper<br>3，返回SqlSessionFactory.opensession  获取 SqlSession 调用Executor执行数据库操作<br>4，连接sql，执行mapper，最底层也是通过sql jdbc  SqlSession包含了执行sql所需要的所有方法</p>\n<h1 id=\"mybatis一级二级缓存\"><a href=\"#mybatis一级二级缓存\" class=\"headerlink\" title=\"mybatis一级二级缓存\"></a>mybatis一级二级缓存</h1><p>1，一级缓存的粒度较小，是与某个SqlSession绑定的，只对该SqlSession的相关查询操作进行缓存，<br>不同SqlSession实例之间相互不影响，缓存为使用本地内存实现；mybatis的一级缓存是默认开启的。LocalCache<br>默认开启不用配置 ；xml setting 配置为localCacheScope 为STATEMENT 则关闭一级缓存</p>\n<p>2，二级缓存是一种全局缓存，是由所有SqlSession实例所共享的，即不同SqlSession实例查询时产生的缓存，对其他SqlSession实例可见。<br>mybatis默认没有开启二级缓存，二级缓存支持在配置中自定义底层所用的缓存实现，包括使用本地内存和分布式缓存。</p>\n<p>3，二级缓存是基于namespace的，即作用域为mapper，故需要在每个mapper中配置自身所使用的二级缓存实现以及缓存策略。<br>同时由于二级缓存是基于namespace的，所以不同namespace之间的相互不影响的，如一个namespace使用的本地内存，<br>另外一个namespace使用的是分布式缓存，如果不同namespace对同一张数据表的数据进行了操作，则可能会存在数据不一致问题。</p>\n<h2 id=\"SESSION级别\"><a href=\"#SESSION级别\" class=\"headerlink\" title=\"SESSION级别\"></a>SESSION级别</h2><p>1,对该SqlSession实例发起的查询操作进行缓存，即由同一SqlSession实例发起的多次相同（SQL和SQL的参数值都相同）的查询操作，<br>第一次是查询数据库，后续则查询缓存；但是如果另外一个SqlSession实例进行相同的查询操作，则需要进行数据库查询。<br>2,针对更新操作，如果是该SqlSession自身进行了更新操作，则该SqlSession对应的一级缓存会被清空；<br>但是如果是其他SqlSession实例进行了更新操作，则此更新操作对该SqlSession不可见。<br>所以该SqlSession的缓存数据是过期失效数据，所以SqlSession实例的生命周期不能过长，否则可能出现数据不一致现象。</p>\n<h2 id=\"STATEMENT级别\"><a href=\"#STATEMENT级别\" class=\"headerlink\" title=\"STATEMENT级别\"></a>STATEMENT级别</h2><p>该级别是指缓存只针对当前执行的查询语句有效，故每次语句执行完之后都会清空缓存，其实是相当于没有缓存，<br>即该sqlSession实例下次调用相同的SQL语句和相同参数值时，由于上一次语句执行后，缓存被清空了，故需要继续查询数据库</p>\n<h2 id=\"怎么才能每次都去数据库查询\"><a href=\"#怎么才能每次都去数据库查询\" class=\"headerlink\" title=\"怎么才能每次都去数据库查询\"></a>怎么才能每次都去数据库查询</h2><p>配置xml文件flushcacherequired</p>\n<h2 id=\"什么时候会清理缓存\"><a href=\"#什么时候会清理缓存\" class=\"headerlink\" title=\"什么时候会清理缓存\"></a>什么时候会清理缓存</h2><p>1，SqlSession内执行更新操作，包括insert/update/delete，都通过PerpetualCache的clear方法清空localCache<br>2，执行commit/rollback时也会清空缓存<br>3，配置中设置localCacheScope为STATEMENT，执行完查询后再清空缓存<br>4，配置xml设置flushcacherequired，每次查询都清空LocalCache</p>\n<h2 id=\"LruCache实现原理\"><a href=\"#LruCache实现原理\" class=\"headerlink\" title=\"LruCache实现原理\"></a>LruCache实现原理</h2><p>Lru算法，就是超量时移除最长时间不被使用的对象。LruCache使用有序集合LinkedHashMap来实现。<br>在setSize方法时，将内部的keyMap创建为LinkedHashMap，同时重写了removeEldestEntry方法，<br>判断如果超过size，则返回最早的元素。</p>\n<h2 id=\"mybatis-ORM框架，用于java-与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射\"><a href=\"#mybatis-ORM框架，用于java-与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射\" class=\"headerlink\" title=\"mybatis ORM框架，用于java 与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射\"></a>mybatis ORM框架，用于java 与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射</h2><h2 id=\"mybatis-加载mapper-有几种方式\"><a href=\"#mybatis-加载mapper-有几种方式\" class=\"headerlink\" title=\"mybatis 加载mapper 有几种方式\"></a>mybatis 加载mapper 有几种方式</h2><p>四种 resource url class package  package优先级最高</p>\n<h2 id=\"mybatis-有多少种执行器\"><a href=\"#mybatis-有多少种执行器\" class=\"headerlink\" title=\"mybatis 有多少种执行器\"></a>mybatis 有多少种执行器</h2><p>三种 simple reuse batch  默认 simple</p>\n","site":{"data":{}},"excerpt":"<p>摘要:mybatis源码解析</p>","more":"<p>#写在前面————————-上次面试的时候问到mybatis源码，自感没看过，有点虚，就去看了源码</p>\n<h1 id=\"mybatis源码解析\"><a href=\"#mybatis源码解析\" class=\"headerlink\" title=\"mybatis源码解析\"></a>mybatis源码解析</h1><p>mybatis工作原理<br>1，XmlConfigBuilder加载property文件获取url password等配置 到Configuration<br>2，XmlMapperBuilder加载xml文件获取mapper<br>3，返回SqlSessionFactory.opensession  获取 SqlSession 调用Executor执行数据库操作<br>4，连接sql，执行mapper，最底层也是通过sql jdbc  SqlSession包含了执行sql所需要的所有方法</p>\n<h1 id=\"mybatis一级二级缓存\"><a href=\"#mybatis一级二级缓存\" class=\"headerlink\" title=\"mybatis一级二级缓存\"></a>mybatis一级二级缓存</h1><p>1，一级缓存的粒度较小，是与某个SqlSession绑定的，只对该SqlSession的相关查询操作进行缓存，<br>不同SqlSession实例之间相互不影响，缓存为使用本地内存实现；mybatis的一级缓存是默认开启的。LocalCache<br>默认开启不用配置 ；xml setting 配置为localCacheScope 为STATEMENT 则关闭一级缓存</p>\n<p>2，二级缓存是一种全局缓存，是由所有SqlSession实例所共享的，即不同SqlSession实例查询时产生的缓存，对其他SqlSession实例可见。<br>mybatis默认没有开启二级缓存，二级缓存支持在配置中自定义底层所用的缓存实现，包括使用本地内存和分布式缓存。</p>\n<p>3，二级缓存是基于namespace的，即作用域为mapper，故需要在每个mapper中配置自身所使用的二级缓存实现以及缓存策略。<br>同时由于二级缓存是基于namespace的，所以不同namespace之间的相互不影响的，如一个namespace使用的本地内存，<br>另外一个namespace使用的是分布式缓存，如果不同namespace对同一张数据表的数据进行了操作，则可能会存在数据不一致问题。</p>\n<h2 id=\"SESSION级别\"><a href=\"#SESSION级别\" class=\"headerlink\" title=\"SESSION级别\"></a>SESSION级别</h2><p>1,对该SqlSession实例发起的查询操作进行缓存，即由同一SqlSession实例发起的多次相同（SQL和SQL的参数值都相同）的查询操作，<br>第一次是查询数据库，后续则查询缓存；但是如果另外一个SqlSession实例进行相同的查询操作，则需要进行数据库查询。<br>2,针对更新操作，如果是该SqlSession自身进行了更新操作，则该SqlSession对应的一级缓存会被清空；<br>但是如果是其他SqlSession实例进行了更新操作，则此更新操作对该SqlSession不可见。<br>所以该SqlSession的缓存数据是过期失效数据，所以SqlSession实例的生命周期不能过长，否则可能出现数据不一致现象。</p>\n<h2 id=\"STATEMENT级别\"><a href=\"#STATEMENT级别\" class=\"headerlink\" title=\"STATEMENT级别\"></a>STATEMENT级别</h2><p>该级别是指缓存只针对当前执行的查询语句有效，故每次语句执行完之后都会清空缓存，其实是相当于没有缓存，<br>即该sqlSession实例下次调用相同的SQL语句和相同参数值时，由于上一次语句执行后，缓存被清空了，故需要继续查询数据库</p>\n<h2 id=\"怎么才能每次都去数据库查询\"><a href=\"#怎么才能每次都去数据库查询\" class=\"headerlink\" title=\"怎么才能每次都去数据库查询\"></a>怎么才能每次都去数据库查询</h2><p>配置xml文件flushcacherequired</p>\n<h2 id=\"什么时候会清理缓存\"><a href=\"#什么时候会清理缓存\" class=\"headerlink\" title=\"什么时候会清理缓存\"></a>什么时候会清理缓存</h2><p>1，SqlSession内执行更新操作，包括insert/update/delete，都通过PerpetualCache的clear方法清空localCache<br>2，执行commit/rollback时也会清空缓存<br>3，配置中设置localCacheScope为STATEMENT，执行完查询后再清空缓存<br>4，配置xml设置flushcacherequired，每次查询都清空LocalCache</p>\n<h2 id=\"LruCache实现原理\"><a href=\"#LruCache实现原理\" class=\"headerlink\" title=\"LruCache实现原理\"></a>LruCache实现原理</h2><p>Lru算法，就是超量时移除最长时间不被使用的对象。LruCache使用有序集合LinkedHashMap来实现。<br>在setSize方法时，将内部的keyMap创建为LinkedHashMap，同时重写了removeEldestEntry方法，<br>判断如果超过size，则返回最早的元素。</p>\n<h2 id=\"mybatis-ORM框架，用于java-与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射\"><a href=\"#mybatis-ORM框架，用于java-与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射\" class=\"headerlink\" title=\"mybatis ORM框架，用于java 与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射\"></a>mybatis ORM框架，用于java 与mysql直接的一个转换，之前java要连接sql的话是写JDBC，现在是mybatis直接转换映射</h2><h2 id=\"mybatis-加载mapper-有几种方式\"><a href=\"#mybatis-加载mapper-有几种方式\" class=\"headerlink\" title=\"mybatis 加载mapper 有几种方式\"></a>mybatis 加载mapper 有几种方式</h2><p>四种 resource url class package  package优先级最高</p>\n<h2 id=\"mybatis-有多少种执行器\"><a href=\"#mybatis-有多少种执行器\" class=\"headerlink\" title=\"mybatis 有多少种执行器\"></a>mybatis 有多少种执行器</h2><p>三种 simple reuse batch  默认 simple</p>"},{"date":"2021-01-06T16:00:00.000Z","status":"public","title":"java面试总结","_content":"\n摘要:java面试总结\n<!--more-->\n# dubbo底层rpc 原理\nip 和端口 通过socket连接\n# mysql主从原理 binlog ->relaylog\n# 动态代理跟静态代理啥区别\n静态代理是直接代理，就是定义一个接口，然后A类实现它，然后另外B类也实现这个接口，B类里面有A类实现每个方法，这样实现的时候B类就可以代替A类，这就叫静态代理\nJDK动态代理是通过invocationhandle实现的 实现一个类实现invocationhandle 实现invoce方法，然后强制转换成对应Proxy类，就不用实现接口的每个方法\nCGlib动态代理类是通过MethodInterceptor  实现的，实现一个类实现MethodInterceptor ，实现intercept 方法， 然后强制转换成newProxy类\n\n# cglib动态代理跟jdk动态代理啥区别\n接口走jdk动态代理，其他走cjlib\n# 怎么实现动态代理，原理\n# rebbitmq   exchange 分几类\n# 有没看mybatis源码 mybatis怎么映射到dao的\n# 线程状态，怎么变成死锁\n# synchronized和reentrantlock 底层原理\n# synchronized除了cas还有锁升级 \n# synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\n# reentrantlock 除了CAS  还有AQS \n# spring 单例模式 工厂模式  观察者模式\n# 观察者模式主要用于什么地方\n# spring事务是属于哪里的，代码怎么实现\n# nio原理\n# netty线程模式\n# dubbo使用的时候遇到过什么问题\n# mysql 建表的时候要注意什么\n# mysql中 使用explain时应注意那些字段\n# 热部署 冷部署\n# docker\n# k8s其他功能\n# #引用的分类  \n## 强引用   jvm 情愿爆出OOM 也不回收的对象\n## 弱引用\tjvm查到的话就会回收 不管内存够不够 \n## 软引用\tJvm 如果内存不够用的时候就会回收\n## 虚引用\tjvm看到就回收\n\n# 字节面试一面总结\n# 算法题 \n在一个字符串S内查找一个子串s的出现位置。\npublic static int indexOf(char[] chars, char[] sub) {\nreturn -1;\n}\n# 如何保证RabbitMQ不被重复消费？\n# 如何保证RabbitMQ消息的可靠传输？\n# activeMQ\n# dubbo 与springcloud 区别\n# zookeeper 单节点还是多节点 如果挂了怎么办\n# zk集群是怎么部署的\n# 并发锁 分布式锁\n# 支付宝微信调用过程中怎么确保安全\n# 微信支付宝是怎么做订单的拦截消费\n# mysql 索引的实现原理\n# mysql 节点存储的是什么 非叶子节点 和叶子节点\n# 一个节点最大存储 16K\n# 16k是相对于什么来说的\n# Username 查询 % 最左前缀原则 为什么\n\n# 浩鲸科技一面\n## dubbo重试机制\n1，Dubbo支持多种失败重试机制：\nFailover Cluster - 失败自动切换\nFailfast Cluster - 快速失败\nFailsafe Cluster - 失败安全\nFailback Cluster - 失败自动恢复\nForking Cluster - 并行调用多个服务提供者\nBroadcast - 广播轮询调用所有Provider\n\n\n## zk服务注册发现过程，如果一个断了，怎么通知到对方\n这里写的非常清楚[zk服务注册发现过程](https://blog.csdn.net/zyhlwzy/article/details/101847565)\n1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode\n2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示\n3，具体流程\n1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。\n服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；\n2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，\n异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；\n4，zk的服务注册和发现流程\n1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，\n即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），比如注册一个用户注册服务（user/register）:\n2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，\n获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，比如发现用户注册服务（user/register）并调用。\n3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，\n因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，\nZookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。\n\n## zk节点类型\n1.持久节点(PERSISTENT)\n持久节点，创建后一直存在，直到主动删除此节点。\n2.持久顺序节点(PERSISTENT_SEQUENTIAL)\n持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。\n3.临时节点(EPHEMERAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。\n4.顺序临时节点(EPHEMERAL_SEQUENTIAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。\n\n## zk还可以用来做什么，具体怎么实现\n1,分布式锁，具体实现方式\n1）znode 可以被监控。\n节点数据修改、子节点变化、节点删除等。\n一旦变化可以通知设置监控的客户端。\n通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。\n2）分布式锁步骤。\n注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器\n\t1. 父节点持久节点/lock\n\t2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推\n\t3. 获取/lock下所有子节点getChildren(\"/lock\")方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，\n\t获得通知后重复该步骤。\n\t4. 执行代码。完成后释放锁。\n4）使用zookeeper + curator，完成分布式锁。\n\n## redis与mysql 怎么做到缓存一致性\n1、MySQL binlog增量发布订阅消费+消息队列+增量数据更新到redis\n\t1）读请求走Redis：热数据基本都在Redis\n\t2）写请求走MySQL: 增删改都操作MySQL\n\t3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis\n2、Redis更新\n\t1）数据操作主要分为两块：\n\t一个是全量(将全部数据一次写入到redis)\n\t一个是增量（实时更新）\n\t这里说的是增量,指的是mysql的update、insert、delate变更数据。\n\t这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。就无需在从业务线去操作缓存内容\n\t2）每次写数据库的时候都把redis的数据给删掉，读数据库的时候再保存到redis 缓存\n3、延迟双删，一定程度可以解决，就是写数据库之后 睡眠一段时间，然后再删除一次，但是不一定百分百解决问题，而且延迟了主线程\n4，分布式锁，可以解决，并发问题串行化，但是效率低\n5，读锁，写锁可以一定程度优化，读多写少，读读不互斥，写写互斥\n\n## 怎么保证redis 高可用\nredis高并发：主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10万的QPS。\nredis高并发的同时，还需要容纳大量的数据：一主多从，每个实例都容纳了完整的数据，比如redis主就10G的内存量，其实你最多只能容纳10g的数据量。\n如果你的缓存要容纳的数据量很大，达到了几十g，甚至几百g，或者是几t，那你就需要redis集群，而且用redis集群之后，可以提供可能每秒几十万的读写并发。\nredis高可用：如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换。\n## redis 集群是怎么搭建的\n当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。\n如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据;如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。\n开始full resynchronization的时候，master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。\nslave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。\n## 分库分表\njava中主要是用的是Sharding-JDBC分库分表  整合springboot 非常方便\n## 分布式事务是怎么做的seata\n1. 二阶段提交协议 (2PC)\n\t协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。\n\t1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志\n\t2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。\n\t缺点 \n\t1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行\n\t2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。\n\t3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，\n\t但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。\n\t\n2. 三阶段提交协议 (3PC)\n针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。\n三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。\n\t1），为甚需要cancommit\n\t假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。\n\t协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。\n\t协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？\n\t所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。\n\t2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务\n\t因为在precommit阶段已经知道所有节点都同意提交事务了\n3. 基于消息的分布式事务\n\t基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失\n## session与token和cookie区别\n1，session的中文翻译是“会话”，当用户打开某个web应用时，便与web服务器产生一次session\n2，cookie是保存在本地终端的数据。cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器\n3，token的意思是“令牌”，是用户身份的验证方式，最简单的token组成uid\n cookie 和session的区别\n1）、cookie数据存放在客户的浏览器上，session数据放在服务器上。\n2）、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗\n   考虑到安全应当使用session。\n3）、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能\n   考虑到减轻服务器性能方面，应当使用COOKIE。\n4）、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。\n5)、所以个人建议：\n   将登陆信息等重要信息存放为SESSION\n   其他信息如果需要保留，可以放在COOKIE中\n\n\n# shein一面\n## springboot有什么优点 特性\n## mysql 插入一千条一万条语句怎么办\nINSERT INTO \nitems(name,city,price,number,picture) \nVALUES\n('耐克运动鞋','广州',500,1000,'003.jpg'),\n......\n('耐克运动鞋2','广州2',500,1000,'002.jpg');\n\njava代码的话是先用for循环先拼接好，然后再拼接语句insert ，然后再执行代码\n## 慢查询怎么看然后怎么优化  举个栗子\n## ABC 三列组合索引 这个时候 A= B in C =   这个时候会不会走索引\n## 为什么最左前缀只走第一列  最左前缀原理 要清楚存储数据原理 一个节点存储了三个值 代表三个数值\n## mybatis 常用标签 foreach\n## redis 常用指令 lpush  lset\n## rabbitmq 确认机制怎么实现 publisher-confirms\n## elk  (Elasticserarch + Logstash + Kibana)\n## romda 表达式\n分组        Map<String, List<User>> groupBySex = userList.stream().collect(Collectors.groupingBy(User::getSex));\n过滤        List<User> userCommonList = userList.stream().filter(a -> !a.getJobNumber().equals(\"201901\")).collect(Collectors.toList());\n\n## 为什么要使用联合索引\n### 减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\n对于大量数据的表，使用联合索引会大大的减少开销！\n### 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。\n那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。\n所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。\n### 效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,\n假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，\n然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！\n\n\n# 保利一面\n## 提前预警系统问题\n## springboot 注解实现原理\n## zookeeper有什么缺点  AP 和 CP  效率不高\n## dubbo 线程模型\n## dubbo怎么做到负载均衡  loadbalance xml配置文件里面直接配置\n## 四种负载均衡  \n1，随机\n2，轮训\n3，一致性哈希\n4，最少活跃数\n## elk 调用链 就是监听requestid log4j \n## 并发高怎么设计系统\n1，使用缓存redis\n2，线程池\n3，nginx 负载均衡\n4，消息队列\n## redis 过期机制\n1，定时删除 在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。\n2，惰性删除 设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。\n3，定期删除 每隔一段时间，我们就对一些key进行检查，删除里面过期的key。\n\n# 阿里一面\n## 秒杀设计 要考虑什么\n1，前端限流 -按钮只能按一次\n2，后端限流 -利用MQ削锋\n3，后端redis防止超卖\n4，后端mysql限制\n5，限制IP多次请求，缓存到redis里面\n6，\n## java代码如何保证原子性 原子加 原子减   AtomicInteger\n## synchronized和reentrantlock 区别\n## synchronized 可以锁哪些对象，有什么区别\n1，对象 变量  对象锁\n2，代码块  对象锁\n3，类  类锁\n1、对于静态方法，由于此时对象还未生成，所以只能采用类锁；\n2、只要采用类锁，就会拦截所有线程，只能让一个线程访问。\n3、对于对象锁（this），如果是同一个实例，就会按顺序访问，但是如果是不同实例，就可以同时访问。\n4、如果对象锁跟访问的对象没有关系，那么就会都同时访问。\n\n## AtomicInteger 原理  CAS volatile修饰的int值 做成原子加 原子减\n## 垃圾处理GC 调优 -XMX  -XMS  -XMN\n\n\n# 美的一面\n## SPI  dubbo的spi机制\nSPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的接口，\n它可以用来启用框架扩展和替换组件。 SPI的作用就是为这些被扩展的API寻找服务实现。\n@spi 配置它可以扩展\n## java spi \n1，一种扩展机制，JDBC实现的接口就是driver，但是这个接口是扩展出去的，很多接口都会实现的 \n需要在META-INF的配置文件里面去配置对应service 接口\n2，缺点：不能做ioc 和aop 不能获取单独的一个实现类\n\n## ZK集群选举的一个过程\nZab协议\n\n## redis集群 同步原理 rdb aof文件 \n## 哨兵怎么跟redis的节点通信的 master  slave节点\n哨兵会给所有节点发ping指令，然后其他节点会回复pong指令，如果一段时间都没回复，那就是断开了\n## 哨兵选举\n1，配置priority 优先级最高的\n2，选择复制量最大的\n## 主从结构哨兵是否有用，假如一个节点掉了，会到哪里\n## mysql集群是用什么来做 模式是怎么样实现的\n## mysql主节点和从节点是怎么同步的 binlog 和relaylog\n## 如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\n## redis 用于哪些方面  用户信息， 分布式锁， 主从同步缓存数据\n## 分布式锁是怎么实现的\nredis setnx指令 finally里面delete  命令执行   要先判断一下当前线程ID 是不是自己的，如果是自己的那就可以删除，不然不能删除\n## redisson\n## mysql优化  开启慢查询 slow_log 开启  explain 一下，然后把对应不走索引的给查出来\n## mysql 有哪些索引 原理\n普通索引、唯一索引、聚集索引、主键索引、全文索引  B+树\n\n## 索引下推是什么原理\n在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，\n然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。\n在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，\n然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。\n索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。\n\n## mysql 还有其他什么日志吗  undo  redo\n## 分布式事务 二段式 三段线   \n## 最终一致性 跟分布式事务有什么区别 \n## 分布式事务 CAP理论 base理论\n## 多线程编程 线程池 类及构造参数\n## 线程池是怎么工作的\n## 最大线程数 如果队列满了咋办\n## worker队列要怎么设置\n## 如果队列都满了，这个时候你要放到mq队列\n## jvm 内存结构\n## jvm 多大就会放到大内存里面 是一个参数\n## 老年代full GC  G1 CMS GC 过程\n\n# 美的二面\n## dubbo文档\n## MQ对比\n## 数据库事务写成功之后往MQ 里面写\n## 事务中是否需要RPC\n\n\n\n\n\n## 高可用方案 从前端到后端\n前端nginx做负载均衡，redis做查询缓存，mysql集群做负载\n\n1，系统拆分  dubbo 加zk 分布式\n2，Cache(缓存)  读多写少 redis做缓存\n大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。\n3，MQ  把数据库操作先放到MQ 排队执行\n大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内\n4，数据库拆分(分库分表) Sharding-JDBC\n当数据量达到某个阀值时，数据库拆分就会成为一个紧急的需求。一般从业务上进行垂直拆分，如果业务单一，也可从水平上进行拆分。\n5，读写分离\n主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。\n6，ElasticSearch\n7，CDN 加速  把页面资源CDN加速一下\n其中有速度快的路径有慢的路径，如何选择最优路径，把每个角落的请求快速的传递到机房，这就是 CDN 的功能。\n8，HTML 页面静态化\n静态页面部署在 NGNIX 中，收到用户请求，Ngnix 不需要访问 Webapp 即可响应用户，减少应用渲染页面的时间，同时也降低了应用的压力。\n\n# 卓志\n## 微服务的技术选项\n易于部署，各个工程各不影响，分模块部署，负载均衡\n## dubbo注册与发现过程\n服务提供者 容器container 服务调用者 注册中心 counter\n## dubbo负载均衡 几种\nDubbo 提供了4种负载均衡实现，分别是基于权重随机算法的 RandomLoadBalance、基于最少活跃调用数算法的 LeastActiveLoadBalance、\n基于 hash 一致性的 ConsistentHashLoadBalance，以及基于加权轮询算法的 RoundRobinLoadBalance\n## dubbo遇到过什么问题吗？\n1，父子类有相同属性时值丢失 \ndubbo默认采用的是hessian序列化&反序列化方式，JavaDeserializer在获取fileds时，采用了Map去重。\n但是在读取值时，根据serializer的顺序，对于同名字段，子类的该字段值会被赋值两次，总是被父类的值覆盖，导致子类的字段值丢失。\n2，序列化问题复杂对象变成了map\n3，Data length too large \n超过8k   修改 payload的值，将其调大 可以调节到16k\n4，服务调用失败  No provider available\n存在一个或多个Provider服务，但是version或者group不匹配。\n例如Consumer侧申明version=1.0.0，而Provider侧申明version=2.0.0，或者group不匹配，都会出现这个ERROR。\n## dubbo遇到过什么序列化的问题\n## dubbo参数对象如果是object属性 可以传递过去吗\n最近遇到一个问题，B 服务调用 A 服务时，返回值反序列化时，POJO对象变成了Map类型。\n在A服务单独测试的时候一直还原不了，在 B 服务进行测试的时候，跟到反序列化数据时才看到原因。\nA 服务的接口方法返回的结果是一个Object（或 Map<String, Object> 中的 value），\nObject 的具体实现不在 A 服务的 API 包中，因此在 B 服务找不到该返回值真正的实现类，\n在 B 服务调用接口返回结果反序列化找不到具体的类型时，就会以 Map 类型进行实例化。\n\n### Java序列化：\nJava序列化会把要序列化的对象类的元数据和业务数据全部序列化为字节流，而且是把整个继承关系上的东西全部序列化了。\n它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。\n但是由于确实是序列化了所有内容，所以可以说什么都可以传输，因此也更可用和可靠。\n### hession序列化：\n它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，\nhessian会序列化成I 1这样的流，I表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，\nhessian把对象所有的属性当成一个Map来序列化，产生类似M className propertyName1 I 1 propertyName S stringValue\n（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。而在序列化过程中，如果一个对象之前出现过，\nhessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。\n这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），\n而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。而且同时因为并没有深入到实现内部去进行序列化，\n所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。\n## zk特点 CAP 理论  CP  consist\n## zk集群挂了会怎么办会投票 【myid ，zid】\n## MQ三大特性 解耦异步削峰\n## MQ 消息丢失\n## rebbitMQ持久化是怎么持久化\n将queue的持久化标识durable设置为true,则代表是一个持久的队列\n## redis分布式锁 lua脚本\nredisson \n## redis如何保证原子性\n单线程的\n## 既然是单线程的，如何做到异步和非阻塞的\n要明白他的线程模型是IO多路复用模型 主要核心是select channel  bufuer类 就是一个线程负责接收连接，其他线程负责解决对应的事务\n## redis 可以用来做什么 \n1，缓存  2，分布式锁  3，zset 排名 4，索引 \n## redis 秒杀的功能是怎么做的\n1，限流和降级 按钮置灰 nginx限流  2，队列削峰MQ  3，服务层分包部署  4，查询的时候查询redis 缓存\n## 多线程是怎么用的\n多线程newcache 保证线程无线 CPU消耗比较大  newfixed 线程数固定 但是队列无线，内存不友好\n## 有无遇到OOM的问题\n## jvm垃圾回收机制 标记计数算法 可达性算法 标记清理 标记整理 复制算法\n## 几个垃圾收集器  CMS标记清理  G1\n\n## 服务挂了的话怎么办 linux 怎么去查服务器日志\nlinux日志文件说明\n/var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一\n/var/log/secure 与安全相关的日志信息\n/var/log/maillog 与邮件相关的日志信息\n/var/log/cron 与定时任务相关的日志信息\n/var/log/spooler 与UUCP和news设备相关的日志信息\n/var/log/boot.log 守护进程启动和停止相关的日志消息\n/var/log/wtmp 该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件\n\n### Java应用程序的问题：发生OOM导致进程Crash\n最常见的是发生堆内存异常“java.lang.OutOfMemoryError: Java heap space”，排查步骤如下：\nStep1: 查看JVM参数 -XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath=*/java.hprof；\nStep2: 根据HeapDumpPath指定的路径查看是否产生dump文件；\nStep3: 若存在dump文件，使用Jhat、VisualVM等工具分析即可；\n### JVM出错：JVM或JDK自身的Bug导致进程Crash\n当JVM出现致命错误时，会生成一个错误文件 hs_err_pid.log，其中包括了导致jvm crash的重要信息，\n可以通过分析该文件定位到导致crash的根源，从而改善以保证系统稳定。当出现crash时，该文件默认会生成到工作目录下，\n然而可以通过jvm参数-XX:ErrorFile指定生成路径。\n### 被操作系统OOM-Killer\nStep1: 查看操作系统日志：sudo grep –color “java” /var/log/messages，确定Java进程是否被操作系统Kill；\nStep2: 若被操作系统Kill，执行dmesg命令查看系统各进程资源占用情况，明确Java占用内存是否合理，\n以及是否有其它进程不合理的占用了大量内存空间；\n\n## 数据库横表与纵表的区分  没什么卵用 都是到横表的 \n 横表就是普通的建表方式，如一个表结构为： 主键、字段1、字段2、字段3。。。 如果变成纵表后，\n 则表结构为： 主键、字段代码、字段值。 而字段代码则为字段1、字段2、字段3。\n## TIDB 最新数据库 \nmysql的一个封装，加快查询效率\n## tcp的头标记\n## rpc 主要框架及对比  dubbo  grpc  thrift dubbox  motan\ngrpc是一个轻量级的java RPC框架。它支持服务注册和发现。\ndubbox有比价完善的服务治理模型，其包含ZK注册中心，服务监控等，可以很方便的为我们服务。 \nmotan新浪微博开源的RPC框架\ngrpc是Google出品，使用了PB协议，但是由于它出现的比较晚，还不怎么成熟，而且采用http协议，非常适合现在的微服务，\n\t不过性能上差了许多，而且像服务治理与监控都需要额外的开发工作，所以放弃grpc。 \nthrift和grpc一样，性能优越，但是开发难度相比较于dubbox和motan也是高了一点点，\n\t需要编写proto文件（其实对于程序员来说这算不上难度）。像服务治理与监控也是需要额外的开发工作。 \ndubbo比较老了，直接弃用。 \ndubbox和后来的motan都比较适合我们的团队。dubbox后来经过当当的开发，引入了rest风格的http协议，\n并且还支持kryo/fst/dubbo/thrift等其他协议，而且其他团队也在使用dubbo，集成方便，服务治理监控功能齐全，所以最终采用dubbox。\n其实我个人而言还是喜欢thrift，毕竟性能优越，在大型分布式系统中，哪怕一点点性能提升累计在一起也是很可观的。\n不过再具体选型的过程中还要结合团队目前的状况和团队其他开发人员的接受程度进行取舍。\n\n\n# 易工品\n## springcloud alibaba 跟springcloud的区别\n注册中心不一样 nacos 集成了Ribbon eureka\n## 最新关注技术点 tidb 优点\n## 做的业务点\n## zk的业务场景 zk的特点\n## rocketmq 卡夫卡 和 rabbitmq的比较\n吞吐量 ：卡夫卡》rocketmq》rabbitmq\n接收的模式：卡夫卡拉取：rabbitmq 推拉\n## 所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\n## 财务金额用的是什么类型存储，怎么去做取整的操作\n## mysql的变更通知\n## 单元测试是怎么做的\nJunit框架，在大多数java的开发环境中已经集成，\n## 生产故障\n## 图数据库和时序数据库\n\n\n## 承担什么责任  做一个项目碰到什么难题  \n电商  支付模块 \n\n\n奥悦家 \n用户支付同步天问接口回调很慢的话怎么办  ，然后会导致用户重复缴费两次\n1，先异步返回，然后给数据库设置一个在缴费中的标志位，返回给业主说正在缴费中\n2，起一个线程去不断查询天问系统接口，然后接收回调接口的返回\n3，在缴费之后就先用redis把查询的费用设置为0，就是说先去redis 查询费用，如果没有的话就去天问查，如果有的话就看多少钱\n使用dubbo中遇到什么问题\n序列化的问题----复杂对象的时候会 变成map\n服务调用失败  No provider available-----版本号不一致\nData length too large 超过8k-------修改 payload的值，将其调大 可以调节到16k\n\n奥悦团购  超卖库存的问题 秒杀\n1前端\n面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】\n　　A：扩容\n　　加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。\n　　B：静态化\n　　将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。\n　　C：限流\n　　一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。\n　　或者活动入口的时候增加游戏或者问题环节进行消峰操作。\n　　\n2后端\nA：将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，\n并且由于Redis的写性能和读性能都远高于MySQL，\n这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。\nB：引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。\n当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。\nC：利用Java的锁机制CAS来实现减库存操作\nD：写sql乐观锁的概念，增加了版本号，\n//1.查询出商品信息\nselect stock, version from t_goods where id=1;\n//2.根据商品信息生成订单\ninsert into t_orders (id,goods_id) values (null,1);\n//3.修改商品库存\nupdate t_goods set stock=stock-1, version = version+1 where id=1, version=version;\n当A线程来更新数量的时候先看版本号有没有动，如果已经变了那就不改并且返回，如果没变，这个时候就更改库存，并且把版本号加一\nE：分布式锁\nsetnx指令，如果能拿到对应标志位的锁的话，那就成功获取锁，并且更改库存，如果不行的话，那就直接返回抢购失败\n\n\n\n# 中移\n## maven调用链依赖重复依赖是怎么解决的\n当一个项目中出现重复的依赖包时，maven 2.0.9之后的版本会用如下的规则来决定使用哪一个版本的包：\n最短路径原则\n比如有如下两个依赖关系：\nA -> B -> C -> D(V1)\nF -> G -> D(V2)\n这个时候项目中就出现了两个版本的D，这时maven会采用最短路径原则，选择V2版本的D，因为V1版本的D是由A包间接依赖的，整个依赖路径长度为3，而V2版本的D是由F包间接依赖的，整个依赖路径长度为2。\n声明优先原则\n假设有如下两个依赖关系：\nA -> B -> D(V1)\nF -> G -> D(V2)\n这个时候因为两个版本的D的依赖路径都是一样长，最短路径原则就失效了。这个时候Maven的解决方案是：\n按照依赖包在pom.xml中声明的先后顺序，优先选择先声明的包\n## ","source":"_posts/java/java面试总结.md","raw":"---\ndate: 2021-01-07\nstatus: public\ntitle: java面试总结\ntags:\n  - JAVA\n---\n\n摘要:java面试总结\n<!--more-->\n# dubbo底层rpc 原理\nip 和端口 通过socket连接\n# mysql主从原理 binlog ->relaylog\n# 动态代理跟静态代理啥区别\n静态代理是直接代理，就是定义一个接口，然后A类实现它，然后另外B类也实现这个接口，B类里面有A类实现每个方法，这样实现的时候B类就可以代替A类，这就叫静态代理\nJDK动态代理是通过invocationhandle实现的 实现一个类实现invocationhandle 实现invoce方法，然后强制转换成对应Proxy类，就不用实现接口的每个方法\nCGlib动态代理类是通过MethodInterceptor  实现的，实现一个类实现MethodInterceptor ，实现intercept 方法， 然后强制转换成newProxy类\n\n# cglib动态代理跟jdk动态代理啥区别\n接口走jdk动态代理，其他走cjlib\n# 怎么实现动态代理，原理\n# rebbitmq   exchange 分几类\n# 有没看mybatis源码 mybatis怎么映射到dao的\n# 线程状态，怎么变成死锁\n# synchronized和reentrantlock 底层原理\n# synchronized除了cas还有锁升级 \n# synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\n# reentrantlock 除了CAS  还有AQS \n# spring 单例模式 工厂模式  观察者模式\n# 观察者模式主要用于什么地方\n# spring事务是属于哪里的，代码怎么实现\n# nio原理\n# netty线程模式\n# dubbo使用的时候遇到过什么问题\n# mysql 建表的时候要注意什么\n# mysql中 使用explain时应注意那些字段\n# 热部署 冷部署\n# docker\n# k8s其他功能\n# #引用的分类  \n## 强引用   jvm 情愿爆出OOM 也不回收的对象\n## 弱引用\tjvm查到的话就会回收 不管内存够不够 \n## 软引用\tJvm 如果内存不够用的时候就会回收\n## 虚引用\tjvm看到就回收\n\n# 字节面试一面总结\n# 算法题 \n在一个字符串S内查找一个子串s的出现位置。\npublic static int indexOf(char[] chars, char[] sub) {\nreturn -1;\n}\n# 如何保证RabbitMQ不被重复消费？\n# 如何保证RabbitMQ消息的可靠传输？\n# activeMQ\n# dubbo 与springcloud 区别\n# zookeeper 单节点还是多节点 如果挂了怎么办\n# zk集群是怎么部署的\n# 并发锁 分布式锁\n# 支付宝微信调用过程中怎么确保安全\n# 微信支付宝是怎么做订单的拦截消费\n# mysql 索引的实现原理\n# mysql 节点存储的是什么 非叶子节点 和叶子节点\n# 一个节点最大存储 16K\n# 16k是相对于什么来说的\n# Username 查询 % 最左前缀原则 为什么\n\n# 浩鲸科技一面\n## dubbo重试机制\n1，Dubbo支持多种失败重试机制：\nFailover Cluster - 失败自动切换\nFailfast Cluster - 快速失败\nFailsafe Cluster - 失败安全\nFailback Cluster - 失败自动恢复\nForking Cluster - 并行调用多个服务提供者\nBroadcast - 广播轮询调用所有Provider\n\n\n## zk服务注册发现过程，如果一个断了，怎么通知到对方\n这里写的非常清楚[zk服务注册发现过程](https://blog.csdn.net/zyhlwzy/article/details/101847565)\n1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode\n2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示\n3，具体流程\n1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。\n服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；\n2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，\n异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；\n4，zk的服务注册和发现流程\n1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，\n即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），比如注册一个用户注册服务（user/register）:\n2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，\n获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，比如发现用户注册服务（user/register）并调用。\n3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，\n因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，\nZookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。\n\n## zk节点类型\n1.持久节点(PERSISTENT)\n持久节点，创建后一直存在，直到主动删除此节点。\n2.持久顺序节点(PERSISTENT_SEQUENTIAL)\n持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。\n3.临时节点(EPHEMERAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。\n4.顺序临时节点(EPHEMERAL_SEQUENTIAL)\n临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。\n\n## zk还可以用来做什么，具体怎么实现\n1,分布式锁，具体实现方式\n1）znode 可以被监控。\n节点数据修改、子节点变化、节点删除等。\n一旦变化可以通知设置监控的客户端。\n通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。\n2）分布式锁步骤。\n注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器\n\t1. 父节点持久节点/lock\n\t2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推\n\t3. 获取/lock下所有子节点getChildren(\"/lock\")方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，\n\t获得通知后重复该步骤。\n\t4. 执行代码。完成后释放锁。\n4）使用zookeeper + curator，完成分布式锁。\n\n## redis与mysql 怎么做到缓存一致性\n1、MySQL binlog增量发布订阅消费+消息队列+增量数据更新到redis\n\t1）读请求走Redis：热数据基本都在Redis\n\t2）写请求走MySQL: 增删改都操作MySQL\n\t3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis\n2、Redis更新\n\t1）数据操作主要分为两块：\n\t一个是全量(将全部数据一次写入到redis)\n\t一个是增量（实时更新）\n\t这里说的是增量,指的是mysql的update、insert、delate变更数据。\n\t这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。就无需在从业务线去操作缓存内容\n\t2）每次写数据库的时候都把redis的数据给删掉，读数据库的时候再保存到redis 缓存\n3、延迟双删，一定程度可以解决，就是写数据库之后 睡眠一段时间，然后再删除一次，但是不一定百分百解决问题，而且延迟了主线程\n4，分布式锁，可以解决，并发问题串行化，但是效率低\n5，读锁，写锁可以一定程度优化，读多写少，读读不互斥，写写互斥\n\n## 怎么保证redis 高可用\nredis高并发：主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10万的QPS。\nredis高并发的同时，还需要容纳大量的数据：一主多从，每个实例都容纳了完整的数据，比如redis主就10G的内存量，其实你最多只能容纳10g的数据量。\n如果你的缓存要容纳的数据量很大，达到了几十g，甚至几百g，或者是几t，那你就需要redis集群，而且用redis集群之后，可以提供可能每秒几十万的读写并发。\nredis高可用：如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换。\n## redis 集群是怎么搭建的\n当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。\n如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据;如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。\n开始full resynchronization的时候，master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。\nslave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。\n## 分库分表\njava中主要是用的是Sharding-JDBC分库分表  整合springboot 非常方便\n## 分布式事务是怎么做的seata\n1. 二阶段提交协议 (2PC)\n\t协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。\n\t1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志\n\t2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。\n\t缺点 \n\t1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行\n\t2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。\n\t3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，\n\t但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。\n\t\n2. 三阶段提交协议 (3PC)\n针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。\n三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。\n\t1），为甚需要cancommit\n\t假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。\n\t协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。\n\t协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？\n\t所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。\n\t2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务\n\t因为在precommit阶段已经知道所有节点都同意提交事务了\n3. 基于消息的分布式事务\n\t基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失\n## session与token和cookie区别\n1，session的中文翻译是“会话”，当用户打开某个web应用时，便与web服务器产生一次session\n2，cookie是保存在本地终端的数据。cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器\n3，token的意思是“令牌”，是用户身份的验证方式，最简单的token组成uid\n cookie 和session的区别\n1）、cookie数据存放在客户的浏览器上，session数据放在服务器上。\n2）、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗\n   考虑到安全应当使用session。\n3）、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能\n   考虑到减轻服务器性能方面，应当使用COOKIE。\n4）、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。\n5)、所以个人建议：\n   将登陆信息等重要信息存放为SESSION\n   其他信息如果需要保留，可以放在COOKIE中\n\n\n# shein一面\n## springboot有什么优点 特性\n## mysql 插入一千条一万条语句怎么办\nINSERT INTO \nitems(name,city,price,number,picture) \nVALUES\n('耐克运动鞋','广州',500,1000,'003.jpg'),\n......\n('耐克运动鞋2','广州2',500,1000,'002.jpg');\n\njava代码的话是先用for循环先拼接好，然后再拼接语句insert ，然后再执行代码\n## 慢查询怎么看然后怎么优化  举个栗子\n## ABC 三列组合索引 这个时候 A= B in C =   这个时候会不会走索引\n## 为什么最左前缀只走第一列  最左前缀原理 要清楚存储数据原理 一个节点存储了三个值 代表三个数值\n## mybatis 常用标签 foreach\n## redis 常用指令 lpush  lset\n## rabbitmq 确认机制怎么实现 publisher-confirms\n## elk  (Elasticserarch + Logstash + Kibana)\n## romda 表达式\n分组        Map<String, List<User>> groupBySex = userList.stream().collect(Collectors.groupingBy(User::getSex));\n过滤        List<User> userCommonList = userList.stream().filter(a -> !a.getJobNumber().equals(\"201901\")).collect(Collectors.toList());\n\n## 为什么要使用联合索引\n### 减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\n对于大量数据的表，使用联合索引会大大的减少开销！\n### 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。\n那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。\n所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。\n### 效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,\n假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，\n然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！\n\n\n# 保利一面\n## 提前预警系统问题\n## springboot 注解实现原理\n## zookeeper有什么缺点  AP 和 CP  效率不高\n## dubbo 线程模型\n## dubbo怎么做到负载均衡  loadbalance xml配置文件里面直接配置\n## 四种负载均衡  \n1，随机\n2，轮训\n3，一致性哈希\n4，最少活跃数\n## elk 调用链 就是监听requestid log4j \n## 并发高怎么设计系统\n1，使用缓存redis\n2，线程池\n3，nginx 负载均衡\n4，消息队列\n## redis 过期机制\n1，定时删除 在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。\n2，惰性删除 设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。\n3，定期删除 每隔一段时间，我们就对一些key进行检查，删除里面过期的key。\n\n# 阿里一面\n## 秒杀设计 要考虑什么\n1，前端限流 -按钮只能按一次\n2，后端限流 -利用MQ削锋\n3，后端redis防止超卖\n4，后端mysql限制\n5，限制IP多次请求，缓存到redis里面\n6，\n## java代码如何保证原子性 原子加 原子减   AtomicInteger\n## synchronized和reentrantlock 区别\n## synchronized 可以锁哪些对象，有什么区别\n1，对象 变量  对象锁\n2，代码块  对象锁\n3，类  类锁\n1、对于静态方法，由于此时对象还未生成，所以只能采用类锁；\n2、只要采用类锁，就会拦截所有线程，只能让一个线程访问。\n3、对于对象锁（this），如果是同一个实例，就会按顺序访问，但是如果是不同实例，就可以同时访问。\n4、如果对象锁跟访问的对象没有关系，那么就会都同时访问。\n\n## AtomicInteger 原理  CAS volatile修饰的int值 做成原子加 原子减\n## 垃圾处理GC 调优 -XMX  -XMS  -XMN\n\n\n# 美的一面\n## SPI  dubbo的spi机制\nSPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的接口，\n它可以用来启用框架扩展和替换组件。 SPI的作用就是为这些被扩展的API寻找服务实现。\n@spi 配置它可以扩展\n## java spi \n1，一种扩展机制，JDBC实现的接口就是driver，但是这个接口是扩展出去的，很多接口都会实现的 \n需要在META-INF的配置文件里面去配置对应service 接口\n2，缺点：不能做ioc 和aop 不能获取单独的一个实现类\n\n## ZK集群选举的一个过程\nZab协议\n\n## redis集群 同步原理 rdb aof文件 \n## 哨兵怎么跟redis的节点通信的 master  slave节点\n哨兵会给所有节点发ping指令，然后其他节点会回复pong指令，如果一段时间都没回复，那就是断开了\n## 哨兵选举\n1，配置priority 优先级最高的\n2，选择复制量最大的\n## 主从结构哨兵是否有用，假如一个节点掉了，会到哪里\n## mysql集群是用什么来做 模式是怎么样实现的\n## mysql主节点和从节点是怎么同步的 binlog 和relaylog\n## 如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\n## redis 用于哪些方面  用户信息， 分布式锁， 主从同步缓存数据\n## 分布式锁是怎么实现的\nredis setnx指令 finally里面delete  命令执行   要先判断一下当前线程ID 是不是自己的，如果是自己的那就可以删除，不然不能删除\n## redisson\n## mysql优化  开启慢查询 slow_log 开启  explain 一下，然后把对应不走索引的给查出来\n## mysql 有哪些索引 原理\n普通索引、唯一索引、聚集索引、主键索引、全文索引  B+树\n\n## 索引下推是什么原理\n在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，\n然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。\n在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，\n然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。\n索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。\n\n## mysql 还有其他什么日志吗  undo  redo\n## 分布式事务 二段式 三段线   \n## 最终一致性 跟分布式事务有什么区别 \n## 分布式事务 CAP理论 base理论\n## 多线程编程 线程池 类及构造参数\n## 线程池是怎么工作的\n## 最大线程数 如果队列满了咋办\n## worker队列要怎么设置\n## 如果队列都满了，这个时候你要放到mq队列\n## jvm 内存结构\n## jvm 多大就会放到大内存里面 是一个参数\n## 老年代full GC  G1 CMS GC 过程\n\n# 美的二面\n## dubbo文档\n## MQ对比\n## 数据库事务写成功之后往MQ 里面写\n## 事务中是否需要RPC\n\n\n\n\n\n## 高可用方案 从前端到后端\n前端nginx做负载均衡，redis做查询缓存，mysql集群做负载\n\n1，系统拆分  dubbo 加zk 分布式\n2，Cache(缓存)  读多写少 redis做缓存\n大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。\n3，MQ  把数据库操作先放到MQ 排队执行\n大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内\n4，数据库拆分(分库分表) Sharding-JDBC\n当数据量达到某个阀值时，数据库拆分就会成为一个紧急的需求。一般从业务上进行垂直拆分，如果业务单一，也可从水平上进行拆分。\n5，读写分离\n主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。\n6，ElasticSearch\n7，CDN 加速  把页面资源CDN加速一下\n其中有速度快的路径有慢的路径，如何选择最优路径，把每个角落的请求快速的传递到机房，这就是 CDN 的功能。\n8，HTML 页面静态化\n静态页面部署在 NGNIX 中，收到用户请求，Ngnix 不需要访问 Webapp 即可响应用户，减少应用渲染页面的时间，同时也降低了应用的压力。\n\n# 卓志\n## 微服务的技术选项\n易于部署，各个工程各不影响，分模块部署，负载均衡\n## dubbo注册与发现过程\n服务提供者 容器container 服务调用者 注册中心 counter\n## dubbo负载均衡 几种\nDubbo 提供了4种负载均衡实现，分别是基于权重随机算法的 RandomLoadBalance、基于最少活跃调用数算法的 LeastActiveLoadBalance、\n基于 hash 一致性的 ConsistentHashLoadBalance，以及基于加权轮询算法的 RoundRobinLoadBalance\n## dubbo遇到过什么问题吗？\n1，父子类有相同属性时值丢失 \ndubbo默认采用的是hessian序列化&反序列化方式，JavaDeserializer在获取fileds时，采用了Map去重。\n但是在读取值时，根据serializer的顺序，对于同名字段，子类的该字段值会被赋值两次，总是被父类的值覆盖，导致子类的字段值丢失。\n2，序列化问题复杂对象变成了map\n3，Data length too large \n超过8k   修改 payload的值，将其调大 可以调节到16k\n4，服务调用失败  No provider available\n存在一个或多个Provider服务，但是version或者group不匹配。\n例如Consumer侧申明version=1.0.0，而Provider侧申明version=2.0.0，或者group不匹配，都会出现这个ERROR。\n## dubbo遇到过什么序列化的问题\n## dubbo参数对象如果是object属性 可以传递过去吗\n最近遇到一个问题，B 服务调用 A 服务时，返回值反序列化时，POJO对象变成了Map类型。\n在A服务单独测试的时候一直还原不了，在 B 服务进行测试的时候，跟到反序列化数据时才看到原因。\nA 服务的接口方法返回的结果是一个Object（或 Map<String, Object> 中的 value），\nObject 的具体实现不在 A 服务的 API 包中，因此在 B 服务找不到该返回值真正的实现类，\n在 B 服务调用接口返回结果反序列化找不到具体的类型时，就会以 Map 类型进行实例化。\n\n### Java序列化：\nJava序列化会把要序列化的对象类的元数据和业务数据全部序列化为字节流，而且是把整个继承关系上的东西全部序列化了。\n它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。\n但是由于确实是序列化了所有内容，所以可以说什么都可以传输，因此也更可用和可靠。\n### hession序列化：\n它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，\nhessian会序列化成I 1这样的流，I表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，\nhessian把对象所有的属性当成一个Map来序列化，产生类似M className propertyName1 I 1 propertyName S stringValue\n（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。而在序列化过程中，如果一个对象之前出现过，\nhessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。\n这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），\n而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。而且同时因为并没有深入到实现内部去进行序列化，\n所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。\n## zk特点 CAP 理论  CP  consist\n## zk集群挂了会怎么办会投票 【myid ，zid】\n## MQ三大特性 解耦异步削峰\n## MQ 消息丢失\n## rebbitMQ持久化是怎么持久化\n将queue的持久化标识durable设置为true,则代表是一个持久的队列\n## redis分布式锁 lua脚本\nredisson \n## redis如何保证原子性\n单线程的\n## 既然是单线程的，如何做到异步和非阻塞的\n要明白他的线程模型是IO多路复用模型 主要核心是select channel  bufuer类 就是一个线程负责接收连接，其他线程负责解决对应的事务\n## redis 可以用来做什么 \n1，缓存  2，分布式锁  3，zset 排名 4，索引 \n## redis 秒杀的功能是怎么做的\n1，限流和降级 按钮置灰 nginx限流  2，队列削峰MQ  3，服务层分包部署  4，查询的时候查询redis 缓存\n## 多线程是怎么用的\n多线程newcache 保证线程无线 CPU消耗比较大  newfixed 线程数固定 但是队列无线，内存不友好\n## 有无遇到OOM的问题\n## jvm垃圾回收机制 标记计数算法 可达性算法 标记清理 标记整理 复制算法\n## 几个垃圾收集器  CMS标记清理  G1\n\n## 服务挂了的话怎么办 linux 怎么去查服务器日志\nlinux日志文件说明\n/var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一\n/var/log/secure 与安全相关的日志信息\n/var/log/maillog 与邮件相关的日志信息\n/var/log/cron 与定时任务相关的日志信息\n/var/log/spooler 与UUCP和news设备相关的日志信息\n/var/log/boot.log 守护进程启动和停止相关的日志消息\n/var/log/wtmp 该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件\n\n### Java应用程序的问题：发生OOM导致进程Crash\n最常见的是发生堆内存异常“java.lang.OutOfMemoryError: Java heap space”，排查步骤如下：\nStep1: 查看JVM参数 -XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath=*/java.hprof；\nStep2: 根据HeapDumpPath指定的路径查看是否产生dump文件；\nStep3: 若存在dump文件，使用Jhat、VisualVM等工具分析即可；\n### JVM出错：JVM或JDK自身的Bug导致进程Crash\n当JVM出现致命错误时，会生成一个错误文件 hs_err_pid.log，其中包括了导致jvm crash的重要信息，\n可以通过分析该文件定位到导致crash的根源，从而改善以保证系统稳定。当出现crash时，该文件默认会生成到工作目录下，\n然而可以通过jvm参数-XX:ErrorFile指定生成路径。\n### 被操作系统OOM-Killer\nStep1: 查看操作系统日志：sudo grep –color “java” /var/log/messages，确定Java进程是否被操作系统Kill；\nStep2: 若被操作系统Kill，执行dmesg命令查看系统各进程资源占用情况，明确Java占用内存是否合理，\n以及是否有其它进程不合理的占用了大量内存空间；\n\n## 数据库横表与纵表的区分  没什么卵用 都是到横表的 \n 横表就是普通的建表方式，如一个表结构为： 主键、字段1、字段2、字段3。。。 如果变成纵表后，\n 则表结构为： 主键、字段代码、字段值。 而字段代码则为字段1、字段2、字段3。\n## TIDB 最新数据库 \nmysql的一个封装，加快查询效率\n## tcp的头标记\n## rpc 主要框架及对比  dubbo  grpc  thrift dubbox  motan\ngrpc是一个轻量级的java RPC框架。它支持服务注册和发现。\ndubbox有比价完善的服务治理模型，其包含ZK注册中心，服务监控等，可以很方便的为我们服务。 \nmotan新浪微博开源的RPC框架\ngrpc是Google出品，使用了PB协议，但是由于它出现的比较晚，还不怎么成熟，而且采用http协议，非常适合现在的微服务，\n\t不过性能上差了许多，而且像服务治理与监控都需要额外的开发工作，所以放弃grpc。 \nthrift和grpc一样，性能优越，但是开发难度相比较于dubbox和motan也是高了一点点，\n\t需要编写proto文件（其实对于程序员来说这算不上难度）。像服务治理与监控也是需要额外的开发工作。 \ndubbo比较老了，直接弃用。 \ndubbox和后来的motan都比较适合我们的团队。dubbox后来经过当当的开发，引入了rest风格的http协议，\n并且还支持kryo/fst/dubbo/thrift等其他协议，而且其他团队也在使用dubbo，集成方便，服务治理监控功能齐全，所以最终采用dubbox。\n其实我个人而言还是喜欢thrift，毕竟性能优越，在大型分布式系统中，哪怕一点点性能提升累计在一起也是很可观的。\n不过再具体选型的过程中还要结合团队目前的状况和团队其他开发人员的接受程度进行取舍。\n\n\n# 易工品\n## springcloud alibaba 跟springcloud的区别\n注册中心不一样 nacos 集成了Ribbon eureka\n## 最新关注技术点 tidb 优点\n## 做的业务点\n## zk的业务场景 zk的特点\n## rocketmq 卡夫卡 和 rabbitmq的比较\n吞吐量 ：卡夫卡》rocketmq》rabbitmq\n接收的模式：卡夫卡拉取：rabbitmq 推拉\n## 所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\n## 财务金额用的是什么类型存储，怎么去做取整的操作\n## mysql的变更通知\n## 单元测试是怎么做的\nJunit框架，在大多数java的开发环境中已经集成，\n## 生产故障\n## 图数据库和时序数据库\n\n\n## 承担什么责任  做一个项目碰到什么难题  \n电商  支付模块 \n\n\n奥悦家 \n用户支付同步天问接口回调很慢的话怎么办  ，然后会导致用户重复缴费两次\n1，先异步返回，然后给数据库设置一个在缴费中的标志位，返回给业主说正在缴费中\n2，起一个线程去不断查询天问系统接口，然后接收回调接口的返回\n3，在缴费之后就先用redis把查询的费用设置为0，就是说先去redis 查询费用，如果没有的话就去天问查，如果有的话就看多少钱\n使用dubbo中遇到什么问题\n序列化的问题----复杂对象的时候会 变成map\n服务调用失败  No provider available-----版本号不一致\nData length too large 超过8k-------修改 payload的值，将其调大 可以调节到16k\n\n奥悦团购  超卖库存的问题 秒杀\n1前端\n面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】\n　　A：扩容\n　　加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。\n　　B：静态化\n　　将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。\n　　C：限流\n　　一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。\n　　或者活动入口的时候增加游戏或者问题环节进行消峰操作。\n　　\n2后端\nA：将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，\n并且由于Redis的写性能和读性能都远高于MySQL，\n这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。\nB：引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。\n当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。\nC：利用Java的锁机制CAS来实现减库存操作\nD：写sql乐观锁的概念，增加了版本号，\n//1.查询出商品信息\nselect stock, version from t_goods where id=1;\n//2.根据商品信息生成订单\ninsert into t_orders (id,goods_id) values (null,1);\n//3.修改商品库存\nupdate t_goods set stock=stock-1, version = version+1 where id=1, version=version;\n当A线程来更新数量的时候先看版本号有没有动，如果已经变了那就不改并且返回，如果没变，这个时候就更改库存，并且把版本号加一\nE：分布式锁\nsetnx指令，如果能拿到对应标志位的锁的话，那就成功获取锁，并且更改库存，如果不行的话，那就直接返回抢购失败\n\n\n\n# 中移\n## maven调用链依赖重复依赖是怎么解决的\n当一个项目中出现重复的依赖包时，maven 2.0.9之后的版本会用如下的规则来决定使用哪一个版本的包：\n最短路径原则\n比如有如下两个依赖关系：\nA -> B -> C -> D(V1)\nF -> G -> D(V2)\n这个时候项目中就出现了两个版本的D，这时maven会采用最短路径原则，选择V2版本的D，因为V1版本的D是由A包间接依赖的，整个依赖路径长度为3，而V2版本的D是由F包间接依赖的，整个依赖路径长度为2。\n声明优先原则\n假设有如下两个依赖关系：\nA -> B -> D(V1)\nF -> G -> D(V2)\n这个时候因为两个版本的D的依赖路径都是一样长，最短路径原则就失效了。这个时候Maven的解决方案是：\n按照依赖包在pom.xml中声明的先后顺序，优先选择先声明的包\n## ","slug":"java/java面试总结","published":1,"updated":"2025-05-16T04:25:25.438Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsu001qskqrb5dvam21","content":"<p>摘要:java面试总结</p>\n<span id=\"more\"></span>\n<h1 id=\"dubbo底层rpc-原理\"><a href=\"#dubbo底层rpc-原理\" class=\"headerlink\" title=\"dubbo底层rpc 原理\"></a>dubbo底层rpc 原理</h1><p>ip 和端口 通过socket连接</p>\n<h1 id=\"mysql主从原理-binlog-gt-relaylog\"><a href=\"#mysql主从原理-binlog-gt-relaylog\" class=\"headerlink\" title=\"mysql主从原理 binlog -&gt;relaylog\"></a>mysql主从原理 binlog -&gt;relaylog</h1><h1 id=\"动态代理跟静态代理啥区别\"><a href=\"#动态代理跟静态代理啥区别\" class=\"headerlink\" title=\"动态代理跟静态代理啥区别\"></a>动态代理跟静态代理啥区别</h1><p>静态代理是直接代理，就是定义一个接口，然后A类实现它，然后另外B类也实现这个接口，B类里面有A类实现每个方法，这样实现的时候B类就可以代替A类，这就叫静态代理<br>JDK动态代理是通过invocationhandle实现的 实现一个类实现invocationhandle 实现invoce方法，然后强制转换成对应Proxy类，就不用实现接口的每个方法<br>CGlib动态代理类是通过MethodInterceptor  实现的，实现一个类实现MethodInterceptor ，实现intercept 方法， 然后强制转换成newProxy类</p>\n<h1 id=\"cglib动态代理跟jdk动态代理啥区别\"><a href=\"#cglib动态代理跟jdk动态代理啥区别\" class=\"headerlink\" title=\"cglib动态代理跟jdk动态代理啥区别\"></a>cglib动态代理跟jdk动态代理啥区别</h1><p>接口走jdk动态代理，其他走cjlib</p>\n<h1 id=\"怎么实现动态代理，原理\"><a href=\"#怎么实现动态代理，原理\" class=\"headerlink\" title=\"怎么实现动态代理，原理\"></a>怎么实现动态代理，原理</h1><h1 id=\"rebbitmq-exchange-分几类\"><a href=\"#rebbitmq-exchange-分几类\" class=\"headerlink\" title=\"rebbitmq   exchange 分几类\"></a>rebbitmq   exchange 分几类</h1><h1 id=\"有没看mybatis源码-mybatis怎么映射到dao的\"><a href=\"#有没看mybatis源码-mybatis怎么映射到dao的\" class=\"headerlink\" title=\"有没看mybatis源码 mybatis怎么映射到dao的\"></a>有没看mybatis源码 mybatis怎么映射到dao的</h1><h1 id=\"线程状态，怎么变成死锁\"><a href=\"#线程状态，怎么变成死锁\" class=\"headerlink\" title=\"线程状态，怎么变成死锁\"></a>线程状态，怎么变成死锁</h1><h1 id=\"synchronized和reentrantlock-底层原理\"><a href=\"#synchronized和reentrantlock-底层原理\" class=\"headerlink\" title=\"synchronized和reentrantlock 底层原理\"></a>synchronized和reentrantlock 底层原理</h1><h1 id=\"synchronized除了cas还有锁升级\"><a href=\"#synchronized除了cas还有锁升级\" class=\"headerlink\" title=\"synchronized除了cas还有锁升级\"></a>synchronized除了cas还有锁升级</h1><h1 id=\"synchronized-的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\"><a href=\"#synchronized-的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\" class=\"headerlink\" title=\"synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\"></a>synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，</h1><h1 id=\"reentrantlock-除了CAS-还有AQS\"><a href=\"#reentrantlock-除了CAS-还有AQS\" class=\"headerlink\" title=\"reentrantlock 除了CAS  还有AQS\"></a>reentrantlock 除了CAS  还有AQS</h1><h1 id=\"spring-单例模式-工厂模式-观察者模式\"><a href=\"#spring-单例模式-工厂模式-观察者模式\" class=\"headerlink\" title=\"spring 单例模式 工厂模式  观察者模式\"></a>spring 单例模式 工厂模式  观察者模式</h1><h1 id=\"观察者模式主要用于什么地方\"><a href=\"#观察者模式主要用于什么地方\" class=\"headerlink\" title=\"观察者模式主要用于什么地方\"></a>观察者模式主要用于什么地方</h1><h1 id=\"spring事务是属于哪里的，代码怎么实现\"><a href=\"#spring事务是属于哪里的，代码怎么实现\" class=\"headerlink\" title=\"spring事务是属于哪里的，代码怎么实现\"></a>spring事务是属于哪里的，代码怎么实现</h1><h1 id=\"nio原理\"><a href=\"#nio原理\" class=\"headerlink\" title=\"nio原理\"></a>nio原理</h1><h1 id=\"netty线程模式\"><a href=\"#netty线程模式\" class=\"headerlink\" title=\"netty线程模式\"></a>netty线程模式</h1><h1 id=\"dubbo使用的时候遇到过什么问题\"><a href=\"#dubbo使用的时候遇到过什么问题\" class=\"headerlink\" title=\"dubbo使用的时候遇到过什么问题\"></a>dubbo使用的时候遇到过什么问题</h1><h1 id=\"mysql-建表的时候要注意什么\"><a href=\"#mysql-建表的时候要注意什么\" class=\"headerlink\" title=\"mysql 建表的时候要注意什么\"></a>mysql 建表的时候要注意什么</h1><h1 id=\"mysql中-使用explain时应注意那些字段\"><a href=\"#mysql中-使用explain时应注意那些字段\" class=\"headerlink\" title=\"mysql中 使用explain时应注意那些字段\"></a>mysql中 使用explain时应注意那些字段</h1><h1 id=\"热部署-冷部署\"><a href=\"#热部署-冷部署\" class=\"headerlink\" title=\"热部署 冷部署\"></a>热部署 冷部署</h1><h1 id=\"docker\"><a href=\"#docker\" class=\"headerlink\" title=\"docker\"></a>docker</h1><h1 id=\"k8s其他功能\"><a href=\"#k8s其他功能\" class=\"headerlink\" title=\"k8s其他功能\"></a>k8s其他功能</h1><h1 id=\"引用的分类\"><a href=\"#引用的分类\" class=\"headerlink\" title=\"#引用的分类\"></a>#引用的分类</h1><h2 id=\"强引用-jvm-情愿爆出OOM-也不回收的对象\"><a href=\"#强引用-jvm-情愿爆出OOM-也不回收的对象\" class=\"headerlink\" title=\"强引用   jvm 情愿爆出OOM 也不回收的对象\"></a>强引用   jvm 情愿爆出OOM 也不回收的对象</h2><h2 id=\"弱引用-jvm查到的话就会回收-不管内存够不够\"><a href=\"#弱引用-jvm查到的话就会回收-不管内存够不够\" class=\"headerlink\" title=\"弱引用    jvm查到的话就会回收 不管内存够不够\"></a>弱引用    jvm查到的话就会回收 不管内存够不够</h2><h2 id=\"软引用-Jvm-如果内存不够用的时候就会回收\"><a href=\"#软引用-Jvm-如果内存不够用的时候就会回收\" class=\"headerlink\" title=\"软引用    Jvm 如果内存不够用的时候就会回收\"></a>软引用    Jvm 如果内存不够用的时候就会回收</h2><h2 id=\"虚引用-jvm看到就回收\"><a href=\"#虚引用-jvm看到就回收\" class=\"headerlink\" title=\"虚引用    jvm看到就回收\"></a>虚引用    jvm看到就回收</h2><h1 id=\"字节面试一面总结\"><a href=\"#字节面试一面总结\" class=\"headerlink\" title=\"字节面试一面总结\"></a>字节面试一面总结</h1><h1 id=\"算法题\"><a href=\"#算法题\" class=\"headerlink\" title=\"算法题\"></a>算法题</h1><p>在一个字符串S内查找一个子串s的出现位置。<br>public static int indexOf(char[] chars, char[] sub) {<br>return -1;<br>}</p>\n<h1 id=\"如何保证RabbitMQ不被重复消费？\"><a href=\"#如何保证RabbitMQ不被重复消费？\" class=\"headerlink\" title=\"如何保证RabbitMQ不被重复消费？\"></a>如何保证RabbitMQ不被重复消费？</h1><h1 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h1><h1 id=\"activeMQ\"><a href=\"#activeMQ\" class=\"headerlink\" title=\"activeMQ\"></a>activeMQ</h1><h1 id=\"dubbo-与springcloud-区别\"><a href=\"#dubbo-与springcloud-区别\" class=\"headerlink\" title=\"dubbo 与springcloud 区别\"></a>dubbo 与springcloud 区别</h1><h1 id=\"zookeeper-单节点还是多节点-如果挂了怎么办\"><a href=\"#zookeeper-单节点还是多节点-如果挂了怎么办\" class=\"headerlink\" title=\"zookeeper 单节点还是多节点 如果挂了怎么办\"></a>zookeeper 单节点还是多节点 如果挂了怎么办</h1><h1 id=\"zk集群是怎么部署的\"><a href=\"#zk集群是怎么部署的\" class=\"headerlink\" title=\"zk集群是怎么部署的\"></a>zk集群是怎么部署的</h1><h1 id=\"并发锁-分布式锁\"><a href=\"#并发锁-分布式锁\" class=\"headerlink\" title=\"并发锁 分布式锁\"></a>并发锁 分布式锁</h1><h1 id=\"支付宝微信调用过程中怎么确保安全\"><a href=\"#支付宝微信调用过程中怎么确保安全\" class=\"headerlink\" title=\"支付宝微信调用过程中怎么确保安全\"></a>支付宝微信调用过程中怎么确保安全</h1><h1 id=\"微信支付宝是怎么做订单的拦截消费\"><a href=\"#微信支付宝是怎么做订单的拦截消费\" class=\"headerlink\" title=\"微信支付宝是怎么做订单的拦截消费\"></a>微信支付宝是怎么做订单的拦截消费</h1><h1 id=\"mysql-索引的实现原理\"><a href=\"#mysql-索引的实现原理\" class=\"headerlink\" title=\"mysql 索引的实现原理\"></a>mysql 索引的实现原理</h1><h1 id=\"mysql-节点存储的是什么-非叶子节点-和叶子节点\"><a href=\"#mysql-节点存储的是什么-非叶子节点-和叶子节点\" class=\"headerlink\" title=\"mysql 节点存储的是什么 非叶子节点 和叶子节点\"></a>mysql 节点存储的是什么 非叶子节点 和叶子节点</h1><h1 id=\"一个节点最大存储-16K\"><a href=\"#一个节点最大存储-16K\" class=\"headerlink\" title=\"一个节点最大存储 16K\"></a>一个节点最大存储 16K</h1><h1 id=\"16k是相对于什么来说的\"><a href=\"#16k是相对于什么来说的\" class=\"headerlink\" title=\"16k是相对于什么来说的\"></a>16k是相对于什么来说的</h1><h1 id=\"Username-查询-最左前缀原则-为什么\"><a href=\"#Username-查询-最左前缀原则-为什么\" class=\"headerlink\" title=\"Username 查询 % 最左前缀原则 为什么\"></a>Username 查询 % 最左前缀原则 为什么</h1><h1 id=\"浩鲸科技一面\"><a href=\"#浩鲸科技一面\" class=\"headerlink\" title=\"浩鲸科技一面\"></a>浩鲸科技一面</h1><h2 id=\"dubbo重试机制\"><a href=\"#dubbo重试机制\" class=\"headerlink\" title=\"dubbo重试机制\"></a>dubbo重试机制</h2><p>1，Dubbo支持多种失败重试机制：<br>Failover Cluster - 失败自动切换<br>Failfast Cluster - 快速失败<br>Failsafe Cluster - 失败安全<br>Failback Cluster - 失败自动恢复<br>Forking Cluster - 并行调用多个服务提供者<br>Broadcast - 广播轮询调用所有Provider</p>\n<h2 id=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"><a href=\"#zk服务注册发现过程，如果一个断了，怎么通知到对方\" class=\"headerlink\" title=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"></a>zk服务注册发现过程，如果一个断了，怎么通知到对方</h2><p>这里写的非常清楚<a href=\"https://blog.csdn.net/zyhlwzy/article/details/101847565\">zk服务注册发现过程</a><br>1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode<br>2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示<br>3，具体流程<br>1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。<br>服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；<br>2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，<br>异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；<br>4，zk的服务注册和发现流程<br>1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，<br>即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），比如注册一个用户注册服务（user/register）:<br>2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，<br>获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，比如发现用户注册服务（user/register）并调用。<br>3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，<br>因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，<br>Zookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。</p>\n<h2 id=\"zk节点类型\"><a href=\"#zk节点类型\" class=\"headerlink\" title=\"zk节点类型\"></a>zk节点类型</h2><p>1.持久节点(PERSISTENT)<br>持久节点，创建后一直存在，直到主动删除此节点。<br>2.持久顺序节点(PERSISTENT_SEQUENTIAL)<br>持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。<br>3.临时节点(EPHEMERAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。<br>4.顺序临时节点(EPHEMERAL_SEQUENTIAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。</p>\n<h2 id=\"zk还可以用来做什么，具体怎么实现\"><a href=\"#zk还可以用来做什么，具体怎么实现\" class=\"headerlink\" title=\"zk还可以用来做什么，具体怎么实现\"></a>zk还可以用来做什么，具体怎么实现</h2><p>1,分布式锁，具体实现方式<br>1）znode 可以被监控。<br>节点数据修改、子节点变化、节点删除等。<br>一旦变化可以通知设置监控的客户端。<br>通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。<br>2）分布式锁步骤。<br>注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器<br>    1. 父节点持久节点/lock<br>    2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推<br>    3. 获取/lock下所有子节点getChildren(“/lock”)方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，<br>    获得通知后重复该步骤。<br>    4. 执行代码。完成后释放锁。<br>4）使用zookeeper + curator，完成分布式锁。</p>\n<h2 id=\"redis与mysql-怎么做到缓存一致性\"><a href=\"#redis与mysql-怎么做到缓存一致性\" class=\"headerlink\" title=\"redis与mysql 怎么做到缓存一致性\"></a>redis与mysql 怎么做到缓存一致性</h2><p>1、MySQL binlog增量发布订阅消费+消息队列+增量数据更新到redis<br>    1）读请求走Redis：热数据基本都在Redis<br>    2）写请求走MySQL: 增删改都操作MySQL<br>    3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis<br>2、Redis更新<br>    1）数据操作主要分为两块：<br>    一个是全量(将全部数据一次写入到redis)<br>    一个是增量（实时更新）<br>    这里说的是增量,指的是mysql的update、insert、delate变更数据。<br>    这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。就无需在从业务线去操作缓存内容<br>    2）每次写数据库的时候都把redis的数据给删掉，读数据库的时候再保存到redis 缓存<br>3、延迟双删，一定程度可以解决，就是写数据库之后 睡眠一段时间，然后再删除一次，但是不一定百分百解决问题，而且延迟了主线程<br>4，分布式锁，可以解决，并发问题串行化，但是效率低<br>5，读锁，写锁可以一定程度优化，读多写少，读读不互斥，写写互斥</p>\n<h2 id=\"怎么保证redis-高可用\"><a href=\"#怎么保证redis-高可用\" class=\"headerlink\" title=\"怎么保证redis 高可用\"></a>怎么保证redis 高可用</h2><p>redis高并发：主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10万的QPS。<br>redis高并发的同时，还需要容纳大量的数据：一主多从，每个实例都容纳了完整的数据，比如redis主就10G的内存量，其实你最多只能容纳10g的数据量。<br>如果你的缓存要容纳的数据量很大，达到了几十g，甚至几百g，或者是几t，那你就需要redis集群，而且用redis集群之后，可以提供可能每秒几十万的读写并发。<br>redis高可用：如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换。</p>\n<h2 id=\"redis-集群是怎么搭建的\"><a href=\"#redis-集群是怎么搭建的\" class=\"headerlink\" title=\"redis 集群是怎么搭建的\"></a>redis 集群是怎么搭建的</h2><p>当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。<br>如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据;如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。<br>开始full resynchronization的时候，master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。<br>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。</p>\n<h2 id=\"分库分表\"><a href=\"#分库分表\" class=\"headerlink\" title=\"分库分表\"></a>分库分表</h2><p>java中主要是用的是Sharding-JDBC分库分表  整合springboot 非常方便</p>\n<h2 id=\"分布式事务是怎么做的seata\"><a href=\"#分布式事务是怎么做的seata\" class=\"headerlink\" title=\"分布式事务是怎么做的seata\"></a>分布式事务是怎么做的seata</h2><ol>\n<li>二阶段提交协议 (2PC)<br> 协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。<br> 1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志<br> 2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。<br> 缺点<br> 1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行<br> 2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。<br> 3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，<br> 但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</li>\n<li>三阶段提交协议 (3PC)<br>针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。<br>三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。<br> 1），为甚需要cancommit<br> 假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。<br> 协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。<br> 协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？<br> 所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。<br> 2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务<br> 因为在precommit阶段已经知道所有节点都同意提交事务了</li>\n<li>基于消息的分布式事务<br> 基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失<h2 id=\"session与token和cookie区别\"><a href=\"#session与token和cookie区别\" class=\"headerlink\" title=\"session与token和cookie区别\"></a>session与token和cookie区别</h2>1，session的中文翻译是“会话”，当用户打开某个web应用时，便与web服务器产生一次session<br>2，cookie是保存在本地终端的数据。cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器<br>3，token的意思是“令牌”，是用户身份的验证方式，最简单的token组成uid<br>cookie 和session的区别<br>1）、cookie数据存放在客户的浏览器上，session数据放在服务器上。<br>2）、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗<br>考虑到安全应当使用session。<br>3）、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能<br>考虑到减轻服务器性能方面，应当使用COOKIE。<br>4）、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。</li>\n</ol>\n<p>5)、所以个人建议：<br>   将登陆信息等重要信息存放为SESSION<br>   其他信息如果需要保留，可以放在COOKIE中</p>\n<h1 id=\"shein一面\"><a href=\"#shein一面\" class=\"headerlink\" title=\"shein一面\"></a>shein一面</h1><h2 id=\"springboot有什么优点-特性\"><a href=\"#springboot有什么优点-特性\" class=\"headerlink\" title=\"springboot有什么优点 特性\"></a>springboot有什么优点 特性</h2><h2 id=\"mysql-插入一千条一万条语句怎么办\"><a href=\"#mysql-插入一千条一万条语句怎么办\" class=\"headerlink\" title=\"mysql 插入一千条一万条语句怎么办\"></a>mysql 插入一千条一万条语句怎么办</h2><p>INSERT INTO<br>items(name,city,price,number,picture)<br>VALUES<br>(‘耐克运动鞋’,’广州’,500,1000,’003.jpg’),<br>……<br>(‘耐克运动鞋2’,’广州2’,500,1000,’002.jpg’);</p>\n<p>java代码的话是先用for循环先拼接好，然后再拼接语句insert ，然后再执行代码</p>\n<h2 id=\"慢查询怎么看然后怎么优化-举个栗子\"><a href=\"#慢查询怎么看然后怎么优化-举个栗子\" class=\"headerlink\" title=\"慢查询怎么看然后怎么优化  举个栗子\"></a>慢查询怎么看然后怎么优化  举个栗子</h2><h2 id=\"ABC-三列组合索引-这个时候-A-B-in-C-这个时候会不会走索引\"><a href=\"#ABC-三列组合索引-这个时候-A-B-in-C-这个时候会不会走索引\" class=\"headerlink\" title=\"ABC 三列组合索引 这个时候 A= B in C =   这个时候会不会走索引\"></a>ABC 三列组合索引 这个时候 A= B in C =   这个时候会不会走索引</h2><h2 id=\"为什么最左前缀只走第一列-最左前缀原理-要清楚存储数据原理-一个节点存储了三个值-代表三个数值\"><a href=\"#为什么最左前缀只走第一列-最左前缀原理-要清楚存储数据原理-一个节点存储了三个值-代表三个数值\" class=\"headerlink\" title=\"为什么最左前缀只走第一列  最左前缀原理 要清楚存储数据原理 一个节点存储了三个值 代表三个数值\"></a>为什么最左前缀只走第一列  最左前缀原理 要清楚存储数据原理 一个节点存储了三个值 代表三个数值</h2><h2 id=\"mybatis-常用标签-foreach\"><a href=\"#mybatis-常用标签-foreach\" class=\"headerlink\" title=\"mybatis 常用标签 foreach\"></a>mybatis 常用标签 foreach</h2><h2 id=\"redis-常用指令-lpush-lset\"><a href=\"#redis-常用指令-lpush-lset\" class=\"headerlink\" title=\"redis 常用指令 lpush  lset\"></a>redis 常用指令 lpush  lset</h2><h2 id=\"rabbitmq-确认机制怎么实现-publisher-confirms\"><a href=\"#rabbitmq-确认机制怎么实现-publisher-confirms\" class=\"headerlink\" title=\"rabbitmq 确认机制怎么实现 publisher-confirms\"></a>rabbitmq 确认机制怎么实现 publisher-confirms</h2><h2 id=\"elk-Elasticserarch-Logstash-Kibana\"><a href=\"#elk-Elasticserarch-Logstash-Kibana\" class=\"headerlink\" title=\"elk  (Elasticserarch + Logstash + Kibana)\"></a>elk  (Elasticserarch + Logstash + Kibana)</h2><h2 id=\"romda-表达式\"><a href=\"#romda-表达式\" class=\"headerlink\" title=\"romda 表达式\"></a>romda 表达式</h2><p>分组        Map&lt;String, List<User>&gt; groupBySex = userList.stream().collect(Collectors.groupingBy(User::getSex));<br>过滤        List<User> userCommonList = userList.stream().filter(a -&gt; !a.getJobNumber().equals(“201901”)).collect(Collectors.toList());</p>\n<h2 id=\"为什么要使用联合索引\"><a href=\"#为什么要使用联合索引\" class=\"headerlink\" title=\"为什么要使用联合索引\"></a>为什么要使用联合索引</h2><h3 id=\"减少开销。建一个联合索引-col1-col2-col3-，实际相当于建了-col1-col1-col2-col1-col2-col3-三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\"><a href=\"#减少开销。建一个联合索引-col1-col2-col3-，实际相当于建了-col1-col1-col2-col1-col2-col3-三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\" class=\"headerlink\" title=\"减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\"></a>减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。</h3><p>对于大量数据的表，使用联合索引会大大的减少开销！</p>\n<h3 id=\"覆盖索引。对联合索引-col1-col2-col3-，如果有如下的sql-select-col1-col2-col3-from-test-where-col1-1-and-col2-2。\"><a href=\"#覆盖索引。对联合索引-col1-col2-col3-，如果有如下的sql-select-col1-col2-col3-from-test-where-col1-1-and-col2-2。\" class=\"headerlink\" title=\"覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。\"></a>覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。</h3><p>那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。<br>所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。</p>\n<h3 id=\"效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql-select-from-table-where-col1-1-and-col2-2-and-col3-3\"><a href=\"#效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql-select-from-table-where-col1-1-and-col2-2-and-col3-3\" class=\"headerlink\" title=\"效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,\"></a>效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,</h3><p>假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，<br>然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！</p>\n<h1 id=\"保利一面\"><a href=\"#保利一面\" class=\"headerlink\" title=\"保利一面\"></a>保利一面</h1><h2 id=\"提前预警系统问题\"><a href=\"#提前预警系统问题\" class=\"headerlink\" title=\"提前预警系统问题\"></a>提前预警系统问题</h2><h2 id=\"springboot-注解实现原理\"><a href=\"#springboot-注解实现原理\" class=\"headerlink\" title=\"springboot 注解实现原理\"></a>springboot 注解实现原理</h2><h2 id=\"zookeeper有什么缺点-AP-和-CP-效率不高\"><a href=\"#zookeeper有什么缺点-AP-和-CP-效率不高\" class=\"headerlink\" title=\"zookeeper有什么缺点  AP 和 CP  效率不高\"></a>zookeeper有什么缺点  AP 和 CP  效率不高</h2><h2 id=\"dubbo-线程模型\"><a href=\"#dubbo-线程模型\" class=\"headerlink\" title=\"dubbo 线程模型\"></a>dubbo 线程模型</h2><h2 id=\"dubbo怎么做到负载均衡-loadbalance-xml配置文件里面直接配置\"><a href=\"#dubbo怎么做到负载均衡-loadbalance-xml配置文件里面直接配置\" class=\"headerlink\" title=\"dubbo怎么做到负载均衡  loadbalance xml配置文件里面直接配置\"></a>dubbo怎么做到负载均衡  loadbalance xml配置文件里面直接配置</h2><h2 id=\"四种负载均衡\"><a href=\"#四种负载均衡\" class=\"headerlink\" title=\"四种负载均衡\"></a>四种负载均衡</h2><p>1，随机<br>2，轮训<br>3，一致性哈希<br>4，最少活跃数</p>\n<h2 id=\"elk-调用链-就是监听requestid-log4j\"><a href=\"#elk-调用链-就是监听requestid-log4j\" class=\"headerlink\" title=\"elk 调用链 就是监听requestid log4j\"></a>elk 调用链 就是监听requestid log4j</h2><h2 id=\"并发高怎么设计系统\"><a href=\"#并发高怎么设计系统\" class=\"headerlink\" title=\"并发高怎么设计系统\"></a>并发高怎么设计系统</h2><p>1，使用缓存redis<br>2，线程池<br>3，nginx 负载均衡<br>4，消息队列</p>\n<h2 id=\"redis-过期机制\"><a href=\"#redis-过期机制\" class=\"headerlink\" title=\"redis 过期机制\"></a>redis 过期机制</h2><p>1，定时删除 在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。<br>2，惰性删除 设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。<br>3，定期删除 每隔一段时间，我们就对一些key进行检查，删除里面过期的key。</p>\n<h1 id=\"阿里一面\"><a href=\"#阿里一面\" class=\"headerlink\" title=\"阿里一面\"></a>阿里一面</h1><h2 id=\"秒杀设计-要考虑什么\"><a href=\"#秒杀设计-要考虑什么\" class=\"headerlink\" title=\"秒杀设计 要考虑什么\"></a>秒杀设计 要考虑什么</h2><p>1，前端限流 -按钮只能按一次<br>2，后端限流 -利用MQ削锋<br>3，后端redis防止超卖<br>4，后端mysql限制<br>5，限制IP多次请求，缓存到redis里面<br>6，</p>\n<h2 id=\"java代码如何保证原子性-原子加-原子减-AtomicInteger\"><a href=\"#java代码如何保证原子性-原子加-原子减-AtomicInteger\" class=\"headerlink\" title=\"java代码如何保证原子性 原子加 原子减   AtomicInteger\"></a>java代码如何保证原子性 原子加 原子减   AtomicInteger</h2><h2 id=\"synchronized和reentrantlock-区别\"><a href=\"#synchronized和reentrantlock-区别\" class=\"headerlink\" title=\"synchronized和reentrantlock 区别\"></a>synchronized和reentrantlock 区别</h2><h2 id=\"synchronized-可以锁哪些对象，有什么区别\"><a href=\"#synchronized-可以锁哪些对象，有什么区别\" class=\"headerlink\" title=\"synchronized 可以锁哪些对象，有什么区别\"></a>synchronized 可以锁哪些对象，有什么区别</h2><p>1，对象 变量  对象锁<br>2，代码块  对象锁<br>3，类  类锁<br>1、对于静态方法，由于此时对象还未生成，所以只能采用类锁；<br>2、只要采用类锁，就会拦截所有线程，只能让一个线程访问。<br>3、对于对象锁（this），如果是同一个实例，就会按顺序访问，但是如果是不同实例，就可以同时访问。<br>4、如果对象锁跟访问的对象没有关系，那么就会都同时访问。</p>\n<h2 id=\"AtomicInteger-原理-CAS-volatile修饰的int值-做成原子加-原子减\"><a href=\"#AtomicInteger-原理-CAS-volatile修饰的int值-做成原子加-原子减\" class=\"headerlink\" title=\"AtomicInteger 原理  CAS volatile修饰的int值 做成原子加 原子减\"></a>AtomicInteger 原理  CAS volatile修饰的int值 做成原子加 原子减</h2><h2 id=\"垃圾处理GC-调优-XMX-XMS-XMN\"><a href=\"#垃圾处理GC-调优-XMX-XMS-XMN\" class=\"headerlink\" title=\"垃圾处理GC 调优 -XMX  -XMS  -XMN\"></a>垃圾处理GC 调优 -XMX  -XMS  -XMN</h2><h1 id=\"美的一面\"><a href=\"#美的一面\" class=\"headerlink\" title=\"美的一面\"></a>美的一面</h1><h2 id=\"SPI-dubbo的spi机制\"><a href=\"#SPI-dubbo的spi机制\" class=\"headerlink\" title=\"SPI  dubbo的spi机制\"></a>SPI  dubbo的spi机制</h2><p>SPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的接口，<br>它可以用来启用框架扩展和替换组件。 SPI的作用就是为这些被扩展的API寻找服务实现。<br>@spi 配置它可以扩展</p>\n<h2 id=\"java-spi\"><a href=\"#java-spi\" class=\"headerlink\" title=\"java spi\"></a>java spi</h2><p>1，一种扩展机制，JDBC实现的接口就是driver，但是这个接口是扩展出去的，很多接口都会实现的<br>需要在META-INF的配置文件里面去配置对应service 接口<br>2，缺点：不能做ioc 和aop 不能获取单独的一个实现类</p>\n<h2 id=\"ZK集群选举的一个过程\"><a href=\"#ZK集群选举的一个过程\" class=\"headerlink\" title=\"ZK集群选举的一个过程\"></a>ZK集群选举的一个过程</h2><p>Zab协议</p>\n<h2 id=\"redis集群-同步原理-rdb-aof文件\"><a href=\"#redis集群-同步原理-rdb-aof文件\" class=\"headerlink\" title=\"redis集群 同步原理 rdb aof文件\"></a>redis集群 同步原理 rdb aof文件</h2><h2 id=\"哨兵怎么跟redis的节点通信的-master-slave节点\"><a href=\"#哨兵怎么跟redis的节点通信的-master-slave节点\" class=\"headerlink\" title=\"哨兵怎么跟redis的节点通信的 master  slave节点\"></a>哨兵怎么跟redis的节点通信的 master  slave节点</h2><p>哨兵会给所有节点发ping指令，然后其他节点会回复pong指令，如果一段时间都没回复，那就是断开了</p>\n<h2 id=\"哨兵选举\"><a href=\"#哨兵选举\" class=\"headerlink\" title=\"哨兵选举\"></a>哨兵选举</h2><p>1，配置priority 优先级最高的<br>2，选择复制量最大的</p>\n<h2 id=\"主从结构哨兵是否有用，假如一个节点掉了，会到哪里\"><a href=\"#主从结构哨兵是否有用，假如一个节点掉了，会到哪里\" class=\"headerlink\" title=\"主从结构哨兵是否有用，假如一个节点掉了，会到哪里\"></a>主从结构哨兵是否有用，假如一个节点掉了，会到哪里</h2><h2 id=\"mysql集群是用什么来做-模式是怎么样实现的\"><a href=\"#mysql集群是用什么来做-模式是怎么样实现的\" class=\"headerlink\" title=\"mysql集群是用什么来做 模式是怎么样实现的\"></a>mysql集群是用什么来做 模式是怎么样实现的</h2><h2 id=\"mysql主节点和从节点是怎么同步的-binlog-和relaylog\"><a href=\"#mysql主节点和从节点是怎么同步的-binlog-和relaylog\" class=\"headerlink\" title=\"mysql主节点和从节点是怎么同步的 binlog 和relaylog\"></a>mysql主节点和从节点是怎么同步的 binlog 和relaylog</h2><h2 id=\"如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\"><a href=\"#如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\" class=\"headerlink\" title=\"如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\"></a>如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）</h2><h2 id=\"redis-用于哪些方面-用户信息，-分布式锁，-主从同步缓存数据\"><a href=\"#redis-用于哪些方面-用户信息，-分布式锁，-主从同步缓存数据\" class=\"headerlink\" title=\"redis 用于哪些方面  用户信息， 分布式锁， 主从同步缓存数据\"></a>redis 用于哪些方面  用户信息， 分布式锁， 主从同步缓存数据</h2><h2 id=\"分布式锁是怎么实现的\"><a href=\"#分布式锁是怎么实现的\" class=\"headerlink\" title=\"分布式锁是怎么实现的\"></a>分布式锁是怎么实现的</h2><p>redis setnx指令 finally里面delete  命令执行   要先判断一下当前线程ID 是不是自己的，如果是自己的那就可以删除，不然不能删除</p>\n<h2 id=\"redisson\"><a href=\"#redisson\" class=\"headerlink\" title=\"redisson\"></a>redisson</h2><h2 id=\"mysql优化-开启慢查询-slow-log-开启-explain-一下，然后把对应不走索引的给查出来\"><a href=\"#mysql优化-开启慢查询-slow-log-开启-explain-一下，然后把对应不走索引的给查出来\" class=\"headerlink\" title=\"mysql优化  开启慢查询 slow_log 开启  explain 一下，然后把对应不走索引的给查出来\"></a>mysql优化  开启慢查询 slow_log 开启  explain 一下，然后把对应不走索引的给查出来</h2><h2 id=\"mysql-有哪些索引-原理\"><a href=\"#mysql-有哪些索引-原理\" class=\"headerlink\" title=\"mysql 有哪些索引 原理\"></a>mysql 有哪些索引 原理</h2><p>普通索引、唯一索引、聚集索引、主键索引、全文索引  B+树</p>\n<h2 id=\"索引下推是什么原理\"><a href=\"#索引下推是什么原理\" class=\"headerlink\" title=\"索引下推是什么原理\"></a>索引下推是什么原理</h2><p>在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，<br>然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。<br>在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，<br>然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。<br>索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。</p>\n<h2 id=\"mysql-还有其他什么日志吗-undo-redo\"><a href=\"#mysql-还有其他什么日志吗-undo-redo\" class=\"headerlink\" title=\"mysql 还有其他什么日志吗  undo  redo\"></a>mysql 还有其他什么日志吗  undo  redo</h2><h2 id=\"分布式事务-二段式-三段线\"><a href=\"#分布式事务-二段式-三段线\" class=\"headerlink\" title=\"分布式事务 二段式 三段线\"></a>分布式事务 二段式 三段线</h2><h2 id=\"最终一致性-跟分布式事务有什么区别\"><a href=\"#最终一致性-跟分布式事务有什么区别\" class=\"headerlink\" title=\"最终一致性 跟分布式事务有什么区别\"></a>最终一致性 跟分布式事务有什么区别</h2><h2 id=\"分布式事务-CAP理论-base理论\"><a href=\"#分布式事务-CAP理论-base理论\" class=\"headerlink\" title=\"分布式事务 CAP理论 base理论\"></a>分布式事务 CAP理论 base理论</h2><h2 id=\"多线程编程-线程池-类及构造参数\"><a href=\"#多线程编程-线程池-类及构造参数\" class=\"headerlink\" title=\"多线程编程 线程池 类及构造参数\"></a>多线程编程 线程池 类及构造参数</h2><h2 id=\"线程池是怎么工作的\"><a href=\"#线程池是怎么工作的\" class=\"headerlink\" title=\"线程池是怎么工作的\"></a>线程池是怎么工作的</h2><h2 id=\"最大线程数-如果队列满了咋办\"><a href=\"#最大线程数-如果队列满了咋办\" class=\"headerlink\" title=\"最大线程数 如果队列满了咋办\"></a>最大线程数 如果队列满了咋办</h2><h2 id=\"worker队列要怎么设置\"><a href=\"#worker队列要怎么设置\" class=\"headerlink\" title=\"worker队列要怎么设置\"></a>worker队列要怎么设置</h2><h2 id=\"如果队列都满了，这个时候你要放到mq队列\"><a href=\"#如果队列都满了，这个时候你要放到mq队列\" class=\"headerlink\" title=\"如果队列都满了，这个时候你要放到mq队列\"></a>如果队列都满了，这个时候你要放到mq队列</h2><h2 id=\"jvm-内存结构\"><a href=\"#jvm-内存结构\" class=\"headerlink\" title=\"jvm 内存结构\"></a>jvm 内存结构</h2><h2 id=\"jvm-多大就会放到大内存里面-是一个参数\"><a href=\"#jvm-多大就会放到大内存里面-是一个参数\" class=\"headerlink\" title=\"jvm 多大就会放到大内存里面 是一个参数\"></a>jvm 多大就会放到大内存里面 是一个参数</h2><h2 id=\"老年代full-GC-G1-CMS-GC-过程\"><a href=\"#老年代full-GC-G1-CMS-GC-过程\" class=\"headerlink\" title=\"老年代full GC  G1 CMS GC 过程\"></a>老年代full GC  G1 CMS GC 过程</h2><h1 id=\"美的二面\"><a href=\"#美的二面\" class=\"headerlink\" title=\"美的二面\"></a>美的二面</h1><h2 id=\"dubbo文档\"><a href=\"#dubbo文档\" class=\"headerlink\" title=\"dubbo文档\"></a>dubbo文档</h2><h2 id=\"MQ对比\"><a href=\"#MQ对比\" class=\"headerlink\" title=\"MQ对比\"></a>MQ对比</h2><h2 id=\"数据库事务写成功之后往MQ-里面写\"><a href=\"#数据库事务写成功之后往MQ-里面写\" class=\"headerlink\" title=\"数据库事务写成功之后往MQ 里面写\"></a>数据库事务写成功之后往MQ 里面写</h2><h2 id=\"事务中是否需要RPC\"><a href=\"#事务中是否需要RPC\" class=\"headerlink\" title=\"事务中是否需要RPC\"></a>事务中是否需要RPC</h2><h2 id=\"高可用方案-从前端到后端\"><a href=\"#高可用方案-从前端到后端\" class=\"headerlink\" title=\"高可用方案 从前端到后端\"></a>高可用方案 从前端到后端</h2><p>前端nginx做负载均衡，redis做查询缓存，mysql集群做负载</p>\n<p>1，系统拆分  dubbo 加zk 分布式<br>2，Cache(缓存)  读多写少 redis做缓存<br>大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。<br>3，MQ  把数据库操作先放到MQ 排队执行<br>大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内<br>4，数据库拆分(分库分表) Sharding-JDBC<br>当数据量达到某个阀值时，数据库拆分就会成为一个紧急的需求。一般从业务上进行垂直拆分，如果业务单一，也可从水平上进行拆分。<br>5，读写分离<br>主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。<br>6，ElasticSearch<br>7，CDN 加速  把页面资源CDN加速一下<br>其中有速度快的路径有慢的路径，如何选择最优路径，把每个角落的请求快速的传递到机房，这就是 CDN 的功能。<br>8，HTML 页面静态化<br>静态页面部署在 NGNIX 中，收到用户请求，Ngnix 不需要访问 Webapp 即可响应用户，减少应用渲染页面的时间，同时也降低了应用的压力。</p>\n<h1 id=\"卓志\"><a href=\"#卓志\" class=\"headerlink\" title=\"卓志\"></a>卓志</h1><h2 id=\"微服务的技术选项\"><a href=\"#微服务的技术选项\" class=\"headerlink\" title=\"微服务的技术选项\"></a>微服务的技术选项</h2><p>易于部署，各个工程各不影响，分模块部署，负载均衡</p>\n<h2 id=\"dubbo注册与发现过程\"><a href=\"#dubbo注册与发现过程\" class=\"headerlink\" title=\"dubbo注册与发现过程\"></a>dubbo注册与发现过程</h2><p>服务提供者 容器container 服务调用者 注册中心 counter</p>\n<h2 id=\"dubbo负载均衡-几种\"><a href=\"#dubbo负载均衡-几种\" class=\"headerlink\" title=\"dubbo负载均衡 几种\"></a>dubbo负载均衡 几种</h2><p>Dubbo 提供了4种负载均衡实现，分别是基于权重随机算法的 RandomLoadBalance、基于最少活跃调用数算法的 LeastActiveLoadBalance、<br>基于 hash 一致性的 ConsistentHashLoadBalance，以及基于加权轮询算法的 RoundRobinLoadBalance</p>\n<h2 id=\"dubbo遇到过什么问题吗？\"><a href=\"#dubbo遇到过什么问题吗？\" class=\"headerlink\" title=\"dubbo遇到过什么问题吗？\"></a>dubbo遇到过什么问题吗？</h2><p>1，父子类有相同属性时值丢失<br>dubbo默认采用的是hessian序列化&amp;反序列化方式，JavaDeserializer在获取fileds时，采用了Map去重。<br>但是在读取值时，根据serializer的顺序，对于同名字段，子类的该字段值会被赋值两次，总是被父类的值覆盖，导致子类的字段值丢失。<br>2，序列化问题复杂对象变成了map<br>3，Data length too large<br>超过8k   修改 payload的值，将其调大 可以调节到16k<br>4，服务调用失败  No provider available<br>存在一个或多个Provider服务，但是version或者group不匹配。<br>例如Consumer侧申明version=1.0.0，而Provider侧申明version=2.0.0，或者group不匹配，都会出现这个ERROR。</p>\n<h2 id=\"dubbo遇到过什么序列化的问题\"><a href=\"#dubbo遇到过什么序列化的问题\" class=\"headerlink\" title=\"dubbo遇到过什么序列化的问题\"></a>dubbo遇到过什么序列化的问题</h2><h2 id=\"dubbo参数对象如果是object属性-可以传递过去吗\"><a href=\"#dubbo参数对象如果是object属性-可以传递过去吗\" class=\"headerlink\" title=\"dubbo参数对象如果是object属性 可以传递过去吗\"></a>dubbo参数对象如果是object属性 可以传递过去吗</h2><p>最近遇到一个问题，B 服务调用 A 服务时，返回值反序列化时，POJO对象变成了Map类型。<br>在A服务单独测试的时候一直还原不了，在 B 服务进行测试的时候，跟到反序列化数据时才看到原因。<br>A 服务的接口方法返回的结果是一个Object（或 Map&lt;String, Object&gt; 中的 value），<br>Object 的具体实现不在 A 服务的 API 包中，因此在 B 服务找不到该返回值真正的实现类，<br>在 B 服务调用接口返回结果反序列化找不到具体的类型时，就会以 Map 类型进行实例化。</p>\n<h3 id=\"Java序列化：\"><a href=\"#Java序列化：\" class=\"headerlink\" title=\"Java序列化：\"></a>Java序列化：</h3><p>Java序列化会把要序列化的对象类的元数据和业务数据全部序列化为字节流，而且是把整个继承关系上的东西全部序列化了。<br>它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。<br>但是由于确实是序列化了所有内容，所以可以说什么都可以传输，因此也更可用和可靠。</p>\n<h3 id=\"hession序列化：\"><a href=\"#hession序列化：\" class=\"headerlink\" title=\"hession序列化：\"></a>hession序列化：</h3><p>它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，<br>hessian会序列化成I 1这样的流，I表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，<br>hessian把对象所有的属性当成一个Map来序列化，产生类似M className propertyName1 I 1 propertyName S stringValue<br>（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。而在序列化过程中，如果一个对象之前出现过，<br>hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。<br>这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），<br>而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。而且同时因为并没有深入到实现内部去进行序列化，<br>所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。</p>\n<h2 id=\"zk特点-CAP-理论-CP-consist\"><a href=\"#zk特点-CAP-理论-CP-consist\" class=\"headerlink\" title=\"zk特点 CAP 理论  CP  consist\"></a>zk特点 CAP 理论  CP  consist</h2><h2 id=\"zk集群挂了会怎么办会投票-【myid-，zid】\"><a href=\"#zk集群挂了会怎么办会投票-【myid-，zid】\" class=\"headerlink\" title=\"zk集群挂了会怎么办会投票 【myid ，zid】\"></a>zk集群挂了会怎么办会投票 【myid ，zid】</h2><h2 id=\"MQ三大特性-解耦异步削峰\"><a href=\"#MQ三大特性-解耦异步削峰\" class=\"headerlink\" title=\"MQ三大特性 解耦异步削峰\"></a>MQ三大特性 解耦异步削峰</h2><h2 id=\"MQ-消息丢失\"><a href=\"#MQ-消息丢失\" class=\"headerlink\" title=\"MQ 消息丢失\"></a>MQ 消息丢失</h2><h2 id=\"rebbitMQ持久化是怎么持久化\"><a href=\"#rebbitMQ持久化是怎么持久化\" class=\"headerlink\" title=\"rebbitMQ持久化是怎么持久化\"></a>rebbitMQ持久化是怎么持久化</h2><p>将queue的持久化标识durable设置为true,则代表是一个持久的队列</p>\n<h2 id=\"redis分布式锁-lua脚本\"><a href=\"#redis分布式锁-lua脚本\" class=\"headerlink\" title=\"redis分布式锁 lua脚本\"></a>redis分布式锁 lua脚本</h2><p>redisson </p>\n<h2 id=\"redis如何保证原子性\"><a href=\"#redis如何保证原子性\" class=\"headerlink\" title=\"redis如何保证原子性\"></a>redis如何保证原子性</h2><p>单线程的</p>\n<h2 id=\"既然是单线程的，如何做到异步和非阻塞的\"><a href=\"#既然是单线程的，如何做到异步和非阻塞的\" class=\"headerlink\" title=\"既然是单线程的，如何做到异步和非阻塞的\"></a>既然是单线程的，如何做到异步和非阻塞的</h2><p>要明白他的线程模型是IO多路复用模型 主要核心是select channel  bufuer类 就是一个线程负责接收连接，其他线程负责解决对应的事务</p>\n<h2 id=\"redis-可以用来做什么\"><a href=\"#redis-可以用来做什么\" class=\"headerlink\" title=\"redis 可以用来做什么\"></a>redis 可以用来做什么</h2><p>1，缓存  2，分布式锁  3，zset 排名 4，索引 </p>\n<h2 id=\"redis-秒杀的功能是怎么做的\"><a href=\"#redis-秒杀的功能是怎么做的\" class=\"headerlink\" title=\"redis 秒杀的功能是怎么做的\"></a>redis 秒杀的功能是怎么做的</h2><p>1，限流和降级 按钮置灰 nginx限流  2，队列削峰MQ  3，服务层分包部署  4，查询的时候查询redis 缓存</p>\n<h2 id=\"多线程是怎么用的\"><a href=\"#多线程是怎么用的\" class=\"headerlink\" title=\"多线程是怎么用的\"></a>多线程是怎么用的</h2><p>多线程newcache 保证线程无线 CPU消耗比较大  newfixed 线程数固定 但是队列无线，内存不友好</p>\n<h2 id=\"有无遇到OOM的问题\"><a href=\"#有无遇到OOM的问题\" class=\"headerlink\" title=\"有无遇到OOM的问题\"></a>有无遇到OOM的问题</h2><h2 id=\"jvm垃圾回收机制-标记计数算法-可达性算法-标记清理-标记整理-复制算法\"><a href=\"#jvm垃圾回收机制-标记计数算法-可达性算法-标记清理-标记整理-复制算法\" class=\"headerlink\" title=\"jvm垃圾回收机制 标记计数算法 可达性算法 标记清理 标记整理 复制算法\"></a>jvm垃圾回收机制 标记计数算法 可达性算法 标记清理 标记整理 复制算法</h2><h2 id=\"几个垃圾收集器-CMS标记清理-G1\"><a href=\"#几个垃圾收集器-CMS标记清理-G1\" class=\"headerlink\" title=\"几个垃圾收集器  CMS标记清理  G1\"></a>几个垃圾收集器  CMS标记清理  G1</h2><h2 id=\"服务挂了的话怎么办-linux-怎么去查服务器日志\"><a href=\"#服务挂了的话怎么办-linux-怎么去查服务器日志\" class=\"headerlink\" title=\"服务挂了的话怎么办 linux 怎么去查服务器日志\"></a>服务挂了的话怎么办 linux 怎么去查服务器日志</h2><p>linux日志文件说明<br>/var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一<br>/var/log/secure 与安全相关的日志信息<br>/var/log/maillog 与邮件相关的日志信息<br>/var/log/cron 与定时任务相关的日志信息<br>/var/log/spooler 与UUCP和news设备相关的日志信息<br>/var/log/boot.log 守护进程启动和停止相关的日志消息<br>/var/log/wtmp 该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件</p>\n<h3 id=\"Java应用程序的问题：发生OOM导致进程Crash\"><a href=\"#Java应用程序的问题：发生OOM导致进程Crash\" class=\"headerlink\" title=\"Java应用程序的问题：发生OOM导致进程Crash\"></a>Java应用程序的问题：发生OOM导致进程Crash</h3><p>最常见的是发生堆内存异常“java.lang.OutOfMemoryError: Java heap space”，排查步骤如下：<br>Step1: 查看JVM参数 -XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath=*/java.hprof；<br>Step2: 根据HeapDumpPath指定的路径查看是否产生dump文件；<br>Step3: 若存在dump文件，使用Jhat、VisualVM等工具分析即可；</p>\n<h3 id=\"JVM出错：JVM或JDK自身的Bug导致进程Crash\"><a href=\"#JVM出错：JVM或JDK自身的Bug导致进程Crash\" class=\"headerlink\" title=\"JVM出错：JVM或JDK自身的Bug导致进程Crash\"></a>JVM出错：JVM或JDK自身的Bug导致进程Crash</h3><p>当JVM出现致命错误时，会生成一个错误文件 hs_err_pid.log，其中包括了导致jvm crash的重要信息，<br>可以通过分析该文件定位到导致crash的根源，从而改善以保证系统稳定。当出现crash时，该文件默认会生成到工作目录下，<br>然而可以通过jvm参数-XX:ErrorFile指定生成路径。</p>\n<h3 id=\"被操作系统OOM-Killer\"><a href=\"#被操作系统OOM-Killer\" class=\"headerlink\" title=\"被操作系统OOM-Killer\"></a>被操作系统OOM-Killer</h3><p>Step1: 查看操作系统日志：sudo grep –color “java” /var/log/messages，确定Java进程是否被操作系统Kill；<br>Step2: 若被操作系统Kill，执行dmesg命令查看系统各进程资源占用情况，明确Java占用内存是否合理，<br>以及是否有其它进程不合理的占用了大量内存空间；</p>\n<h2 id=\"数据库横表与纵表的区分-没什么卵用-都是到横表的\"><a href=\"#数据库横表与纵表的区分-没什么卵用-都是到横表的\" class=\"headerlink\" title=\"数据库横表与纵表的区分  没什么卵用 都是到横表的\"></a>数据库横表与纵表的区分  没什么卵用 都是到横表的</h2><p> 横表就是普通的建表方式，如一个表结构为： 主键、字段1、字段2、字段3。。。 如果变成纵表后，<br> 则表结构为： 主键、字段代码、字段值。 而字段代码则为字段1、字段2、字段3。</p>\n<h2 id=\"TIDB-最新数据库\"><a href=\"#TIDB-最新数据库\" class=\"headerlink\" title=\"TIDB 最新数据库\"></a>TIDB 最新数据库</h2><p>mysql的一个封装，加快查询效率</p>\n<h2 id=\"tcp的头标记\"><a href=\"#tcp的头标记\" class=\"headerlink\" title=\"tcp的头标记\"></a>tcp的头标记</h2><h2 id=\"rpc-主要框架及对比-dubbo-grpc-thrift-dubbox-motan\"><a href=\"#rpc-主要框架及对比-dubbo-grpc-thrift-dubbox-motan\" class=\"headerlink\" title=\"rpc 主要框架及对比  dubbo  grpc  thrift dubbox  motan\"></a>rpc 主要框架及对比  dubbo  grpc  thrift dubbox  motan</h2><p>grpc是一个轻量级的java RPC框架。它支持服务注册和发现。<br>dubbox有比价完善的服务治理模型，其包含ZK注册中心，服务监控等，可以很方便的为我们服务。<br>motan新浪微博开源的RPC框架<br>grpc是Google出品，使用了PB协议，但是由于它出现的比较晚，还不怎么成熟，而且采用http协议，非常适合现在的微服务，<br>    不过性能上差了许多，而且像服务治理与监控都需要额外的开发工作，所以放弃grpc。<br>thrift和grpc一样，性能优越，但是开发难度相比较于dubbox和motan也是高了一点点，<br>    需要编写proto文件（其实对于程序员来说这算不上难度）。像服务治理与监控也是需要额外的开发工作。<br>dubbo比较老了，直接弃用。<br>dubbox和后来的motan都比较适合我们的团队。dubbox后来经过当当的开发，引入了rest风格的http协议，<br>并且还支持kryo/fst/dubbo/thrift等其他协议，而且其他团队也在使用dubbo，集成方便，服务治理监控功能齐全，所以最终采用dubbox。<br>其实我个人而言还是喜欢thrift，毕竟性能优越，在大型分布式系统中，哪怕一点点性能提升累计在一起也是很可观的。<br>不过再具体选型的过程中还要结合团队目前的状况和团队其他开发人员的接受程度进行取舍。</p>\n<h1 id=\"易工品\"><a href=\"#易工品\" class=\"headerlink\" title=\"易工品\"></a>易工品</h1><h2 id=\"springcloud-alibaba-跟springcloud的区别\"><a href=\"#springcloud-alibaba-跟springcloud的区别\" class=\"headerlink\" title=\"springcloud alibaba 跟springcloud的区别\"></a>springcloud alibaba 跟springcloud的区别</h2><p>注册中心不一样 nacos 集成了Ribbon eureka</p>\n<h2 id=\"最新关注技术点-tidb-优点\"><a href=\"#最新关注技术点-tidb-优点\" class=\"headerlink\" title=\"最新关注技术点 tidb 优点\"></a>最新关注技术点 tidb 优点</h2><h2 id=\"做的业务点\"><a href=\"#做的业务点\" class=\"headerlink\" title=\"做的业务点\"></a>做的业务点</h2><h2 id=\"zk的业务场景-zk的特点\"><a href=\"#zk的业务场景-zk的特点\" class=\"headerlink\" title=\"zk的业务场景 zk的特点\"></a>zk的业务场景 zk的特点</h2><h2 id=\"rocketmq-卡夫卡-和-rabbitmq的比较\"><a href=\"#rocketmq-卡夫卡-和-rabbitmq的比较\" class=\"headerlink\" title=\"rocketmq 卡夫卡 和 rabbitmq的比较\"></a>rocketmq 卡夫卡 和 rabbitmq的比较</h2><p>吞吐量 ：卡夫卡》rocketmq》rabbitmq<br>接收的模式：卡夫卡拉取：rabbitmq 推拉</p>\n<h2 id=\"所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\"><a href=\"#所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\" class=\"headerlink\" title=\"所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\"></a>所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？</h2><h2 id=\"财务金额用的是什么类型存储，怎么去做取整的操作\"><a href=\"#财务金额用的是什么类型存储，怎么去做取整的操作\" class=\"headerlink\" title=\"财务金额用的是什么类型存储，怎么去做取整的操作\"></a>财务金额用的是什么类型存储，怎么去做取整的操作</h2><h2 id=\"mysql的变更通知\"><a href=\"#mysql的变更通知\" class=\"headerlink\" title=\"mysql的变更通知\"></a>mysql的变更通知</h2><h2 id=\"单元测试是怎么做的\"><a href=\"#单元测试是怎么做的\" class=\"headerlink\" title=\"单元测试是怎么做的\"></a>单元测试是怎么做的</h2><p>Junit框架，在大多数java的开发环境中已经集成，</p>\n<h2 id=\"生产故障\"><a href=\"#生产故障\" class=\"headerlink\" title=\"生产故障\"></a>生产故障</h2><h2 id=\"图数据库和时序数据库\"><a href=\"#图数据库和时序数据库\" class=\"headerlink\" title=\"图数据库和时序数据库\"></a>图数据库和时序数据库</h2><h2 id=\"承担什么责任-做一个项目碰到什么难题\"><a href=\"#承担什么责任-做一个项目碰到什么难题\" class=\"headerlink\" title=\"承担什么责任  做一个项目碰到什么难题\"></a>承担什么责任  做一个项目碰到什么难题</h2><p>电商  支付模块 </p>\n<p>奥悦家<br>用户支付同步天问接口回调很慢的话怎么办  ，然后会导致用户重复缴费两次<br>1，先异步返回，然后给数据库设置一个在缴费中的标志位，返回给业主说正在缴费中<br>2，起一个线程去不断查询天问系统接口，然后接收回调接口的返回<br>3，在缴费之后就先用redis把查询的费用设置为0，就是说先去redis 查询费用，如果没有的话就去天问查，如果有的话就看多少钱<br>使用dubbo中遇到什么问题<br>序列化的问题—-复杂对象的时候会 变成map<br>服务调用失败  No provider available—–版本号不一致<br>Data length too large 超过8k——-修改 payload的值，将其调大 可以调节到16k</p>\n<p>奥悦团购  超卖库存的问题 秒杀<br>1前端<br>面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】<br>　　A：扩容<br>　　加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。<br>　　B：静态化<br>　　将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。<br>　　C：限流<br>　　一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。<br>　　或者活动入口的时候增加游戏或者问题环节进行消峰操作。<br>　　<br>2后端<br>A：将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，<br>并且由于Redis的写性能和读性能都远高于MySQL，<br>这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。<br>B：引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。<br>当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。<br>C：利用Java的锁机制CAS来实现减库存操作<br>D：写sql乐观锁的概念，增加了版本号，<br>//1.查询出商品信息<br>select stock, version from t_goods where id=1;<br>//2.根据商品信息生成订单<br>insert into t_orders (id,goods_id) values (null,1);<br>//3.修改商品库存<br>update t_goods set stock=stock-1, version = version+1 where id=1, version=version;<br>当A线程来更新数量的时候先看版本号有没有动，如果已经变了那就不改并且返回，如果没变，这个时候就更改库存，并且把版本号加一<br>E：分布式锁<br>setnx指令，如果能拿到对应标志位的锁的话，那就成功获取锁，并且更改库存，如果不行的话，那就直接返回抢购失败</p>\n<h1 id=\"中移\"><a href=\"#中移\" class=\"headerlink\" title=\"中移\"></a>中移</h1><h2 id=\"maven调用链依赖重复依赖是怎么解决的\"><a href=\"#maven调用链依赖重复依赖是怎么解决的\" class=\"headerlink\" title=\"maven调用链依赖重复依赖是怎么解决的\"></a>maven调用链依赖重复依赖是怎么解决的</h2><p>当一个项目中出现重复的依赖包时，maven 2.0.9之后的版本会用如下的规则来决定使用哪一个版本的包：<br>最短路径原则<br>比如有如下两个依赖关系：<br>A -&gt; B -&gt; C -&gt; D(V1)<br>F -&gt; G -&gt; D(V2)<br>这个时候项目中就出现了两个版本的D，这时maven会采用最短路径原则，选择V2版本的D，因为V1版本的D是由A包间接依赖的，整个依赖路径长度为3，而V2版本的D是由F包间接依赖的，整个依赖路径长度为2。<br>声明优先原则<br>假设有如下两个依赖关系：<br>A -&gt; B -&gt; D(V1)<br>F -&gt; G -&gt; D(V2)<br>这个时候因为两个版本的D的依赖路径都是一样长，最短路径原则就失效了。这个时候Maven的解决方案是：<br>按照依赖包在pom.xml中声明的先后顺序，优先选择先声明的包</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","site":{"data":{}},"excerpt":"<p>摘要:java面试总结</p>","more":"<h1 id=\"dubbo底层rpc-原理\"><a href=\"#dubbo底层rpc-原理\" class=\"headerlink\" title=\"dubbo底层rpc 原理\"></a>dubbo底层rpc 原理</h1><p>ip 和端口 通过socket连接</p>\n<h1 id=\"mysql主从原理-binlog-gt-relaylog\"><a href=\"#mysql主从原理-binlog-gt-relaylog\" class=\"headerlink\" title=\"mysql主从原理 binlog -&gt;relaylog\"></a>mysql主从原理 binlog -&gt;relaylog</h1><h1 id=\"动态代理跟静态代理啥区别\"><a href=\"#动态代理跟静态代理啥区别\" class=\"headerlink\" title=\"动态代理跟静态代理啥区别\"></a>动态代理跟静态代理啥区别</h1><p>静态代理是直接代理，就是定义一个接口，然后A类实现它，然后另外B类也实现这个接口，B类里面有A类实现每个方法，这样实现的时候B类就可以代替A类，这就叫静态代理<br>JDK动态代理是通过invocationhandle实现的 实现一个类实现invocationhandle 实现invoce方法，然后强制转换成对应Proxy类，就不用实现接口的每个方法<br>CGlib动态代理类是通过MethodInterceptor  实现的，实现一个类实现MethodInterceptor ，实现intercept 方法， 然后强制转换成newProxy类</p>\n<h1 id=\"cglib动态代理跟jdk动态代理啥区别\"><a href=\"#cglib动态代理跟jdk动态代理啥区别\" class=\"headerlink\" title=\"cglib动态代理跟jdk动态代理啥区别\"></a>cglib动态代理跟jdk动态代理啥区别</h1><p>接口走jdk动态代理，其他走cjlib</p>\n<h1 id=\"怎么实现动态代理，原理\"><a href=\"#怎么实现动态代理，原理\" class=\"headerlink\" title=\"怎么实现动态代理，原理\"></a>怎么实现动态代理，原理</h1><h1 id=\"rebbitmq-exchange-分几类\"><a href=\"#rebbitmq-exchange-分几类\" class=\"headerlink\" title=\"rebbitmq   exchange 分几类\"></a>rebbitmq   exchange 分几类</h1><h1 id=\"有没看mybatis源码-mybatis怎么映射到dao的\"><a href=\"#有没看mybatis源码-mybatis怎么映射到dao的\" class=\"headerlink\" title=\"有没看mybatis源码 mybatis怎么映射到dao的\"></a>有没看mybatis源码 mybatis怎么映射到dao的</h1><h1 id=\"线程状态，怎么变成死锁\"><a href=\"#线程状态，怎么变成死锁\" class=\"headerlink\" title=\"线程状态，怎么变成死锁\"></a>线程状态，怎么变成死锁</h1><h1 id=\"synchronized和reentrantlock-底层原理\"><a href=\"#synchronized和reentrantlock-底层原理\" class=\"headerlink\" title=\"synchronized和reentrantlock 底层原理\"></a>synchronized和reentrantlock 底层原理</h1><h1 id=\"synchronized除了cas还有锁升级\"><a href=\"#synchronized除了cas还有锁升级\" class=\"headerlink\" title=\"synchronized除了cas还有锁升级\"></a>synchronized除了cas还有锁升级</h1><h1 id=\"synchronized-的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\"><a href=\"#synchronized-的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\" class=\"headerlink\" title=\"synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，\"></a>synchronized 的实现涉及到锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁，</h1><h1 id=\"reentrantlock-除了CAS-还有AQS\"><a href=\"#reentrantlock-除了CAS-还有AQS\" class=\"headerlink\" title=\"reentrantlock 除了CAS  还有AQS\"></a>reentrantlock 除了CAS  还有AQS</h1><h1 id=\"spring-单例模式-工厂模式-观察者模式\"><a href=\"#spring-单例模式-工厂模式-观察者模式\" class=\"headerlink\" title=\"spring 单例模式 工厂模式  观察者模式\"></a>spring 单例模式 工厂模式  观察者模式</h1><h1 id=\"观察者模式主要用于什么地方\"><a href=\"#观察者模式主要用于什么地方\" class=\"headerlink\" title=\"观察者模式主要用于什么地方\"></a>观察者模式主要用于什么地方</h1><h1 id=\"spring事务是属于哪里的，代码怎么实现\"><a href=\"#spring事务是属于哪里的，代码怎么实现\" class=\"headerlink\" title=\"spring事务是属于哪里的，代码怎么实现\"></a>spring事务是属于哪里的，代码怎么实现</h1><h1 id=\"nio原理\"><a href=\"#nio原理\" class=\"headerlink\" title=\"nio原理\"></a>nio原理</h1><h1 id=\"netty线程模式\"><a href=\"#netty线程模式\" class=\"headerlink\" title=\"netty线程模式\"></a>netty线程模式</h1><h1 id=\"dubbo使用的时候遇到过什么问题\"><a href=\"#dubbo使用的时候遇到过什么问题\" class=\"headerlink\" title=\"dubbo使用的时候遇到过什么问题\"></a>dubbo使用的时候遇到过什么问题</h1><h1 id=\"mysql-建表的时候要注意什么\"><a href=\"#mysql-建表的时候要注意什么\" class=\"headerlink\" title=\"mysql 建表的时候要注意什么\"></a>mysql 建表的时候要注意什么</h1><h1 id=\"mysql中-使用explain时应注意那些字段\"><a href=\"#mysql中-使用explain时应注意那些字段\" class=\"headerlink\" title=\"mysql中 使用explain时应注意那些字段\"></a>mysql中 使用explain时应注意那些字段</h1><h1 id=\"热部署-冷部署\"><a href=\"#热部署-冷部署\" class=\"headerlink\" title=\"热部署 冷部署\"></a>热部署 冷部署</h1><h1 id=\"docker\"><a href=\"#docker\" class=\"headerlink\" title=\"docker\"></a>docker</h1><h1 id=\"k8s其他功能\"><a href=\"#k8s其他功能\" class=\"headerlink\" title=\"k8s其他功能\"></a>k8s其他功能</h1><h1 id=\"引用的分类\"><a href=\"#引用的分类\" class=\"headerlink\" title=\"#引用的分类\"></a>#引用的分类</h1><h2 id=\"强引用-jvm-情愿爆出OOM-也不回收的对象\"><a href=\"#强引用-jvm-情愿爆出OOM-也不回收的对象\" class=\"headerlink\" title=\"强引用   jvm 情愿爆出OOM 也不回收的对象\"></a>强引用   jvm 情愿爆出OOM 也不回收的对象</h2><h2 id=\"弱引用-jvm查到的话就会回收-不管内存够不够\"><a href=\"#弱引用-jvm查到的话就会回收-不管内存够不够\" class=\"headerlink\" title=\"弱引用    jvm查到的话就会回收 不管内存够不够\"></a>弱引用    jvm查到的话就会回收 不管内存够不够</h2><h2 id=\"软引用-Jvm-如果内存不够用的时候就会回收\"><a href=\"#软引用-Jvm-如果内存不够用的时候就会回收\" class=\"headerlink\" title=\"软引用    Jvm 如果内存不够用的时候就会回收\"></a>软引用    Jvm 如果内存不够用的时候就会回收</h2><h2 id=\"虚引用-jvm看到就回收\"><a href=\"#虚引用-jvm看到就回收\" class=\"headerlink\" title=\"虚引用    jvm看到就回收\"></a>虚引用    jvm看到就回收</h2><h1 id=\"字节面试一面总结\"><a href=\"#字节面试一面总结\" class=\"headerlink\" title=\"字节面试一面总结\"></a>字节面试一面总结</h1><h1 id=\"算法题\"><a href=\"#算法题\" class=\"headerlink\" title=\"算法题\"></a>算法题</h1><p>在一个字符串S内查找一个子串s的出现位置。<br>public static int indexOf(char[] chars, char[] sub) {<br>return -1;<br>}</p>\n<h1 id=\"如何保证RabbitMQ不被重复消费？\"><a href=\"#如何保证RabbitMQ不被重复消费？\" class=\"headerlink\" title=\"如何保证RabbitMQ不被重复消费？\"></a>如何保证RabbitMQ不被重复消费？</h1><h1 id=\"如何保证RabbitMQ消息的可靠传输？\"><a href=\"#如何保证RabbitMQ消息的可靠传输？\" class=\"headerlink\" title=\"如何保证RabbitMQ消息的可靠传输？\"></a>如何保证RabbitMQ消息的可靠传输？</h1><h1 id=\"activeMQ\"><a href=\"#activeMQ\" class=\"headerlink\" title=\"activeMQ\"></a>activeMQ</h1><h1 id=\"dubbo-与springcloud-区别\"><a href=\"#dubbo-与springcloud-区别\" class=\"headerlink\" title=\"dubbo 与springcloud 区别\"></a>dubbo 与springcloud 区别</h1><h1 id=\"zookeeper-单节点还是多节点-如果挂了怎么办\"><a href=\"#zookeeper-单节点还是多节点-如果挂了怎么办\" class=\"headerlink\" title=\"zookeeper 单节点还是多节点 如果挂了怎么办\"></a>zookeeper 单节点还是多节点 如果挂了怎么办</h1><h1 id=\"zk集群是怎么部署的\"><a href=\"#zk集群是怎么部署的\" class=\"headerlink\" title=\"zk集群是怎么部署的\"></a>zk集群是怎么部署的</h1><h1 id=\"并发锁-分布式锁\"><a href=\"#并发锁-分布式锁\" class=\"headerlink\" title=\"并发锁 分布式锁\"></a>并发锁 分布式锁</h1><h1 id=\"支付宝微信调用过程中怎么确保安全\"><a href=\"#支付宝微信调用过程中怎么确保安全\" class=\"headerlink\" title=\"支付宝微信调用过程中怎么确保安全\"></a>支付宝微信调用过程中怎么确保安全</h1><h1 id=\"微信支付宝是怎么做订单的拦截消费\"><a href=\"#微信支付宝是怎么做订单的拦截消费\" class=\"headerlink\" title=\"微信支付宝是怎么做订单的拦截消费\"></a>微信支付宝是怎么做订单的拦截消费</h1><h1 id=\"mysql-索引的实现原理\"><a href=\"#mysql-索引的实现原理\" class=\"headerlink\" title=\"mysql 索引的实现原理\"></a>mysql 索引的实现原理</h1><h1 id=\"mysql-节点存储的是什么-非叶子节点-和叶子节点\"><a href=\"#mysql-节点存储的是什么-非叶子节点-和叶子节点\" class=\"headerlink\" title=\"mysql 节点存储的是什么 非叶子节点 和叶子节点\"></a>mysql 节点存储的是什么 非叶子节点 和叶子节点</h1><h1 id=\"一个节点最大存储-16K\"><a href=\"#一个节点最大存储-16K\" class=\"headerlink\" title=\"一个节点最大存储 16K\"></a>一个节点最大存储 16K</h1><h1 id=\"16k是相对于什么来说的\"><a href=\"#16k是相对于什么来说的\" class=\"headerlink\" title=\"16k是相对于什么来说的\"></a>16k是相对于什么来说的</h1><h1 id=\"Username-查询-最左前缀原则-为什么\"><a href=\"#Username-查询-最左前缀原则-为什么\" class=\"headerlink\" title=\"Username 查询 % 最左前缀原则 为什么\"></a>Username 查询 % 最左前缀原则 为什么</h1><h1 id=\"浩鲸科技一面\"><a href=\"#浩鲸科技一面\" class=\"headerlink\" title=\"浩鲸科技一面\"></a>浩鲸科技一面</h1><h2 id=\"dubbo重试机制\"><a href=\"#dubbo重试机制\" class=\"headerlink\" title=\"dubbo重试机制\"></a>dubbo重试机制</h2><p>1，Dubbo支持多种失败重试机制：<br>Failover Cluster - 失败自动切换<br>Failfast Cluster - 快速失败<br>Failsafe Cluster - 失败安全<br>Failback Cluster - 失败自动恢复<br>Forking Cluster - 并行调用多个服务提供者<br>Broadcast - 广播轮询调用所有Provider</p>\n<h2 id=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"><a href=\"#zk服务注册发现过程，如果一个断了，怎么通知到对方\" class=\"headerlink\" title=\"zk服务注册发现过程，如果一个断了，怎么通知到对方\"></a>zk服务注册发现过程，如果一个断了，怎么通知到对方</h2><p>这里写的非常清楚<a href=\"https://blog.csdn.net/zyhlwzy/article/details/101847565\">zk服务注册发现过程</a><br>1，要清楚zk的数据模型，主要是一个树形结构，也就是目录结构 eg:/11/22/33 数据模型中的每一个节点，Zookeeper称之为Znode<br>2，zk的watcher机制，和znode绑定的一个监听器，当有节点不提供服务的时候自动提示<br>3，具体流程<br>1）客户端调用getData方法向服务器获取某个Znode节点的数据时，设置watch为true。<br>服务端接到请求后，返回节点的数据，并在维护的WatchTable中插入被Watch的Znode路径以及Watcher（watch该Znode的客户端）；<br>2）当被Watch的Znode被删除或者更新之后，Zookeeper服务器会查找Watch Table，找到在Znode上对应的所有Watcher，<br>异步通知对应的客户端，并且删除Watch Table中对应的Key：Value；<br>4，zk的服务注册和发现流程<br>1）服务注册：服务提供者（Provider）启动时，会向Zookeeper服务端注册服务信息，<br>即会在Zookeeper服务器上创建一个服务节点，并在节点上存储服务的相关数据（如服务提供者的ip地址、端口等），比如注册一个用户注册服务（user/register）:<br>2）服务发现：服务消费者（Consumer）启动时，会根据本身依赖的服务信息，向Zookeeper服务端获取注册的服务信息并设置Watch，<br>获取到注册的服务信息之后将服务提供者信息缓存在本地，调用服务时直接根据从Zookeeper注册中心获取到的服务注册信息调用服务，比如发现用户注册服务（user/register）并调用。<br>3）服务通知（类似服务心跳检测）：当服务提供者因为某种原因宕机或不提供服务之后，Zookeeper服务注册中心的对应服务节点会被删除，<br>因为服务消费者在获取服务信息的时候在对应节点上设置了Watch，因此节点删除之后会触发对应的Watcher，<br>Zookeeper注册中心会异步向服务所关联的所有服务消费者发出节点删除的通知，服务消费者根据收到的通知更新缓存的服务列表。</p>\n<h2 id=\"zk节点类型\"><a href=\"#zk节点类型\" class=\"headerlink\" title=\"zk节点类型\"></a>zk节点类型</h2><p>1.持久节点(PERSISTENT)<br>持久节点，创建后一直存在，直到主动删除此节点。<br>2.持久顺序节点(PERSISTENT_SEQUENTIAL)<br>持久顺序节点，创建后一直存在，直到主动删除此节点。在ZK中，每个父节点会为它的第一级子节点维护一份时序，记录每个子节点创建的先后顺序。<br>3.临时节点(EPHEMERAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。<br>4.顺序临时节点(EPHEMERAL_SEQUENTIAL)<br>临时节点在客户端会话失效后节点自动清除。临时节点下面不能创建子节点。父节点getChildren会获得顺序的节点列表。</p>\n<h2 id=\"zk还可以用来做什么，具体怎么实现\"><a href=\"#zk还可以用来做什么，具体怎么实现\" class=\"headerlink\" title=\"zk还可以用来做什么，具体怎么实现\"></a>zk还可以用来做什么，具体怎么实现</h2><p>1,分布式锁，具体实现方式<br>1）znode 可以被监控。<br>节点数据修改、子节点变化、节点删除等。<br>一旦变化可以通知设置监控的客户端。<br>通过这个特性可以实现的功能包括配置的集中管理，集群管理，分布式锁等等。<br>2）分布式锁步骤。<br>注：zk设置watcher的操作和读操作是原子的。读取子节点列表同时设置监听器<br>    1. 父节点持久节点/lock<br>    2. 所有客户端在/lock下创建 瞬时有序节点/lock/seq-0000000000、/lock/seq-0000000001、依次类推<br>    3. 获取/lock下所有子节点getChildren(“/lock”)方法，判断自己是否为最小的。是：获取锁； 否：监听自己前一位子节点的删除消息(调用exist()方法，同时注册事件监听。 )，<br>    获得通知后重复该步骤。<br>    4. 执行代码。完成后释放锁。<br>4）使用zookeeper + curator，完成分布式锁。</p>\n<h2 id=\"redis与mysql-怎么做到缓存一致性\"><a href=\"#redis与mysql-怎么做到缓存一致性\" class=\"headerlink\" title=\"redis与mysql 怎么做到缓存一致性\"></a>redis与mysql 怎么做到缓存一致性</h2><p>1、MySQL binlog增量发布订阅消费+消息队列+增量数据更新到redis<br>    1）读请求走Redis：热数据基本都在Redis<br>    2）写请求走MySQL: 增删改都操作MySQL<br>    3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis<br>2、Redis更新<br>    1）数据操作主要分为两块：<br>    一个是全量(将全部数据一次写入到redis)<br>    一个是增量（实时更新）<br>    这里说的是增量,指的是mysql的update、insert、delate变更数据。<br>    这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。就无需在从业务线去操作缓存内容<br>    2）每次写数据库的时候都把redis的数据给删掉，读数据库的时候再保存到redis 缓存<br>3、延迟双删，一定程度可以解决，就是写数据库之后 睡眠一段时间，然后再删除一次，但是不一定百分百解决问题，而且延迟了主线程<br>4，分布式锁，可以解决，并发问题串行化，但是效率低<br>5，读锁，写锁可以一定程度优化，读多写少，读读不互斥，写写互斥</p>\n<h2 id=\"怎么保证redis-高可用\"><a href=\"#怎么保证redis-高可用\" class=\"headerlink\" title=\"怎么保证redis 高可用\"></a>怎么保证redis 高可用</h2><p>redis高并发：主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10万的QPS。<br>redis高并发的同时，还需要容纳大量的数据：一主多从，每个实例都容纳了完整的数据，比如redis主就10G的内存量，其实你最多只能容纳10g的数据量。<br>如果你的缓存要容纳的数据量很大，达到了几十g，甚至几百g，或者是几t，那你就需要redis集群，而且用redis集群之后，可以提供可能每秒几十万的读写并发。<br>redis高可用：如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换。</p>\n<h2 id=\"redis-集群是怎么搭建的\"><a href=\"#redis-集群是怎么搭建的\" class=\"headerlink\" title=\"redis 集群是怎么搭建的\"></a>redis 集群是怎么搭建的</h2><p>当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。<br>如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据;如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。<br>开始full resynchronization的时候，master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。<br>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。</p>\n<h2 id=\"分库分表\"><a href=\"#分库分表\" class=\"headerlink\" title=\"分库分表\"></a>分库分表</h2><p>java中主要是用的是Sharding-JDBC分库分表  整合springboot 非常方便</p>\n<h2 id=\"分布式事务是怎么做的seata\"><a href=\"#分布式事务是怎么做的seata\" class=\"headerlink\" title=\"分布式事务是怎么做的seata\"></a>分布式事务是怎么做的seata</h2><ol>\n<li>二阶段提交协议 (2PC)<br> 协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。<br> 1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志<br> 2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。<br> 缺点<br> 1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行<br> 2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。<br> 3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，<br> 但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</li>\n<li>三阶段提交协议 (3PC)<br>针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。<br>三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。<br> 1），为甚需要cancommit<br> 假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。<br> 协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。<br> 协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？<br> 所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。<br> 2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务<br> 因为在precommit阶段已经知道所有节点都同意提交事务了</li>\n<li>基于消息的分布式事务<br> 基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失<h2 id=\"session与token和cookie区别\"><a href=\"#session与token和cookie区别\" class=\"headerlink\" title=\"session与token和cookie区别\"></a>session与token和cookie区别</h2>1，session的中文翻译是“会话”，当用户打开某个web应用时，便与web服务器产生一次session<br>2，cookie是保存在本地终端的数据。cookie由服务器生成，发送给浏览器，浏览器把cookie以kv形式保存到某个目录下的文本文件内，下一次请求同一网站时会把该cookie发送给服务器<br>3，token的意思是“令牌”，是用户身份的验证方式，最简单的token组成uid<br>cookie 和session的区别<br>1）、cookie数据存放在客户的浏览器上，session数据放在服务器上。<br>2）、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗<br>考虑到安全应当使用session。<br>3）、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能<br>考虑到减轻服务器性能方面，应当使用COOKIE。<br>4）、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。</li>\n</ol>\n<p>5)、所以个人建议：<br>   将登陆信息等重要信息存放为SESSION<br>   其他信息如果需要保留，可以放在COOKIE中</p>\n<h1 id=\"shein一面\"><a href=\"#shein一面\" class=\"headerlink\" title=\"shein一面\"></a>shein一面</h1><h2 id=\"springboot有什么优点-特性\"><a href=\"#springboot有什么优点-特性\" class=\"headerlink\" title=\"springboot有什么优点 特性\"></a>springboot有什么优点 特性</h2><h2 id=\"mysql-插入一千条一万条语句怎么办\"><a href=\"#mysql-插入一千条一万条语句怎么办\" class=\"headerlink\" title=\"mysql 插入一千条一万条语句怎么办\"></a>mysql 插入一千条一万条语句怎么办</h2><p>INSERT INTO<br>items(name,city,price,number,picture)<br>VALUES<br>(‘耐克运动鞋’,’广州’,500,1000,’003.jpg’),<br>……<br>(‘耐克运动鞋2’,’广州2’,500,1000,’002.jpg’);</p>\n<p>java代码的话是先用for循环先拼接好，然后再拼接语句insert ，然后再执行代码</p>\n<h2 id=\"慢查询怎么看然后怎么优化-举个栗子\"><a href=\"#慢查询怎么看然后怎么优化-举个栗子\" class=\"headerlink\" title=\"慢查询怎么看然后怎么优化  举个栗子\"></a>慢查询怎么看然后怎么优化  举个栗子</h2><h2 id=\"ABC-三列组合索引-这个时候-A-B-in-C-这个时候会不会走索引\"><a href=\"#ABC-三列组合索引-这个时候-A-B-in-C-这个时候会不会走索引\" class=\"headerlink\" title=\"ABC 三列组合索引 这个时候 A= B in C =   这个时候会不会走索引\"></a>ABC 三列组合索引 这个时候 A= B in C =   这个时候会不会走索引</h2><h2 id=\"为什么最左前缀只走第一列-最左前缀原理-要清楚存储数据原理-一个节点存储了三个值-代表三个数值\"><a href=\"#为什么最左前缀只走第一列-最左前缀原理-要清楚存储数据原理-一个节点存储了三个值-代表三个数值\" class=\"headerlink\" title=\"为什么最左前缀只走第一列  最左前缀原理 要清楚存储数据原理 一个节点存储了三个值 代表三个数值\"></a>为什么最左前缀只走第一列  最左前缀原理 要清楚存储数据原理 一个节点存储了三个值 代表三个数值</h2><h2 id=\"mybatis-常用标签-foreach\"><a href=\"#mybatis-常用标签-foreach\" class=\"headerlink\" title=\"mybatis 常用标签 foreach\"></a>mybatis 常用标签 foreach</h2><h2 id=\"redis-常用指令-lpush-lset\"><a href=\"#redis-常用指令-lpush-lset\" class=\"headerlink\" title=\"redis 常用指令 lpush  lset\"></a>redis 常用指令 lpush  lset</h2><h2 id=\"rabbitmq-确认机制怎么实现-publisher-confirms\"><a href=\"#rabbitmq-确认机制怎么实现-publisher-confirms\" class=\"headerlink\" title=\"rabbitmq 确认机制怎么实现 publisher-confirms\"></a>rabbitmq 确认机制怎么实现 publisher-confirms</h2><h2 id=\"elk-Elasticserarch-Logstash-Kibana\"><a href=\"#elk-Elasticserarch-Logstash-Kibana\" class=\"headerlink\" title=\"elk  (Elasticserarch + Logstash + Kibana)\"></a>elk  (Elasticserarch + Logstash + Kibana)</h2><h2 id=\"romda-表达式\"><a href=\"#romda-表达式\" class=\"headerlink\" title=\"romda 表达式\"></a>romda 表达式</h2><p>分组        Map&lt;String, List<User>&gt; groupBySex = userList.stream().collect(Collectors.groupingBy(User::getSex));<br>过滤        List<User> userCommonList = userList.stream().filter(a -&gt; !a.getJobNumber().equals(“201901”)).collect(Collectors.toList());</p>\n<h2 id=\"为什么要使用联合索引\"><a href=\"#为什么要使用联合索引\" class=\"headerlink\" title=\"为什么要使用联合索引\"></a>为什么要使用联合索引</h2><h3 id=\"减少开销。建一个联合索引-col1-col2-col3-，实际相当于建了-col1-col1-col2-col1-col2-col3-三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\"><a href=\"#减少开销。建一个联合索引-col1-col2-col3-，实际相当于建了-col1-col1-col2-col1-col2-col3-三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\" class=\"headerlink\" title=\"减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。\"></a>减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。</h3><p>对于大量数据的表，使用联合索引会大大的减少开销！</p>\n<h3 id=\"覆盖索引。对联合索引-col1-col2-col3-，如果有如下的sql-select-col1-col2-col3-from-test-where-col1-1-and-col2-2。\"><a href=\"#覆盖索引。对联合索引-col1-col2-col3-，如果有如下的sql-select-col1-col2-col3-from-test-where-col1-1-and-col2-2。\" class=\"headerlink\" title=\"覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。\"></a>覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。</h3><p>那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。<br>所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。</p>\n<h3 id=\"效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql-select-from-table-where-col1-1-and-col2-2-and-col3-3\"><a href=\"#效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql-select-from-table-where-col1-1-and-col2-2-and-col3-3\" class=\"headerlink\" title=\"效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,\"></a>效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,</h3><p>假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，<br>然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！</p>\n<h1 id=\"保利一面\"><a href=\"#保利一面\" class=\"headerlink\" title=\"保利一面\"></a>保利一面</h1><h2 id=\"提前预警系统问题\"><a href=\"#提前预警系统问题\" class=\"headerlink\" title=\"提前预警系统问题\"></a>提前预警系统问题</h2><h2 id=\"springboot-注解实现原理\"><a href=\"#springboot-注解实现原理\" class=\"headerlink\" title=\"springboot 注解实现原理\"></a>springboot 注解实现原理</h2><h2 id=\"zookeeper有什么缺点-AP-和-CP-效率不高\"><a href=\"#zookeeper有什么缺点-AP-和-CP-效率不高\" class=\"headerlink\" title=\"zookeeper有什么缺点  AP 和 CP  效率不高\"></a>zookeeper有什么缺点  AP 和 CP  效率不高</h2><h2 id=\"dubbo-线程模型\"><a href=\"#dubbo-线程模型\" class=\"headerlink\" title=\"dubbo 线程模型\"></a>dubbo 线程模型</h2><h2 id=\"dubbo怎么做到负载均衡-loadbalance-xml配置文件里面直接配置\"><a href=\"#dubbo怎么做到负载均衡-loadbalance-xml配置文件里面直接配置\" class=\"headerlink\" title=\"dubbo怎么做到负载均衡  loadbalance xml配置文件里面直接配置\"></a>dubbo怎么做到负载均衡  loadbalance xml配置文件里面直接配置</h2><h2 id=\"四种负载均衡\"><a href=\"#四种负载均衡\" class=\"headerlink\" title=\"四种负载均衡\"></a>四种负载均衡</h2><p>1，随机<br>2，轮训<br>3，一致性哈希<br>4，最少活跃数</p>\n<h2 id=\"elk-调用链-就是监听requestid-log4j\"><a href=\"#elk-调用链-就是监听requestid-log4j\" class=\"headerlink\" title=\"elk 调用链 就是监听requestid log4j\"></a>elk 调用链 就是监听requestid log4j</h2><h2 id=\"并发高怎么设计系统\"><a href=\"#并发高怎么设计系统\" class=\"headerlink\" title=\"并发高怎么设计系统\"></a>并发高怎么设计系统</h2><p>1，使用缓存redis<br>2，线程池<br>3，nginx 负载均衡<br>4，消息队列</p>\n<h2 id=\"redis-过期机制\"><a href=\"#redis-过期机制\" class=\"headerlink\" title=\"redis 过期机制\"></a>redis 过期机制</h2><p>1，定时删除 在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。<br>2，惰性删除 设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。<br>3，定期删除 每隔一段时间，我们就对一些key进行检查，删除里面过期的key。</p>\n<h1 id=\"阿里一面\"><a href=\"#阿里一面\" class=\"headerlink\" title=\"阿里一面\"></a>阿里一面</h1><h2 id=\"秒杀设计-要考虑什么\"><a href=\"#秒杀设计-要考虑什么\" class=\"headerlink\" title=\"秒杀设计 要考虑什么\"></a>秒杀设计 要考虑什么</h2><p>1，前端限流 -按钮只能按一次<br>2，后端限流 -利用MQ削锋<br>3，后端redis防止超卖<br>4，后端mysql限制<br>5，限制IP多次请求，缓存到redis里面<br>6，</p>\n<h2 id=\"java代码如何保证原子性-原子加-原子减-AtomicInteger\"><a href=\"#java代码如何保证原子性-原子加-原子减-AtomicInteger\" class=\"headerlink\" title=\"java代码如何保证原子性 原子加 原子减   AtomicInteger\"></a>java代码如何保证原子性 原子加 原子减   AtomicInteger</h2><h2 id=\"synchronized和reentrantlock-区别\"><a href=\"#synchronized和reentrantlock-区别\" class=\"headerlink\" title=\"synchronized和reentrantlock 区别\"></a>synchronized和reentrantlock 区别</h2><h2 id=\"synchronized-可以锁哪些对象，有什么区别\"><a href=\"#synchronized-可以锁哪些对象，有什么区别\" class=\"headerlink\" title=\"synchronized 可以锁哪些对象，有什么区别\"></a>synchronized 可以锁哪些对象，有什么区别</h2><p>1，对象 变量  对象锁<br>2，代码块  对象锁<br>3，类  类锁<br>1、对于静态方法，由于此时对象还未生成，所以只能采用类锁；<br>2、只要采用类锁，就会拦截所有线程，只能让一个线程访问。<br>3、对于对象锁（this），如果是同一个实例，就会按顺序访问，但是如果是不同实例，就可以同时访问。<br>4、如果对象锁跟访问的对象没有关系，那么就会都同时访问。</p>\n<h2 id=\"AtomicInteger-原理-CAS-volatile修饰的int值-做成原子加-原子减\"><a href=\"#AtomicInteger-原理-CAS-volatile修饰的int值-做成原子加-原子减\" class=\"headerlink\" title=\"AtomicInteger 原理  CAS volatile修饰的int值 做成原子加 原子减\"></a>AtomicInteger 原理  CAS volatile修饰的int值 做成原子加 原子减</h2><h2 id=\"垃圾处理GC-调优-XMX-XMS-XMN\"><a href=\"#垃圾处理GC-调优-XMX-XMS-XMN\" class=\"headerlink\" title=\"垃圾处理GC 调优 -XMX  -XMS  -XMN\"></a>垃圾处理GC 调优 -XMX  -XMS  -XMN</h2><h1 id=\"美的一面\"><a href=\"#美的一面\" class=\"headerlink\" title=\"美的一面\"></a>美的一面</h1><h2 id=\"SPI-dubbo的spi机制\"><a href=\"#SPI-dubbo的spi机制\" class=\"headerlink\" title=\"SPI  dubbo的spi机制\"></a>SPI  dubbo的spi机制</h2><p>SPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的接口，<br>它可以用来启用框架扩展和替换组件。 SPI的作用就是为这些被扩展的API寻找服务实现。<br>@spi 配置它可以扩展</p>\n<h2 id=\"java-spi\"><a href=\"#java-spi\" class=\"headerlink\" title=\"java spi\"></a>java spi</h2><p>1，一种扩展机制，JDBC实现的接口就是driver，但是这个接口是扩展出去的，很多接口都会实现的<br>需要在META-INF的配置文件里面去配置对应service 接口<br>2，缺点：不能做ioc 和aop 不能获取单独的一个实现类</p>\n<h2 id=\"ZK集群选举的一个过程\"><a href=\"#ZK集群选举的一个过程\" class=\"headerlink\" title=\"ZK集群选举的一个过程\"></a>ZK集群选举的一个过程</h2><p>Zab协议</p>\n<h2 id=\"redis集群-同步原理-rdb-aof文件\"><a href=\"#redis集群-同步原理-rdb-aof文件\" class=\"headerlink\" title=\"redis集群 同步原理 rdb aof文件\"></a>redis集群 同步原理 rdb aof文件</h2><h2 id=\"哨兵怎么跟redis的节点通信的-master-slave节点\"><a href=\"#哨兵怎么跟redis的节点通信的-master-slave节点\" class=\"headerlink\" title=\"哨兵怎么跟redis的节点通信的 master  slave节点\"></a>哨兵怎么跟redis的节点通信的 master  slave节点</h2><p>哨兵会给所有节点发ping指令，然后其他节点会回复pong指令，如果一段时间都没回复，那就是断开了</p>\n<h2 id=\"哨兵选举\"><a href=\"#哨兵选举\" class=\"headerlink\" title=\"哨兵选举\"></a>哨兵选举</h2><p>1，配置priority 优先级最高的<br>2，选择复制量最大的</p>\n<h2 id=\"主从结构哨兵是否有用，假如一个节点掉了，会到哪里\"><a href=\"#主从结构哨兵是否有用，假如一个节点掉了，会到哪里\" class=\"headerlink\" title=\"主从结构哨兵是否有用，假如一个节点掉了，会到哪里\"></a>主从结构哨兵是否有用，假如一个节点掉了，会到哪里</h2><h2 id=\"mysql集群是用什么来做-模式是怎么样实现的\"><a href=\"#mysql集群是用什么来做-模式是怎么样实现的\" class=\"headerlink\" title=\"mysql集群是用什么来做 模式是怎么样实现的\"></a>mysql集群是用什么来做 模式是怎么样实现的</h2><h2 id=\"mysql主节点和从节点是怎么同步的-binlog-和relaylog\"><a href=\"#mysql主节点和从节点是怎么同步的-binlog-和relaylog\" class=\"headerlink\" title=\"mysql主节点和从节点是怎么同步的 binlog 和relaylog\"></a>mysql主节点和从节点是怎么同步的 binlog 和relaylog</h2><h2 id=\"如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\"><a href=\"#如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\" class=\"headerlink\" title=\"如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）\"></a>如果从库查没有的话，这个时候你要怎么办，你要先保存到redis，之后再存到从节点（主从延迟）</h2><h2 id=\"redis-用于哪些方面-用户信息，-分布式锁，-主从同步缓存数据\"><a href=\"#redis-用于哪些方面-用户信息，-分布式锁，-主从同步缓存数据\" class=\"headerlink\" title=\"redis 用于哪些方面  用户信息， 分布式锁， 主从同步缓存数据\"></a>redis 用于哪些方面  用户信息， 分布式锁， 主从同步缓存数据</h2><h2 id=\"分布式锁是怎么实现的\"><a href=\"#分布式锁是怎么实现的\" class=\"headerlink\" title=\"分布式锁是怎么实现的\"></a>分布式锁是怎么实现的</h2><p>redis setnx指令 finally里面delete  命令执行   要先判断一下当前线程ID 是不是自己的，如果是自己的那就可以删除，不然不能删除</p>\n<h2 id=\"redisson\"><a href=\"#redisson\" class=\"headerlink\" title=\"redisson\"></a>redisson</h2><h2 id=\"mysql优化-开启慢查询-slow-log-开启-explain-一下，然后把对应不走索引的给查出来\"><a href=\"#mysql优化-开启慢查询-slow-log-开启-explain-一下，然后把对应不走索引的给查出来\" class=\"headerlink\" title=\"mysql优化  开启慢查询 slow_log 开启  explain 一下，然后把对应不走索引的给查出来\"></a>mysql优化  开启慢查询 slow_log 开启  explain 一下，然后把对应不走索引的给查出来</h2><h2 id=\"mysql-有哪些索引-原理\"><a href=\"#mysql-有哪些索引-原理\" class=\"headerlink\" title=\"mysql 有哪些索引 原理\"></a>mysql 有哪些索引 原理</h2><p>普通索引、唯一索引、聚集索引、主键索引、全文索引  B+树</p>\n<h2 id=\"索引下推是什么原理\"><a href=\"#索引下推是什么原理\" class=\"headerlink\" title=\"索引下推是什么原理\"></a>索引下推是什么原理</h2><p>在不使用ICP的情况下，在使用非主键索引（又叫普通索引或者二级索引）进行查询时，存储引擎通过索引检索到数据，<br>然后返回给MySQL服务器，服务器然后判断数据是否符合条件 。<br>在使用ICP的情况下，如果存在某些被索引的列的判断条件时，MySQL服务器将这一部分判断条件传递给存储引擎，<br>然后由存储引擎通过判断索引是否符合MySQL服务器传递的条件，只有当索引符合条件时才会将数据检索出来返回给MySQL服务器 。<br>索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。</p>\n<h2 id=\"mysql-还有其他什么日志吗-undo-redo\"><a href=\"#mysql-还有其他什么日志吗-undo-redo\" class=\"headerlink\" title=\"mysql 还有其他什么日志吗  undo  redo\"></a>mysql 还有其他什么日志吗  undo  redo</h2><h2 id=\"分布式事务-二段式-三段线\"><a href=\"#分布式事务-二段式-三段线\" class=\"headerlink\" title=\"分布式事务 二段式 三段线\"></a>分布式事务 二段式 三段线</h2><h2 id=\"最终一致性-跟分布式事务有什么区别\"><a href=\"#最终一致性-跟分布式事务有什么区别\" class=\"headerlink\" title=\"最终一致性 跟分布式事务有什么区别\"></a>最终一致性 跟分布式事务有什么区别</h2><h2 id=\"分布式事务-CAP理论-base理论\"><a href=\"#分布式事务-CAP理论-base理论\" class=\"headerlink\" title=\"分布式事务 CAP理论 base理论\"></a>分布式事务 CAP理论 base理论</h2><h2 id=\"多线程编程-线程池-类及构造参数\"><a href=\"#多线程编程-线程池-类及构造参数\" class=\"headerlink\" title=\"多线程编程 线程池 类及构造参数\"></a>多线程编程 线程池 类及构造参数</h2><h2 id=\"线程池是怎么工作的\"><a href=\"#线程池是怎么工作的\" class=\"headerlink\" title=\"线程池是怎么工作的\"></a>线程池是怎么工作的</h2><h2 id=\"最大线程数-如果队列满了咋办\"><a href=\"#最大线程数-如果队列满了咋办\" class=\"headerlink\" title=\"最大线程数 如果队列满了咋办\"></a>最大线程数 如果队列满了咋办</h2><h2 id=\"worker队列要怎么设置\"><a href=\"#worker队列要怎么设置\" class=\"headerlink\" title=\"worker队列要怎么设置\"></a>worker队列要怎么设置</h2><h2 id=\"如果队列都满了，这个时候你要放到mq队列\"><a href=\"#如果队列都满了，这个时候你要放到mq队列\" class=\"headerlink\" title=\"如果队列都满了，这个时候你要放到mq队列\"></a>如果队列都满了，这个时候你要放到mq队列</h2><h2 id=\"jvm-内存结构\"><a href=\"#jvm-内存结构\" class=\"headerlink\" title=\"jvm 内存结构\"></a>jvm 内存结构</h2><h2 id=\"jvm-多大就会放到大内存里面-是一个参数\"><a href=\"#jvm-多大就会放到大内存里面-是一个参数\" class=\"headerlink\" title=\"jvm 多大就会放到大内存里面 是一个参数\"></a>jvm 多大就会放到大内存里面 是一个参数</h2><h2 id=\"老年代full-GC-G1-CMS-GC-过程\"><a href=\"#老年代full-GC-G1-CMS-GC-过程\" class=\"headerlink\" title=\"老年代full GC  G1 CMS GC 过程\"></a>老年代full GC  G1 CMS GC 过程</h2><h1 id=\"美的二面\"><a href=\"#美的二面\" class=\"headerlink\" title=\"美的二面\"></a>美的二面</h1><h2 id=\"dubbo文档\"><a href=\"#dubbo文档\" class=\"headerlink\" title=\"dubbo文档\"></a>dubbo文档</h2><h2 id=\"MQ对比\"><a href=\"#MQ对比\" class=\"headerlink\" title=\"MQ对比\"></a>MQ对比</h2><h2 id=\"数据库事务写成功之后往MQ-里面写\"><a href=\"#数据库事务写成功之后往MQ-里面写\" class=\"headerlink\" title=\"数据库事务写成功之后往MQ 里面写\"></a>数据库事务写成功之后往MQ 里面写</h2><h2 id=\"事务中是否需要RPC\"><a href=\"#事务中是否需要RPC\" class=\"headerlink\" title=\"事务中是否需要RPC\"></a>事务中是否需要RPC</h2><h2 id=\"高可用方案-从前端到后端\"><a href=\"#高可用方案-从前端到后端\" class=\"headerlink\" title=\"高可用方案 从前端到后端\"></a>高可用方案 从前端到后端</h2><p>前端nginx做负载均衡，redis做查询缓存，mysql集群做负载</p>\n<p>1，系统拆分  dubbo 加zk 分布式<br>2，Cache(缓存)  读多写少 redis做缓存<br>大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。<br>3，MQ  把数据库操作先放到MQ 排队执行<br>大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内<br>4，数据库拆分(分库分表) Sharding-JDBC<br>当数据量达到某个阀值时，数据库拆分就会成为一个紧急的需求。一般从业务上进行垂直拆分，如果业务单一，也可从水平上进行拆分。<br>5，读写分离<br>主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。<br>6，ElasticSearch<br>7，CDN 加速  把页面资源CDN加速一下<br>其中有速度快的路径有慢的路径，如何选择最优路径，把每个角落的请求快速的传递到机房，这就是 CDN 的功能。<br>8，HTML 页面静态化<br>静态页面部署在 NGNIX 中，收到用户请求，Ngnix 不需要访问 Webapp 即可响应用户，减少应用渲染页面的时间，同时也降低了应用的压力。</p>\n<h1 id=\"卓志\"><a href=\"#卓志\" class=\"headerlink\" title=\"卓志\"></a>卓志</h1><h2 id=\"微服务的技术选项\"><a href=\"#微服务的技术选项\" class=\"headerlink\" title=\"微服务的技术选项\"></a>微服务的技术选项</h2><p>易于部署，各个工程各不影响，分模块部署，负载均衡</p>\n<h2 id=\"dubbo注册与发现过程\"><a href=\"#dubbo注册与发现过程\" class=\"headerlink\" title=\"dubbo注册与发现过程\"></a>dubbo注册与发现过程</h2><p>服务提供者 容器container 服务调用者 注册中心 counter</p>\n<h2 id=\"dubbo负载均衡-几种\"><a href=\"#dubbo负载均衡-几种\" class=\"headerlink\" title=\"dubbo负载均衡 几种\"></a>dubbo负载均衡 几种</h2><p>Dubbo 提供了4种负载均衡实现，分别是基于权重随机算法的 RandomLoadBalance、基于最少活跃调用数算法的 LeastActiveLoadBalance、<br>基于 hash 一致性的 ConsistentHashLoadBalance，以及基于加权轮询算法的 RoundRobinLoadBalance</p>\n<h2 id=\"dubbo遇到过什么问题吗？\"><a href=\"#dubbo遇到过什么问题吗？\" class=\"headerlink\" title=\"dubbo遇到过什么问题吗？\"></a>dubbo遇到过什么问题吗？</h2><p>1，父子类有相同属性时值丢失<br>dubbo默认采用的是hessian序列化&amp;反序列化方式，JavaDeserializer在获取fileds时，采用了Map去重。<br>但是在读取值时，根据serializer的顺序，对于同名字段，子类的该字段值会被赋值两次，总是被父类的值覆盖，导致子类的字段值丢失。<br>2，序列化问题复杂对象变成了map<br>3，Data length too large<br>超过8k   修改 payload的值，将其调大 可以调节到16k<br>4，服务调用失败  No provider available<br>存在一个或多个Provider服务，但是version或者group不匹配。<br>例如Consumer侧申明version=1.0.0，而Provider侧申明version=2.0.0，或者group不匹配，都会出现这个ERROR。</p>\n<h2 id=\"dubbo遇到过什么序列化的问题\"><a href=\"#dubbo遇到过什么序列化的问题\" class=\"headerlink\" title=\"dubbo遇到过什么序列化的问题\"></a>dubbo遇到过什么序列化的问题</h2><h2 id=\"dubbo参数对象如果是object属性-可以传递过去吗\"><a href=\"#dubbo参数对象如果是object属性-可以传递过去吗\" class=\"headerlink\" title=\"dubbo参数对象如果是object属性 可以传递过去吗\"></a>dubbo参数对象如果是object属性 可以传递过去吗</h2><p>最近遇到一个问题，B 服务调用 A 服务时，返回值反序列化时，POJO对象变成了Map类型。<br>在A服务单独测试的时候一直还原不了，在 B 服务进行测试的时候，跟到反序列化数据时才看到原因。<br>A 服务的接口方法返回的结果是一个Object（或 Map&lt;String, Object&gt; 中的 value），<br>Object 的具体实现不在 A 服务的 API 包中，因此在 B 服务找不到该返回值真正的实现类，<br>在 B 服务调用接口返回结果反序列化找不到具体的类型时，就会以 Map 类型进行实例化。</p>\n<h3 id=\"Java序列化：\"><a href=\"#Java序列化：\" class=\"headerlink\" title=\"Java序列化：\"></a>Java序列化：</h3><p>Java序列化会把要序列化的对象类的元数据和业务数据全部序列化为字节流，而且是把整个继承关系上的东西全部序列化了。<br>它序列化出来的字节流是对那个对象结构到内容的完全描述，包含所有的信息，因此效率较低而且字节流比较大。<br>但是由于确实是序列化了所有内容，所以可以说什么都可以传输，因此也更可用和可靠。</p>\n<h3 id=\"hession序列化：\"><a href=\"#hession序列化：\" class=\"headerlink\" title=\"hession序列化：\"></a>hession序列化：</h3><p>它的实现机制是着重于数据，附带简单的类型信息的方法。就像Integer a = 1，<br>hessian会序列化成I 1这样的流，I表示int or Integer，1就是数据内容。而对于复杂对象，通过Java的反射机制，<br>hessian把对象所有的属性当成一个Map来序列化，产生类似M className propertyName1 I 1 propertyName S stringValue<br>（大概如此，确切的忘了）这样的流，包含了基本的类型描述和数据内容。而在序列化过程中，如果一个对象之前出现过，<br>hessian会直接插入一个R index这样的块来表示一个引用位置，从而省去再次序列化和反序列化的时间。<br>这样做的代价就是hessian需要对不同的类型进行不同的处理（因此hessian直接偷懒不支持short），<br>而且遇到某些特殊对象还要做特殊的处理（比如StackTraceElement）。而且同时因为并没有深入到实现内部去进行序列化，<br>所以在某些场合会发生一定的不一致，比如通过Collections.synchronizedMap得到的map。</p>\n<h2 id=\"zk特点-CAP-理论-CP-consist\"><a href=\"#zk特点-CAP-理论-CP-consist\" class=\"headerlink\" title=\"zk特点 CAP 理论  CP  consist\"></a>zk特点 CAP 理论  CP  consist</h2><h2 id=\"zk集群挂了会怎么办会投票-【myid-，zid】\"><a href=\"#zk集群挂了会怎么办会投票-【myid-，zid】\" class=\"headerlink\" title=\"zk集群挂了会怎么办会投票 【myid ，zid】\"></a>zk集群挂了会怎么办会投票 【myid ，zid】</h2><h2 id=\"MQ三大特性-解耦异步削峰\"><a href=\"#MQ三大特性-解耦异步削峰\" class=\"headerlink\" title=\"MQ三大特性 解耦异步削峰\"></a>MQ三大特性 解耦异步削峰</h2><h2 id=\"MQ-消息丢失\"><a href=\"#MQ-消息丢失\" class=\"headerlink\" title=\"MQ 消息丢失\"></a>MQ 消息丢失</h2><h2 id=\"rebbitMQ持久化是怎么持久化\"><a href=\"#rebbitMQ持久化是怎么持久化\" class=\"headerlink\" title=\"rebbitMQ持久化是怎么持久化\"></a>rebbitMQ持久化是怎么持久化</h2><p>将queue的持久化标识durable设置为true,则代表是一个持久的队列</p>\n<h2 id=\"redis分布式锁-lua脚本\"><a href=\"#redis分布式锁-lua脚本\" class=\"headerlink\" title=\"redis分布式锁 lua脚本\"></a>redis分布式锁 lua脚本</h2><p>redisson </p>\n<h2 id=\"redis如何保证原子性\"><a href=\"#redis如何保证原子性\" class=\"headerlink\" title=\"redis如何保证原子性\"></a>redis如何保证原子性</h2><p>单线程的</p>\n<h2 id=\"既然是单线程的，如何做到异步和非阻塞的\"><a href=\"#既然是单线程的，如何做到异步和非阻塞的\" class=\"headerlink\" title=\"既然是单线程的，如何做到异步和非阻塞的\"></a>既然是单线程的，如何做到异步和非阻塞的</h2><p>要明白他的线程模型是IO多路复用模型 主要核心是select channel  bufuer类 就是一个线程负责接收连接，其他线程负责解决对应的事务</p>\n<h2 id=\"redis-可以用来做什么\"><a href=\"#redis-可以用来做什么\" class=\"headerlink\" title=\"redis 可以用来做什么\"></a>redis 可以用来做什么</h2><p>1，缓存  2，分布式锁  3，zset 排名 4，索引 </p>\n<h2 id=\"redis-秒杀的功能是怎么做的\"><a href=\"#redis-秒杀的功能是怎么做的\" class=\"headerlink\" title=\"redis 秒杀的功能是怎么做的\"></a>redis 秒杀的功能是怎么做的</h2><p>1，限流和降级 按钮置灰 nginx限流  2，队列削峰MQ  3，服务层分包部署  4，查询的时候查询redis 缓存</p>\n<h2 id=\"多线程是怎么用的\"><a href=\"#多线程是怎么用的\" class=\"headerlink\" title=\"多线程是怎么用的\"></a>多线程是怎么用的</h2><p>多线程newcache 保证线程无线 CPU消耗比较大  newfixed 线程数固定 但是队列无线，内存不友好</p>\n<h2 id=\"有无遇到OOM的问题\"><a href=\"#有无遇到OOM的问题\" class=\"headerlink\" title=\"有无遇到OOM的问题\"></a>有无遇到OOM的问题</h2><h2 id=\"jvm垃圾回收机制-标记计数算法-可达性算法-标记清理-标记整理-复制算法\"><a href=\"#jvm垃圾回收机制-标记计数算法-可达性算法-标记清理-标记整理-复制算法\" class=\"headerlink\" title=\"jvm垃圾回收机制 标记计数算法 可达性算法 标记清理 标记整理 复制算法\"></a>jvm垃圾回收机制 标记计数算法 可达性算法 标记清理 标记整理 复制算法</h2><h2 id=\"几个垃圾收集器-CMS标记清理-G1\"><a href=\"#几个垃圾收集器-CMS标记清理-G1\" class=\"headerlink\" title=\"几个垃圾收集器  CMS标记清理  G1\"></a>几个垃圾收集器  CMS标记清理  G1</h2><h2 id=\"服务挂了的话怎么办-linux-怎么去查服务器日志\"><a href=\"#服务挂了的话怎么办-linux-怎么去查服务器日志\" class=\"headerlink\" title=\"服务挂了的话怎么办 linux 怎么去查服务器日志\"></a>服务挂了的话怎么办 linux 怎么去查服务器日志</h2><p>linux日志文件说明<br>/var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一<br>/var/log/secure 与安全相关的日志信息<br>/var/log/maillog 与邮件相关的日志信息<br>/var/log/cron 与定时任务相关的日志信息<br>/var/log/spooler 与UUCP和news设备相关的日志信息<br>/var/log/boot.log 守护进程启动和停止相关的日志消息<br>/var/log/wtmp 该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件</p>\n<h3 id=\"Java应用程序的问题：发生OOM导致进程Crash\"><a href=\"#Java应用程序的问题：发生OOM导致进程Crash\" class=\"headerlink\" title=\"Java应用程序的问题：发生OOM导致进程Crash\"></a>Java应用程序的问题：发生OOM导致进程Crash</h3><p>最常见的是发生堆内存异常“java.lang.OutOfMemoryError: Java heap space”，排查步骤如下：<br>Step1: 查看JVM参数 -XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath=*/java.hprof；<br>Step2: 根据HeapDumpPath指定的路径查看是否产生dump文件；<br>Step3: 若存在dump文件，使用Jhat、VisualVM等工具分析即可；</p>\n<h3 id=\"JVM出错：JVM或JDK自身的Bug导致进程Crash\"><a href=\"#JVM出错：JVM或JDK自身的Bug导致进程Crash\" class=\"headerlink\" title=\"JVM出错：JVM或JDK自身的Bug导致进程Crash\"></a>JVM出错：JVM或JDK自身的Bug导致进程Crash</h3><p>当JVM出现致命错误时，会生成一个错误文件 hs_err_pid.log，其中包括了导致jvm crash的重要信息，<br>可以通过分析该文件定位到导致crash的根源，从而改善以保证系统稳定。当出现crash时，该文件默认会生成到工作目录下，<br>然而可以通过jvm参数-XX:ErrorFile指定生成路径。</p>\n<h3 id=\"被操作系统OOM-Killer\"><a href=\"#被操作系统OOM-Killer\" class=\"headerlink\" title=\"被操作系统OOM-Killer\"></a>被操作系统OOM-Killer</h3><p>Step1: 查看操作系统日志：sudo grep –color “java” /var/log/messages，确定Java进程是否被操作系统Kill；<br>Step2: 若被操作系统Kill，执行dmesg命令查看系统各进程资源占用情况，明确Java占用内存是否合理，<br>以及是否有其它进程不合理的占用了大量内存空间；</p>\n<h2 id=\"数据库横表与纵表的区分-没什么卵用-都是到横表的\"><a href=\"#数据库横表与纵表的区分-没什么卵用-都是到横表的\" class=\"headerlink\" title=\"数据库横表与纵表的区分  没什么卵用 都是到横表的\"></a>数据库横表与纵表的区分  没什么卵用 都是到横表的</h2><p> 横表就是普通的建表方式，如一个表结构为： 主键、字段1、字段2、字段3。。。 如果变成纵表后，<br> 则表结构为： 主键、字段代码、字段值。 而字段代码则为字段1、字段2、字段3。</p>\n<h2 id=\"TIDB-最新数据库\"><a href=\"#TIDB-最新数据库\" class=\"headerlink\" title=\"TIDB 最新数据库\"></a>TIDB 最新数据库</h2><p>mysql的一个封装，加快查询效率</p>\n<h2 id=\"tcp的头标记\"><a href=\"#tcp的头标记\" class=\"headerlink\" title=\"tcp的头标记\"></a>tcp的头标记</h2><h2 id=\"rpc-主要框架及对比-dubbo-grpc-thrift-dubbox-motan\"><a href=\"#rpc-主要框架及对比-dubbo-grpc-thrift-dubbox-motan\" class=\"headerlink\" title=\"rpc 主要框架及对比  dubbo  grpc  thrift dubbox  motan\"></a>rpc 主要框架及对比  dubbo  grpc  thrift dubbox  motan</h2><p>grpc是一个轻量级的java RPC框架。它支持服务注册和发现。<br>dubbox有比价完善的服务治理模型，其包含ZK注册中心，服务监控等，可以很方便的为我们服务。<br>motan新浪微博开源的RPC框架<br>grpc是Google出品，使用了PB协议，但是由于它出现的比较晚，还不怎么成熟，而且采用http协议，非常适合现在的微服务，<br>    不过性能上差了许多，而且像服务治理与监控都需要额外的开发工作，所以放弃grpc。<br>thrift和grpc一样，性能优越，但是开发难度相比较于dubbox和motan也是高了一点点，<br>    需要编写proto文件（其实对于程序员来说这算不上难度）。像服务治理与监控也是需要额外的开发工作。<br>dubbo比较老了，直接弃用。<br>dubbox和后来的motan都比较适合我们的团队。dubbox后来经过当当的开发，引入了rest风格的http协议，<br>并且还支持kryo/fst/dubbo/thrift等其他协议，而且其他团队也在使用dubbo，集成方便，服务治理监控功能齐全，所以最终采用dubbox。<br>其实我个人而言还是喜欢thrift，毕竟性能优越，在大型分布式系统中，哪怕一点点性能提升累计在一起也是很可观的。<br>不过再具体选型的过程中还要结合团队目前的状况和团队其他开发人员的接受程度进行取舍。</p>\n<h1 id=\"易工品\"><a href=\"#易工品\" class=\"headerlink\" title=\"易工品\"></a>易工品</h1><h2 id=\"springcloud-alibaba-跟springcloud的区别\"><a href=\"#springcloud-alibaba-跟springcloud的区别\" class=\"headerlink\" title=\"springcloud alibaba 跟springcloud的区别\"></a>springcloud alibaba 跟springcloud的区别</h2><p>注册中心不一样 nacos 集成了Ribbon eureka</p>\n<h2 id=\"最新关注技术点-tidb-优点\"><a href=\"#最新关注技术点-tidb-优点\" class=\"headerlink\" title=\"最新关注技术点 tidb 优点\"></a>最新关注技术点 tidb 优点</h2><h2 id=\"做的业务点\"><a href=\"#做的业务点\" class=\"headerlink\" title=\"做的业务点\"></a>做的业务点</h2><h2 id=\"zk的业务场景-zk的特点\"><a href=\"#zk的业务场景-zk的特点\" class=\"headerlink\" title=\"zk的业务场景 zk的特点\"></a>zk的业务场景 zk的特点</h2><h2 id=\"rocketmq-卡夫卡-和-rabbitmq的比较\"><a href=\"#rocketmq-卡夫卡-和-rabbitmq的比较\" class=\"headerlink\" title=\"rocketmq 卡夫卡 和 rabbitmq的比较\"></a>rocketmq 卡夫卡 和 rabbitmq的比较</h2><p>吞吐量 ：卡夫卡》rocketmq》rabbitmq<br>接收的模式：卡夫卡拉取：rabbitmq 推拉</p>\n<h2 id=\"所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\"><a href=\"#所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\" class=\"headerlink\" title=\"所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？\"></a>所有人都订阅了这个消息，推送消息的话，所有都接收的话卡夫卡合适吗？</h2><h2 id=\"财务金额用的是什么类型存储，怎么去做取整的操作\"><a href=\"#财务金额用的是什么类型存储，怎么去做取整的操作\" class=\"headerlink\" title=\"财务金额用的是什么类型存储，怎么去做取整的操作\"></a>财务金额用的是什么类型存储，怎么去做取整的操作</h2><h2 id=\"mysql的变更通知\"><a href=\"#mysql的变更通知\" class=\"headerlink\" title=\"mysql的变更通知\"></a>mysql的变更通知</h2><h2 id=\"单元测试是怎么做的\"><a href=\"#单元测试是怎么做的\" class=\"headerlink\" title=\"单元测试是怎么做的\"></a>单元测试是怎么做的</h2><p>Junit框架，在大多数java的开发环境中已经集成，</p>\n<h2 id=\"生产故障\"><a href=\"#生产故障\" class=\"headerlink\" title=\"生产故障\"></a>生产故障</h2><h2 id=\"图数据库和时序数据库\"><a href=\"#图数据库和时序数据库\" class=\"headerlink\" title=\"图数据库和时序数据库\"></a>图数据库和时序数据库</h2><h2 id=\"承担什么责任-做一个项目碰到什么难题\"><a href=\"#承担什么责任-做一个项目碰到什么难题\" class=\"headerlink\" title=\"承担什么责任  做一个项目碰到什么难题\"></a>承担什么责任  做一个项目碰到什么难题</h2><p>电商  支付模块 </p>\n<p>奥悦家<br>用户支付同步天问接口回调很慢的话怎么办  ，然后会导致用户重复缴费两次<br>1，先异步返回，然后给数据库设置一个在缴费中的标志位，返回给业主说正在缴费中<br>2，起一个线程去不断查询天问系统接口，然后接收回调接口的返回<br>3，在缴费之后就先用redis把查询的费用设置为0，就是说先去redis 查询费用，如果没有的话就去天问查，如果有的话就看多少钱<br>使用dubbo中遇到什么问题<br>序列化的问题—-复杂对象的时候会 变成map<br>服务调用失败  No provider available—–版本号不一致<br>Data length too large 超过8k——-修改 payload的值，将其调大 可以调节到16k</p>\n<p>奥悦团购  超卖库存的问题 秒杀<br>1前端<br>面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】<br>　　A：扩容<br>　　加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。<br>　　B：静态化<br>　　将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。<br>　　C：限流<br>　　一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。<br>　　或者活动入口的时候增加游戏或者问题环节进行消峰操作。<br>　　<br>2后端<br>A：将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，<br>并且由于Redis的写性能和读性能都远高于MySQL，<br>这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。<br>B：引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。<br>当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。<br>C：利用Java的锁机制CAS来实现减库存操作<br>D：写sql乐观锁的概念，增加了版本号，<br>//1.查询出商品信息<br>select stock, version from t_goods where id=1;<br>//2.根据商品信息生成订单<br>insert into t_orders (id,goods_id) values (null,1);<br>//3.修改商品库存<br>update t_goods set stock=stock-1, version = version+1 where id=1, version=version;<br>当A线程来更新数量的时候先看版本号有没有动，如果已经变了那就不改并且返回，如果没变，这个时候就更改库存，并且把版本号加一<br>E：分布式锁<br>setnx指令，如果能拿到对应标志位的锁的话，那就成功获取锁，并且更改库存，如果不行的话，那就直接返回抢购失败</p>\n<h1 id=\"中移\"><a href=\"#中移\" class=\"headerlink\" title=\"中移\"></a>中移</h1><h2 id=\"maven调用链依赖重复依赖是怎么解决的\"><a href=\"#maven调用链依赖重复依赖是怎么解决的\" class=\"headerlink\" title=\"maven调用链依赖重复依赖是怎么解决的\"></a>maven调用链依赖重复依赖是怎么解决的</h2><p>当一个项目中出现重复的依赖包时，maven 2.0.9之后的版本会用如下的规则来决定使用哪一个版本的包：<br>最短路径原则<br>比如有如下两个依赖关系：<br>A -&gt; B -&gt; C -&gt; D(V1)<br>F -&gt; G -&gt; D(V2)<br>这个时候项目中就出现了两个版本的D，这时maven会采用最短路径原则，选择V2版本的D，因为V1版本的D是由A包间接依赖的，整个依赖路径长度为3，而V2版本的D是由F包间接依赖的，整个依赖路径长度为2。<br>声明优先原则<br>假设有如下两个依赖关系：<br>A -&gt; B -&gt; D(V1)<br>F -&gt; G -&gt; D(V2)<br>这个时候因为两个版本的D的依赖路径都是一样长，最短路径原则就失效了。这个时候Maven的解决方案是：<br>按照依赖包在pom.xml中声明的先后顺序，优先选择先声明的包</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>"},{"date":"2020-03-26T16:00:00.000Z","status":"public","title":"servlet原理","_content":"\n摘要:servlet原理\n<!--more-->\n# servlet 生命周期\n首先加载servlet的class，实例化servlet，然后初始化servlet调用init()的方法，\n接着调用服务的service的方法处理doGet和doPost方法，最后是我的还有容器关闭时候调用destroy 销毁方法。\n![avatar](/img/servlet1.jpeg)\n\n从这张图上面可以看到整个生命周期，请求到来-通过tomcat找到对应web-通过配置文件找到servlet\n-找到并且实例化-调用init-调用service方法-找到对应类-处理问题实现doget dopost-destroy销毁\n\n\n","source":"_posts/java/servlet.md","raw":"---\ndate: 2020-03-27\nstatus: public\ntitle: servlet原理\ntags:\n  - JAVA\n  - servlet\n---\n\n摘要:servlet原理\n<!--more-->\n# servlet 生命周期\n首先加载servlet的class，实例化servlet，然后初始化servlet调用init()的方法，\n接着调用服务的service的方法处理doGet和doPost方法，最后是我的还有容器关闭时候调用destroy 销毁方法。\n![avatar](/img/servlet1.jpeg)\n\n从这张图上面可以看到整个生命周期，请求到来-通过tomcat找到对应web-通过配置文件找到servlet\n-找到并且实例化-调用init-调用service方法-找到对应类-处理问题实现doget dopost-destroy销毁\n\n\n","slug":"java/servlet","published":1,"updated":"2025-05-16T04:25:25.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsw001sskqr8p1b95uc","content":"<p>摘要:servlet原理</p>\n<span id=\"more\"></span>\n<h1 id=\"servlet-生命周期\"><a href=\"#servlet-生命周期\" class=\"headerlink\" title=\"servlet 生命周期\"></a>servlet 生命周期</h1><p>首先加载servlet的class，实例化servlet，然后初始化servlet调用init()的方法，<br>接着调用服务的service的方法处理doGet和doPost方法，最后是我的还有容器关闭时候调用destroy 销毁方法。<br><img src=\"/img/servlet1.jpeg\" alt=\"avatar\"></p>\n<p>从这张图上面可以看到整个生命周期，请求到来-通过tomcat找到对应web-通过配置文件找到servlet<br>-找到并且实例化-调用init-调用service方法-找到对应类-处理问题实现doget dopost-destroy销毁</p>\n","site":{"data":{}},"excerpt":"<p>摘要:servlet原理</p>","more":"<h1 id=\"servlet-生命周期\"><a href=\"#servlet-生命周期\" class=\"headerlink\" title=\"servlet 生命周期\"></a>servlet 生命周期</h1><p>首先加载servlet的class，实例化servlet，然后初始化servlet调用init()的方法，<br>接着调用服务的service的方法处理doGet和doPost方法，最后是我的还有容器关闭时候调用destroy 销毁方法。<br><img src=\"/img/servlet1.jpeg\" alt=\"avatar\"></p>\n<p>从这张图上面可以看到整个生命周期，请求到来-通过tomcat找到对应web-通过配置文件找到servlet<br>-找到并且实例化-调用init-调用service方法-找到对应类-处理问题实现doget dopost-destroy销毁</p>"},{"date":"2020-03-20T16:00:00.000Z","status":"public","title":"mysql机制","_content":"\n摘要:mysql机制\n<!--more-->\n# mysql 优化\n\n1，要分析mysql，explain，执行看是否有使用索引\n2，不要用like，!=，等等，like %这个走在前面不走索引\n3，尽量不要在where里面做表达式操作，判空操作，会导致不走索引\n\n# 事务须知\n## 事务实现\nstart transaction;\n\ncommit;\n## 实现方式\n### 代码方式\ndbc = new DataBaseConnection(); \nConnection con = dbc.getConnection(); \ntry { \n\tdbc.executeUpdate(\"delete from xiao_affix where bylawid=\" + sID); \n\tcon.commit();//提交JDBC事务 \n\tcon.setAutoCommit(true);// 恢复JDBC事务的默认提交方式\n\tdbc.close(); \n}catch (Exception exc) { \n　　 con.rollBack();//回滚JDBC事务 \n　　 exc.printStackTrace(); \n　　 dbc.close(); \n　　 return -1; \n} \n### 基于 @Transactional 的声明式事务管理\n@Transactional(isolation=Isolation.DEFAULT,propagation=Propagation.REQUIRED)\n\n## 有没有用过事务 事务用于什么地方\n事务用于缴费的时候要更新多个地方时候，执行报错的时候需要回滚\n\n## 事务注解参数 事务注解有没有什么参数 你需要去配置\nRollBackfor NotRollBackfor timeout  事务隔离级别 事务传播行为\n\n一般回滚的话runtimeexception 都会回滚，error也会回滚\n\n## 事务什么时候会回滚  是不是什么报错都会回滚\n设置了notrollbackfor 就不会回滚，myisam存储引擎不会回滚事务，innerdb会回滚\n如果你抛出的异常是Exception，是不会回滚的，需要抛出一个RuntimeException\n\n## 事务传播行为类型\nTransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。\nTransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。\nTransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。\nTransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。\nTransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。\nTransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。\nTransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；\n如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。\n\n## 事务四性 \nACID \n\n原子性：1的操作 任何操作都是1或者0 这个是靠undo日志来实现的\n\n持久性：故障之后任然可以达到恢复 用的是redo日志来实现的\n\n隔离性： 两个事务互相不打扰 是使用读写锁和MVCC来实现的\n\n一致性：数据加起来等于1 是用上面的三个来共同维护的\n\n## redo undo bin log relay log\nredo日志 及undo 日志\nredo，undo日志都是保存到磁盘里面的\n\nredo日志当你操作的时候，突然程序崩溃了或者宕机，系统断电了\n这个时候重启之后，redo日志会同步到数据库里面\n \nundo日志是用于回滚操作的，当你事务要执行回滚的时候，你就得通过undo日志来进行回滚\n\nbinlog 这个也可以做数据恢复，最新也是先写到binlog里面，然后再写到redo日志里面，最后复制到数据库存储里面\n\nredo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）\n\n所以说Oracle 也是有undo 和redo log的，但是没有binlog\n\nmysql主从复制，复制的是binlog 里面的数据   ，写到relay log  然后再写到数据库\n\n### binlog日志录入格式\n1，statement，保存用户的所有操作sql，每一条修改数据的sql 都会保存到binlog中\n2，row，不记录sql上下文语句，仅仅保存哪条数据被修改\n3，mixed，是上面两种的混合\n\n## 事务隔离级别\n脏读：就是你提交了数据，我读取了你的数据，这个时候你又回滚了操作，我读取了你的脏数据\n\n不可重复读：就是你读取了数据，我update了数据，这个时候你又读取了数据，数据不一致\nA select   -》 B update -》A select  这种应该是不可重复读啊\n\n幻读：你update100条数据，这个时候我又insert了一条，这个时候你查询一次，发现还有一条数据没有update\nA select  -》 A update -》B insert -》A select   这种应该就是幻读了\n\n读未提交（read-uncommitted）\n读的是别人未提交的数据\n\n读提交（read-committed）\n读的是别人commit 数据 还是会出现幻读\n\n可重复读（repeatable-read）\n读别人commit数据，然后加间隙锁不给读写\n\n串行化（serializable）\n所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。\n\n# mysql 锁机制\n\n## 乐观锁 悲观锁\nmysql 里面统一为悲观锁，没有乐观锁，乐观锁是人为的加个状态，例如版本号，更改一下版本号来更改状态，\n悲观锁为读写锁，行 表锁，在操作之前先锁住表\n\n## 读写锁\n读锁可以并行，写锁又叫排他锁，不可以并行，会造成死锁，互相争夺资源\n\n## 行锁 表锁\n\n## 间隙锁\n间隙锁是发生在可重复读的事务隔离级别，在更新插入的时候会自动形成对应的间隙锁，间隙锁是一个分段锁，0-100 ，100-200,200-300...\n，当有事务A 要插入的时候会引入间隙锁，这个时候B无法提交，这个就是间隙锁，但是这里会引发死锁问题，当事务B 也引入间隙锁\n这个时候就死锁，谁也没法提交事务\n\n[锁机制](https://www.cnblogs.com/lusaisai/p/13400088.html)\n\n## MVCC多版本控制\nundo log 中记录某行数据的多个版本的数据\n\n## 当前读  快照读\n当前读就是读取当前版本，insert update 这些操作都是当前读，会先获取当前最新数据，然后读取出来加锁，然后再操作\n快照读就是读取历史版本，select 就是快照读\n当前读的话会进行加锁的机制，在当前读会发生间隙锁的机制，就是不给别人读写，加上排他锁\n\n# 索引\n索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。\n\n了解索引之前，首先要了解B+树，它是不能在非叶子节点命中的树，它的叶子节点全部是排序的，装载了所有数据\n\n索引的原理很简单，就是把无序的数据变成有序的查询\n1、把创建了索引的列的内容进行排序\n2、对排序结果生成倒排表\n3、在倒排表内容上拼上数据地址链\n4、在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据\n\n## 聚簇索引和非聚簇索引\n非聚簇索引就是叶子节点存储的是地址，然后地址指向数据\n这个时候查询会变慢，为了优化这点问题，加上了聚簇索引，它可以实现叶子节点直接存储数据，不是指针\n\n索引算法有 BTree算法和Hash算法\n## 主键索引\n\n## 唯一索引\n\n## 组合索引\n\n这里要说到最左前缀，组合索引要把最常查询的字段排在最前面，ABC三个组成的索引，A开头会走索引，其他开头不走索引\n\n## 普通索引\n\n## 回表\n例如我添加了普通索引K ，然后我select a from test where k = 12;\n这个时候呢我们会先走k的索引，然后再查询到这条数据的主键，然后再通过主键查询到所有数据，这一个流程称为回表\n\n# 解决mysql两个update 操作的解决方案\n## 问题1 超卖问题\n不能用快照读，要用当前读，不然数据多的时候会出现超卖问题，就是说解决方案\n1，同步机制synchronized\n2，要么写sql：update xx set count = count +1 where id=#{id},保证是当前读\n3，加锁，加单个锁，变成一个进程 给库存表和余额表添加操作版本号字段，即使用乐观策略，进行cas操作。在每次update的时候先比较版本号是不是自己所获取到的版本号，是，则更新；否，则进行重试。\n4，select .... for update语句触发mysql的互斥锁，这样其他线程在查询库存的时候就阻塞，从而达到并发安全。\n## 问题2 保证两个update 原子性\n1，用事务机制，保证原子性，一个update是另外一个update成功的前提，不然就回滚\n 这个方法会出现长事务，数据库锁等待频繁，效率稍微低一些，但是还是可以接受的。\n2，捕捉异常，手动进行回滚  执行效率提升，但是代码的复杂度会高很多。\n\n\n# MySQL中varchar与char的区别及varchar(50)中50代表什么含义？\nvarchar 是可变长度的   char 是不可变长度的，当同样存储‘hello’这个字符时候，varchar 就只是占用5个字符后面,而char(100)，就算存储5个字符\n也会暂用100个字符，用varchar 可以节省存储空间。char(100)在后面都是补空格来填充的，但是order by 的时候会去掉。\n\n# mysql索引数据结构\n1，二叉树------要是有序的数字的话，二叉树不合适会一直右边排布下去\n2，红黑树------会自动平衡，不会一直排布下去，高度非常高，树的高度非常高，磁盘IO 非常多\n3，B树---------控制高度，树的高度比较少，但是没法进行范围查找，B树节点里面存储了数据，这里面要用到很多存储空间\n4，B+树--------可以进行范围查找，同时节点里面只是存key，没有存储数据，数据放到叶子页面，这样可以存储很多数据\n\n# 为什么mysql 要增加一个自增索引 用int 类型  为啥不用UUID\n1，有利于范围查找\n2，增加排序效率\n3，提高扫表能力，顺序访问\n4，减少分层，如果是UUID的话数据量会比较大\n5，这个还要从表的插入有关，自增id的话 每次都在最后面一个插入，这样插入容易\n但是用UUID的话 就每次插入都是要计算一遍，看下具体位置是在哪里，这个时候效率就比较低下了\n然后当一页插不进去的时候，这个时候要插入额外的一条数据的时候，自增ID 没有这个问题，但是用UUID 会要分裂，分表来插入，这个时候会有问题\n\n\n# mysql 主从复制原理\n原理：\n（1）master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；\n（2）slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件\n（3）同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。\n也就是说：\n## 从库会生成两个线程,一个I/O线程,一个SQL线程;\nI/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中;\n主库会生成一个log dump线程,用来给从库I/O线程传binlog;\nSQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行;\n\n\n## 分布式事务是怎么做的（seata框架）\n1. 二阶段提交协议 (2PC)\n\t协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。\n\t1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志\n\t2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。\n\t缺点 \n\t1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行\n\t2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。\n\t3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，\n\t但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。\n\t\n2. 三阶段提交协议 (3PC)\n针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。\n三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。\n\t1），为甚需要cancommit\n\t假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。\n\t协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。\n\t协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？\n\t所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。\n\t2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务\n\t因为在precommit阶段已经知道所有节点都同意提交事务了\n3. 基于消息的分布式事务\n\t基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失\n\t\n# 怎么处理慢查询\n1，先开启慢查询，并且把慢查询的日志打印，开启的是slow_query_log\n2，explain去查看语句，看下语句有无走索引\n3，优化sql，不要去用like及一些比较复杂的运算","source":"_posts/java/mysql机制.md","raw":"---\ndate: 2020-03-21\nstatus: public\ntitle: mysql机制\ntags:\n  - JAVA\n  - mysql\n---\n\n摘要:mysql机制\n<!--more-->\n# mysql 优化\n\n1，要分析mysql，explain，执行看是否有使用索引\n2，不要用like，!=，等等，like %这个走在前面不走索引\n3，尽量不要在where里面做表达式操作，判空操作，会导致不走索引\n\n# 事务须知\n## 事务实现\nstart transaction;\n\ncommit;\n## 实现方式\n### 代码方式\ndbc = new DataBaseConnection(); \nConnection con = dbc.getConnection(); \ntry { \n\tdbc.executeUpdate(\"delete from xiao_affix where bylawid=\" + sID); \n\tcon.commit();//提交JDBC事务 \n\tcon.setAutoCommit(true);// 恢复JDBC事务的默认提交方式\n\tdbc.close(); \n}catch (Exception exc) { \n　　 con.rollBack();//回滚JDBC事务 \n　　 exc.printStackTrace(); \n　　 dbc.close(); \n　　 return -1; \n} \n### 基于 @Transactional 的声明式事务管理\n@Transactional(isolation=Isolation.DEFAULT,propagation=Propagation.REQUIRED)\n\n## 有没有用过事务 事务用于什么地方\n事务用于缴费的时候要更新多个地方时候，执行报错的时候需要回滚\n\n## 事务注解参数 事务注解有没有什么参数 你需要去配置\nRollBackfor NotRollBackfor timeout  事务隔离级别 事务传播行为\n\n一般回滚的话runtimeexception 都会回滚，error也会回滚\n\n## 事务什么时候会回滚  是不是什么报错都会回滚\n设置了notrollbackfor 就不会回滚，myisam存储引擎不会回滚事务，innerdb会回滚\n如果你抛出的异常是Exception，是不会回滚的，需要抛出一个RuntimeException\n\n## 事务传播行为类型\nTransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。\nTransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。\nTransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。\nTransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。\nTransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。\nTransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。\nTransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；\n如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。\n\n## 事务四性 \nACID \n\n原子性：1的操作 任何操作都是1或者0 这个是靠undo日志来实现的\n\n持久性：故障之后任然可以达到恢复 用的是redo日志来实现的\n\n隔离性： 两个事务互相不打扰 是使用读写锁和MVCC来实现的\n\n一致性：数据加起来等于1 是用上面的三个来共同维护的\n\n## redo undo bin log relay log\nredo日志 及undo 日志\nredo，undo日志都是保存到磁盘里面的\n\nredo日志当你操作的时候，突然程序崩溃了或者宕机，系统断电了\n这个时候重启之后，redo日志会同步到数据库里面\n \nundo日志是用于回滚操作的，当你事务要执行回滚的时候，你就得通过undo日志来进行回滚\n\nbinlog 这个也可以做数据恢复，最新也是先写到binlog里面，然后再写到redo日志里面，最后复制到数据库存储里面\n\nredo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）\n\n所以说Oracle 也是有undo 和redo log的，但是没有binlog\n\nmysql主从复制，复制的是binlog 里面的数据   ，写到relay log  然后再写到数据库\n\n### binlog日志录入格式\n1，statement，保存用户的所有操作sql，每一条修改数据的sql 都会保存到binlog中\n2，row，不记录sql上下文语句，仅仅保存哪条数据被修改\n3，mixed，是上面两种的混合\n\n## 事务隔离级别\n脏读：就是你提交了数据，我读取了你的数据，这个时候你又回滚了操作，我读取了你的脏数据\n\n不可重复读：就是你读取了数据，我update了数据，这个时候你又读取了数据，数据不一致\nA select   -》 B update -》A select  这种应该是不可重复读啊\n\n幻读：你update100条数据，这个时候我又insert了一条，这个时候你查询一次，发现还有一条数据没有update\nA select  -》 A update -》B insert -》A select   这种应该就是幻读了\n\n读未提交（read-uncommitted）\n读的是别人未提交的数据\n\n读提交（read-committed）\n读的是别人commit 数据 还是会出现幻读\n\n可重复读（repeatable-read）\n读别人commit数据，然后加间隙锁不给读写\n\n串行化（serializable）\n所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。\n\n# mysql 锁机制\n\n## 乐观锁 悲观锁\nmysql 里面统一为悲观锁，没有乐观锁，乐观锁是人为的加个状态，例如版本号，更改一下版本号来更改状态，\n悲观锁为读写锁，行 表锁，在操作之前先锁住表\n\n## 读写锁\n读锁可以并行，写锁又叫排他锁，不可以并行，会造成死锁，互相争夺资源\n\n## 行锁 表锁\n\n## 间隙锁\n间隙锁是发生在可重复读的事务隔离级别，在更新插入的时候会自动形成对应的间隙锁，间隙锁是一个分段锁，0-100 ，100-200,200-300...\n，当有事务A 要插入的时候会引入间隙锁，这个时候B无法提交，这个就是间隙锁，但是这里会引发死锁问题，当事务B 也引入间隙锁\n这个时候就死锁，谁也没法提交事务\n\n[锁机制](https://www.cnblogs.com/lusaisai/p/13400088.html)\n\n## MVCC多版本控制\nundo log 中记录某行数据的多个版本的数据\n\n## 当前读  快照读\n当前读就是读取当前版本，insert update 这些操作都是当前读，会先获取当前最新数据，然后读取出来加锁，然后再操作\n快照读就是读取历史版本，select 就是快照读\n当前读的话会进行加锁的机制，在当前读会发生间隙锁的机制，就是不给别人读写，加上排他锁\n\n# 索引\n索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。\n\n了解索引之前，首先要了解B+树，它是不能在非叶子节点命中的树，它的叶子节点全部是排序的，装载了所有数据\n\n索引的原理很简单，就是把无序的数据变成有序的查询\n1、把创建了索引的列的内容进行排序\n2、对排序结果生成倒排表\n3、在倒排表内容上拼上数据地址链\n4、在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据\n\n## 聚簇索引和非聚簇索引\n非聚簇索引就是叶子节点存储的是地址，然后地址指向数据\n这个时候查询会变慢，为了优化这点问题，加上了聚簇索引，它可以实现叶子节点直接存储数据，不是指针\n\n索引算法有 BTree算法和Hash算法\n## 主键索引\n\n## 唯一索引\n\n## 组合索引\n\n这里要说到最左前缀，组合索引要把最常查询的字段排在最前面，ABC三个组成的索引，A开头会走索引，其他开头不走索引\n\n## 普通索引\n\n## 回表\n例如我添加了普通索引K ，然后我select a from test where k = 12;\n这个时候呢我们会先走k的索引，然后再查询到这条数据的主键，然后再通过主键查询到所有数据，这一个流程称为回表\n\n# 解决mysql两个update 操作的解决方案\n## 问题1 超卖问题\n不能用快照读，要用当前读，不然数据多的时候会出现超卖问题，就是说解决方案\n1，同步机制synchronized\n2，要么写sql：update xx set count = count +1 where id=#{id},保证是当前读\n3，加锁，加单个锁，变成一个进程 给库存表和余额表添加操作版本号字段，即使用乐观策略，进行cas操作。在每次update的时候先比较版本号是不是自己所获取到的版本号，是，则更新；否，则进行重试。\n4，select .... for update语句触发mysql的互斥锁，这样其他线程在查询库存的时候就阻塞，从而达到并发安全。\n## 问题2 保证两个update 原子性\n1，用事务机制，保证原子性，一个update是另外一个update成功的前提，不然就回滚\n 这个方法会出现长事务，数据库锁等待频繁，效率稍微低一些，但是还是可以接受的。\n2，捕捉异常，手动进行回滚  执行效率提升，但是代码的复杂度会高很多。\n\n\n# MySQL中varchar与char的区别及varchar(50)中50代表什么含义？\nvarchar 是可变长度的   char 是不可变长度的，当同样存储‘hello’这个字符时候，varchar 就只是占用5个字符后面,而char(100)，就算存储5个字符\n也会暂用100个字符，用varchar 可以节省存储空间。char(100)在后面都是补空格来填充的，但是order by 的时候会去掉。\n\n# mysql索引数据结构\n1，二叉树------要是有序的数字的话，二叉树不合适会一直右边排布下去\n2，红黑树------会自动平衡，不会一直排布下去，高度非常高，树的高度非常高，磁盘IO 非常多\n3，B树---------控制高度，树的高度比较少，但是没法进行范围查找，B树节点里面存储了数据，这里面要用到很多存储空间\n4，B+树--------可以进行范围查找，同时节点里面只是存key，没有存储数据，数据放到叶子页面，这样可以存储很多数据\n\n# 为什么mysql 要增加一个自增索引 用int 类型  为啥不用UUID\n1，有利于范围查找\n2，增加排序效率\n3，提高扫表能力，顺序访问\n4，减少分层，如果是UUID的话数据量会比较大\n5，这个还要从表的插入有关，自增id的话 每次都在最后面一个插入，这样插入容易\n但是用UUID的话 就每次插入都是要计算一遍，看下具体位置是在哪里，这个时候效率就比较低下了\n然后当一页插不进去的时候，这个时候要插入额外的一条数据的时候，自增ID 没有这个问题，但是用UUID 会要分裂，分表来插入，这个时候会有问题\n\n\n# mysql 主从复制原理\n原理：\n（1）master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；\n（2）slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件\n（3）同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。\n也就是说：\n## 从库会生成两个线程,一个I/O线程,一个SQL线程;\nI/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中;\n主库会生成一个log dump线程,用来给从库I/O线程传binlog;\nSQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行;\n\n\n## 分布式事务是怎么做的（seata框架）\n1. 二阶段提交协议 (2PC)\n\t协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。\n\t1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志\n\t2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。\n\t缺点 \n\t1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行\n\t2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。\n\t3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，\n\t但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。\n\t\n2. 三阶段提交协议 (3PC)\n针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。\n三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。\n\t1），为甚需要cancommit\n\t假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。\n\t协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。\n\t协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？\n\t所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。\n\t2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务\n\t因为在precommit阶段已经知道所有节点都同意提交事务了\n3. 基于消息的分布式事务\n\t基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失\n\t\n# 怎么处理慢查询\n1，先开启慢查询，并且把慢查询的日志打印，开启的是slow_query_log\n2，explain去查看语句，看下语句有无走索引\n3，优化sql，不要去用like及一些比较复杂的运算","slug":"java/mysql机制","published":1,"updated":"2025-05-16T04:25:25.425Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsx001vskqr54zs290m","content":"<p>摘要:mysql机制</p>\n<span id=\"more\"></span>\n<h1 id=\"mysql-优化\"><a href=\"#mysql-优化\" class=\"headerlink\" title=\"mysql 优化\"></a>mysql 优化</h1><p>1，要分析mysql，explain，执行看是否有使用索引<br>2，不要用like，!=，等等，like %这个走在前面不走索引<br>3，尽量不要在where里面做表达式操作，判空操作，会导致不走索引</p>\n<h1 id=\"事务须知\"><a href=\"#事务须知\" class=\"headerlink\" title=\"事务须知\"></a>事务须知</h1><h2 id=\"事务实现\"><a href=\"#事务实现\" class=\"headerlink\" title=\"事务实现\"></a>事务实现</h2><p>start transaction;</p>\n<p>commit;</p>\n<h2 id=\"实现方式\"><a href=\"#实现方式\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h2><h3 id=\"代码方式\"><a href=\"#代码方式\" class=\"headerlink\" title=\"代码方式\"></a>代码方式</h3><p>dbc = new DataBaseConnection();<br>Connection con = dbc.getConnection();<br>try {<br>    dbc.executeUpdate(“delete from xiao_affix where bylawid=” + sID);<br>    con.commit();//提交JDBC事务<br>    con.setAutoCommit(true);// 恢复JDBC事务的默认提交方式<br>    dbc.close();<br>}catch (Exception exc) {<br>　　 con.rollBack();//回滚JDBC事务<br>　　 exc.printStackTrace();<br>　　 dbc.close();<br>　　 return -1;<br>} </p>\n<h3 id=\"基于-Transactional-的声明式事务管理\"><a href=\"#基于-Transactional-的声明式事务管理\" class=\"headerlink\" title=\"基于 @Transactional 的声明式事务管理\"></a>基于 @Transactional 的声明式事务管理</h3><p>@Transactional(isolation=Isolation.DEFAULT,propagation=Propagation.REQUIRED)</p>\n<h2 id=\"有没有用过事务-事务用于什么地方\"><a href=\"#有没有用过事务-事务用于什么地方\" class=\"headerlink\" title=\"有没有用过事务 事务用于什么地方\"></a>有没有用过事务 事务用于什么地方</h2><p>事务用于缴费的时候要更新多个地方时候，执行报错的时候需要回滚</p>\n<h2 id=\"事务注解参数-事务注解有没有什么参数-你需要去配置\"><a href=\"#事务注解参数-事务注解有没有什么参数-你需要去配置\" class=\"headerlink\" title=\"事务注解参数 事务注解有没有什么参数 你需要去配置\"></a>事务注解参数 事务注解有没有什么参数 你需要去配置</h2><p>RollBackfor NotRollBackfor timeout  事务隔离级别 事务传播行为</p>\n<p>一般回滚的话runtimeexception 都会回滚，error也会回滚</p>\n<h2 id=\"事务什么时候会回滚-是不是什么报错都会回滚\"><a href=\"#事务什么时候会回滚-是不是什么报错都会回滚\" class=\"headerlink\" title=\"事务什么时候会回滚  是不是什么报错都会回滚\"></a>事务什么时候会回滚  是不是什么报错都会回滚</h2><p>设置了notrollbackfor 就不会回滚，myisam存储引擎不会回滚事务，innerdb会回滚<br>如果你抛出的异常是Exception，是不会回滚的，需要抛出一个RuntimeException</p>\n<h2 id=\"事务传播行为类型\"><a href=\"#事务传播行为类型\" class=\"headerlink\" title=\"事务传播行为类型\"></a>事务传播行为类型</h2><p>TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。<br>TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。<br>TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。<br>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。<br>TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。<br>TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。<br>TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；<br>如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。</p>\n<h2 id=\"事务四性\"><a href=\"#事务四性\" class=\"headerlink\" title=\"事务四性\"></a>事务四性</h2><p>ACID </p>\n<p>原子性：1的操作 任何操作都是1或者0 这个是靠undo日志来实现的</p>\n<p>持久性：故障之后任然可以达到恢复 用的是redo日志来实现的</p>\n<p>隔离性： 两个事务互相不打扰 是使用读写锁和MVCC来实现的</p>\n<p>一致性：数据加起来等于1 是用上面的三个来共同维护的</p>\n<h2 id=\"redo-undo-bin-log-relay-log\"><a href=\"#redo-undo-bin-log-relay-log\" class=\"headerlink\" title=\"redo undo bin log relay log\"></a>redo undo bin log relay log</h2><p>redo日志 及undo 日志<br>redo，undo日志都是保存到磁盘里面的</p>\n<p>redo日志当你操作的时候，突然程序崩溃了或者宕机，系统断电了<br>这个时候重启之后，redo日志会同步到数据库里面</p>\n<p>undo日志是用于回滚操作的，当你事务要执行回滚的时候，你就得通过undo日志来进行回滚</p>\n<p>binlog 这个也可以做数据恢复，最新也是先写到binlog里面，然后再写到redo日志里面，最后复制到数据库存储里面</p>\n<p>redo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）</p>\n<p>所以说Oracle 也是有undo 和redo log的，但是没有binlog</p>\n<p>mysql主从复制，复制的是binlog 里面的数据   ，写到relay log  然后再写到数据库</p>\n<h3 id=\"binlog日志录入格式\"><a href=\"#binlog日志录入格式\" class=\"headerlink\" title=\"binlog日志录入格式\"></a>binlog日志录入格式</h3><p>1，statement，保存用户的所有操作sql，每一条修改数据的sql 都会保存到binlog中<br>2，row，不记录sql上下文语句，仅仅保存哪条数据被修改<br>3，mixed，是上面两种的混合</p>\n<h2 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h2><p>脏读：就是你提交了数据，我读取了你的数据，这个时候你又回滚了操作，我读取了你的脏数据</p>\n<p>不可重复读：就是你读取了数据，我update了数据，这个时候你又读取了数据，数据不一致<br>A select   -》 B update -》A select  这种应该是不可重复读啊</p>\n<p>幻读：你update100条数据，这个时候我又insert了一条，这个时候你查询一次，发现还有一条数据没有update<br>A select  -》 A update -》B insert -》A select   这种应该就是幻读了</p>\n<p>读未提交（read-uncommitted）<br>读的是别人未提交的数据</p>\n<p>读提交（read-committed）<br>读的是别人commit 数据 还是会出现幻读</p>\n<p>可重复读（repeatable-read）<br>读别人commit数据，然后加间隙锁不给读写</p>\n<p>串行化（serializable）<br>所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。</p>\n<h1 id=\"mysql-锁机制\"><a href=\"#mysql-锁机制\" class=\"headerlink\" title=\"mysql 锁机制\"></a>mysql 锁机制</h1><h2 id=\"乐观锁-悲观锁\"><a href=\"#乐观锁-悲观锁\" class=\"headerlink\" title=\"乐观锁 悲观锁\"></a>乐观锁 悲观锁</h2><p>mysql 里面统一为悲观锁，没有乐观锁，乐观锁是人为的加个状态，例如版本号，更改一下版本号来更改状态，<br>悲观锁为读写锁，行 表锁，在操作之前先锁住表</p>\n<h2 id=\"读写锁\"><a href=\"#读写锁\" class=\"headerlink\" title=\"读写锁\"></a>读写锁</h2><p>读锁可以并行，写锁又叫排他锁，不可以并行，会造成死锁，互相争夺资源</p>\n<h2 id=\"行锁-表锁\"><a href=\"#行锁-表锁\" class=\"headerlink\" title=\"行锁 表锁\"></a>行锁 表锁</h2><h2 id=\"间隙锁\"><a href=\"#间隙锁\" class=\"headerlink\" title=\"间隙锁\"></a>间隙锁</h2><p>间隙锁是发生在可重复读的事务隔离级别，在更新插入的时候会自动形成对应的间隙锁，间隙锁是一个分段锁，0-100 ，100-200,200-300…<br>，当有事务A 要插入的时候会引入间隙锁，这个时候B无法提交，这个就是间隙锁，但是这里会引发死锁问题，当事务B 也引入间隙锁<br>这个时候就死锁，谁也没法提交事务</p>\n<p><a href=\"https://www.cnblogs.com/lusaisai/p/13400088.html\">锁机制</a></p>\n<h2 id=\"MVCC多版本控制\"><a href=\"#MVCC多版本控制\" class=\"headerlink\" title=\"MVCC多版本控制\"></a>MVCC多版本控制</h2><p>undo log 中记录某行数据的多个版本的数据</p>\n<h2 id=\"当前读-快照读\"><a href=\"#当前读-快照读\" class=\"headerlink\" title=\"当前读  快照读\"></a>当前读  快照读</h2><p>当前读就是读取当前版本，insert update 这些操作都是当前读，会先获取当前最新数据，然后读取出来加锁，然后再操作<br>快照读就是读取历史版本，select 就是快照读<br>当前读的话会进行加锁的机制，在当前读会发生间隙锁的机制，就是不给别人读写，加上排他锁</p>\n<h1 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h1><p>索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。</p>\n<p>了解索引之前，首先要了解B+树，它是不能在非叶子节点命中的树，它的叶子节点全部是排序的，装载了所有数据</p>\n<p>索引的原理很简单，就是把无序的数据变成有序的查询<br>1、把创建了索引的列的内容进行排序<br>2、对排序结果生成倒排表<br>3、在倒排表内容上拼上数据地址链<br>4、在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据</p>\n<h2 id=\"聚簇索引和非聚簇索引\"><a href=\"#聚簇索引和非聚簇索引\" class=\"headerlink\" title=\"聚簇索引和非聚簇索引\"></a>聚簇索引和非聚簇索引</h2><p>非聚簇索引就是叶子节点存储的是地址，然后地址指向数据<br>这个时候查询会变慢，为了优化这点问题，加上了聚簇索引，它可以实现叶子节点直接存储数据，不是指针</p>\n<p>索引算法有 BTree算法和Hash算法</p>\n<h2 id=\"主键索引\"><a href=\"#主键索引\" class=\"headerlink\" title=\"主键索引\"></a>主键索引</h2><h2 id=\"唯一索引\"><a href=\"#唯一索引\" class=\"headerlink\" title=\"唯一索引\"></a>唯一索引</h2><h2 id=\"组合索引\"><a href=\"#组合索引\" class=\"headerlink\" title=\"组合索引\"></a>组合索引</h2><p>这里要说到最左前缀，组合索引要把最常查询的字段排在最前面，ABC三个组成的索引，A开头会走索引，其他开头不走索引</p>\n<h2 id=\"普通索引\"><a href=\"#普通索引\" class=\"headerlink\" title=\"普通索引\"></a>普通索引</h2><h2 id=\"回表\"><a href=\"#回表\" class=\"headerlink\" title=\"回表\"></a>回表</h2><p>例如我添加了普通索引K ，然后我select a from test where k = 12;<br>这个时候呢我们会先走k的索引，然后再查询到这条数据的主键，然后再通过主键查询到所有数据，这一个流程称为回表</p>\n<h1 id=\"解决mysql两个update-操作的解决方案\"><a href=\"#解决mysql两个update-操作的解决方案\" class=\"headerlink\" title=\"解决mysql两个update 操作的解决方案\"></a>解决mysql两个update 操作的解决方案</h1><h2 id=\"问题1-超卖问题\"><a href=\"#问题1-超卖问题\" class=\"headerlink\" title=\"问题1 超卖问题\"></a>问题1 超卖问题</h2><p>不能用快照读，要用当前读，不然数据多的时候会出现超卖问题，就是说解决方案<br>1，同步机制synchronized<br>2，要么写sql：update xx set count = count +1 where id=#{id},保证是当前读<br>3，加锁，加单个锁，变成一个进程 给库存表和余额表添加操作版本号字段，即使用乐观策略，进行cas操作。在每次update的时候先比较版本号是不是自己所获取到的版本号，是，则更新；否，则进行重试。<br>4，select …. for update语句触发mysql的互斥锁，这样其他线程在查询库存的时候就阻塞，从而达到并发安全。</p>\n<h2 id=\"问题2-保证两个update-原子性\"><a href=\"#问题2-保证两个update-原子性\" class=\"headerlink\" title=\"问题2 保证两个update 原子性\"></a>问题2 保证两个update 原子性</h2><p>1，用事务机制，保证原子性，一个update是另外一个update成功的前提，不然就回滚<br> 这个方法会出现长事务，数据库锁等待频繁，效率稍微低一些，但是还是可以接受的。<br>2，捕捉异常，手动进行回滚  执行效率提升，但是代码的复杂度会高很多。</p>\n<h1 id=\"MySQL中varchar与char的区别及varchar-50-中50代表什么含义？\"><a href=\"#MySQL中varchar与char的区别及varchar-50-中50代表什么含义？\" class=\"headerlink\" title=\"MySQL中varchar与char的区别及varchar(50)中50代表什么含义？\"></a>MySQL中varchar与char的区别及varchar(50)中50代表什么含义？</h1><p>varchar 是可变长度的   char 是不可变长度的，当同样存储‘hello’这个字符时候，varchar 就只是占用5个字符后面,而char(100)，就算存储5个字符<br>也会暂用100个字符，用varchar 可以节省存储空间。char(100)在后面都是补空格来填充的，但是order by 的时候会去掉。</p>\n<h1 id=\"mysql索引数据结构\"><a href=\"#mysql索引数据结构\" class=\"headerlink\" title=\"mysql索引数据结构\"></a>mysql索引数据结构</h1><p>1，二叉树——要是有序的数字的话，二叉树不合适会一直右边排布下去<br>2，红黑树——会自动平衡，不会一直排布下去，高度非常高，树的高度非常高，磁盘IO 非常多<br>3，B树———控制高度，树的高度比较少，但是没法进行范围查找，B树节点里面存储了数据，这里面要用到很多存储空间<br>4，B+树——–可以进行范围查找，同时节点里面只是存key，没有存储数据，数据放到叶子页面，这样可以存储很多数据</p>\n<h1 id=\"为什么mysql-要增加一个自增索引-用int-类型-为啥不用UUID\"><a href=\"#为什么mysql-要增加一个自增索引-用int-类型-为啥不用UUID\" class=\"headerlink\" title=\"为什么mysql 要增加一个自增索引 用int 类型  为啥不用UUID\"></a>为什么mysql 要增加一个自增索引 用int 类型  为啥不用UUID</h1><p>1，有利于范围查找<br>2，增加排序效率<br>3，提高扫表能力，顺序访问<br>4，减少分层，如果是UUID的话数据量会比较大<br>5，这个还要从表的插入有关，自增id的话 每次都在最后面一个插入，这样插入容易<br>但是用UUID的话 就每次插入都是要计算一遍，看下具体位置是在哪里，这个时候效率就比较低下了<br>然后当一页插不进去的时候，这个时候要插入额外的一条数据的时候，自增ID 没有这个问题，但是用UUID 会要分裂，分表来插入，这个时候会有问题</p>\n<h1 id=\"mysql-主从复制原理\"><a href=\"#mysql-主从复制原理\" class=\"headerlink\" title=\"mysql 主从复制原理\"></a>mysql 主从复制原理</h1><p>原理：<br>（1）master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；<br>（2）slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件<br>（3）同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。<br>也就是说：</p>\n<h2 id=\"从库会生成两个线程-一个I-O线程-一个SQL线程\"><a href=\"#从库会生成两个线程-一个I-O线程-一个SQL线程\" class=\"headerlink\" title=\"从库会生成两个线程,一个I/O线程,一个SQL线程;\"></a>从库会生成两个线程,一个I/O线程,一个SQL线程;</h2><p>I/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中;<br>主库会生成一个log dump线程,用来给从库I/O线程传binlog;<br>SQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行;</p>\n<h2 id=\"分布式事务是怎么做的（seata框架）\"><a href=\"#分布式事务是怎么做的（seata框架）\" class=\"headerlink\" title=\"分布式事务是怎么做的（seata框架）\"></a>分布式事务是怎么做的（seata框架）</h2><ol>\n<li>二阶段提交协议 (2PC)<br> 协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。<br> 1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志<br> 2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。<br> 缺点<br> 1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行<br> 2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。<br> 3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，<br> 但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</li>\n<li>三阶段提交协议 (3PC)<br>针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。<br>三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。<br> 1），为甚需要cancommit<br> 假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。<br> 协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。<br> 协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？<br> 所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。<br> 2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务<br> 因为在precommit阶段已经知道所有节点都同意提交事务了</li>\n<li>基于消息的分布式事务<br> 基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失</li>\n</ol>\n<h1 id=\"怎么处理慢查询\"><a href=\"#怎么处理慢查询\" class=\"headerlink\" title=\"怎么处理慢查询\"></a>怎么处理慢查询</h1><p>1，先开启慢查询，并且把慢查询的日志打印，开启的是slow_query_log<br>2，explain去查看语句，看下语句有无走索引<br>3，优化sql，不要去用like及一些比较复杂的运算</p>\n","site":{"data":{}},"excerpt":"<p>摘要:mysql机制</p>","more":"<h1 id=\"mysql-优化\"><a href=\"#mysql-优化\" class=\"headerlink\" title=\"mysql 优化\"></a>mysql 优化</h1><p>1，要分析mysql，explain，执行看是否有使用索引<br>2，不要用like，!=，等等，like %这个走在前面不走索引<br>3，尽量不要在where里面做表达式操作，判空操作，会导致不走索引</p>\n<h1 id=\"事务须知\"><a href=\"#事务须知\" class=\"headerlink\" title=\"事务须知\"></a>事务须知</h1><h2 id=\"事务实现\"><a href=\"#事务实现\" class=\"headerlink\" title=\"事务实现\"></a>事务实现</h2><p>start transaction;</p>\n<p>commit;</p>\n<h2 id=\"实现方式\"><a href=\"#实现方式\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h2><h3 id=\"代码方式\"><a href=\"#代码方式\" class=\"headerlink\" title=\"代码方式\"></a>代码方式</h3><p>dbc = new DataBaseConnection();<br>Connection con = dbc.getConnection();<br>try {<br>    dbc.executeUpdate(“delete from xiao_affix where bylawid=” + sID);<br>    con.commit();//提交JDBC事务<br>    con.setAutoCommit(true);// 恢复JDBC事务的默认提交方式<br>    dbc.close();<br>}catch (Exception exc) {<br>　　 con.rollBack();//回滚JDBC事务<br>　　 exc.printStackTrace();<br>　　 dbc.close();<br>　　 return -1;<br>} </p>\n<h3 id=\"基于-Transactional-的声明式事务管理\"><a href=\"#基于-Transactional-的声明式事务管理\" class=\"headerlink\" title=\"基于 @Transactional 的声明式事务管理\"></a>基于 @Transactional 的声明式事务管理</h3><p>@Transactional(isolation=Isolation.DEFAULT,propagation=Propagation.REQUIRED)</p>\n<h2 id=\"有没有用过事务-事务用于什么地方\"><a href=\"#有没有用过事务-事务用于什么地方\" class=\"headerlink\" title=\"有没有用过事务 事务用于什么地方\"></a>有没有用过事务 事务用于什么地方</h2><p>事务用于缴费的时候要更新多个地方时候，执行报错的时候需要回滚</p>\n<h2 id=\"事务注解参数-事务注解有没有什么参数-你需要去配置\"><a href=\"#事务注解参数-事务注解有没有什么参数-你需要去配置\" class=\"headerlink\" title=\"事务注解参数 事务注解有没有什么参数 你需要去配置\"></a>事务注解参数 事务注解有没有什么参数 你需要去配置</h2><p>RollBackfor NotRollBackfor timeout  事务隔离级别 事务传播行为</p>\n<p>一般回滚的话runtimeexception 都会回滚，error也会回滚</p>\n<h2 id=\"事务什么时候会回滚-是不是什么报错都会回滚\"><a href=\"#事务什么时候会回滚-是不是什么报错都会回滚\" class=\"headerlink\" title=\"事务什么时候会回滚  是不是什么报错都会回滚\"></a>事务什么时候会回滚  是不是什么报错都会回滚</h2><p>设置了notrollbackfor 就不会回滚，myisam存储引擎不会回滚事务，innerdb会回滚<br>如果你抛出的异常是Exception，是不会回滚的，需要抛出一个RuntimeException</p>\n<h2 id=\"事务传播行为类型\"><a href=\"#事务传播行为类型\" class=\"headerlink\" title=\"事务传播行为类型\"></a>事务传播行为类型</h2><p>TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。<br>TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。<br>TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。<br>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。<br>TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。<br>TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。<br>TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；<br>如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。</p>\n<h2 id=\"事务四性\"><a href=\"#事务四性\" class=\"headerlink\" title=\"事务四性\"></a>事务四性</h2><p>ACID </p>\n<p>原子性：1的操作 任何操作都是1或者0 这个是靠undo日志来实现的</p>\n<p>持久性：故障之后任然可以达到恢复 用的是redo日志来实现的</p>\n<p>隔离性： 两个事务互相不打扰 是使用读写锁和MVCC来实现的</p>\n<p>一致性：数据加起来等于1 是用上面的三个来共同维护的</p>\n<h2 id=\"redo-undo-bin-log-relay-log\"><a href=\"#redo-undo-bin-log-relay-log\" class=\"headerlink\" title=\"redo undo bin log relay log\"></a>redo undo bin log relay log</h2><p>redo日志 及undo 日志<br>redo，undo日志都是保存到磁盘里面的</p>\n<p>redo日志当你操作的时候，突然程序崩溃了或者宕机，系统断电了<br>这个时候重启之后，redo日志会同步到数据库里面</p>\n<p>undo日志是用于回滚操作的，当你事务要执行回滚的时候，你就得通过undo日志来进行回滚</p>\n<p>binlog 这个也可以做数据恢复，最新也是先写到binlog里面，然后再写到redo日志里面，最后复制到数据库存储里面</p>\n<p>redo log是InnoDB存储引擎层的日志，binlog是MySQL Server层记录的日志， 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）</p>\n<p>所以说Oracle 也是有undo 和redo log的，但是没有binlog</p>\n<p>mysql主从复制，复制的是binlog 里面的数据   ，写到relay log  然后再写到数据库</p>\n<h3 id=\"binlog日志录入格式\"><a href=\"#binlog日志录入格式\" class=\"headerlink\" title=\"binlog日志录入格式\"></a>binlog日志录入格式</h3><p>1，statement，保存用户的所有操作sql，每一条修改数据的sql 都会保存到binlog中<br>2，row，不记录sql上下文语句，仅仅保存哪条数据被修改<br>3，mixed，是上面两种的混合</p>\n<h2 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h2><p>脏读：就是你提交了数据，我读取了你的数据，这个时候你又回滚了操作，我读取了你的脏数据</p>\n<p>不可重复读：就是你读取了数据，我update了数据，这个时候你又读取了数据，数据不一致<br>A select   -》 B update -》A select  这种应该是不可重复读啊</p>\n<p>幻读：你update100条数据，这个时候我又insert了一条，这个时候你查询一次，发现还有一条数据没有update<br>A select  -》 A update -》B insert -》A select   这种应该就是幻读了</p>\n<p>读未提交（read-uncommitted）<br>读的是别人未提交的数据</p>\n<p>读提交（read-committed）<br>读的是别人commit 数据 还是会出现幻读</p>\n<p>可重复读（repeatable-read）<br>读别人commit数据，然后加间隙锁不给读写</p>\n<p>串行化（serializable）<br>所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。</p>\n<h1 id=\"mysql-锁机制\"><a href=\"#mysql-锁机制\" class=\"headerlink\" title=\"mysql 锁机制\"></a>mysql 锁机制</h1><h2 id=\"乐观锁-悲观锁\"><a href=\"#乐观锁-悲观锁\" class=\"headerlink\" title=\"乐观锁 悲观锁\"></a>乐观锁 悲观锁</h2><p>mysql 里面统一为悲观锁，没有乐观锁，乐观锁是人为的加个状态，例如版本号，更改一下版本号来更改状态，<br>悲观锁为读写锁，行 表锁，在操作之前先锁住表</p>\n<h2 id=\"读写锁\"><a href=\"#读写锁\" class=\"headerlink\" title=\"读写锁\"></a>读写锁</h2><p>读锁可以并行，写锁又叫排他锁，不可以并行，会造成死锁，互相争夺资源</p>\n<h2 id=\"行锁-表锁\"><a href=\"#行锁-表锁\" class=\"headerlink\" title=\"行锁 表锁\"></a>行锁 表锁</h2><h2 id=\"间隙锁\"><a href=\"#间隙锁\" class=\"headerlink\" title=\"间隙锁\"></a>间隙锁</h2><p>间隙锁是发生在可重复读的事务隔离级别，在更新插入的时候会自动形成对应的间隙锁，间隙锁是一个分段锁，0-100 ，100-200,200-300…<br>，当有事务A 要插入的时候会引入间隙锁，这个时候B无法提交，这个就是间隙锁，但是这里会引发死锁问题，当事务B 也引入间隙锁<br>这个时候就死锁，谁也没法提交事务</p>\n<p><a href=\"https://www.cnblogs.com/lusaisai/p/13400088.html\">锁机制</a></p>\n<h2 id=\"MVCC多版本控制\"><a href=\"#MVCC多版本控制\" class=\"headerlink\" title=\"MVCC多版本控制\"></a>MVCC多版本控制</h2><p>undo log 中记录某行数据的多个版本的数据</p>\n<h2 id=\"当前读-快照读\"><a href=\"#当前读-快照读\" class=\"headerlink\" title=\"当前读  快照读\"></a>当前读  快照读</h2><p>当前读就是读取当前版本，insert update 这些操作都是当前读，会先获取当前最新数据，然后读取出来加锁，然后再操作<br>快照读就是读取历史版本，select 就是快照读<br>当前读的话会进行加锁的机制，在当前读会发生间隙锁的机制，就是不给别人读写，加上排他锁</p>\n<h1 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h1><p>索引用来快速地寻找那些具有特定值的记录。如果没有索引，一般来说执行查询时遍历整张表。</p>\n<p>了解索引之前，首先要了解B+树，它是不能在非叶子节点命中的树，它的叶子节点全部是排序的，装载了所有数据</p>\n<p>索引的原理很简单，就是把无序的数据变成有序的查询<br>1、把创建了索引的列的内容进行排序<br>2、对排序结果生成倒排表<br>3、在倒排表内容上拼上数据地址链<br>4、在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据</p>\n<h2 id=\"聚簇索引和非聚簇索引\"><a href=\"#聚簇索引和非聚簇索引\" class=\"headerlink\" title=\"聚簇索引和非聚簇索引\"></a>聚簇索引和非聚簇索引</h2><p>非聚簇索引就是叶子节点存储的是地址，然后地址指向数据<br>这个时候查询会变慢，为了优化这点问题，加上了聚簇索引，它可以实现叶子节点直接存储数据，不是指针</p>\n<p>索引算法有 BTree算法和Hash算法</p>\n<h2 id=\"主键索引\"><a href=\"#主键索引\" class=\"headerlink\" title=\"主键索引\"></a>主键索引</h2><h2 id=\"唯一索引\"><a href=\"#唯一索引\" class=\"headerlink\" title=\"唯一索引\"></a>唯一索引</h2><h2 id=\"组合索引\"><a href=\"#组合索引\" class=\"headerlink\" title=\"组合索引\"></a>组合索引</h2><p>这里要说到最左前缀，组合索引要把最常查询的字段排在最前面，ABC三个组成的索引，A开头会走索引，其他开头不走索引</p>\n<h2 id=\"普通索引\"><a href=\"#普通索引\" class=\"headerlink\" title=\"普通索引\"></a>普通索引</h2><h2 id=\"回表\"><a href=\"#回表\" class=\"headerlink\" title=\"回表\"></a>回表</h2><p>例如我添加了普通索引K ，然后我select a from test where k = 12;<br>这个时候呢我们会先走k的索引，然后再查询到这条数据的主键，然后再通过主键查询到所有数据，这一个流程称为回表</p>\n<h1 id=\"解决mysql两个update-操作的解决方案\"><a href=\"#解决mysql两个update-操作的解决方案\" class=\"headerlink\" title=\"解决mysql两个update 操作的解决方案\"></a>解决mysql两个update 操作的解决方案</h1><h2 id=\"问题1-超卖问题\"><a href=\"#问题1-超卖问题\" class=\"headerlink\" title=\"问题1 超卖问题\"></a>问题1 超卖问题</h2><p>不能用快照读，要用当前读，不然数据多的时候会出现超卖问题，就是说解决方案<br>1，同步机制synchronized<br>2，要么写sql：update xx set count = count +1 where id=#{id},保证是当前读<br>3，加锁，加单个锁，变成一个进程 给库存表和余额表添加操作版本号字段，即使用乐观策略，进行cas操作。在每次update的时候先比较版本号是不是自己所获取到的版本号，是，则更新；否，则进行重试。<br>4，select …. for update语句触发mysql的互斥锁，这样其他线程在查询库存的时候就阻塞，从而达到并发安全。</p>\n<h2 id=\"问题2-保证两个update-原子性\"><a href=\"#问题2-保证两个update-原子性\" class=\"headerlink\" title=\"问题2 保证两个update 原子性\"></a>问题2 保证两个update 原子性</h2><p>1，用事务机制，保证原子性，一个update是另外一个update成功的前提，不然就回滚<br> 这个方法会出现长事务，数据库锁等待频繁，效率稍微低一些，但是还是可以接受的。<br>2，捕捉异常，手动进行回滚  执行效率提升，但是代码的复杂度会高很多。</p>\n<h1 id=\"MySQL中varchar与char的区别及varchar-50-中50代表什么含义？\"><a href=\"#MySQL中varchar与char的区别及varchar-50-中50代表什么含义？\" class=\"headerlink\" title=\"MySQL中varchar与char的区别及varchar(50)中50代表什么含义？\"></a>MySQL中varchar与char的区别及varchar(50)中50代表什么含义？</h1><p>varchar 是可变长度的   char 是不可变长度的，当同样存储‘hello’这个字符时候，varchar 就只是占用5个字符后面,而char(100)，就算存储5个字符<br>也会暂用100个字符，用varchar 可以节省存储空间。char(100)在后面都是补空格来填充的，但是order by 的时候会去掉。</p>\n<h1 id=\"mysql索引数据结构\"><a href=\"#mysql索引数据结构\" class=\"headerlink\" title=\"mysql索引数据结构\"></a>mysql索引数据结构</h1><p>1，二叉树——要是有序的数字的话，二叉树不合适会一直右边排布下去<br>2，红黑树——会自动平衡，不会一直排布下去，高度非常高，树的高度非常高，磁盘IO 非常多<br>3，B树———控制高度，树的高度比较少，但是没法进行范围查找，B树节点里面存储了数据，这里面要用到很多存储空间<br>4，B+树——–可以进行范围查找，同时节点里面只是存key，没有存储数据，数据放到叶子页面，这样可以存储很多数据</p>\n<h1 id=\"为什么mysql-要增加一个自增索引-用int-类型-为啥不用UUID\"><a href=\"#为什么mysql-要增加一个自增索引-用int-类型-为啥不用UUID\" class=\"headerlink\" title=\"为什么mysql 要增加一个自增索引 用int 类型  为啥不用UUID\"></a>为什么mysql 要增加一个自增索引 用int 类型  为啥不用UUID</h1><p>1，有利于范围查找<br>2，增加排序效率<br>3，提高扫表能力，顺序访问<br>4，减少分层，如果是UUID的话数据量会比较大<br>5，这个还要从表的插入有关，自增id的话 每次都在最后面一个插入，这样插入容易<br>但是用UUID的话 就每次插入都是要计算一遍，看下具体位置是在哪里，这个时候效率就比较低下了<br>然后当一页插不进去的时候，这个时候要插入额外的一条数据的时候，自增ID 没有这个问题，但是用UUID 会要分裂，分表来插入，这个时候会有问题</p>\n<h1 id=\"mysql-主从复制原理\"><a href=\"#mysql-主从复制原理\" class=\"headerlink\" title=\"mysql 主从复制原理\"></a>mysql 主从复制原理</h1><p>原理：<br>（1）master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；<br>（2）slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件<br>（3）同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。<br>也就是说：</p>\n<h2 id=\"从库会生成两个线程-一个I-O线程-一个SQL线程\"><a href=\"#从库会生成两个线程-一个I-O线程-一个SQL线程\" class=\"headerlink\" title=\"从库会生成两个线程,一个I/O线程,一个SQL线程;\"></a>从库会生成两个线程,一个I/O线程,一个SQL线程;</h2><p>I/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中;<br>主库会生成一个log dump线程,用来给从库I/O线程传binlog;<br>SQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行;</p>\n<h2 id=\"分布式事务是怎么做的（seata框架）\"><a href=\"#分布式事务是怎么做的（seata框架）\" class=\"headerlink\" title=\"分布式事务是怎么做的（seata框架）\"></a>分布式事务是怎么做的（seata框架）</h2><ol>\n<li>二阶段提交协议 (2PC)<br> 协议中有两类节点：一个中心化协调者 (Coordinator) 节点与 N 个参与者 (Cohort) 节点。<br> 1），协调者询问所有的参与者是否可以提交事务，所有参与者向协调者投票，同时参与者执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入本地日志<br> 2），协调者根据参与者的投票结果，做出是否事务可以全局提交的决定，并通知所有参与者执行该决定，如若一个节点没有回复，那就是通知所有事务回滚。<br> 缺点<br> 1），一旦协调者所在服务器宕机，就会影响整个数据库集群的正常运行<br> 2），所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，这样效率极其低下。<br> 3），两阶段提交协议虽然是分布式数据强一致性所设计，但仍然存在数据不一致性的可能性。比如在第二阶段中，假设协调者发出了事务 commit 通知，<br> 但是因为网络问题该通知仅被一部分参与者所收到并执行了commit 操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。</li>\n<li>三阶段提交协议 (3PC)<br>针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。<br>三阶段提交的三个阶段分别为：预询盘（can_commit）、预提交（pre_commit），以及事务提交（do_commit）。<br> 1），为甚需要cancommit<br> 假设有1个协调者，9个参与者。其中有一个参与者不具备执行该事务的能力。<br> 协调者发出prepare消息之后，其余参与者都将资源锁住，执行事务，写入undo和redo日志。<br> 协调者收到相应之后，发现有一个参与者不能参与。所以，又出一个roolback消息。其余8个参与者，又对消息进行回滚。这样子，是不是做了很多无用功？<br> 所以，引入can-Commit阶段，主要是为了在预执行之前，保证所有参与者都具备可执行条件，从而减少资源浪费。<br> 2)，这种方案解决了服务协调者单点问题，在cancommit 之后 precommit 之后 所有节点在docommit阶段要是超时没有收到协调者信息的时候会默认提交事务<br> 因为在precommit阶段已经知道所有节点都同意提交事务了</li>\n<li>基于消息的分布式事务<br> 基于rabbitmq的消息队列，每次发送的时候先执行A，然后再发送给rabbitmq 这样就不会消息丢失</li>\n</ol>\n<h1 id=\"怎么处理慢查询\"><a href=\"#怎么处理慢查询\" class=\"headerlink\" title=\"怎么处理慢查询\"></a>怎么处理慢查询</h1><p>1，先开启慢查询，并且把慢查询的日志打印，开启的是slow_query_log<br>2，explain去查看语句，看下语句有无走索引<br>3，优化sql，不要去用like及一些比较复杂的运算</p>"},{"date":"2020-03-16T16:00:00.000Z","status":"public","title":"redis机制","_content":"\n摘要:redis机制\n<!--more-->\n\n\n## 底层原理\nredis 是基于C 语言写的 ，基于内存的底层的，key-value  ，nosql 数据库\n\n## redis 特点\n### 硬盘持久化\n持久化方式： RDB AOF  \nRDB 就是快照缓存，就是每次都是生成一个RDB 文件，然后覆盖掉之前的文件，redis默认是RDB，save 和 bgsave 会触发这个缓存，然后生成一个RDB文件，一段时间之后替换\nAOF 就是每次进行操作的时候，都会把操作命令写到AOF 文件里面，会把每个命令都写到AOF 文件里面，这就导致AOF文件比较大\n\nRDB AOF 选择，默认是RDB，RDB恢复大数据集的时候会更快，RDB缺点就是一段时间才开启一次快照缓存，如果这段时间宕机了，这段时间的数据就丢失了\nAOF 只是对RDB的一个补充，AOF 默认是不开启的，AOF是实时写进命令的，所以一般宕机啥的数据恢复都不会丢失，但是这个命令一直写进去AOF文件，就导致数据文件非常大\n\nSlaver先将Master那边获取到的信息压入磁盘，再load进内存，client端是从内存中读取信息的，所以Redis是内存数据库。\n\n### 主从模式\n主从复制，防止数据丢失 ,读写分离，在主节点写入，其他节点读出\n\n### 哨兵模式\n选主的概念，当主宕机之后就会立马，从几个从节点当中选主\n\n## 支持的数据类型\nString set list sortset map\n\n## sortset 是什么数据格式\n跳跃表，所谓跳跃表就是一个链表，原本这个链表查询是需要从1->10这样子查询，但是跳表实现了多层查询，通过分层1->5,6->10这样子查询\n当查询数字为5的时候，跳表只要查一次就行，大大加快了效率\n利用sortset实现延迟队列，在卡夫卡里面是不能实现延迟队列的，这些都是消息队列，来一个消费一个，达到解耦削锋异步的效果，\n但是要实现延迟多少时间固定消费哪些消息，这个卡夫卡是做不到，但是redis的sortset是可以实现的，先用过把所有消息都用时间来作为score，\nscore 就是set的key，当一段时间之后就通过ZRANGEBYSCORE查询出所有的消息，包括已过期和当前达到时间的消息体，\n再消费之后通过ZREM 来消除这个消息体，但是这个不是原子的，可能使得一条消息被消费多次，需要lua脚本保证原子性\n时间复杂度O(Log(N))\n\n## redis 与Memcached对比\n1，redis支持数据类型多，mencached只支持string\n2，redis支持主从，高可用\n3，redis支持哨兵模式\n4，redis 速度快，单线程\n5，redis 支持持久化\n\n## nosql\n非关系型数据库，\n\n## 缓存雪崩\n这个问题是大量请求的时候，请求一个接口，这个时候会设置一个缓存来缓存数据，这样子别人来请求的时候就会读取缓存，缓解数据库压力，但是在缓存时间过期的时候，\n这个时候还是会有大量请求回过来，这个时候redis压力过大，就会出现缓存雪崩，要尽量把缓存失效时间分散一点，同时对于不常用的key要过滤掉，永久不失效\n##缓存穿透\n外界请求不断请求一个没有缓存的key  一直请求，而且是一次性大量操作来请求你的接口，这个就叫缓存穿透。解决办法是尽量把不需要用的key过滤掉，然后永久不失效\n另外一个解决办法是布隆过滤器\n\n## 缓存雪崩怎么解决\n1，加上一个map存在key里面，每次都检查一遍看下有没有对应的key，就不用去查数据库了\n2，缓存雪崩主要是大量的key失效，导致请求一起来，这个要设置各个key的过期时间尽量均匀，不要同一时间过期\n\n## 布隆过滤器(Bloom Filter)详解\n直观的说，bloom算法类似一个hash set，用来判断某个元素（key）是否在某个集合中。\n和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。\n\n算法：\n1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数\n2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0\n3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1\n4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。\n\n## redis的分布式锁\n这个时候还是需要让redis 设置锁来实现，setnx， set if not exits，\n如果在设置锁之后，更新缓存意外退出了，这个时候还要给锁设置一个过期时间，但是setnx 没有设置过期时间，这个时候还需要expire 来设置过期时间\n\n## 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\n使用keys指令可以扫出指定模式的key列表。如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？\n这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。\n这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，\n但是整体所花费的时间会比直接用keys指令长。\n\n## redis 集群\n### 主从复制原理\n从节点发送 SYNC 命令的主服务器将开始执行 BGSAVE ， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。\n当 BGSAVE 执行完毕后， 主服务器将执行保存操作所得的 .rdb 文件发送给从服务器， 从服务器接收这个 .rdb 文件， \n并将文件中的数据载入到内存中\n### redis cluster\nRedis 集群采用  Gossip（流言）协议，Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，\n这种方式类似流言传播。通过不断发送ping/pong，每个节点都会单独开一个TCP通道，彼此通信\n三主三从，这里采用去中心化，\n\n### redis 槽 重新分配的时候，它是怎么提供服务的\n他会一个槽一个槽的转移，当这个时候客户端来查询的时候，源节点会先在自己的数据库里面查找指定的键，如果找到的话，\n就直接执行客户端发送的命令，相反地，如果源节点没能在自己的数据库里面找到指定的键，\n那么这个键有可能已经被迁移到了目标节点，\n源节点将向客户端返回一个ASK错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令\n\n## redis缓存 怎么解决map 存储大量数据\n存储到bitmap 里面 ，bitmap 可以存储大量数据\n\n\n#redis 过期键删除策略\n## 设置key的过期删除指令\n通过EXPIRE命令或者PEXPIRE命令\nEXPIRE＜key＞＜ttl＞命令用于将键key的生存时间设置为ttl秒\n\nEXPIRE、PEXPIRE和EXPIREAT三个命令都会转换成PEXPIREAT命令来执行\n\n##  过期字典\nredisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典\n\n##  key剩余时间查询 TTL\n剩余时间要是无限的话就返回-1，TTL命令以秒为单位返回键的剩余生存时间，而PTTL命令则以毫秒为单位返回键的剩余生存时间\n##  主节点的过期删除策略\n1，定时删除，创建键值的同时创建一个定时器，在时间到期之后删除键值 -----对cpu不友好\n2，惰性删除，就是放任键值过期，每次来取值的时候就检查一遍时间是否过期了 -----对内存不友好\n3，定期删除，一段时间就删除一大片的过期数据\n\nRedis服务器实际使用的是惰性删除和定期删除两种策略\n\n定期删除的原理，可以设置一段时间检查一定数量数据库中的一定数量的key过期，有个全局变量会纪录当前检查到哪个库了，例如这次检查1-10，下次检查就从11开始检查了\n然后等全部库检查完之后又是把这个值设置为0开始，检查单个库的时候会有一定时间检查key 有无过期，一定时间过去之后就轮到下一个库了\n\n##  从节点的过期策略\n从节点过期key是如何删除的呢？主节点在key到期时，会在AOF文件里增加一条del指令。\nAOF文件被同步到从节点以后，从节点根据AOF中的这个del指令来执行删除过期key的操作。\n\n# 内存溢出控制策略\n1，noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。\n2，allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。\n3，allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。\n4，volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。\n5，volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。\n6，volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。如果没有对应的键，则回退到noeviction策略。\n\n# redis slot 为什么是16384个\n因为作者觉得够用了，在增加节点的时候，搭建者要给两个几点发送meet指令，发送完成之后两个节点就会不断发送ping，和pong的通信了\n，但是ping的指令里面是包括数据的（消息体和消息头组成），如果这个槽的大小为65535的话2……16的话 那就数据量很大了，会很慢，同事redis设计初衷\n，节点不会超过1一千个，所以作者觉得16384够用了。\n\n# redis 哨兵的选举算法\n会对slave进行排序\n（1）按照slave优先级进行排序，slave priority越低，优先级就越高\n（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高\n（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave\n\n\n# redis 事务\nredis 的事务其实就是一堆命令的集合，其顺序如下：\nmulti : 标记一个事务块的开始\nset，命令入队列\nexec : 执行所有事务块的命令，一旦执行会锁住\ndiscard : 取消事务，放弃事务块中的所有命令\n\n# redis 工具类\nspringframework RedisTemplate->RedisConnectionFactory->Jedis pool\njedis Redis官方推荐的Java连接开发工具。要在Java开发中使用好Redis中间件\nJedis的基本使用非常简单，只需要创建Jedis对象的时候指定host，port, password即可\nJedis是Redis官方推荐的面向Java的操作Redis的客户端，而RedisTemplate是SpringDataRedis中对JedisApi的高度封装。\nSpringDataRedis相对于Jedis来说可以方便地更换Redis的Java客户端，\n比Jedis多了自动管理连接池的特性，方便与其他Spring框架进行搭配使用\n\n# redis主从是怎么同步的\n全量同步\nRedis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： \n-  从服务器连接主服务器，发送SYNC命令； \n-  主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； \n-  主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； \n-  从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； \n-  主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； \n-  从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；\n-  \n增量同步\nRedis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 \n增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。‘\n\n# 红锁\n分布式多个地方都加锁，只有超过一半的锁成功了 才说明成功加锁了\n# 读写锁\n读多写少，读读不互斥  读写互斥  写写互斥\n\n# redis工具使用\n删除CacheRefresh开头的数据\n```bash\nredis-cli --scan --pattern \"CacheRefresh:*\" | xargs redis-cli del\n```","source":"_posts/java/redis机制.md","raw":"---\ndate: 2020-03-17\nstatus: public\ntitle: redis机制\ntags:\n  - JAVA \n  - redis\n---\n\n摘要:redis机制\n<!--more-->\n\n\n## 底层原理\nredis 是基于C 语言写的 ，基于内存的底层的，key-value  ，nosql 数据库\n\n## redis 特点\n### 硬盘持久化\n持久化方式： RDB AOF  \nRDB 就是快照缓存，就是每次都是生成一个RDB 文件，然后覆盖掉之前的文件，redis默认是RDB，save 和 bgsave 会触发这个缓存，然后生成一个RDB文件，一段时间之后替换\nAOF 就是每次进行操作的时候，都会把操作命令写到AOF 文件里面，会把每个命令都写到AOF 文件里面，这就导致AOF文件比较大\n\nRDB AOF 选择，默认是RDB，RDB恢复大数据集的时候会更快，RDB缺点就是一段时间才开启一次快照缓存，如果这段时间宕机了，这段时间的数据就丢失了\nAOF 只是对RDB的一个补充，AOF 默认是不开启的，AOF是实时写进命令的，所以一般宕机啥的数据恢复都不会丢失，但是这个命令一直写进去AOF文件，就导致数据文件非常大\n\nSlaver先将Master那边获取到的信息压入磁盘，再load进内存，client端是从内存中读取信息的，所以Redis是内存数据库。\n\n### 主从模式\n主从复制，防止数据丢失 ,读写分离，在主节点写入，其他节点读出\n\n### 哨兵模式\n选主的概念，当主宕机之后就会立马，从几个从节点当中选主\n\n## 支持的数据类型\nString set list sortset map\n\n## sortset 是什么数据格式\n跳跃表，所谓跳跃表就是一个链表，原本这个链表查询是需要从1->10这样子查询，但是跳表实现了多层查询，通过分层1->5,6->10这样子查询\n当查询数字为5的时候，跳表只要查一次就行，大大加快了效率\n利用sortset实现延迟队列，在卡夫卡里面是不能实现延迟队列的，这些都是消息队列，来一个消费一个，达到解耦削锋异步的效果，\n但是要实现延迟多少时间固定消费哪些消息，这个卡夫卡是做不到，但是redis的sortset是可以实现的，先用过把所有消息都用时间来作为score，\nscore 就是set的key，当一段时间之后就通过ZRANGEBYSCORE查询出所有的消息，包括已过期和当前达到时间的消息体，\n再消费之后通过ZREM 来消除这个消息体，但是这个不是原子的，可能使得一条消息被消费多次，需要lua脚本保证原子性\n时间复杂度O(Log(N))\n\n## redis 与Memcached对比\n1，redis支持数据类型多，mencached只支持string\n2，redis支持主从，高可用\n3，redis支持哨兵模式\n4，redis 速度快，单线程\n5，redis 支持持久化\n\n## nosql\n非关系型数据库，\n\n## 缓存雪崩\n这个问题是大量请求的时候，请求一个接口，这个时候会设置一个缓存来缓存数据，这样子别人来请求的时候就会读取缓存，缓解数据库压力，但是在缓存时间过期的时候，\n这个时候还是会有大量请求回过来，这个时候redis压力过大，就会出现缓存雪崩，要尽量把缓存失效时间分散一点，同时对于不常用的key要过滤掉，永久不失效\n##缓存穿透\n外界请求不断请求一个没有缓存的key  一直请求，而且是一次性大量操作来请求你的接口，这个就叫缓存穿透。解决办法是尽量把不需要用的key过滤掉，然后永久不失效\n另外一个解决办法是布隆过滤器\n\n## 缓存雪崩怎么解决\n1，加上一个map存在key里面，每次都检查一遍看下有没有对应的key，就不用去查数据库了\n2，缓存雪崩主要是大量的key失效，导致请求一起来，这个要设置各个key的过期时间尽量均匀，不要同一时间过期\n\n## 布隆过滤器(Bloom Filter)详解\n直观的说，bloom算法类似一个hash set，用来判断某个元素（key）是否在某个集合中。\n和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。\n\n算法：\n1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数\n2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0\n3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1\n4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。\n\n## redis的分布式锁\n这个时候还是需要让redis 设置锁来实现，setnx， set if not exits，\n如果在设置锁之后，更新缓存意外退出了，这个时候还要给锁设置一个过期时间，但是setnx 没有设置过期时间，这个时候还需要expire 来设置过期时间\n\n## 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\n使用keys指令可以扫出指定模式的key列表。如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？\n这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。\n这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，\n但是整体所花费的时间会比直接用keys指令长。\n\n## redis 集群\n### 主从复制原理\n从节点发送 SYNC 命令的主服务器将开始执行 BGSAVE ， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。\n当 BGSAVE 执行完毕后， 主服务器将执行保存操作所得的 .rdb 文件发送给从服务器， 从服务器接收这个 .rdb 文件， \n并将文件中的数据载入到内存中\n### redis cluster\nRedis 集群采用  Gossip（流言）协议，Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，\n这种方式类似流言传播。通过不断发送ping/pong，每个节点都会单独开一个TCP通道，彼此通信\n三主三从，这里采用去中心化，\n\n### redis 槽 重新分配的时候，它是怎么提供服务的\n他会一个槽一个槽的转移，当这个时候客户端来查询的时候，源节点会先在自己的数据库里面查找指定的键，如果找到的话，\n就直接执行客户端发送的命令，相反地，如果源节点没能在自己的数据库里面找到指定的键，\n那么这个键有可能已经被迁移到了目标节点，\n源节点将向客户端返回一个ASK错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令\n\n## redis缓存 怎么解决map 存储大量数据\n存储到bitmap 里面 ，bitmap 可以存储大量数据\n\n\n#redis 过期键删除策略\n## 设置key的过期删除指令\n通过EXPIRE命令或者PEXPIRE命令\nEXPIRE＜key＞＜ttl＞命令用于将键key的生存时间设置为ttl秒\n\nEXPIRE、PEXPIRE和EXPIREAT三个命令都会转换成PEXPIREAT命令来执行\n\n##  过期字典\nredisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典\n\n##  key剩余时间查询 TTL\n剩余时间要是无限的话就返回-1，TTL命令以秒为单位返回键的剩余生存时间，而PTTL命令则以毫秒为单位返回键的剩余生存时间\n##  主节点的过期删除策略\n1，定时删除，创建键值的同时创建一个定时器，在时间到期之后删除键值 -----对cpu不友好\n2，惰性删除，就是放任键值过期，每次来取值的时候就检查一遍时间是否过期了 -----对内存不友好\n3，定期删除，一段时间就删除一大片的过期数据\n\nRedis服务器实际使用的是惰性删除和定期删除两种策略\n\n定期删除的原理，可以设置一段时间检查一定数量数据库中的一定数量的key过期，有个全局变量会纪录当前检查到哪个库了，例如这次检查1-10，下次检查就从11开始检查了\n然后等全部库检查完之后又是把这个值设置为0开始，检查单个库的时候会有一定时间检查key 有无过期，一定时间过去之后就轮到下一个库了\n\n##  从节点的过期策略\n从节点过期key是如何删除的呢？主节点在key到期时，会在AOF文件里增加一条del指令。\nAOF文件被同步到从节点以后，从节点根据AOF中的这个del指令来执行删除过期key的操作。\n\n# 内存溢出控制策略\n1，noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。\n2，allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。\n3，allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。\n4，volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。\n5，volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。\n6，volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。如果没有对应的键，则回退到noeviction策略。\n\n# redis slot 为什么是16384个\n因为作者觉得够用了，在增加节点的时候，搭建者要给两个几点发送meet指令，发送完成之后两个节点就会不断发送ping，和pong的通信了\n，但是ping的指令里面是包括数据的（消息体和消息头组成），如果这个槽的大小为65535的话2……16的话 那就数据量很大了，会很慢，同事redis设计初衷\n，节点不会超过1一千个，所以作者觉得16384够用了。\n\n# redis 哨兵的选举算法\n会对slave进行排序\n（1）按照slave优先级进行排序，slave priority越低，优先级就越高\n（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高\n（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave\n\n\n# redis 事务\nredis 的事务其实就是一堆命令的集合，其顺序如下：\nmulti : 标记一个事务块的开始\nset，命令入队列\nexec : 执行所有事务块的命令，一旦执行会锁住\ndiscard : 取消事务，放弃事务块中的所有命令\n\n# redis 工具类\nspringframework RedisTemplate->RedisConnectionFactory->Jedis pool\njedis Redis官方推荐的Java连接开发工具。要在Java开发中使用好Redis中间件\nJedis的基本使用非常简单，只需要创建Jedis对象的时候指定host，port, password即可\nJedis是Redis官方推荐的面向Java的操作Redis的客户端，而RedisTemplate是SpringDataRedis中对JedisApi的高度封装。\nSpringDataRedis相对于Jedis来说可以方便地更换Redis的Java客户端，\n比Jedis多了自动管理连接池的特性，方便与其他Spring框架进行搭配使用\n\n# redis主从是怎么同步的\n全量同步\nRedis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： \n-  从服务器连接主服务器，发送SYNC命令； \n-  主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； \n-  主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； \n-  从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； \n-  主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； \n-  从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；\n-  \n增量同步\nRedis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 \n增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。‘\n\n# 红锁\n分布式多个地方都加锁，只有超过一半的锁成功了 才说明成功加锁了\n# 读写锁\n读多写少，读读不互斥  读写互斥  写写互斥\n\n# redis工具使用\n删除CacheRefresh开头的数据\n```bash\nredis-cli --scan --pattern \"CacheRefresh:*\" | xargs redis-cli del\n```","slug":"java/redis机制","published":1,"updated":"2025-05-16T08:14:04.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jsy001xskqr9ztv51tk","content":"<p>摘要:redis机制</p>\n<span id=\"more\"></span>\n\n\n<h2 id=\"底层原理\"><a href=\"#底层原理\" class=\"headerlink\" title=\"底层原理\"></a>底层原理</h2><p>redis 是基于C 语言写的 ，基于内存的底层的，key-value  ，nosql 数据库</p>\n<h2 id=\"redis-特点\"><a href=\"#redis-特点\" class=\"headerlink\" title=\"redis 特点\"></a>redis 特点</h2><h3 id=\"硬盘持久化\"><a href=\"#硬盘持久化\" class=\"headerlink\" title=\"硬盘持久化\"></a>硬盘持久化</h3><p>持久化方式： RDB AOF<br>RDB 就是快照缓存，就是每次都是生成一个RDB 文件，然后覆盖掉之前的文件，redis默认是RDB，save 和 bgsave 会触发这个缓存，然后生成一个RDB文件，一段时间之后替换<br>AOF 就是每次进行操作的时候，都会把操作命令写到AOF 文件里面，会把每个命令都写到AOF 文件里面，这就导致AOF文件比较大</p>\n<p>RDB AOF 选择，默认是RDB，RDB恢复大数据集的时候会更快，RDB缺点就是一段时间才开启一次快照缓存，如果这段时间宕机了，这段时间的数据就丢失了<br>AOF 只是对RDB的一个补充，AOF 默认是不开启的，AOF是实时写进命令的，所以一般宕机啥的数据恢复都不会丢失，但是这个命令一直写进去AOF文件，就导致数据文件非常大</p>\n<p>Slaver先将Master那边获取到的信息压入磁盘，再load进内存，client端是从内存中读取信息的，所以Redis是内存数据库。</p>\n<h3 id=\"主从模式\"><a href=\"#主从模式\" class=\"headerlink\" title=\"主从模式\"></a>主从模式</h3><p>主从复制，防止数据丢失 ,读写分离，在主节点写入，其他节点读出</p>\n<h3 id=\"哨兵模式\"><a href=\"#哨兵模式\" class=\"headerlink\" title=\"哨兵模式\"></a>哨兵模式</h3><p>选主的概念，当主宕机之后就会立马，从几个从节点当中选主</p>\n<h2 id=\"支持的数据类型\"><a href=\"#支持的数据类型\" class=\"headerlink\" title=\"支持的数据类型\"></a>支持的数据类型</h2><p>String set list sortset map</p>\n<h2 id=\"sortset-是什么数据格式\"><a href=\"#sortset-是什么数据格式\" class=\"headerlink\" title=\"sortset 是什么数据格式\"></a>sortset 是什么数据格式</h2><p>跳跃表，所谓跳跃表就是一个链表，原本这个链表查询是需要从1-&gt;10这样子查询，但是跳表实现了多层查询，通过分层1-&gt;5,6-&gt;10这样子查询<br>当查询数字为5的时候，跳表只要查一次就行，大大加快了效率<br>利用sortset实现延迟队列，在卡夫卡里面是不能实现延迟队列的，这些都是消息队列，来一个消费一个，达到解耦削锋异步的效果，<br>但是要实现延迟多少时间固定消费哪些消息，这个卡夫卡是做不到，但是redis的sortset是可以实现的，先用过把所有消息都用时间来作为score，<br>score 就是set的key，当一段时间之后就通过ZRANGEBYSCORE查询出所有的消息，包括已过期和当前达到时间的消息体，<br>再消费之后通过ZREM 来消除这个消息体，但是这个不是原子的，可能使得一条消息被消费多次，需要lua脚本保证原子性<br>时间复杂度O(Log(N))</p>\n<h2 id=\"redis-与Memcached对比\"><a href=\"#redis-与Memcached对比\" class=\"headerlink\" title=\"redis 与Memcached对比\"></a>redis 与Memcached对比</h2><p>1，redis支持数据类型多，mencached只支持string<br>2，redis支持主从，高可用<br>3，redis支持哨兵模式<br>4，redis 速度快，单线程<br>5，redis 支持持久化</p>\n<h2 id=\"nosql\"><a href=\"#nosql\" class=\"headerlink\" title=\"nosql\"></a>nosql</h2><p>非关系型数据库，</p>\n<h2 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h2><p>这个问题是大量请求的时候，请求一个接口，这个时候会设置一个缓存来缓存数据，这样子别人来请求的时候就会读取缓存，缓解数据库压力，但是在缓存时间过期的时候，<br>这个时候还是会有大量请求回过来，这个时候redis压力过大，就会出现缓存雪崩，要尽量把缓存失效时间分散一点，同时对于不常用的key要过滤掉，永久不失效<br>##缓存穿透<br>外界请求不断请求一个没有缓存的key  一直请求，而且是一次性大量操作来请求你的接口，这个就叫缓存穿透。解决办法是尽量把不需要用的key过滤掉，然后永久不失效<br>另外一个解决办法是布隆过滤器</p>\n<h2 id=\"缓存雪崩怎么解决\"><a href=\"#缓存雪崩怎么解决\" class=\"headerlink\" title=\"缓存雪崩怎么解决\"></a>缓存雪崩怎么解决</h2><p>1，加上一个map存在key里面，每次都检查一遍看下有没有对应的key，就不用去查数据库了<br>2，缓存雪崩主要是大量的key失效，导致请求一起来，这个要设置各个key的过期时间尽量均匀，不要同一时间过期</p>\n<h2 id=\"布隆过滤器-Bloom-Filter-详解\"><a href=\"#布隆过滤器-Bloom-Filter-详解\" class=\"headerlink\" title=\"布隆过滤器(Bloom Filter)详解\"></a>布隆过滤器(Bloom Filter)详解</h2><p>直观的说，bloom算法类似一个hash set，用来判断某个元素（key）是否在某个集合中。<br>和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。</p>\n<p>算法：</p>\n<ol>\n<li>首先需要k个hash函数，每个函数可以把key散列成为1个整数</li>\n<li>初始化时，需要一个长度为n比特的数组，每个比特位初始化为0</li>\n<li>某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1</li>\n<li>判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。</li>\n</ol>\n<h2 id=\"redis的分布式锁\"><a href=\"#redis的分布式锁\" class=\"headerlink\" title=\"redis的分布式锁\"></a>redis的分布式锁</h2><p>这个时候还是需要让redis 设置锁来实现，setnx， set if not exits，<br>如果在设置锁之后，更新缓存意外退出了，这个时候还要给锁设置一个过期时间，但是setnx 没有设置过期时间，这个时候还需要expire 来设置过期时间</p>\n<h2 id=\"假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\"><a href=\"#假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\" class=\"headerlink\" title=\"假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\"></a>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？</h2><p>使用keys指令可以扫出指定模式的key列表。如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？<br>这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。<br>这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，<br>但是整体所花费的时间会比直接用keys指令长。</p>\n<h2 id=\"redis-集群\"><a href=\"#redis-集群\" class=\"headerlink\" title=\"redis 集群\"></a>redis 集群</h2><h3 id=\"主从复制原理\"><a href=\"#主从复制原理\" class=\"headerlink\" title=\"主从复制原理\"></a>主从复制原理</h3><p>从节点发送 SYNC 命令的主服务器将开始执行 BGSAVE ， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。<br>当 BGSAVE 执行完毕后， 主服务器将执行保存操作所得的 .rdb 文件发送给从服务器， 从服务器接收这个 .rdb 文件，<br>并将文件中的数据载入到内存中</p>\n<h3 id=\"redis-cluster\"><a href=\"#redis-cluster\" class=\"headerlink\" title=\"redis cluster\"></a>redis cluster</h3><p>Redis 集群采用  Gossip（流言）协议，Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，<br>这种方式类似流言传播。通过不断发送ping/pong，每个节点都会单独开一个TCP通道，彼此通信<br>三主三从，这里采用去中心化，</p>\n<h3 id=\"redis-槽-重新分配的时候，它是怎么提供服务的\"><a href=\"#redis-槽-重新分配的时候，它是怎么提供服务的\" class=\"headerlink\" title=\"redis 槽 重新分配的时候，它是怎么提供服务的\"></a>redis 槽 重新分配的时候，它是怎么提供服务的</h3><p>他会一个槽一个槽的转移，当这个时候客户端来查询的时候，源节点会先在自己的数据库里面查找指定的键，如果找到的话，<br>就直接执行客户端发送的命令，相反地，如果源节点没能在自己的数据库里面找到指定的键，<br>那么这个键有可能已经被迁移到了目标节点，<br>源节点将向客户端返回一个ASK错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令</p>\n<h2 id=\"redis缓存-怎么解决map-存储大量数据\"><a href=\"#redis缓存-怎么解决map-存储大量数据\" class=\"headerlink\" title=\"redis缓存 怎么解决map 存储大量数据\"></a>redis缓存 怎么解决map 存储大量数据</h2><p>存储到bitmap 里面 ，bitmap 可以存储大量数据</p>\n<p>#redis 过期键删除策略</p>\n<h2 id=\"设置key的过期删除指令\"><a href=\"#设置key的过期删除指令\" class=\"headerlink\" title=\"设置key的过期删除指令\"></a>设置key的过期删除指令</h2><p>通过EXPIRE命令或者PEXPIRE命令<br>EXPIRE＜key＞＜ttl＞命令用于将键key的生存时间设置为ttl秒</p>\n<p>EXPIRE、PEXPIRE和EXPIREAT三个命令都会转换成PEXPIREAT命令来执行</p>\n<h2 id=\"过期字典\"><a href=\"#过期字典\" class=\"headerlink\" title=\"过期字典\"></a>过期字典</h2><p>redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典</p>\n<h2 id=\"key剩余时间查询-TTL\"><a href=\"#key剩余时间查询-TTL\" class=\"headerlink\" title=\"key剩余时间查询 TTL\"></a>key剩余时间查询 TTL</h2><p>剩余时间要是无限的话就返回-1，TTL命令以秒为单位返回键的剩余生存时间，而PTTL命令则以毫秒为单位返回键的剩余生存时间</p>\n<h2 id=\"主节点的过期删除策略\"><a href=\"#主节点的过期删除策略\" class=\"headerlink\" title=\"主节点的过期删除策略\"></a>主节点的过期删除策略</h2><p>1，定时删除，创建键值的同时创建一个定时器，在时间到期之后删除键值 —–对cpu不友好<br>2，惰性删除，就是放任键值过期，每次来取值的时候就检查一遍时间是否过期了 —–对内存不友好<br>3，定期删除，一段时间就删除一大片的过期数据</p>\n<p>Redis服务器实际使用的是惰性删除和定期删除两种策略</p>\n<p>定期删除的原理，可以设置一段时间检查一定数量数据库中的一定数量的key过期，有个全局变量会纪录当前检查到哪个库了，例如这次检查1-10，下次检查就从11开始检查了<br>然后等全部库检查完之后又是把这个值设置为0开始，检查单个库的时候会有一定时间检查key 有无过期，一定时间过去之后就轮到下一个库了</p>\n<h2 id=\"从节点的过期策略\"><a href=\"#从节点的过期策略\" class=\"headerlink\" title=\"从节点的过期策略\"></a>从节点的过期策略</h2><p>从节点过期key是如何删除的呢？主节点在key到期时，会在AOF文件里增加一条del指令。<br>AOF文件被同步到从节点以后，从节点根据AOF中的这个del指令来执行删除过期key的操作。</p>\n<h1 id=\"内存溢出控制策略\"><a href=\"#内存溢出控制策略\" class=\"headerlink\" title=\"内存溢出控制策略\"></a>内存溢出控制策略</h1><p>1，noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。<br>2，allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。<br>3，allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。<br>4，volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。<br>5，volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。<br>6，volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。如果没有对应的键，则回退到noeviction策略。</p>\n<h1 id=\"redis-slot-为什么是16384个\"><a href=\"#redis-slot-为什么是16384个\" class=\"headerlink\" title=\"redis slot 为什么是16384个\"></a>redis slot 为什么是16384个</h1><p>因为作者觉得够用了，在增加节点的时候，搭建者要给两个几点发送meet指令，发送完成之后两个节点就会不断发送ping，和pong的通信了<br>，但是ping的指令里面是包括数据的（消息体和消息头组成），如果这个槽的大小为65535的话2……16的话 那就数据量很大了，会很慢，同事redis设计初衷<br>，节点不会超过1一千个，所以作者觉得16384够用了。</p>\n<h1 id=\"redis-哨兵的选举算法\"><a href=\"#redis-哨兵的选举算法\" class=\"headerlink\" title=\"redis 哨兵的选举算法\"></a>redis 哨兵的选举算法</h1><p>会对slave进行排序<br>（1）按照slave优先级进行排序，slave priority越低，优先级就越高<br>（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高<br>（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p>\n<h1 id=\"redis-事务\"><a href=\"#redis-事务\" class=\"headerlink\" title=\"redis 事务\"></a>redis 事务</h1><p>redis 的事务其实就是一堆命令的集合，其顺序如下：<br>multi : 标记一个事务块的开始<br>set，命令入队列<br>exec : 执行所有事务块的命令，一旦执行会锁住<br>discard : 取消事务，放弃事务块中的所有命令</p>\n<h1 id=\"redis-工具类\"><a href=\"#redis-工具类\" class=\"headerlink\" title=\"redis 工具类\"></a>redis 工具类</h1><p>springframework RedisTemplate-&gt;RedisConnectionFactory-&gt;Jedis pool<br>jedis Redis官方推荐的Java连接开发工具。要在Java开发中使用好Redis中间件<br>Jedis的基本使用非常简单，只需要创建Jedis对象的时候指定host，port, password即可<br>Jedis是Redis官方推荐的面向Java的操作Redis的客户端，而RedisTemplate是SpringDataRedis中对JedisApi的高度封装。<br>SpringDataRedis相对于Jedis来说可以方便地更换Redis的Java客户端，<br>比Jedis多了自动管理连接池的特性，方便与其他Spring框架进行搭配使用</p>\n<h1 id=\"redis主从是怎么同步的\"><a href=\"#redis主从是怎么同步的\" class=\"headerlink\" title=\"redis主从是怎么同步的\"></a>redis主从是怎么同步的</h1><p>全量同步<br>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： </p>\n<ul>\n<li> 从服务器连接主服务器，发送SYNC命令； </li>\n<li> 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； </li>\n<li> 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； </li>\n<li> 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； </li>\n<li> 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； </li>\n<li> 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</li>\n<li>增量同步<br>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。<br>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。‘</li>\n</ul>\n<h1 id=\"红锁\"><a href=\"#红锁\" class=\"headerlink\" title=\"红锁\"></a>红锁</h1><p>分布式多个地方都加锁，只有超过一半的锁成功了 才说明成功加锁了</p>\n<h1 id=\"读写锁\"><a href=\"#读写锁\" class=\"headerlink\" title=\"读写锁\"></a>读写锁</h1><p>读多写少，读读不互斥  读写互斥  写写互斥</p>\n<h1 id=\"redis工具使用\"><a href=\"#redis工具使用\" class=\"headerlink\" title=\"redis工具使用\"></a>redis工具使用</h1><p>删除CacheRefresh开头的数据</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis-cli --scan --pattern <span class=\"string\">&quot;CacheRefresh:*&quot;</span> | xargs redis-cli del</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>摘要:redis机制</p>","more":"<h2 id=\"底层原理\"><a href=\"#底层原理\" class=\"headerlink\" title=\"底层原理\"></a>底层原理</h2><p>redis 是基于C 语言写的 ，基于内存的底层的，key-value  ，nosql 数据库</p>\n<h2 id=\"redis-特点\"><a href=\"#redis-特点\" class=\"headerlink\" title=\"redis 特点\"></a>redis 特点</h2><h3 id=\"硬盘持久化\"><a href=\"#硬盘持久化\" class=\"headerlink\" title=\"硬盘持久化\"></a>硬盘持久化</h3><p>持久化方式： RDB AOF<br>RDB 就是快照缓存，就是每次都是生成一个RDB 文件，然后覆盖掉之前的文件，redis默认是RDB，save 和 bgsave 会触发这个缓存，然后生成一个RDB文件，一段时间之后替换<br>AOF 就是每次进行操作的时候，都会把操作命令写到AOF 文件里面，会把每个命令都写到AOF 文件里面，这就导致AOF文件比较大</p>\n<p>RDB AOF 选择，默认是RDB，RDB恢复大数据集的时候会更快，RDB缺点就是一段时间才开启一次快照缓存，如果这段时间宕机了，这段时间的数据就丢失了<br>AOF 只是对RDB的一个补充，AOF 默认是不开启的，AOF是实时写进命令的，所以一般宕机啥的数据恢复都不会丢失，但是这个命令一直写进去AOF文件，就导致数据文件非常大</p>\n<p>Slaver先将Master那边获取到的信息压入磁盘，再load进内存，client端是从内存中读取信息的，所以Redis是内存数据库。</p>\n<h3 id=\"主从模式\"><a href=\"#主从模式\" class=\"headerlink\" title=\"主从模式\"></a>主从模式</h3><p>主从复制，防止数据丢失 ,读写分离，在主节点写入，其他节点读出</p>\n<h3 id=\"哨兵模式\"><a href=\"#哨兵模式\" class=\"headerlink\" title=\"哨兵模式\"></a>哨兵模式</h3><p>选主的概念，当主宕机之后就会立马，从几个从节点当中选主</p>\n<h2 id=\"支持的数据类型\"><a href=\"#支持的数据类型\" class=\"headerlink\" title=\"支持的数据类型\"></a>支持的数据类型</h2><p>String set list sortset map</p>\n<h2 id=\"sortset-是什么数据格式\"><a href=\"#sortset-是什么数据格式\" class=\"headerlink\" title=\"sortset 是什么数据格式\"></a>sortset 是什么数据格式</h2><p>跳跃表，所谓跳跃表就是一个链表，原本这个链表查询是需要从1-&gt;10这样子查询，但是跳表实现了多层查询，通过分层1-&gt;5,6-&gt;10这样子查询<br>当查询数字为5的时候，跳表只要查一次就行，大大加快了效率<br>利用sortset实现延迟队列，在卡夫卡里面是不能实现延迟队列的，这些都是消息队列，来一个消费一个，达到解耦削锋异步的效果，<br>但是要实现延迟多少时间固定消费哪些消息，这个卡夫卡是做不到，但是redis的sortset是可以实现的，先用过把所有消息都用时间来作为score，<br>score 就是set的key，当一段时间之后就通过ZRANGEBYSCORE查询出所有的消息，包括已过期和当前达到时间的消息体，<br>再消费之后通过ZREM 来消除这个消息体，但是这个不是原子的，可能使得一条消息被消费多次，需要lua脚本保证原子性<br>时间复杂度O(Log(N))</p>\n<h2 id=\"redis-与Memcached对比\"><a href=\"#redis-与Memcached对比\" class=\"headerlink\" title=\"redis 与Memcached对比\"></a>redis 与Memcached对比</h2><p>1，redis支持数据类型多，mencached只支持string<br>2，redis支持主从，高可用<br>3，redis支持哨兵模式<br>4，redis 速度快，单线程<br>5，redis 支持持久化</p>\n<h2 id=\"nosql\"><a href=\"#nosql\" class=\"headerlink\" title=\"nosql\"></a>nosql</h2><p>非关系型数据库，</p>\n<h2 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h2><p>这个问题是大量请求的时候，请求一个接口，这个时候会设置一个缓存来缓存数据，这样子别人来请求的时候就会读取缓存，缓解数据库压力，但是在缓存时间过期的时候，<br>这个时候还是会有大量请求回过来，这个时候redis压力过大，就会出现缓存雪崩，要尽量把缓存失效时间分散一点，同时对于不常用的key要过滤掉，永久不失效<br>##缓存穿透<br>外界请求不断请求一个没有缓存的key  一直请求，而且是一次性大量操作来请求你的接口，这个就叫缓存穿透。解决办法是尽量把不需要用的key过滤掉，然后永久不失效<br>另外一个解决办法是布隆过滤器</p>\n<h2 id=\"缓存雪崩怎么解决\"><a href=\"#缓存雪崩怎么解决\" class=\"headerlink\" title=\"缓存雪崩怎么解决\"></a>缓存雪崩怎么解决</h2><p>1，加上一个map存在key里面，每次都检查一遍看下有没有对应的key，就不用去查数据库了<br>2，缓存雪崩主要是大量的key失效，导致请求一起来，这个要设置各个key的过期时间尽量均匀，不要同一时间过期</p>\n<h2 id=\"布隆过滤器-Bloom-Filter-详解\"><a href=\"#布隆过滤器-Bloom-Filter-详解\" class=\"headerlink\" title=\"布隆过滤器(Bloom Filter)详解\"></a>布隆过滤器(Bloom Filter)详解</h2><p>直观的说，bloom算法类似一个hash set，用来判断某个元素（key）是否在某个集合中。<br>和一般的hash set不同的是，这个算法无需存储key的值，对于每个key，只需要k个比特位，每个存储一个标志，用来判断key是否在集合中。</p>\n<p>算法：</p>\n<ol>\n<li>首先需要k个hash函数，每个函数可以把key散列成为1个整数</li>\n<li>初始化时，需要一个长度为n比特的数组，每个比特位初始化为0</li>\n<li>某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1</li>\n<li>判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。</li>\n</ol>\n<h2 id=\"redis的分布式锁\"><a href=\"#redis的分布式锁\" class=\"headerlink\" title=\"redis的分布式锁\"></a>redis的分布式锁</h2><p>这个时候还是需要让redis 设置锁来实现，setnx， set if not exits，<br>如果在设置锁之后，更新缓存意外退出了，这个时候还要给锁设置一个过期时间，但是setnx 没有设置过期时间，这个时候还需要expire 来设置过期时间</p>\n<h2 id=\"假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\"><a href=\"#假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\" class=\"headerlink\" title=\"假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？\"></a>假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？</h2><p>使用keys指令可以扫出指定模式的key列表。如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？<br>这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。<br>这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，<br>但是整体所花费的时间会比直接用keys指令长。</p>\n<h2 id=\"redis-集群\"><a href=\"#redis-集群\" class=\"headerlink\" title=\"redis 集群\"></a>redis 集群</h2><h3 id=\"主从复制原理\"><a href=\"#主从复制原理\" class=\"headerlink\" title=\"主从复制原理\"></a>主从复制原理</h3><p>从节点发送 SYNC 命令的主服务器将开始执行 BGSAVE ， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。<br>当 BGSAVE 执行完毕后， 主服务器将执行保存操作所得的 .rdb 文件发送给从服务器， 从服务器接收这个 .rdb 文件，<br>并将文件中的数据载入到内存中</p>\n<h3 id=\"redis-cluster\"><a href=\"#redis-cluster\" class=\"headerlink\" title=\"redis cluster\"></a>redis cluster</h3><p>Redis 集群采用  Gossip（流言）协议，Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，<br>这种方式类似流言传播。通过不断发送ping/pong，每个节点都会单独开一个TCP通道，彼此通信<br>三主三从，这里采用去中心化，</p>\n<h3 id=\"redis-槽-重新分配的时候，它是怎么提供服务的\"><a href=\"#redis-槽-重新分配的时候，它是怎么提供服务的\" class=\"headerlink\" title=\"redis 槽 重新分配的时候，它是怎么提供服务的\"></a>redis 槽 重新分配的时候，它是怎么提供服务的</h3><p>他会一个槽一个槽的转移，当这个时候客户端来查询的时候，源节点会先在自己的数据库里面查找指定的键，如果找到的话，<br>就直接执行客户端发送的命令，相反地，如果源节点没能在自己的数据库里面找到指定的键，<br>那么这个键有可能已经被迁移到了目标节点，<br>源节点将向客户端返回一个ASK错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令</p>\n<h2 id=\"redis缓存-怎么解决map-存储大量数据\"><a href=\"#redis缓存-怎么解决map-存储大量数据\" class=\"headerlink\" title=\"redis缓存 怎么解决map 存储大量数据\"></a>redis缓存 怎么解决map 存储大量数据</h2><p>存储到bitmap 里面 ，bitmap 可以存储大量数据</p>\n<p>#redis 过期键删除策略</p>\n<h2 id=\"设置key的过期删除指令\"><a href=\"#设置key的过期删除指令\" class=\"headerlink\" title=\"设置key的过期删除指令\"></a>设置key的过期删除指令</h2><p>通过EXPIRE命令或者PEXPIRE命令<br>EXPIRE＜key＞＜ttl＞命令用于将键key的生存时间设置为ttl秒</p>\n<p>EXPIRE、PEXPIRE和EXPIREAT三个命令都会转换成PEXPIREAT命令来执行</p>\n<h2 id=\"过期字典\"><a href=\"#过期字典\" class=\"headerlink\" title=\"过期字典\"></a>过期字典</h2><p>redisDb结构的expires字典保存了数据库中所有键的过期时间，我们称这个字典为过期字典</p>\n<h2 id=\"key剩余时间查询-TTL\"><a href=\"#key剩余时间查询-TTL\" class=\"headerlink\" title=\"key剩余时间查询 TTL\"></a>key剩余时间查询 TTL</h2><p>剩余时间要是无限的话就返回-1，TTL命令以秒为单位返回键的剩余生存时间，而PTTL命令则以毫秒为单位返回键的剩余生存时间</p>\n<h2 id=\"主节点的过期删除策略\"><a href=\"#主节点的过期删除策略\" class=\"headerlink\" title=\"主节点的过期删除策略\"></a>主节点的过期删除策略</h2><p>1，定时删除，创建键值的同时创建一个定时器，在时间到期之后删除键值 —–对cpu不友好<br>2，惰性删除，就是放任键值过期，每次来取值的时候就检查一遍时间是否过期了 —–对内存不友好<br>3，定期删除，一段时间就删除一大片的过期数据</p>\n<p>Redis服务器实际使用的是惰性删除和定期删除两种策略</p>\n<p>定期删除的原理，可以设置一段时间检查一定数量数据库中的一定数量的key过期，有个全局变量会纪录当前检查到哪个库了，例如这次检查1-10，下次检查就从11开始检查了<br>然后等全部库检查完之后又是把这个值设置为0开始，检查单个库的时候会有一定时间检查key 有无过期，一定时间过去之后就轮到下一个库了</p>\n<h2 id=\"从节点的过期策略\"><a href=\"#从节点的过期策略\" class=\"headerlink\" title=\"从节点的过期策略\"></a>从节点的过期策略</h2><p>从节点过期key是如何删除的呢？主节点在key到期时，会在AOF文件里增加一条del指令。<br>AOF文件被同步到从节点以后，从节点根据AOF中的这个del指令来执行删除过期key的操作。</p>\n<h1 id=\"内存溢出控制策略\"><a href=\"#内存溢出控制策略\" class=\"headerlink\" title=\"内存溢出控制策略\"></a>内存溢出控制策略</h1><p>1，noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。<br>2，allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。<br>3，allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。<br>4，volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。<br>5，volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。<br>6，volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。如果没有对应的键，则回退到noeviction策略。</p>\n<h1 id=\"redis-slot-为什么是16384个\"><a href=\"#redis-slot-为什么是16384个\" class=\"headerlink\" title=\"redis slot 为什么是16384个\"></a>redis slot 为什么是16384个</h1><p>因为作者觉得够用了，在增加节点的时候，搭建者要给两个几点发送meet指令，发送完成之后两个节点就会不断发送ping，和pong的通信了<br>，但是ping的指令里面是包括数据的（消息体和消息头组成），如果这个槽的大小为65535的话2……16的话 那就数据量很大了，会很慢，同事redis设计初衷<br>，节点不会超过1一千个，所以作者觉得16384够用了。</p>\n<h1 id=\"redis-哨兵的选举算法\"><a href=\"#redis-哨兵的选举算法\" class=\"headerlink\" title=\"redis 哨兵的选举算法\"></a>redis 哨兵的选举算法</h1><p>会对slave进行排序<br>（1）按照slave优先级进行排序，slave priority越低，优先级就越高<br>（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高<br>（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p>\n<h1 id=\"redis-事务\"><a href=\"#redis-事务\" class=\"headerlink\" title=\"redis 事务\"></a>redis 事务</h1><p>redis 的事务其实就是一堆命令的集合，其顺序如下：<br>multi : 标记一个事务块的开始<br>set，命令入队列<br>exec : 执行所有事务块的命令，一旦执行会锁住<br>discard : 取消事务，放弃事务块中的所有命令</p>\n<h1 id=\"redis-工具类\"><a href=\"#redis-工具类\" class=\"headerlink\" title=\"redis 工具类\"></a>redis 工具类</h1><p>springframework RedisTemplate-&gt;RedisConnectionFactory-&gt;Jedis pool<br>jedis Redis官方推荐的Java连接开发工具。要在Java开发中使用好Redis中间件<br>Jedis的基本使用非常简单，只需要创建Jedis对象的时候指定host，port, password即可<br>Jedis是Redis官方推荐的面向Java的操作Redis的客户端，而RedisTemplate是SpringDataRedis中对JedisApi的高度封装。<br>SpringDataRedis相对于Jedis来说可以方便地更换Redis的Java客户端，<br>比Jedis多了自动管理连接池的特性，方便与其他Spring框架进行搭配使用</p>\n<h1 id=\"redis主从是怎么同步的\"><a href=\"#redis主从是怎么同步的\" class=\"headerlink\" title=\"redis主从是怎么同步的\"></a>redis主从是怎么同步的</h1><p>全量同步<br>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： </p>\n<ul>\n<li> 从服务器连接主服务器，发送SYNC命令； </li>\n<li> 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； </li>\n<li> 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； </li>\n<li> 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； </li>\n<li> 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； </li>\n<li> 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</li>\n<li>增量同步<br>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。<br>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。‘</li>\n</ul>\n<h1 id=\"红锁\"><a href=\"#红锁\" class=\"headerlink\" title=\"红锁\"></a>红锁</h1><p>分布式多个地方都加锁，只有超过一半的锁成功了 才说明成功加锁了</p>\n<h1 id=\"读写锁\"><a href=\"#读写锁\" class=\"headerlink\" title=\"读写锁\"></a>读写锁</h1><p>读多写少，读读不互斥  读写互斥  写写互斥</p>\n<h1 id=\"redis工具使用\"><a href=\"#redis工具使用\" class=\"headerlink\" title=\"redis工具使用\"></a>redis工具使用</h1><p>删除CacheRefresh开头的数据</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">redis-cli --scan --pattern <span class=\"string\">&quot;CacheRefresh:*&quot;</span> | xargs redis-cli del</span><br></pre></td></tr></table></figure>"},{"date":"2021-01-12T16:00:00.000Z","status":"public","title":"springcloud","_content":"\n摘要:springcloud\n<!--more-->\n# springcloud 五大组件\n## Eureka 服务注册发现有关\n一个RESTful服务 ，主要包括两方面一个是Eureka 服务端 一个是Eureka客户端 主要用于服务注册和发现\n\n## Ribbon 负载均衡有关\n简单轮询负载均衡\n加权响应时间负载均衡\n区域感知轮询负载均衡\n随机负载均衡\n\n## Hystrix 熔断机制\n断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期\n断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响\n\n## Zuul 网关\n类似nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。\n\n## Spring cloud Config 分布式配置\n这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。\n\n# springcloud 与springcloud alibaba 什么区别\n## nacos 注册中心  \n## ","source":"_posts/java/springcloud.md","raw":"\n---\ndate: 2021-01-13\nstatus: public\ntitle: springcloud\ntags:\n  - JAVA\n---\n\n摘要:springcloud\n<!--more-->\n# springcloud 五大组件\n## Eureka 服务注册发现有关\n一个RESTful服务 ，主要包括两方面一个是Eureka 服务端 一个是Eureka客户端 主要用于服务注册和发现\n\n## Ribbon 负载均衡有关\n简单轮询负载均衡\n加权响应时间负载均衡\n区域感知轮询负载均衡\n随机负载均衡\n\n## Hystrix 熔断机制\n断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期\n断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响\n\n## Zuul 网关\n类似nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。\n\n## Spring cloud Config 分布式配置\n这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。\n\n# springcloud 与springcloud alibaba 什么区别\n## nacos 注册中心  \n## ","slug":"java/springcloud","published":1,"updated":"2025-05-16T04:25:25.429Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jt00020skqr82vicyqc","content":"<p>摘要:springcloud</p>\n<span id=\"more\"></span>\n<h1 id=\"springcloud-五大组件\"><a href=\"#springcloud-五大组件\" class=\"headerlink\" title=\"springcloud 五大组件\"></a>springcloud 五大组件</h1><h2 id=\"Eureka-服务注册发现有关\"><a href=\"#Eureka-服务注册发现有关\" class=\"headerlink\" title=\"Eureka 服务注册发现有关\"></a>Eureka 服务注册发现有关</h2><p>一个RESTful服务 ，主要包括两方面一个是Eureka 服务端 一个是Eureka客户端 主要用于服务注册和发现</p>\n<h2 id=\"Ribbon-负载均衡有关\"><a href=\"#Ribbon-负载均衡有关\" class=\"headerlink\" title=\"Ribbon 负载均衡有关\"></a>Ribbon 负载均衡有关</h2><p>简单轮询负载均衡<br>加权响应时间负载均衡<br>区域感知轮询负载均衡<br>随机负载均衡</p>\n<h2 id=\"Hystrix-熔断机制\"><a href=\"#Hystrix-熔断机制\" class=\"headerlink\" title=\"Hystrix 熔断机制\"></a>Hystrix 熔断机制</h2><p>断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期<br>断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响</p>\n<h2 id=\"Zuul-网关\"><a href=\"#Zuul-网关\" class=\"headerlink\" title=\"Zuul 网关\"></a>Zuul 网关</h2><p>类似nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。</p>\n<h2 id=\"Spring-cloud-Config-分布式配置\"><a href=\"#Spring-cloud-Config-分布式配置\" class=\"headerlink\" title=\"Spring cloud Config 分布式配置\"></a>Spring cloud Config 分布式配置</h2><p>这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。</p>\n<h1 id=\"springcloud-与springcloud-alibaba-什么区别\"><a href=\"#springcloud-与springcloud-alibaba-什么区别\" class=\"headerlink\" title=\"springcloud 与springcloud alibaba 什么区别\"></a>springcloud 与springcloud alibaba 什么区别</h1><h2 id=\"nacos-注册中心\"><a href=\"#nacos-注册中心\" class=\"headerlink\" title=\"nacos 注册中心\"></a>nacos 注册中心</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","site":{"data":{}},"excerpt":"<p>摘要:springcloud</p>","more":"<h1 id=\"springcloud-五大组件\"><a href=\"#springcloud-五大组件\" class=\"headerlink\" title=\"springcloud 五大组件\"></a>springcloud 五大组件</h1><h2 id=\"Eureka-服务注册发现有关\"><a href=\"#Eureka-服务注册发现有关\" class=\"headerlink\" title=\"Eureka 服务注册发现有关\"></a>Eureka 服务注册发现有关</h2><p>一个RESTful服务 ，主要包括两方面一个是Eureka 服务端 一个是Eureka客户端 主要用于服务注册和发现</p>\n<h2 id=\"Ribbon-负载均衡有关\"><a href=\"#Ribbon-负载均衡有关\" class=\"headerlink\" title=\"Ribbon 负载均衡有关\"></a>Ribbon 负载均衡有关</h2><p>简单轮询负载均衡<br>加权响应时间负载均衡<br>区域感知轮询负载均衡<br>随机负载均衡</p>\n<h2 id=\"Hystrix-熔断机制\"><a href=\"#Hystrix-熔断机制\" class=\"headerlink\" title=\"Hystrix 熔断机制\"></a>Hystrix 熔断机制</h2><p>断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期<br>断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响</p>\n<h2 id=\"Zuul-网关\"><a href=\"#Zuul-网关\" class=\"headerlink\" title=\"Zuul 网关\"></a>Zuul 网关</h2><p>类似nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。</p>\n<h2 id=\"Spring-cloud-Config-分布式配置\"><a href=\"#Spring-cloud-Config-分布式配置\" class=\"headerlink\" title=\"Spring cloud Config 分布式配置\"></a>Spring cloud Config 分布式配置</h2><p>这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。</p>\n<h1 id=\"springcloud-与springcloud-alibaba-什么区别\"><a href=\"#springcloud-与springcloud-alibaba-什么区别\" class=\"headerlink\" title=\"springcloud 与springcloud alibaba 什么区别\"></a>springcloud 与springcloud alibaba 什么区别</h1><h2 id=\"nacos-注册中心\"><a href=\"#nacos-注册中心\" class=\"headerlink\" title=\"nacos 注册中心\"></a>nacos 注册中心</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>"},{"date":"2020-11-25T16:00:00.000Z","status":"public","title":"线程池","_content":"\n摘要:线程池\n<!--more-->\n# 线程\n在说线程池之前要先说线程，什么是线程？资源调用最小单位\n## 线程实现方式\nJDK 1.5前 \n1，继承Thread 实现run方法\n2，实现runnable接口 实现run方法\nJDK 1.5后\n实现Callable 接口 实现Call 方法\ncall方法可以返回结果到Future,Future 有get 方法可以获取到call 方法的返回\n调用方式是new Thread.start(Callable); 底层是传callable 过去然后获取到执行结果然后set一下\n## start 和run 有啥区别\nstart 是会新起一个线程来执行，可以实现多线程；run方法只是方法级别的调用，直接用调用主线程来执行方法\n\n## 一个线程两次调用start()方法会出现什么情况？谈谈线程的生命周期和状态转移。\nJava的线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException，这是一种运行时异常，多次调用start被认为是编程错误。\n新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个Java内部状态。\n就绪（RUNNABLE），表示该线程已经在JVM中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它CPU片段，在就绪队列里面排队。\n在其他一些分析中，会额外区分一种状态RUNNING，但是从Java API的角度，并不能表示出来。\n阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待Monitor lock。比如，线程试图通过synchronized去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。\n等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似notify等动作，通知消费线程可以继续工作了。Thread.join()也会令线程进入等待状态。\n计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如wait或join等方法的指定超时版本，如下面示例：\npublic final native void wait(long timeout) throws InterruptedException;\n终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。\n\n# 线程池\n## 线程池分类\n线程池分类主要分为四种：\n1，newCachedThreadPool 线程无限大，如果线程都在运行的话，就不断新建线程来运行任务，如果有线程没在运行的话，就复用  工作队列  SynchronousQueue  核心线程没用\n缺点 ： worke 为N  这个时候 CPU 会消耗很大\n2，newFixedThreadPool 线程数为固定，如果大于这个线程数的话就队列中等待  工作队列  LinkedBlockingQueue  非核心线程没用\n缺点 ： 队列无限 内存占用太多  容易 OOM\n3，newSingleThreadPool 单个核心线程数，一直复用这个线程运行任务  工作队列  LinkedBlockingQueue  newCache的单一线程版本\n缺点 ： 队列无限 内存占用太多  容易 OOM\n4，newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行\n\n## 线程池继承（线程池 多个请求来的时候  你去其他地方请求接口你怎么知道回来数据了）\n线程池最下面的是ThreadPoolExcutor，其实他是集成AbstrictExcutorService 又集成了ExcutorService接口，然后又集成了Excutor接口。\nExcutor 主要有一个Excutor方法，执行runnable接口，但是run方法没有返回值是一个void类型；ExcutorService接口增加了submit方法，\n里面可以执行callable方法Future、Call方法，Future的get方法在获取结果时候将进入阻塞，阻塞直到Callable中的call返回。\n\n## ThreadPoolExcutor （线程池 参数）\n参数：七个参数，包括 1核心线程数corepoolsize 2 maximunsize最大线程数 3 worker队列 4 保活时间 5 保活时间单位 \n6 threadfactory 线程工厂 7 拒绝策略\n实现原理： 进来一个线程，先获取当前工作线程数 1 如果小于核心线程数，则创建线程来执行 2 如果大于核心线程数 小于最大线程数，\n而且工作队列还不满，则创建线程进入工作队列 3 如果大于核心线程数，小于最大线程数，工作队列已满，则创建额外线程来执行 \n4 如果超过最大线程，则走拒绝策略\n\n提交顺序 核心线程-》工作队列-》非核心线程\n执行顺序 核心线程-》非核心线程-》工作队列\n\n## 线程池拒绝策略\n1，abortpolicy 直接抛出异常 2，discardPolicy 直接抛弃任务而且不抛出异常 \n3，discardOldestPolisy 把最远的任务抛弃，然后把拒绝的任务加上 4，callerRunsPolicy直接用调用的线程来执行这个线程\n\n## 线程池用于什么地方\n数据库主要是为了解决 1 资源复用 2 提高效率 3 提高性能\n主要使用场景 1，去数据库查询的时候多个线程池去查提高效率 2，调用第三方接口的时候，同时执行提高效率 3\n\n## 线程池五个状态\n1、RUNNING\n(1) 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。\n(02) 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0！\n\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n2、 SHUTDOWN\n\n(1) 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。\n(2) 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -> SHUTDOWN。\n\n3、STOP\n\n(1) 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。\n(2) 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -> STOP。\n\n4、TIDYING\n\n(1) 状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。\n(2) 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -> TIDYING。\n当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -> TIDYING。\n\n5、 TERMINATED\n\n(1) 状态说明：线程池彻底终止，就变成TERMINATED状态。\n(2) 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -> TERMINATED。\n\n# 线程池怎么知道各个线程都执行完毕了\n Future是一个接口，他提供给了我们方法来检测当前的任务是否已经结束，\n 还可以等待任务结束并且拿到一个结果，通过调用Future的get（）方法可以当任务结束后返回一个结果值，\n 如果线程里的任何一个线程工作没有结束，则线程会自动阻塞，直到任务执行完毕，\n 我们可以通过调用cancel（）方法来停止一个任务，如果任务已经停止，则cancel（）方法会返回true；\n 如果任务已经完成或者已经停止了或者这个任务无法停止，则cancel（）会返回一个false。\n 当一个任务被成功停止后，他无法再次执行。isDone（）和isCancel（）方法可以判断当前工作是否完成和是否取消，\n 他的作用通过callable的回调获得我们请求的结果。\n 线程都是通过实现callable接口，然后实现submit 方法 提交信息\n \n # 线程池有哪些工作队列\n 1、ArrayBlockingQueue\n 是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。\n 2、LinkedBlockingQueue\n 一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列\n 3、SynchronousQueue\n 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool（5）使用了这个队列。\n 4、PriorityBlockingQueue\n 一个具有优先级的无限阻塞队列。","source":"_posts/java/线程池.md","raw":"---\ndate: 2020-11-26\nstatus: public\ntitle: 线程池\ntags:\n  - JAVA\n---\n\n摘要:线程池\n<!--more-->\n# 线程\n在说线程池之前要先说线程，什么是线程？资源调用最小单位\n## 线程实现方式\nJDK 1.5前 \n1，继承Thread 实现run方法\n2，实现runnable接口 实现run方法\nJDK 1.5后\n实现Callable 接口 实现Call 方法\ncall方法可以返回结果到Future,Future 有get 方法可以获取到call 方法的返回\n调用方式是new Thread.start(Callable); 底层是传callable 过去然后获取到执行结果然后set一下\n## start 和run 有啥区别\nstart 是会新起一个线程来执行，可以实现多线程；run方法只是方法级别的调用，直接用调用主线程来执行方法\n\n## 一个线程两次调用start()方法会出现什么情况？谈谈线程的生命周期和状态转移。\nJava的线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException，这是一种运行时异常，多次调用start被认为是编程错误。\n新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个Java内部状态。\n就绪（RUNNABLE），表示该线程已经在JVM中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它CPU片段，在就绪队列里面排队。\n在其他一些分析中，会额外区分一种状态RUNNING，但是从Java API的角度，并不能表示出来。\n阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待Monitor lock。比如，线程试图通过synchronized去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。\n等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似notify等动作，通知消费线程可以继续工作了。Thread.join()也会令线程进入等待状态。\n计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如wait或join等方法的指定超时版本，如下面示例：\npublic final native void wait(long timeout) throws InterruptedException;\n终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。\n\n# 线程池\n## 线程池分类\n线程池分类主要分为四种：\n1，newCachedThreadPool 线程无限大，如果线程都在运行的话，就不断新建线程来运行任务，如果有线程没在运行的话，就复用  工作队列  SynchronousQueue  核心线程没用\n缺点 ： worke 为N  这个时候 CPU 会消耗很大\n2，newFixedThreadPool 线程数为固定，如果大于这个线程数的话就队列中等待  工作队列  LinkedBlockingQueue  非核心线程没用\n缺点 ： 队列无限 内存占用太多  容易 OOM\n3，newSingleThreadPool 单个核心线程数，一直复用这个线程运行任务  工作队列  LinkedBlockingQueue  newCache的单一线程版本\n缺点 ： 队列无限 内存占用太多  容易 OOM\n4，newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行\n\n## 线程池继承（线程池 多个请求来的时候  你去其他地方请求接口你怎么知道回来数据了）\n线程池最下面的是ThreadPoolExcutor，其实他是集成AbstrictExcutorService 又集成了ExcutorService接口，然后又集成了Excutor接口。\nExcutor 主要有一个Excutor方法，执行runnable接口，但是run方法没有返回值是一个void类型；ExcutorService接口增加了submit方法，\n里面可以执行callable方法Future、Call方法，Future的get方法在获取结果时候将进入阻塞，阻塞直到Callable中的call返回。\n\n## ThreadPoolExcutor （线程池 参数）\n参数：七个参数，包括 1核心线程数corepoolsize 2 maximunsize最大线程数 3 worker队列 4 保活时间 5 保活时间单位 \n6 threadfactory 线程工厂 7 拒绝策略\n实现原理： 进来一个线程，先获取当前工作线程数 1 如果小于核心线程数，则创建线程来执行 2 如果大于核心线程数 小于最大线程数，\n而且工作队列还不满，则创建线程进入工作队列 3 如果大于核心线程数，小于最大线程数，工作队列已满，则创建额外线程来执行 \n4 如果超过最大线程，则走拒绝策略\n\n提交顺序 核心线程-》工作队列-》非核心线程\n执行顺序 核心线程-》非核心线程-》工作队列\n\n## 线程池拒绝策略\n1，abortpolicy 直接抛出异常 2，discardPolicy 直接抛弃任务而且不抛出异常 \n3，discardOldestPolisy 把最远的任务抛弃，然后把拒绝的任务加上 4，callerRunsPolicy直接用调用的线程来执行这个线程\n\n## 线程池用于什么地方\n数据库主要是为了解决 1 资源复用 2 提高效率 3 提高性能\n主要使用场景 1，去数据库查询的时候多个线程池去查提高效率 2，调用第三方接口的时候，同时执行提高效率 3\n\n## 线程池五个状态\n1、RUNNING\n(1) 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。\n(02) 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0！\n\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n2、 SHUTDOWN\n\n(1) 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。\n(2) 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -> SHUTDOWN。\n\n3、STOP\n\n(1) 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。\n(2) 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -> STOP。\n\n4、TIDYING\n\n(1) 状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。\n(2) 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -> TIDYING。\n当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -> TIDYING。\n\n5、 TERMINATED\n\n(1) 状态说明：线程池彻底终止，就变成TERMINATED状态。\n(2) 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -> TERMINATED。\n\n# 线程池怎么知道各个线程都执行完毕了\n Future是一个接口，他提供给了我们方法来检测当前的任务是否已经结束，\n 还可以等待任务结束并且拿到一个结果，通过调用Future的get（）方法可以当任务结束后返回一个结果值，\n 如果线程里的任何一个线程工作没有结束，则线程会自动阻塞，直到任务执行完毕，\n 我们可以通过调用cancel（）方法来停止一个任务，如果任务已经停止，则cancel（）方法会返回true；\n 如果任务已经完成或者已经停止了或者这个任务无法停止，则cancel（）会返回一个false。\n 当一个任务被成功停止后，他无法再次执行。isDone（）和isCancel（）方法可以判断当前工作是否完成和是否取消，\n 他的作用通过callable的回调获得我们请求的结果。\n 线程都是通过实现callable接口，然后实现submit 方法 提交信息\n \n # 线程池有哪些工作队列\n 1、ArrayBlockingQueue\n 是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。\n 2、LinkedBlockingQueue\n 一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列\n 3、SynchronousQueue\n 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool（5）使用了这个队列。\n 4、PriorityBlockingQueue\n 一个具有优先级的无限阻塞队列。","slug":"java/线程池","published":1,"updated":"2025-05-16T04:25:25.439Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jth002tskqrftbuf4ad","content":"<p>摘要:线程池</p>\n<span id=\"more\"></span>\n<h1 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h1><p>在说线程池之前要先说线程，什么是线程？资源调用最小单位</p>\n<h2 id=\"线程实现方式\"><a href=\"#线程实现方式\" class=\"headerlink\" title=\"线程实现方式\"></a>线程实现方式</h2><p>JDK 1.5前<br>1，继承Thread 实现run方法<br>2，实现runnable接口 实现run方法<br>JDK 1.5后<br>实现Callable 接口 实现Call 方法<br>call方法可以返回结果到Future,Future 有get 方法可以获取到call 方法的返回<br>调用方式是new Thread.start(Callable); 底层是传callable 过去然后获取到执行结果然后set一下</p>\n<h2 id=\"start-和run-有啥区别\"><a href=\"#start-和run-有啥区别\" class=\"headerlink\" title=\"start 和run 有啥区别\"></a>start 和run 有啥区别</h2><p>start 是会新起一个线程来执行，可以实现多线程；run方法只是方法级别的调用，直接用调用主线程来执行方法</p>\n<h2 id=\"一个线程两次调用start-方法会出现什么情况？谈谈线程的生命周期和状态转移。\"><a href=\"#一个线程两次调用start-方法会出现什么情况？谈谈线程的生命周期和状态转移。\" class=\"headerlink\" title=\"一个线程两次调用start()方法会出现什么情况？谈谈线程的生命周期和状态转移。\"></a>一个线程两次调用start()方法会出现什么情况？谈谈线程的生命周期和状态转移。</h2><p>Java的线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException，这是一种运行时异常，多次调用start被认为是编程错误。<br>新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个Java内部状态。<br>就绪（RUNNABLE），表示该线程已经在JVM中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它CPU片段，在就绪队列里面排队。<br>在其他一些分析中，会额外区分一种状态RUNNING，但是从Java API的角度，并不能表示出来。<br>阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待Monitor lock。比如，线程试图通过synchronized去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。<br>等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似notify等动作，通知消费线程可以继续工作了。Thread.join()也会令线程进入等待状态。<br>计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如wait或join等方法的指定超时版本，如下面示例：<br>public final native void wait(long timeout) throws InterruptedException;<br>终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。</p>\n<h1 id=\"线程池\"><a href=\"#线程池\" class=\"headerlink\" title=\"线程池\"></a>线程池</h1><h2 id=\"线程池分类\"><a href=\"#线程池分类\" class=\"headerlink\" title=\"线程池分类\"></a>线程池分类</h2><p>线程池分类主要分为四种：<br>1，newCachedThreadPool 线程无限大，如果线程都在运行的话，就不断新建线程来运行任务，如果有线程没在运行的话，就复用  工作队列  SynchronousQueue  核心线程没用<br>缺点 ： worke 为N  这个时候 CPU 会消耗很大<br>2，newFixedThreadPool 线程数为固定，如果大于这个线程数的话就队列中等待  工作队列  LinkedBlockingQueue  非核心线程没用<br>缺点 ： 队列无限 内存占用太多  容易 OOM<br>3，newSingleThreadPool 单个核心线程数，一直复用这个线程运行任务  工作队列  LinkedBlockingQueue  newCache的单一线程版本<br>缺点 ： 队列无限 内存占用太多  容易 OOM<br>4，newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行</p>\n<h2 id=\"线程池继承（线程池-多个请求来的时候-你去其他地方请求接口你怎么知道回来数据了）\"><a href=\"#线程池继承（线程池-多个请求来的时候-你去其他地方请求接口你怎么知道回来数据了）\" class=\"headerlink\" title=\"线程池继承（线程池 多个请求来的时候  你去其他地方请求接口你怎么知道回来数据了）\"></a>线程池继承（线程池 多个请求来的时候  你去其他地方请求接口你怎么知道回来数据了）</h2><p>线程池最下面的是ThreadPoolExcutor，其实他是集成AbstrictExcutorService 又集成了ExcutorService接口，然后又集成了Excutor接口。<br>Excutor 主要有一个Excutor方法，执行runnable接口，但是run方法没有返回值是一个void类型；ExcutorService接口增加了submit方法，<br>里面可以执行callable方法Future、Call方法，Future的get方法在获取结果时候将进入阻塞，阻塞直到Callable中的call返回。</p>\n<h2 id=\"ThreadPoolExcutor-（线程池-参数）\"><a href=\"#ThreadPoolExcutor-（线程池-参数）\" class=\"headerlink\" title=\"ThreadPoolExcutor （线程池 参数）\"></a>ThreadPoolExcutor （线程池 参数）</h2><p>参数：七个参数，包括 1核心线程数corepoolsize 2 maximunsize最大线程数 3 worker队列 4 保活时间 5 保活时间单位<br>6 threadfactory 线程工厂 7 拒绝策略<br>实现原理： 进来一个线程，先获取当前工作线程数 1 如果小于核心线程数，则创建线程来执行 2 如果大于核心线程数 小于最大线程数，<br>而且工作队列还不满，则创建线程进入工作队列 3 如果大于核心线程数，小于最大线程数，工作队列已满，则创建额外线程来执行<br>4 如果超过最大线程，则走拒绝策略</p>\n<p>提交顺序 核心线程-》工作队列-》非核心线程<br>执行顺序 核心线程-》非核心线程-》工作队列</p>\n<h2 id=\"线程池拒绝策略\"><a href=\"#线程池拒绝策略\" class=\"headerlink\" title=\"线程池拒绝策略\"></a>线程池拒绝策略</h2><p>1，abortpolicy 直接抛出异常 2，discardPolicy 直接抛弃任务而且不抛出异常<br>3，discardOldestPolisy 把最远的任务抛弃，然后把拒绝的任务加上 4，callerRunsPolicy直接用调用的线程来执行这个线程</p>\n<h2 id=\"线程池用于什么地方\"><a href=\"#线程池用于什么地方\" class=\"headerlink\" title=\"线程池用于什么地方\"></a>线程池用于什么地方</h2><p>数据库主要是为了解决 1 资源复用 2 提高效率 3 提高性能<br>主要使用场景 1，去数据库查询的时候多个线程池去查提高效率 2，调用第三方接口的时候，同时执行提高效率 3</p>\n<h2 id=\"线程池五个状态\"><a href=\"#线程池五个状态\" class=\"headerlink\" title=\"线程池五个状态\"></a>线程池五个状态</h2><p>1、RUNNING<br>(1) 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。<br>(02) 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0！</p>\n<p>private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));<br>2、 SHUTDOWN</p>\n<p>(1) 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。<br>(2) 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN。</p>\n<p>3、STOP</p>\n<p>(1) 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。<br>(2) 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP。</p>\n<p>4、TIDYING</p>\n<p>(1) 状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。<br>(2) 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。<br>当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING。</p>\n<p>5、 TERMINATED</p>\n<p>(1) 状态说明：线程池彻底终止，就变成TERMINATED状态。<br>(2) 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED。</p>\n<h1 id=\"线程池怎么知道各个线程都执行完毕了\"><a href=\"#线程池怎么知道各个线程都执行完毕了\" class=\"headerlink\" title=\"线程池怎么知道各个线程都执行完毕了\"></a>线程池怎么知道各个线程都执行完毕了</h1><p> Future是一个接口，他提供给了我们方法来检测当前的任务是否已经结束，<br> 还可以等待任务结束并且拿到一个结果，通过调用Future的get（）方法可以当任务结束后返回一个结果值，<br> 如果线程里的任何一个线程工作没有结束，则线程会自动阻塞，直到任务执行完毕，<br> 我们可以通过调用cancel（）方法来停止一个任务，如果任务已经停止，则cancel（）方法会返回true；<br> 如果任务已经完成或者已经停止了或者这个任务无法停止，则cancel（）会返回一个false。<br> 当一个任务被成功停止后，他无法再次执行。isDone（）和isCancel（）方法可以判断当前工作是否完成和是否取消，<br> 他的作用通过callable的回调获得我们请求的结果。<br> 线程都是通过实现callable接口，然后实现submit 方法 提交信息</p>\n<h1 id=\"线程池有哪些工作队列\"><a href=\"#线程池有哪些工作队列\" class=\"headerlink\" title=\"线程池有哪些工作队列\"></a>线程池有哪些工作队列</h1><p> 1、ArrayBlockingQueue<br> 是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。<br> 2、LinkedBlockingQueue<br> 一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列<br> 3、SynchronousQueue<br> 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool（5）使用了这个队列。<br> 4、PriorityBlockingQueue<br> 一个具有优先级的无限阻塞队列。</p>\n","site":{"data":{}},"excerpt":"<p>摘要:线程池</p>","more":"<h1 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h1><p>在说线程池之前要先说线程，什么是线程？资源调用最小单位</p>\n<h2 id=\"线程实现方式\"><a href=\"#线程实现方式\" class=\"headerlink\" title=\"线程实现方式\"></a>线程实现方式</h2><p>JDK 1.5前<br>1，继承Thread 实现run方法<br>2，实现runnable接口 实现run方法<br>JDK 1.5后<br>实现Callable 接口 实现Call 方法<br>call方法可以返回结果到Future,Future 有get 方法可以获取到call 方法的返回<br>调用方式是new Thread.start(Callable); 底层是传callable 过去然后获取到执行结果然后set一下</p>\n<h2 id=\"start-和run-有啥区别\"><a href=\"#start-和run-有啥区别\" class=\"headerlink\" title=\"start 和run 有啥区别\"></a>start 和run 有啥区别</h2><p>start 是会新起一个线程来执行，可以实现多线程；run方法只是方法级别的调用，直接用调用主线程来执行方法</p>\n<h2 id=\"一个线程两次调用start-方法会出现什么情况？谈谈线程的生命周期和状态转移。\"><a href=\"#一个线程两次调用start-方法会出现什么情况？谈谈线程的生命周期和状态转移。\" class=\"headerlink\" title=\"一个线程两次调用start()方法会出现什么情况？谈谈线程的生命周期和状态转移。\"></a>一个线程两次调用start()方法会出现什么情况？谈谈线程的生命周期和状态转移。</h2><p>Java的线程是不允许启动两次的，第二次调用必然会抛出IllegalThreadStateException，这是一种运行时异常，多次调用start被认为是编程错误。<br>新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个Java内部状态。<br>就绪（RUNNABLE），表示该线程已经在JVM中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它CPU片段，在就绪队列里面排队。<br>在其他一些分析中，会额外区分一种状态RUNNING，但是从Java API的角度，并不能表示出来。<br>阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待Monitor lock。比如，线程试图通过synchronized去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。<br>等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似notify等动作，通知消费线程可以继续工作了。Thread.join()也会令线程进入等待状态。<br>计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如wait或join等方法的指定超时版本，如下面示例：<br>public final native void wait(long timeout) throws InterruptedException;<br>终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。</p>\n<h1 id=\"线程池\"><a href=\"#线程池\" class=\"headerlink\" title=\"线程池\"></a>线程池</h1><h2 id=\"线程池分类\"><a href=\"#线程池分类\" class=\"headerlink\" title=\"线程池分类\"></a>线程池分类</h2><p>线程池分类主要分为四种：<br>1，newCachedThreadPool 线程无限大，如果线程都在运行的话，就不断新建线程来运行任务，如果有线程没在运行的话，就复用  工作队列  SynchronousQueue  核心线程没用<br>缺点 ： worke 为N  这个时候 CPU 会消耗很大<br>2，newFixedThreadPool 线程数为固定，如果大于这个线程数的话就队列中等待  工作队列  LinkedBlockingQueue  非核心线程没用<br>缺点 ： 队列无限 内存占用太多  容易 OOM<br>3，newSingleThreadPool 单个核心线程数，一直复用这个线程运行任务  工作队列  LinkedBlockingQueue  newCache的单一线程版本<br>缺点 ： 队列无限 内存占用太多  容易 OOM<br>4，newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行</p>\n<h2 id=\"线程池继承（线程池-多个请求来的时候-你去其他地方请求接口你怎么知道回来数据了）\"><a href=\"#线程池继承（线程池-多个请求来的时候-你去其他地方请求接口你怎么知道回来数据了）\" class=\"headerlink\" title=\"线程池继承（线程池 多个请求来的时候  你去其他地方请求接口你怎么知道回来数据了）\"></a>线程池继承（线程池 多个请求来的时候  你去其他地方请求接口你怎么知道回来数据了）</h2><p>线程池最下面的是ThreadPoolExcutor，其实他是集成AbstrictExcutorService 又集成了ExcutorService接口，然后又集成了Excutor接口。<br>Excutor 主要有一个Excutor方法，执行runnable接口，但是run方法没有返回值是一个void类型；ExcutorService接口增加了submit方法，<br>里面可以执行callable方法Future、Call方法，Future的get方法在获取结果时候将进入阻塞，阻塞直到Callable中的call返回。</p>\n<h2 id=\"ThreadPoolExcutor-（线程池-参数）\"><a href=\"#ThreadPoolExcutor-（线程池-参数）\" class=\"headerlink\" title=\"ThreadPoolExcutor （线程池 参数）\"></a>ThreadPoolExcutor （线程池 参数）</h2><p>参数：七个参数，包括 1核心线程数corepoolsize 2 maximunsize最大线程数 3 worker队列 4 保活时间 5 保活时间单位<br>6 threadfactory 线程工厂 7 拒绝策略<br>实现原理： 进来一个线程，先获取当前工作线程数 1 如果小于核心线程数，则创建线程来执行 2 如果大于核心线程数 小于最大线程数，<br>而且工作队列还不满，则创建线程进入工作队列 3 如果大于核心线程数，小于最大线程数，工作队列已满，则创建额外线程来执行<br>4 如果超过最大线程，则走拒绝策略</p>\n<p>提交顺序 核心线程-》工作队列-》非核心线程<br>执行顺序 核心线程-》非核心线程-》工作队列</p>\n<h2 id=\"线程池拒绝策略\"><a href=\"#线程池拒绝策略\" class=\"headerlink\" title=\"线程池拒绝策略\"></a>线程池拒绝策略</h2><p>1，abortpolicy 直接抛出异常 2，discardPolicy 直接抛弃任务而且不抛出异常<br>3，discardOldestPolisy 把最远的任务抛弃，然后把拒绝的任务加上 4，callerRunsPolicy直接用调用的线程来执行这个线程</p>\n<h2 id=\"线程池用于什么地方\"><a href=\"#线程池用于什么地方\" class=\"headerlink\" title=\"线程池用于什么地方\"></a>线程池用于什么地方</h2><p>数据库主要是为了解决 1 资源复用 2 提高效率 3 提高性能<br>主要使用场景 1，去数据库查询的时候多个线程池去查提高效率 2，调用第三方接口的时候，同时执行提高效率 3</p>\n<h2 id=\"线程池五个状态\"><a href=\"#线程池五个状态\" class=\"headerlink\" title=\"线程池五个状态\"></a>线程池五个状态</h2><p>1、RUNNING<br>(1) 状态说明：线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。<br>(02) 状态切换：线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0！</p>\n<p>private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));<br>2、 SHUTDOWN</p>\n<p>(1) 状态说明：线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。<br>(2) 状态切换：调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN。</p>\n<p>3、STOP</p>\n<p>(1) 状态说明：线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。<br>(2) 状态切换：调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP。</p>\n<p>4、TIDYING</p>\n<p>(1) 状态说明：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。<br>(2) 状态切换：当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。<br>当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING。</p>\n<p>5、 TERMINATED</p>\n<p>(1) 状态说明：线程池彻底终止，就变成TERMINATED状态。<br>(2) 状态切换：线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -&gt; TERMINATED。</p>\n<h1 id=\"线程池怎么知道各个线程都执行完毕了\"><a href=\"#线程池怎么知道各个线程都执行完毕了\" class=\"headerlink\" title=\"线程池怎么知道各个线程都执行完毕了\"></a>线程池怎么知道各个线程都执行完毕了</h1><p> Future是一个接口，他提供给了我们方法来检测当前的任务是否已经结束，<br> 还可以等待任务结束并且拿到一个结果，通过调用Future的get（）方法可以当任务结束后返回一个结果值，<br> 如果线程里的任何一个线程工作没有结束，则线程会自动阻塞，直到任务执行完毕，<br> 我们可以通过调用cancel（）方法来停止一个任务，如果任务已经停止，则cancel（）方法会返回true；<br> 如果任务已经完成或者已经停止了或者这个任务无法停止，则cancel（）会返回一个false。<br> 当一个任务被成功停止后，他无法再次执行。isDone（）和isCancel（）方法可以判断当前工作是否完成和是否取消，<br> 他的作用通过callable的回调获得我们请求的结果。<br> 线程都是通过实现callable接口，然后实现submit 方法 提交信息</p>\n<h1 id=\"线程池有哪些工作队列\"><a href=\"#线程池有哪些工作队列\" class=\"headerlink\" title=\"线程池有哪些工作队列\"></a>线程池有哪些工作队列</h1><p> 1、ArrayBlockingQueue<br> 是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。<br> 2、LinkedBlockingQueue<br> 一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列<br> 3、SynchronousQueue<br> 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool（5）使用了这个队列。<br> 4、PriorityBlockingQueue<br> 一个具有优先级的无限阻塞队列。</p>"},{"date":"2020-04-21T16:00:00.000Z","status":"public","title":"锁机制","_content":"\n摘要:锁机制\n<!--more-->\n# java的锁\njava的锁适合单机部署，部署一个服务的时候，很实用，其实就是把这个服务变成单进程，例如之前做的抽奖的，由于有不同人的抽奖\n在抽奖成功之后需要商品总数量减一，商品表一张表，里面还用到了虚拟券的表，要是商品是虚拟券，还要去把虚拟券的商品减一，\n这个时候多人同时操作的话，更新了商品表的时候，虚拟商品会减一，但是由于是同时操作，这个时候会更新了商品表，然后同时把同一个虚拟商品数量减一\n，就是秒杀的避免问题\n## lock\nReadWriteLock是读写锁接口，自己设置锁lock 之后还得自己去释放这个锁，\n\n## synchronized\nsynchronized是Java的关键字,直接把这个对象都给锁住，这个时候就是单线程操作，单个入口\n### 原理\nsync 就是锁对象的对象头------》java对象的布局-----》java对象由什么组成\n----》堆里面---》堆里面分配多少内存----》\n堆里面的对象数据组成\n1，对象头----固定\n2，java对象的实例属性----非固定   如果没有实例属性 那就只有填充数据\n3，数据对齐----填充数据  如果不够凑齐8的倍数 就填充\n\n### 为什么需要填充数据\n因为他们做了大量实验，觉得8的倍数寻址最优，所以要填充8的倍数\n\n64位jvm虚拟机 一个对象就有16byte  对象头有12个对象头\n\n### 对象头 96bit 16byte --包含hashcode  还有同步状态 、GC 状态就是survicor的年龄 15次复制算法之后到old 区、还有类型 元空间模板类型 指针地址\nmarkword-------32bit  4byte   64位64bit\n不固定 hashcode  age biased_lock lock \n无锁    unused 25 identity_hashcode 31 unused 1 age 4 biased_lock 1 lock 2\n偏向锁  thred 54 epoch 2 unused 1 age 4 biased_lock 1 lock 2\n轻量级锁  ptr_to_lock_record 62 lock 2\n重量级锁  ptr_to_heavyweigh_monitor 62 lock 2\ngc标记没有了 \n\n\nKlass pointer---- 类的元数据 指针地址 后面32bit 64bit 开启指针压缩的时候\n\n\n\n## 锁升级  是对应的几个状态\n无锁(01)-》偏向锁(01)-》轻量级锁(00)-》重量级锁(10)-》gc标记没有了(11)\n倒数第三位 为1为偏向锁  为0 则为无锁\n## 偏向锁\n默认认知为没有其他线程来竞争锁，然后就变成偏向锁，启用了偏向锁会走偏向锁，偏向锁的头部会写入线程ID，这个线程ID 不会变更，当有一个新线程来了之后会CAS\n如果一样的话就用当前线程去执行，如果不一样的话就升级轻量级锁\n## 轻量级锁\n有两个线程在竞争，这个时候一个线程已经拿到轻量级锁，另外一个就会自旋，自旋一段时间之后还是没拿到锁，这个时候就会变成重量级锁\n## 重量级锁\n重量级锁就是线程的状态转换 用户态到内核态（线程上下级切换），通过线程间的互斥锁实现的，由于状态之间的转换需要时间，所以这就是为什么synchronized慢的原因\n\n用户态到内核态为什么耗资源\n阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长\n\n## synchronized和lock的区别\nLock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；\nsynchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，\n如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；\nLock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；\n通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。\nLock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）\n性能上来说，在资源竞争不激烈的情形下，Lock性能稍微比synchronized差点（编译程序通常会尽可能的进行优化synchronized）\n。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。\n\n\n## Reentrantlock \nCAS+AQS队列\n### CAS \n原子操作，CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。\nCAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。\n更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。\n[CAS机制](https://www.jianshu.com/p/ae25eb3cfb5d)\n先获取到内存中的旧的值A，然后要替换的值B，内存地址V，然后去替换的时候，先对比V 的值跟A 是不是不一样，不一样则替换，如果一样\n就自旋，就是重新获取内存中的值A和要替换的值B\n底层是C++的 一个汇编指令完成的  硬件指令lock 缓存行锁 总线锁\n### ABA 问题  线程1 把A改成B  但是线程2把A 改成了C 然后又改回了A   这个时候 线程1还是可以cas成功的  这就是ABA问题  解决办法就是加版本号 版本号加一\n### AQS\n一个缓冲队列，AQS是一个用于构建锁和同步容器的框架。是一个缓存队列简单框架，同时提供了原子式管理同步，阻塞，唤醒线程等功能\n\n### ReentrantLock的流程\n1 ReentrantLock先通过CAS尝试获取锁，通过CAS设置变量State（同步状态）（volatile 类型）成功，也就是获取锁成功，则将当前线程设置为独占线程。\n2 如果此时锁已经被占用，该线程加入AQS队列并wait()\n3 当前驱线程的锁被释放，挂在CLH队列为首的线程就会被notify()，然后继续CAS尝试获取锁，此时：\n1）非公平锁，如果有其他线程尝试lock()，有可能被其他刚好申请锁的线程抢占。  \n2）公平锁，只有在CLH队列头的线程才可以获取锁，新来的线程只能插入到队尾。\n这个可以举个栗子就是打饭的时候排队，一群人处于等待唤醒状态，如果这个时候又新来一个人，如果他在最后面排队 那他就是公平的，如果他看到刚好最前面的人打饭完了\n然后他就直接插队去打饭了，这个就是非公平的\n\n其实就是有一个标志位，然后通过CAS去抢占锁，如果抢占成功就变成1，没成功就加锁失败\n\n## ReentrantLock和synchronized都是重入锁  都是悲观锁\n可重入锁就是可以重复获取锁，不可重入锁是说一个线程执行完成之前就不能再加锁了\n\n#基于数据库的锁机制\n同样的问题，秒杀实现，但是这个时候是分机器部署的，为了负载均衡，这个时候再用java的锁，明显是不行了，这个时候需要用到数据库的锁机制\n## 在数据表里面加版本号\n加版本号这个就是在表行里面加多一个版本号，只要操作这条数据，就把版本号设置为1，这个时候别的操作只能等待，不能操作\n另外一个是需要锁住某个方法时，往该表中插入一条相关的记录，然后执行完成这个方法之后就删除这个记录，这个中间时候\n别人不能来操作这个方法\n\n## 用sql自己的锁机制  for update 数据库的排他锁\n这个机制在查询的时候 select * from XXX for update,\n\n# 基于redis 的分布式锁实现\n## setnx\n\n# 多并发线程可见性 volatile\n\n## 底层原理：缓存一致性协议\n最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。\n它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，\n会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，\n发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n\n\n\n# 自旋锁\n\n\n# 分布式锁\n## 基于redis的分布式锁\n直接给个标志位，存储这个key到redis，然后下一个请求过来之后要看这个key对应的value是否为空，为空则插入值获取锁，然后如果值不为空，那就返回友好提示\n最好redis删除key的时候在finally里面执行，redistamplate会有一个setnx及expire的合并方法\n## 基于sql的分布式锁\n直接新建一张表，纪录锁表信息，每次去查的时候先看有没有对应信息，如果没有则插入，有的话就删除，字段要做唯一性约束，另外的请求来的话就插不进去，\n需要注意：\n1这种锁没有失效时间，一旦释放锁的操作失败就会导致锁记录一直在数据库中，其它线程无法获得锁。这个缺陷也很好解决，比如可以做一个定时任务去定时清理。\n2这种锁的可靠性依赖于数据库。建议设置备库，避免单点，进一步提高可靠性。\n3这种锁是非阻塞的，因为插入数据失败之后会直接报错，想要获得锁就需要再次操作。如果需要阻塞式的，可以弄个for循环、while循环之类的，直至INSERT成功再返回。\n4这种锁也是非可重入的，因为同一个线程在没有释放锁之前无法再次获得锁，因为数据库中已经存在同一份记录了。想要实现可重入锁，可以在数据库中添加一些字段，\n比如获得锁的主机信息、线程信息等，那么在再次获得锁的时候可以先查询数据，如果当前的主机信息和线程信息等能被查到的话，可以直接把锁分配给它。\n## 乐观锁 版本号\n定义一个字段,版本号，然后设置唯一标示，然后更新的时候 把版本号也加一\nSTEP1 - 获取资源： SELECT resource, version FROM optimistic_lock WHERE id = 1\nSTEP2 - 执行业务逻辑\nSTEP3 - 更新资源：UPDATE optimistic_lock SET resource = resource -1, version = version + 1 WHERE id = 1 AND version = oldVersion\n## 悲观锁 \n在查询语句后面增加FOR UPDATE，数据库会在查询过程中给数据库表增加悲观锁，也称排他锁。\n当某条记录被加上悲观锁之后，其它线程也就无法再改行上增加悲观锁。\n## 基于Zookeeper的分布式锁\n1客户端连接zookeeper，并在/lock下创建临时的且有序的子节点，第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。\n2客户端获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁，否则监听/lock的子节点变更消息，获得子节点变更通知后重复此步骤直至获得锁；\n3执行业务代码；\n4完成业务流程后，删除对应的子节点释放锁。\n\n虽然zookeeper原生客户端暴露的API已经非常简洁了，但是实现一个分布式锁还是比较麻烦的…我们可以直接使用curator这个开源项目提供的zookeeper分布式锁实现。\n\n## redis 和zk的区别\n1，redis 是先响应请求，然后同步到其他节点里面，是AP 架构 avaliable，而zk的话是先保证各个节点一致性，然后再响应请求，所以redis集群估计还有问题，而zk 没有\n2，zk有ZAB协议可以保证强一致性和集群不崩溃\n3，redis 性能比zk 高，而zk 比redis更可用，主从架构保证key 不丢失\n\n## 锁续命   加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\n## redis son 用于分布式   \nlua 脚本，在java代码里面就会保证原子性\n","source":"_posts/java/锁.md","raw":"---\ndate: 2020-04-22\nstatus: public\ntitle: 锁机制\ntags:\n  - JAVA\n  - 锁\n---\n\n摘要:锁机制\n<!--more-->\n# java的锁\njava的锁适合单机部署，部署一个服务的时候，很实用，其实就是把这个服务变成单进程，例如之前做的抽奖的，由于有不同人的抽奖\n在抽奖成功之后需要商品总数量减一，商品表一张表，里面还用到了虚拟券的表，要是商品是虚拟券，还要去把虚拟券的商品减一，\n这个时候多人同时操作的话，更新了商品表的时候，虚拟商品会减一，但是由于是同时操作，这个时候会更新了商品表，然后同时把同一个虚拟商品数量减一\n，就是秒杀的避免问题\n## lock\nReadWriteLock是读写锁接口，自己设置锁lock 之后还得自己去释放这个锁，\n\n## synchronized\nsynchronized是Java的关键字,直接把这个对象都给锁住，这个时候就是单线程操作，单个入口\n### 原理\nsync 就是锁对象的对象头------》java对象的布局-----》java对象由什么组成\n----》堆里面---》堆里面分配多少内存----》\n堆里面的对象数据组成\n1，对象头----固定\n2，java对象的实例属性----非固定   如果没有实例属性 那就只有填充数据\n3，数据对齐----填充数据  如果不够凑齐8的倍数 就填充\n\n### 为什么需要填充数据\n因为他们做了大量实验，觉得8的倍数寻址最优，所以要填充8的倍数\n\n64位jvm虚拟机 一个对象就有16byte  对象头有12个对象头\n\n### 对象头 96bit 16byte --包含hashcode  还有同步状态 、GC 状态就是survicor的年龄 15次复制算法之后到old 区、还有类型 元空间模板类型 指针地址\nmarkword-------32bit  4byte   64位64bit\n不固定 hashcode  age biased_lock lock \n无锁    unused 25 identity_hashcode 31 unused 1 age 4 biased_lock 1 lock 2\n偏向锁  thred 54 epoch 2 unused 1 age 4 biased_lock 1 lock 2\n轻量级锁  ptr_to_lock_record 62 lock 2\n重量级锁  ptr_to_heavyweigh_monitor 62 lock 2\ngc标记没有了 \n\n\nKlass pointer---- 类的元数据 指针地址 后面32bit 64bit 开启指针压缩的时候\n\n\n\n## 锁升级  是对应的几个状态\n无锁(01)-》偏向锁(01)-》轻量级锁(00)-》重量级锁(10)-》gc标记没有了(11)\n倒数第三位 为1为偏向锁  为0 则为无锁\n## 偏向锁\n默认认知为没有其他线程来竞争锁，然后就变成偏向锁，启用了偏向锁会走偏向锁，偏向锁的头部会写入线程ID，这个线程ID 不会变更，当有一个新线程来了之后会CAS\n如果一样的话就用当前线程去执行，如果不一样的话就升级轻量级锁\n## 轻量级锁\n有两个线程在竞争，这个时候一个线程已经拿到轻量级锁，另外一个就会自旋，自旋一段时间之后还是没拿到锁，这个时候就会变成重量级锁\n## 重量级锁\n重量级锁就是线程的状态转换 用户态到内核态（线程上下级切换），通过线程间的互斥锁实现的，由于状态之间的转换需要时间，所以这就是为什么synchronized慢的原因\n\n用户态到内核态为什么耗资源\n阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长\n\n## synchronized和lock的区别\nLock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；\nsynchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，\n如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；\nLock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；\n通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。\nLock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）\n性能上来说，在资源竞争不激烈的情形下，Lock性能稍微比synchronized差点（编译程序通常会尽可能的进行优化synchronized）\n。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。\n\n\n## Reentrantlock \nCAS+AQS队列\n### CAS \n原子操作，CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。\nCAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。\n更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。\n[CAS机制](https://www.jianshu.com/p/ae25eb3cfb5d)\n先获取到内存中的旧的值A，然后要替换的值B，内存地址V，然后去替换的时候，先对比V 的值跟A 是不是不一样，不一样则替换，如果一样\n就自旋，就是重新获取内存中的值A和要替换的值B\n底层是C++的 一个汇编指令完成的  硬件指令lock 缓存行锁 总线锁\n### ABA 问题  线程1 把A改成B  但是线程2把A 改成了C 然后又改回了A   这个时候 线程1还是可以cas成功的  这就是ABA问题  解决办法就是加版本号 版本号加一\n### AQS\n一个缓冲队列，AQS是一个用于构建锁和同步容器的框架。是一个缓存队列简单框架，同时提供了原子式管理同步，阻塞，唤醒线程等功能\n\n### ReentrantLock的流程\n1 ReentrantLock先通过CAS尝试获取锁，通过CAS设置变量State（同步状态）（volatile 类型）成功，也就是获取锁成功，则将当前线程设置为独占线程。\n2 如果此时锁已经被占用，该线程加入AQS队列并wait()\n3 当前驱线程的锁被释放，挂在CLH队列为首的线程就会被notify()，然后继续CAS尝试获取锁，此时：\n1）非公平锁，如果有其他线程尝试lock()，有可能被其他刚好申请锁的线程抢占。  \n2）公平锁，只有在CLH队列头的线程才可以获取锁，新来的线程只能插入到队尾。\n这个可以举个栗子就是打饭的时候排队，一群人处于等待唤醒状态，如果这个时候又新来一个人，如果他在最后面排队 那他就是公平的，如果他看到刚好最前面的人打饭完了\n然后他就直接插队去打饭了，这个就是非公平的\n\n其实就是有一个标志位，然后通过CAS去抢占锁，如果抢占成功就变成1，没成功就加锁失败\n\n## ReentrantLock和synchronized都是重入锁  都是悲观锁\n可重入锁就是可以重复获取锁，不可重入锁是说一个线程执行完成之前就不能再加锁了\n\n#基于数据库的锁机制\n同样的问题，秒杀实现，但是这个时候是分机器部署的，为了负载均衡，这个时候再用java的锁，明显是不行了，这个时候需要用到数据库的锁机制\n## 在数据表里面加版本号\n加版本号这个就是在表行里面加多一个版本号，只要操作这条数据，就把版本号设置为1，这个时候别的操作只能等待，不能操作\n另外一个是需要锁住某个方法时，往该表中插入一条相关的记录，然后执行完成这个方法之后就删除这个记录，这个中间时候\n别人不能来操作这个方法\n\n## 用sql自己的锁机制  for update 数据库的排他锁\n这个机制在查询的时候 select * from XXX for update,\n\n# 基于redis 的分布式锁实现\n## setnx\n\n# 多并发线程可见性 volatile\n\n## 底层原理：缓存一致性协议\n最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。\n它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，\n会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，\n发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n\n\n\n# 自旋锁\n\n\n# 分布式锁\n## 基于redis的分布式锁\n直接给个标志位，存储这个key到redis，然后下一个请求过来之后要看这个key对应的value是否为空，为空则插入值获取锁，然后如果值不为空，那就返回友好提示\n最好redis删除key的时候在finally里面执行，redistamplate会有一个setnx及expire的合并方法\n## 基于sql的分布式锁\n直接新建一张表，纪录锁表信息，每次去查的时候先看有没有对应信息，如果没有则插入，有的话就删除，字段要做唯一性约束，另外的请求来的话就插不进去，\n需要注意：\n1这种锁没有失效时间，一旦释放锁的操作失败就会导致锁记录一直在数据库中，其它线程无法获得锁。这个缺陷也很好解决，比如可以做一个定时任务去定时清理。\n2这种锁的可靠性依赖于数据库。建议设置备库，避免单点，进一步提高可靠性。\n3这种锁是非阻塞的，因为插入数据失败之后会直接报错，想要获得锁就需要再次操作。如果需要阻塞式的，可以弄个for循环、while循环之类的，直至INSERT成功再返回。\n4这种锁也是非可重入的，因为同一个线程在没有释放锁之前无法再次获得锁，因为数据库中已经存在同一份记录了。想要实现可重入锁，可以在数据库中添加一些字段，\n比如获得锁的主机信息、线程信息等，那么在再次获得锁的时候可以先查询数据，如果当前的主机信息和线程信息等能被查到的话，可以直接把锁分配给它。\n## 乐观锁 版本号\n定义一个字段,版本号，然后设置唯一标示，然后更新的时候 把版本号也加一\nSTEP1 - 获取资源： SELECT resource, version FROM optimistic_lock WHERE id = 1\nSTEP2 - 执行业务逻辑\nSTEP3 - 更新资源：UPDATE optimistic_lock SET resource = resource -1, version = version + 1 WHERE id = 1 AND version = oldVersion\n## 悲观锁 \n在查询语句后面增加FOR UPDATE，数据库会在查询过程中给数据库表增加悲观锁，也称排他锁。\n当某条记录被加上悲观锁之后，其它线程也就无法再改行上增加悲观锁。\n## 基于Zookeeper的分布式锁\n1客户端连接zookeeper，并在/lock下创建临时的且有序的子节点，第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。\n2客户端获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁，否则监听/lock的子节点变更消息，获得子节点变更通知后重复此步骤直至获得锁；\n3执行业务代码；\n4完成业务流程后，删除对应的子节点释放锁。\n\n虽然zookeeper原生客户端暴露的API已经非常简洁了，但是实现一个分布式锁还是比较麻烦的…我们可以直接使用curator这个开源项目提供的zookeeper分布式锁实现。\n\n## redis 和zk的区别\n1，redis 是先响应请求，然后同步到其他节点里面，是AP 架构 avaliable，而zk的话是先保证各个节点一致性，然后再响应请求，所以redis集群估计还有问题，而zk 没有\n2，zk有ZAB协议可以保证强一致性和集群不崩溃\n3，redis 性能比zk 高，而zk 比redis更可用，主从架构保证key 不丢失\n\n## 锁续命   加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\n## redis son 用于分布式   \nlua 脚本，在java代码里面就会保证原子性\n","slug":"java/锁","published":1,"updated":"2025-05-16T07:14:19.615Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cmawa4jtj002uskqr86fggrc5","content":"<p>摘要:锁机制</p>\n<span id=\"more\"></span>\n<h1 id=\"java的锁\"><a href=\"#java的锁\" class=\"headerlink\" title=\"java的锁\"></a>java的锁</h1><p>java的锁适合单机部署，部署一个服务的时候，很实用，其实就是把这个服务变成单进程，例如之前做的抽奖的，由于有不同人的抽奖<br>在抽奖成功之后需要商品总数量减一，商品表一张表，里面还用到了虚拟券的表，要是商品是虚拟券，还要去把虚拟券的商品减一，<br>这个时候多人同时操作的话，更新了商品表的时候，虚拟商品会减一，但是由于是同时操作，这个时候会更新了商品表，然后同时把同一个虚拟商品数量减一<br>，就是秒杀的避免问题</p>\n<h2 id=\"lock\"><a href=\"#lock\" class=\"headerlink\" title=\"lock\"></a>lock</h2><p>ReadWriteLock是读写锁接口，自己设置锁lock 之后还得自己去释放这个锁，</p>\n<h2 id=\"synchronized\"><a href=\"#synchronized\" class=\"headerlink\" title=\"synchronized\"></a>synchronized</h2><p>synchronized是Java的关键字,直接把这个对象都给锁住，这个时候就是单线程操作，单个入口</p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p>sync 就是锁对象的对象头——》java对象的布局—–》java对象由什么组成<br>—-》堆里面—》堆里面分配多少内存—-》<br>堆里面的对象数据组成<br>1，对象头—-固定<br>2，java对象的实例属性—-非固定   如果没有实例属性 那就只有填充数据<br>3，数据对齐—-填充数据  如果不够凑齐8的倍数 就填充</p>\n<h3 id=\"为什么需要填充数据\"><a href=\"#为什么需要填充数据\" class=\"headerlink\" title=\"为什么需要填充数据\"></a>为什么需要填充数据</h3><p>因为他们做了大量实验，觉得8的倍数寻址最优，所以要填充8的倍数</p>\n<p>64位jvm虚拟机 一个对象就有16byte  对象头有12个对象头</p>\n<h3 id=\"对象头-96bit-16byte-–包含hashcode-还有同步状态-、GC-状态就是survicor的年龄-15次复制算法之后到old-区、还有类型-元空间模板类型-指针地址\"><a href=\"#对象头-96bit-16byte-–包含hashcode-还有同步状态-、GC-状态就是survicor的年龄-15次复制算法之后到old-区、还有类型-元空间模板类型-指针地址\" class=\"headerlink\" title=\"对象头 96bit 16byte –包含hashcode  还有同步状态 、GC 状态就是survicor的年龄 15次复制算法之后到old 区、还有类型 元空间模板类型 指针地址\"></a>对象头 96bit 16byte –包含hashcode  还有同步状态 、GC 状态就是survicor的年龄 15次复制算法之后到old 区、还有类型 元空间模板类型 指针地址</h3><p>markword——-32bit  4byte   64位64bit<br>不固定 hashcode  age biased_lock lock<br>无锁    unused 25 identity_hashcode 31 unused 1 age 4 biased_lock 1 lock 2<br>偏向锁  thred 54 epoch 2 unused 1 age 4 biased_lock 1 lock 2<br>轻量级锁  ptr_to_lock_record 62 lock 2<br>重量级锁  ptr_to_heavyweigh_monitor 62 lock 2<br>gc标记没有了 </p>\n<p>Klass pointer—- 类的元数据 指针地址 后面32bit 64bit 开启指针压缩的时候</p>\n<h2 id=\"锁升级-是对应的几个状态\"><a href=\"#锁升级-是对应的几个状态\" class=\"headerlink\" title=\"锁升级  是对应的几个状态\"></a>锁升级  是对应的几个状态</h2><p>无锁(01)-》偏向锁(01)-》轻量级锁(00)-》重量级锁(10)-》gc标记没有了(11)<br>倒数第三位 为1为偏向锁  为0 则为无锁</p>\n<h2 id=\"偏向锁\"><a href=\"#偏向锁\" class=\"headerlink\" title=\"偏向锁\"></a>偏向锁</h2><p>默认认知为没有其他线程来竞争锁，然后就变成偏向锁，启用了偏向锁会走偏向锁，偏向锁的头部会写入线程ID，这个线程ID 不会变更，当有一个新线程来了之后会CAS<br>如果一样的话就用当前线程去执行，如果不一样的话就升级轻量级锁</p>\n<h2 id=\"轻量级锁\"><a href=\"#轻量级锁\" class=\"headerlink\" title=\"轻量级锁\"></a>轻量级锁</h2><p>有两个线程在竞争，这个时候一个线程已经拿到轻量级锁，另外一个就会自旋，自旋一段时间之后还是没拿到锁，这个时候就会变成重量级锁</p>\n<h2 id=\"重量级锁\"><a href=\"#重量级锁\" class=\"headerlink\" title=\"重量级锁\"></a>重量级锁</h2><p>重量级锁就是线程的状态转换 用户态到内核态（线程上下级切换），通过线程间的互斥锁实现的，由于状态之间的转换需要时间，所以这就是为什么synchronized慢的原因</p>\n<p>用户态到内核态为什么耗资源<br>阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长</p>\n<h2 id=\"synchronized和lock的区别\"><a href=\"#synchronized和lock的区别\" class=\"headerlink\" title=\"synchronized和lock的区别\"></a>synchronized和lock的区别</h2><p>Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；<br>synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，<br>如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；<br>Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；<br>通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。<br>Lock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）<br>性能上来说，在资源竞争不激烈的情形下，Lock性能稍微比synchronized差点（编译程序通常会尽可能的进行优化synchronized）<br>。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。</p>\n<h2 id=\"Reentrantlock\"><a href=\"#Reentrantlock\" class=\"headerlink\" title=\"Reentrantlock\"></a>Reentrantlock</h2><p>CAS+AQS队列</p>\n<h3 id=\"CAS\"><a href=\"#CAS\" class=\"headerlink\" title=\"CAS\"></a>CAS</h3><p>原子操作，CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。<br>CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。<br>更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。<br><a href=\"https://www.jianshu.com/p/ae25eb3cfb5d\">CAS机制</a><br>先获取到内存中的旧的值A，然后要替换的值B，内存地址V，然后去替换的时候，先对比V 的值跟A 是不是不一样，不一样则替换，如果一样<br>就自旋，就是重新获取内存中的值A和要替换的值B<br>底层是C++的 一个汇编指令完成的  硬件指令lock 缓存行锁 总线锁</p>\n<h3 id=\"ABA-问题-线程1-把A改成B-但是线程2把A-改成了C-然后又改回了A-这个时候-线程1还是可以cas成功的-这就是ABA问题-解决办法就是加版本号-版本号加一\"><a href=\"#ABA-问题-线程1-把A改成B-但是线程2把A-改成了C-然后又改回了A-这个时候-线程1还是可以cas成功的-这就是ABA问题-解决办法就是加版本号-版本号加一\" class=\"headerlink\" title=\"ABA 问题  线程1 把A改成B  但是线程2把A 改成了C 然后又改回了A   这个时候 线程1还是可以cas成功的  这就是ABA问题  解决办法就是加版本号 版本号加一\"></a>ABA 问题  线程1 把A改成B  但是线程2把A 改成了C 然后又改回了A   这个时候 线程1还是可以cas成功的  这就是ABA问题  解决办法就是加版本号 版本号加一</h3><h3 id=\"AQS\"><a href=\"#AQS\" class=\"headerlink\" title=\"AQS\"></a>AQS</h3><p>一个缓冲队列，AQS是一个用于构建锁和同步容器的框架。是一个缓存队列简单框架，同时提供了原子式管理同步，阻塞，唤醒线程等功能</p>\n<h3 id=\"ReentrantLock的流程\"><a href=\"#ReentrantLock的流程\" class=\"headerlink\" title=\"ReentrantLock的流程\"></a>ReentrantLock的流程</h3><p>1 ReentrantLock先通过CAS尝试获取锁，通过CAS设置变量State（同步状态）（volatile 类型）成功，也就是获取锁成功，则将当前线程设置为独占线程。<br>2 如果此时锁已经被占用，该线程加入AQS队列并wait()<br>3 当前驱线程的锁被释放，挂在CLH队列为首的线程就会被notify()，然后继续CAS尝试获取锁，此时：<br>1）非公平锁，如果有其他线程尝试lock()，有可能被其他刚好申请锁的线程抢占。<br>2）公平锁，只有在CLH队列头的线程才可以获取锁，新来的线程只能插入到队尾。<br>这个可以举个栗子就是打饭的时候排队，一群人处于等待唤醒状态，如果这个时候又新来一个人，如果他在最后面排队 那他就是公平的，如果他看到刚好最前面的人打饭完了<br>然后他就直接插队去打饭了，这个就是非公平的</p>\n<p>其实就是有一个标志位，然后通过CAS去抢占锁，如果抢占成功就变成1，没成功就加锁失败</p>\n<h2 id=\"ReentrantLock和synchronized都是重入锁-都是悲观锁\"><a href=\"#ReentrantLock和synchronized都是重入锁-都是悲观锁\" class=\"headerlink\" title=\"ReentrantLock和synchronized都是重入锁  都是悲观锁\"></a>ReentrantLock和synchronized都是重入锁  都是悲观锁</h2><p>可重入锁就是可以重复获取锁，不可重入锁是说一个线程执行完成之前就不能再加锁了</p>\n<p>#基于数据库的锁机制<br>同样的问题，秒杀实现，但是这个时候是分机器部署的，为了负载均衡，这个时候再用java的锁，明显是不行了，这个时候需要用到数据库的锁机制</p>\n<h2 id=\"在数据表里面加版本号\"><a href=\"#在数据表里面加版本号\" class=\"headerlink\" title=\"在数据表里面加版本号\"></a>在数据表里面加版本号</h2><p>加版本号这个就是在表行里面加多一个版本号，只要操作这条数据，就把版本号设置为1，这个时候别的操作只能等待，不能操作<br>另外一个是需要锁住某个方法时，往该表中插入一条相关的记录，然后执行完成这个方法之后就删除这个记录，这个中间时候<br>别人不能来操作这个方法</p>\n<h2 id=\"用sql自己的锁机制-for-update-数据库的排他锁\"><a href=\"#用sql自己的锁机制-for-update-数据库的排他锁\" class=\"headerlink\" title=\"用sql自己的锁机制  for update 数据库的排他锁\"></a>用sql自己的锁机制  for update 数据库的排他锁</h2><p>这个机制在查询的时候 select * from XXX for update,</p>\n<h1 id=\"基于redis-的分布式锁实现\"><a href=\"#基于redis-的分布式锁实现\" class=\"headerlink\" title=\"基于redis 的分布式锁实现\"></a>基于redis 的分布式锁实现</h1><h2 id=\"setnx\"><a href=\"#setnx\" class=\"headerlink\" title=\"setnx\"></a>setnx</h2><h1 id=\"多并发线程可见性-volatile\"><a href=\"#多并发线程可见性-volatile\" class=\"headerlink\" title=\"多并发线程可见性 volatile\"></a>多并发线程可见性 volatile</h1><h2 id=\"底层原理：缓存一致性协议\"><a href=\"#底层原理：缓存一致性协议\" class=\"headerlink\" title=\"底层原理：缓存一致性协议\"></a>底层原理：缓存一致性协议</h2><p>最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。<br>它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，<br>会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，<br>发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。</p>\n<h1 id=\"自旋锁\"><a href=\"#自旋锁\" class=\"headerlink\" title=\"自旋锁\"></a>自旋锁</h1><h1 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h1><h2 id=\"基于redis的分布式锁\"><a href=\"#基于redis的分布式锁\" class=\"headerlink\" title=\"基于redis的分布式锁\"></a>基于redis的分布式锁</h2><p>直接给个标志位，存储这个key到redis，然后下一个请求过来之后要看这个key对应的value是否为空，为空则插入值获取锁，然后如果值不为空，那就返回友好提示<br>最好redis删除key的时候在finally里面执行，redistamplate会有一个setnx及expire的合并方法</p>\n<h2 id=\"基于sql的分布式锁\"><a href=\"#基于sql的分布式锁\" class=\"headerlink\" title=\"基于sql的分布式锁\"></a>基于sql的分布式锁</h2><p>直接新建一张表，纪录锁表信息，每次去查的时候先看有没有对应信息，如果没有则插入，有的话就删除，字段要做唯一性约束，另外的请求来的话就插不进去，<br>需要注意：<br>1这种锁没有失效时间，一旦释放锁的操作失败就会导致锁记录一直在数据库中，其它线程无法获得锁。这个缺陷也很好解决，比如可以做一个定时任务去定时清理。<br>2这种锁的可靠性依赖于数据库。建议设置备库，避免单点，进一步提高可靠性。<br>3这种锁是非阻塞的，因为插入数据失败之后会直接报错，想要获得锁就需要再次操作。如果需要阻塞式的，可以弄个for循环、while循环之类的，直至INSERT成功再返回。<br>4这种锁也是非可重入的，因为同一个线程在没有释放锁之前无法再次获得锁，因为数据库中已经存在同一份记录了。想要实现可重入锁，可以在数据库中添加一些字段，<br>比如获得锁的主机信息、线程信息等，那么在再次获得锁的时候可以先查询数据，如果当前的主机信息和线程信息等能被查到的话，可以直接把锁分配给它。</p>\n<h2 id=\"乐观锁-版本号\"><a href=\"#乐观锁-版本号\" class=\"headerlink\" title=\"乐观锁 版本号\"></a>乐观锁 版本号</h2><p>定义一个字段,版本号，然后设置唯一标示，然后更新的时候 把版本号也加一<br>STEP1 - 获取资源： SELECT resource, version FROM optimistic_lock WHERE id = 1<br>STEP2 - 执行业务逻辑<br>STEP3 - 更新资源：UPDATE optimistic_lock SET resource = resource -1, version = version + 1 WHERE id = 1 AND version = oldVersion</p>\n<h2 id=\"悲观锁\"><a href=\"#悲观锁\" class=\"headerlink\" title=\"悲观锁\"></a>悲观锁</h2><p>在查询语句后面增加FOR UPDATE，数据库会在查询过程中给数据库表增加悲观锁，也称排他锁。<br>当某条记录被加上悲观锁之后，其它线程也就无法再改行上增加悲观锁。</p>\n<h2 id=\"基于Zookeeper的分布式锁\"><a href=\"#基于Zookeeper的分布式锁\" class=\"headerlink\" title=\"基于Zookeeper的分布式锁\"></a>基于Zookeeper的分布式锁</h2><p>1客户端连接zookeeper，并在/lock下创建临时的且有序的子节点，第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。<br>2客户端获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁，否则监听/lock的子节点变更消息，获得子节点变更通知后重复此步骤直至获得锁；<br>3执行业务代码；<br>4完成业务流程后，删除对应的子节点释放锁。</p>\n<p>虽然zookeeper原生客户端暴露的API已经非常简洁了，但是实现一个分布式锁还是比较麻烦的…我们可以直接使用curator这个开源项目提供的zookeeper分布式锁实现。</p>\n<h2 id=\"redis-和zk的区别\"><a href=\"#redis-和zk的区别\" class=\"headerlink\" title=\"redis 和zk的区别\"></a>redis 和zk的区别</h2><p>1，redis 是先响应请求，然后同步到其他节点里面，是AP 架构 avaliable，而zk的话是先保证各个节点一致性，然后再响应请求，所以redis集群估计还有问题，而zk 没有<br>2，zk有ZAB协议可以保证强一致性和集群不崩溃<br>3，redis 性能比zk 高，而zk 比redis更可用，主从架构保证key 不丢失</p>\n<h2 id=\"锁续命-加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\"><a href=\"#锁续命-加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\" class=\"headerlink\" title=\"锁续命   加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\"></a>锁续命   加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束</h2><h2 id=\"redis-son-用于分布式\"><a href=\"#redis-son-用于分布式\" class=\"headerlink\" title=\"redis son 用于分布式\"></a>redis son 用于分布式</h2><p>lua 脚本，在java代码里面就会保证原子性</p>\n","site":{"data":{}},"excerpt":"<p>摘要:锁机制</p>","more":"<h1 id=\"java的锁\"><a href=\"#java的锁\" class=\"headerlink\" title=\"java的锁\"></a>java的锁</h1><p>java的锁适合单机部署，部署一个服务的时候，很实用，其实就是把这个服务变成单进程，例如之前做的抽奖的，由于有不同人的抽奖<br>在抽奖成功之后需要商品总数量减一，商品表一张表，里面还用到了虚拟券的表，要是商品是虚拟券，还要去把虚拟券的商品减一，<br>这个时候多人同时操作的话，更新了商品表的时候，虚拟商品会减一，但是由于是同时操作，这个时候会更新了商品表，然后同时把同一个虚拟商品数量减一<br>，就是秒杀的避免问题</p>\n<h2 id=\"lock\"><a href=\"#lock\" class=\"headerlink\" title=\"lock\"></a>lock</h2><p>ReadWriteLock是读写锁接口，自己设置锁lock 之后还得自己去释放这个锁，</p>\n<h2 id=\"synchronized\"><a href=\"#synchronized\" class=\"headerlink\" title=\"synchronized\"></a>synchronized</h2><p>synchronized是Java的关键字,直接把这个对象都给锁住，这个时候就是单线程操作，单个入口</p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p>sync 就是锁对象的对象头——》java对象的布局—–》java对象由什么组成<br>—-》堆里面—》堆里面分配多少内存—-》<br>堆里面的对象数据组成<br>1，对象头—-固定<br>2，java对象的实例属性—-非固定   如果没有实例属性 那就只有填充数据<br>3，数据对齐—-填充数据  如果不够凑齐8的倍数 就填充</p>\n<h3 id=\"为什么需要填充数据\"><a href=\"#为什么需要填充数据\" class=\"headerlink\" title=\"为什么需要填充数据\"></a>为什么需要填充数据</h3><p>因为他们做了大量实验，觉得8的倍数寻址最优，所以要填充8的倍数</p>\n<p>64位jvm虚拟机 一个对象就有16byte  对象头有12个对象头</p>\n<h3 id=\"对象头-96bit-16byte-–包含hashcode-还有同步状态-、GC-状态就是survicor的年龄-15次复制算法之后到old-区、还有类型-元空间模板类型-指针地址\"><a href=\"#对象头-96bit-16byte-–包含hashcode-还有同步状态-、GC-状态就是survicor的年龄-15次复制算法之后到old-区、还有类型-元空间模板类型-指针地址\" class=\"headerlink\" title=\"对象头 96bit 16byte –包含hashcode  还有同步状态 、GC 状态就是survicor的年龄 15次复制算法之后到old 区、还有类型 元空间模板类型 指针地址\"></a>对象头 96bit 16byte –包含hashcode  还有同步状态 、GC 状态就是survicor的年龄 15次复制算法之后到old 区、还有类型 元空间模板类型 指针地址</h3><p>markword——-32bit  4byte   64位64bit<br>不固定 hashcode  age biased_lock lock<br>无锁    unused 25 identity_hashcode 31 unused 1 age 4 biased_lock 1 lock 2<br>偏向锁  thred 54 epoch 2 unused 1 age 4 biased_lock 1 lock 2<br>轻量级锁  ptr_to_lock_record 62 lock 2<br>重量级锁  ptr_to_heavyweigh_monitor 62 lock 2<br>gc标记没有了 </p>\n<p>Klass pointer—- 类的元数据 指针地址 后面32bit 64bit 开启指针压缩的时候</p>\n<h2 id=\"锁升级-是对应的几个状态\"><a href=\"#锁升级-是对应的几个状态\" class=\"headerlink\" title=\"锁升级  是对应的几个状态\"></a>锁升级  是对应的几个状态</h2><p>无锁(01)-》偏向锁(01)-》轻量级锁(00)-》重量级锁(10)-》gc标记没有了(11)<br>倒数第三位 为1为偏向锁  为0 则为无锁</p>\n<h2 id=\"偏向锁\"><a href=\"#偏向锁\" class=\"headerlink\" title=\"偏向锁\"></a>偏向锁</h2><p>默认认知为没有其他线程来竞争锁，然后就变成偏向锁，启用了偏向锁会走偏向锁，偏向锁的头部会写入线程ID，这个线程ID 不会变更，当有一个新线程来了之后会CAS<br>如果一样的话就用当前线程去执行，如果不一样的话就升级轻量级锁</p>\n<h2 id=\"轻量级锁\"><a href=\"#轻量级锁\" class=\"headerlink\" title=\"轻量级锁\"></a>轻量级锁</h2><p>有两个线程在竞争，这个时候一个线程已经拿到轻量级锁，另外一个就会自旋，自旋一段时间之后还是没拿到锁，这个时候就会变成重量级锁</p>\n<h2 id=\"重量级锁\"><a href=\"#重量级锁\" class=\"headerlink\" title=\"重量级锁\"></a>重量级锁</h2><p>重量级锁就是线程的状态转换 用户态到内核态（线程上下级切换），通过线程间的互斥锁实现的，由于状态之间的转换需要时间，所以这就是为什么synchronized慢的原因</p>\n<p>用户态到内核态为什么耗资源<br>阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长</p>\n<h2 id=\"synchronized和lock的区别\"><a href=\"#synchronized和lock的区别\" class=\"headerlink\" title=\"synchronized和lock的区别\"></a>synchronized和lock的区别</h2><p>Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；<br>synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，<br>如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；<br>Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；<br>通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。<br>Lock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）<br>性能上来说，在资源竞争不激烈的情形下，Lock性能稍微比synchronized差点（编译程序通常会尽可能的进行优化synchronized）<br>。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。</p>\n<h2 id=\"Reentrantlock\"><a href=\"#Reentrantlock\" class=\"headerlink\" title=\"Reentrantlock\"></a>Reentrantlock</h2><p>CAS+AQS队列</p>\n<h3 id=\"CAS\"><a href=\"#CAS\" class=\"headerlink\" title=\"CAS\"></a>CAS</h3><p>原子操作，CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。<br>CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。<br>更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。<br><a href=\"https://www.jianshu.com/p/ae25eb3cfb5d\">CAS机制</a><br>先获取到内存中的旧的值A，然后要替换的值B，内存地址V，然后去替换的时候，先对比V 的值跟A 是不是不一样，不一样则替换，如果一样<br>就自旋，就是重新获取内存中的值A和要替换的值B<br>底层是C++的 一个汇编指令完成的  硬件指令lock 缓存行锁 总线锁</p>\n<h3 id=\"ABA-问题-线程1-把A改成B-但是线程2把A-改成了C-然后又改回了A-这个时候-线程1还是可以cas成功的-这就是ABA问题-解决办法就是加版本号-版本号加一\"><a href=\"#ABA-问题-线程1-把A改成B-但是线程2把A-改成了C-然后又改回了A-这个时候-线程1还是可以cas成功的-这就是ABA问题-解决办法就是加版本号-版本号加一\" class=\"headerlink\" title=\"ABA 问题  线程1 把A改成B  但是线程2把A 改成了C 然后又改回了A   这个时候 线程1还是可以cas成功的  这就是ABA问题  解决办法就是加版本号 版本号加一\"></a>ABA 问题  线程1 把A改成B  但是线程2把A 改成了C 然后又改回了A   这个时候 线程1还是可以cas成功的  这就是ABA问题  解决办法就是加版本号 版本号加一</h3><h3 id=\"AQS\"><a href=\"#AQS\" class=\"headerlink\" title=\"AQS\"></a>AQS</h3><p>一个缓冲队列，AQS是一个用于构建锁和同步容器的框架。是一个缓存队列简单框架，同时提供了原子式管理同步，阻塞，唤醒线程等功能</p>\n<h3 id=\"ReentrantLock的流程\"><a href=\"#ReentrantLock的流程\" class=\"headerlink\" title=\"ReentrantLock的流程\"></a>ReentrantLock的流程</h3><p>1 ReentrantLock先通过CAS尝试获取锁，通过CAS设置变量State（同步状态）（volatile 类型）成功，也就是获取锁成功，则将当前线程设置为独占线程。<br>2 如果此时锁已经被占用，该线程加入AQS队列并wait()<br>3 当前驱线程的锁被释放，挂在CLH队列为首的线程就会被notify()，然后继续CAS尝试获取锁，此时：<br>1）非公平锁，如果有其他线程尝试lock()，有可能被其他刚好申请锁的线程抢占。<br>2）公平锁，只有在CLH队列头的线程才可以获取锁，新来的线程只能插入到队尾。<br>这个可以举个栗子就是打饭的时候排队，一群人处于等待唤醒状态，如果这个时候又新来一个人，如果他在最后面排队 那他就是公平的，如果他看到刚好最前面的人打饭完了<br>然后他就直接插队去打饭了，这个就是非公平的</p>\n<p>其实就是有一个标志位，然后通过CAS去抢占锁，如果抢占成功就变成1，没成功就加锁失败</p>\n<h2 id=\"ReentrantLock和synchronized都是重入锁-都是悲观锁\"><a href=\"#ReentrantLock和synchronized都是重入锁-都是悲观锁\" class=\"headerlink\" title=\"ReentrantLock和synchronized都是重入锁  都是悲观锁\"></a>ReentrantLock和synchronized都是重入锁  都是悲观锁</h2><p>可重入锁就是可以重复获取锁，不可重入锁是说一个线程执行完成之前就不能再加锁了</p>\n<p>#基于数据库的锁机制<br>同样的问题，秒杀实现，但是这个时候是分机器部署的，为了负载均衡，这个时候再用java的锁，明显是不行了，这个时候需要用到数据库的锁机制</p>\n<h2 id=\"在数据表里面加版本号\"><a href=\"#在数据表里面加版本号\" class=\"headerlink\" title=\"在数据表里面加版本号\"></a>在数据表里面加版本号</h2><p>加版本号这个就是在表行里面加多一个版本号，只要操作这条数据，就把版本号设置为1，这个时候别的操作只能等待，不能操作<br>另外一个是需要锁住某个方法时，往该表中插入一条相关的记录，然后执行完成这个方法之后就删除这个记录，这个中间时候<br>别人不能来操作这个方法</p>\n<h2 id=\"用sql自己的锁机制-for-update-数据库的排他锁\"><a href=\"#用sql自己的锁机制-for-update-数据库的排他锁\" class=\"headerlink\" title=\"用sql自己的锁机制  for update 数据库的排他锁\"></a>用sql自己的锁机制  for update 数据库的排他锁</h2><p>这个机制在查询的时候 select * from XXX for update,</p>\n<h1 id=\"基于redis-的分布式锁实现\"><a href=\"#基于redis-的分布式锁实现\" class=\"headerlink\" title=\"基于redis 的分布式锁实现\"></a>基于redis 的分布式锁实现</h1><h2 id=\"setnx\"><a href=\"#setnx\" class=\"headerlink\" title=\"setnx\"></a>setnx</h2><h1 id=\"多并发线程可见性-volatile\"><a href=\"#多并发线程可见性-volatile\" class=\"headerlink\" title=\"多并发线程可见性 volatile\"></a>多并发线程可见性 volatile</h1><h2 id=\"底层原理：缓存一致性协议\"><a href=\"#底层原理：缓存一致性协议\" class=\"headerlink\" title=\"底层原理：缓存一致性协议\"></a>底层原理：缓存一致性协议</h2><p>最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。<br>它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，<br>会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，<br>发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。</p>\n<h1 id=\"自旋锁\"><a href=\"#自旋锁\" class=\"headerlink\" title=\"自旋锁\"></a>自旋锁</h1><h1 id=\"分布式锁\"><a href=\"#分布式锁\" class=\"headerlink\" title=\"分布式锁\"></a>分布式锁</h1><h2 id=\"基于redis的分布式锁\"><a href=\"#基于redis的分布式锁\" class=\"headerlink\" title=\"基于redis的分布式锁\"></a>基于redis的分布式锁</h2><p>直接给个标志位，存储这个key到redis，然后下一个请求过来之后要看这个key对应的value是否为空，为空则插入值获取锁，然后如果值不为空，那就返回友好提示<br>最好redis删除key的时候在finally里面执行，redistamplate会有一个setnx及expire的合并方法</p>\n<h2 id=\"基于sql的分布式锁\"><a href=\"#基于sql的分布式锁\" class=\"headerlink\" title=\"基于sql的分布式锁\"></a>基于sql的分布式锁</h2><p>直接新建一张表，纪录锁表信息，每次去查的时候先看有没有对应信息，如果没有则插入，有的话就删除，字段要做唯一性约束，另外的请求来的话就插不进去，<br>需要注意：<br>1这种锁没有失效时间，一旦释放锁的操作失败就会导致锁记录一直在数据库中，其它线程无法获得锁。这个缺陷也很好解决，比如可以做一个定时任务去定时清理。<br>2这种锁的可靠性依赖于数据库。建议设置备库，避免单点，进一步提高可靠性。<br>3这种锁是非阻塞的，因为插入数据失败之后会直接报错，想要获得锁就需要再次操作。如果需要阻塞式的，可以弄个for循环、while循环之类的，直至INSERT成功再返回。<br>4这种锁也是非可重入的，因为同一个线程在没有释放锁之前无法再次获得锁，因为数据库中已经存在同一份记录了。想要实现可重入锁，可以在数据库中添加一些字段，<br>比如获得锁的主机信息、线程信息等，那么在再次获得锁的时候可以先查询数据，如果当前的主机信息和线程信息等能被查到的话，可以直接把锁分配给它。</p>\n<h2 id=\"乐观锁-版本号\"><a href=\"#乐观锁-版本号\" class=\"headerlink\" title=\"乐观锁 版本号\"></a>乐观锁 版本号</h2><p>定义一个字段,版本号，然后设置唯一标示，然后更新的时候 把版本号也加一<br>STEP1 - 获取资源： SELECT resource, version FROM optimistic_lock WHERE id = 1<br>STEP2 - 执行业务逻辑<br>STEP3 - 更新资源：UPDATE optimistic_lock SET resource = resource -1, version = version + 1 WHERE id = 1 AND version = oldVersion</p>\n<h2 id=\"悲观锁\"><a href=\"#悲观锁\" class=\"headerlink\" title=\"悲观锁\"></a>悲观锁</h2><p>在查询语句后面增加FOR UPDATE，数据库会在查询过程中给数据库表增加悲观锁，也称排他锁。<br>当某条记录被加上悲观锁之后，其它线程也就无法再改行上增加悲观锁。</p>\n<h2 id=\"基于Zookeeper的分布式锁\"><a href=\"#基于Zookeeper的分布式锁\" class=\"headerlink\" title=\"基于Zookeeper的分布式锁\"></a>基于Zookeeper的分布式锁</h2><p>1客户端连接zookeeper，并在/lock下创建临时的且有序的子节点，第一个客户端对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。<br>2客户端获取/lock下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁，否则监听/lock的子节点变更消息，获得子节点变更通知后重复此步骤直至获得锁；<br>3执行业务代码；<br>4完成业务流程后，删除对应的子节点释放锁。</p>\n<p>虽然zookeeper原生客户端暴露的API已经非常简洁了，但是实现一个分布式锁还是比较麻烦的…我们可以直接使用curator这个开源项目提供的zookeeper分布式锁实现。</p>\n<h2 id=\"redis-和zk的区别\"><a href=\"#redis-和zk的区别\" class=\"headerlink\" title=\"redis 和zk的区别\"></a>redis 和zk的区别</h2><p>1，redis 是先响应请求，然后同步到其他节点里面，是AP 架构 avaliable，而zk的话是先保证各个节点一致性，然后再响应请求，所以redis集群估计还有问题，而zk 没有<br>2，zk有ZAB协议可以保证强一致性和集群不崩溃<br>3，redis 性能比zk 高，而zk 比redis更可用，主从架构保证key 不丢失</p>\n<h2 id=\"锁续命-加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\"><a href=\"#锁续命-加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\" class=\"headerlink\" title=\"锁续命   加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束\"></a>锁续命   加多一个线程定时判断当前线程有没有释放锁，如果没有释放，那就把时间再延长，如果已经释放，那线程就结束</h2><h2 id=\"redis-son-用于分布式\"><a href=\"#redis-son-用于分布式\" class=\"headerlink\" title=\"redis son 用于分布式\"></a>redis son 用于分布式</h2><p>lua 脚本，在java代码里面就会保证原子性</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cmawa4jrg000askqrg734gvem","category_id":"cmawa4jrj000eskqrepc09exr","_id":"cmawa4jrr000qskqrd7a34vq2"},{"post_id":"cmawa4jrn000kskqr7xr3fxv0","category_id":"cmawa4jrq000oskqr84oi8e19","_id":"cmawa4jrt000xskqr10q2c8yc"}],"PostTag":[{"post_id":"cmawa4jra0004skqr533590lx","tag_id":"cmawa4jr70002skqrbzqt9pb9","_id":"cmawa4jre0007skqrb1xx7okd"},{"post_id":"cmawa4jqx0000skqrgxq7gp4h","tag_id":"cmawa4jr70002skqrbzqt9pb9","_id":"cmawa4jrf0009skqrcc66cprz"},{"post_id":"cmawa4jr50001skqrgo3324ih","tag_id":"cmawa4jr70002skqrbzqt9pb9","_id":"cmawa4jrh000cskqr3eikcl8p"},{"post_id":"cmawa4jrg000askqrg734gvem","tag_id":"cmawa4jr70002skqrbzqt9pb9","_id":"cmawa4jrj000fskqra4n7b5c4"},{"post_id":"cmawa4jr90003skqrgv0z3rbf","tag_id":"cmawa4jrg000bskqr6rlp2ulk","_id":"cmawa4jrn000jskqrdcvf5f8p"},{"post_id":"cmawa4jrb0005skqr758k0nmj","tag_id":"cmawa4jrl000hskqresf60759","_id":"cmawa4jrq000nskqre8lmghlq"},{"post_id":"cmawa4jrn000kskqr7xr3fxv0","tag_id":"cmawa4jr70002skqrbzqt9pb9","_id":"cmawa4jrr000rskqr6o2i4gg9"},{"post_id":"cmawa4jrp000mskqr6m7l0wt3","tag_id":"cmawa4jro000lskqr3sf5cnoc","_id":"cmawa4jrs000tskqr6r3y0d43"},{"post_id":"cmawa4jre0008skqr6nm6b0jr","tag_id":"cmawa4jro000lskqr3sf5cnoc","_id":"cmawa4jrs000uskqr7ip00i33"},{"post_id":"cmawa4jrq000pskqr0llwavm9","tag_id":"cmawa4jro000lskqr3sf5cnoc","_id":"cmawa4jrt000wskqraxwa80x5"},{"post_id":"cmawa4jri000dskqrcwpf6w7s","tag_id":"cmawa4jro000lskqr3sf5cnoc","_id":"cmawa4jrt000yskqr0yiea06z"},{"post_id":"cmawa4jrj000gskqr4bwu4rd9","tag_id":"cmawa4jro000lskqr3sf5cnoc","_id":"cmawa4jru0010skqrc2c3b6tz"},{"post_id":"cmawa4jrm000iskqr74u3eux0","tag_id":"cmawa4jro000lskqr3sf5cnoc","_id":"cmawa4jru0011skqrehhxes4c"},{"post_id":"cmawa4jse0012skqrbb98abza","tag_id":"cmawa4jsg0014skqrej920xu0","_id":"cmawa4jsj0019skqr7yvq49sp"},{"post_id":"cmawa4jsf0013skqrhf4k4t2v","tag_id":"cmawa4jsg0014skqrej920xu0","_id":"cmawa4jso001dskqr0d0iaeil"},{"post_id":"cmawa4jsh0015skqrb9h591fe","tag_id":"cmawa4jsl001cskqrco5lckun","_id":"cmawa4jsr001iskqr9nmy9iz1"},{"post_id":"cmawa4jsq001hskqre57rabdt","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jss001lskqr0j863frb"},{"post_id":"cmawa4jsr001jskqr67iafzhm","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jst001nskqrfl84ero9"},{"post_id":"cmawa4jsi0016skqra6gdbrtp","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jsw001rskqr58pv79z5"},{"post_id":"cmawa4jsi0016skqra6gdbrtp","tag_id":"cmawa4jss001kskqrdo9edcm1","_id":"cmawa4jsx001tskqrdjbt18yk"},{"post_id":"cmawa4jsu001qskqrb5dvam21","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jsy001wskqr01e93y22"},{"post_id":"cmawa4jsi0017skqr8y98gda1","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jsz001yskqra56486i6"},{"post_id":"cmawa4jt00020skqr82vicyqc","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt00021skqrb879aodh"},{"post_id":"cmawa4jsk001askqr8prybngo","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt10023skqr7ko9h60e"},{"post_id":"cmawa4jsk001askqr8prybngo","tag_id":"cmawa4jsz001zskqr3yjt2vox","_id":"cmawa4jt10024skqr4fi25eye"},{"post_id":"cmawa4jsk001bskqrecwi8yua","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt20027skqr733zbuxl"},{"post_id":"cmawa4jsk001bskqrecwi8yua","tag_id":"cmawa4jt10025skqrbc264ab8","_id":"cmawa4jt30028skqrhdf81kts"},{"post_id":"cmawa4jso001eskqr7mmo7qq6","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt3002askqr4up6h41z"},{"post_id":"cmawa4jsp001fskqre85h6qop","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt6002cskqrfisv9wc6"},{"post_id":"cmawa4jss001mskqr6mstb62m","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt7002eskqrdknrhhey"},{"post_id":"cmawa4jss001mskqr6mstb62m","tag_id":"cmawa4jt4002bskqr9nesgy41","_id":"cmawa4jt7002fskqrgxu35snd"},{"post_id":"cmawa4jst001oskqr8mq6emro","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt8002iskqrhjujauq3"},{"post_id":"cmawa4jst001oskqr8mq6emro","tag_id":"cmawa4jt4002bskqr9nesgy41","_id":"cmawa4jt8002jskqrdut30jq4"},{"post_id":"cmawa4jst001oskqr8mq6emro","tag_id":"cmawa4jt7002gskqrgx3aepmh","_id":"cmawa4jt8002lskqr9fbbf5rz"},{"post_id":"cmawa4jsw001sskqr8p1b95uc","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt8002mskqrc4tva5hi"},{"post_id":"cmawa4jsw001sskqr8p1b95uc","tag_id":"cmawa4jt7002hskqr7mcl1qsc","_id":"cmawa4jt9002oskqr4450fzwd"},{"post_id":"cmawa4jsx001vskqr54zs290m","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jt9002pskqrh4268s6x"},{"post_id":"cmawa4jsx001vskqr54zs290m","tag_id":"cmawa4jt4002bskqr9nesgy41","_id":"cmawa4jt9002qskqr0x228ng6"},{"post_id":"cmawa4jsy001xskqr9ztv51tk","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jta002rskqr78tafvtf"},{"post_id":"cmawa4jsy001xskqr9ztv51tk","tag_id":"cmawa4jt9002nskqr6rotakiw","_id":"cmawa4jta002sskqr0nvw30lo"},{"post_id":"cmawa4jth002tskqrftbuf4ad","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4jtk002vskqrgvvoe5z6"},{"post_id":"cmawa4jtj002uskqr86fggrc5","tag_id":"cmawa4jsq001gskqr3nct9l56","_id":"cmawa4ju0002xskqr6k0v45qw"},{"post_id":"cmawa4jtj002uskqr86fggrc5","tag_id":"cmawa4jtk002wskqr2wdt3ix9","_id":"cmawa4ju3002yskqrghxtev3n"}],"Tag":[{"name":"其他","_id":"cmawa4jr70002skqrbzqt9pb9"},{"name":"nginx","_id":"cmawa4jrg000bskqr6rlp2ulk"},{"name":"Android","_id":"cmawa4jrl000hskqresf60759"},{"name":"安卓","_id":"cmawa4jro000lskqr3sf5cnoc"},{"name":"H5","_id":"cmawa4jsg0014skqrej920xu0"},{"name":"java","_id":"cmawa4jsl001cskqrco5lckun"},{"name":"JAVA","_id":"cmawa4jsq001gskqr3nct9l56"},{"name":"MQ","_id":"cmawa4jss001kskqrdo9edcm1"},{"name":"arthas","_id":"cmawa4jsz001zskqr3yjt2vox"},{"name":"hashmap","_id":"cmawa4jt10025skqrbc264ab8"},{"name":"mysql","_id":"cmawa4jt4002bskqr9nesgy41"},{"name":"mybatis","_id":"cmawa4jt7002gskqrgx3aepmh"},{"name":"servlet","_id":"cmawa4jt7002hskqr7mcl1qsc"},{"name":"redis","_id":"cmawa4jt9002nskqr6rotakiw"},{"name":"锁","_id":"cmawa4jtk002wskqr2wdt3ix9"}]}}